<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="Jacques Du Pasquier (jacques@dtext.com)">
<meta name="Subject" content="Re: Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Sun Jan 13 06:14:36 2002" -->
<!-- isoreceived="20020113131436" -->
<!-- sent="Sun, 13 Jan 2002 14:17:24 +0100" -->
<!-- isosent="20020113131724" -->
<!-- name="Jacques Du Pasquier" -->
<!-- email="jacques@dtext.com" -->
<!-- subject="Re: Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="15425.35044.394175.946901@localhost.localdomain" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="000601c19afa$4b7e1460$0100a8c0@Pc2" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jacques Du Pasquier (<a href="mailto:jacques@dtext.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>jacques@dtext.com</em></a>)<br>
<strong>Date:</strong> Sun Jan 13 2002 - 06:17:24 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0886.html">Eugene Leitl: "RE: Hidden M-Brains"</a>
<li><strong>Previous message:</strong> <a href="0884.html">Reason: "RE: Hidden M-Brains"</a>
<li><strong>In reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0902.html">J. R. Molloy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#885">[ date ]</a>
<a href="index.html#885">[ thread ]</a>
<a href="subject.html#885">[ subject ]</a>
<a href="author.html#885">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
You can read his &quot;One Half Of A Manifesto&quot; at
<br>
<a href="http://www.edge.org/documents/archive/edge74.html">http://www.edge.org/documents/archive/edge74.html</a>
<br>
<p>Then you can read Dennett's short answer at (you need to scroll a bit)
<br>
<a href="http://www.edge.org/documents/archive/edge76.html">http://www.edge.org/documents/archive/edge76.html</a>
<br>
<p>Quote from the latter : &quot;Grow up and do some real criticism, worth
<br>
responding to.&quot;
<br>
<p>(By the way, in that same answer, Dennett states that expecting to get
<br>
soon physical immortality through cell repair is a foolish
<br>
technocratic fantasy that bizarrely underestimate the complexities
<br>
of life.)
<br>
<p><p>Colin Hales wrote (12.1.2002/10:47) :
<br>
<em>&gt; This is a dec 29 Guardian article on Jaron Lanier. Boy I wish we had more
</em><br>
<em>&gt; 'eccentics' like this around. We need 'em. He's well worth following. One of
</em><br>
<em>&gt; the great 'sleeping bear pokers'.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The Guardian Profile -Jaron Lanier - The virtual visionary
</em><br>
<em>&gt; <a href="http://www.guardian.co.uk/Archive/Article/0,4273,4326550,00.html">http://www.guardian.co.uk/Archive/Article/0,4273,4326550,00.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; However, I'm a bit mystified by his attitude on AI.  Maybe my logic is down
</em><br>
<em>&gt; the toilet. I can't tell, maybe you can.
</em><br>
<em>&gt; My thoughts, written after I read the article, I dump here.
</em><br>
<em>&gt; ===============
</em><br>
<em>&gt; Jaron Lanier is a regular at www.edge.org &lt;<a href="http://www.edge.org">http://www.edge.org</a>&gt;. He's always
</em><br>
<em>&gt; very challenging and seems to make sense. However, I don't understand his
</em><br>
<em>&gt; ideas about the limits of technology. We, humans, are technology. Just
</em><br>
<em>&gt; because we're constructed with DNA or any method you'd care to consider in
</em><br>
<em>&gt; no way invalidates another method for creation of intelligence. If it were
</em><br>
<em>&gt; possible to invalidate other methods we'd already know how to make it,
</em><br>
<em>&gt; making the whole ‘problem' moot!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I am having trouble understanding how he could come to this position by
</em><br>
<em>&gt; means of logic, unless he sees far deeper into everything than me. I am
</em><br>
<em>&gt; willing to accept this, but I'd like to see some meat on the argument. All
</em><br>
<em>&gt; through the history of technological development reality, in my view, has
</em><br>
<em>&gt; outstripped the imaginations of the pundits. The trend is obvious. The
</em><br>
<em>&gt; possibilities are endless. Why would this kind of grey luddite view be view
</em><br>
<em>&gt; be put?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Putting AI as an engineering goal is precisely what I'm doing. Thus
</em><br>
<em>&gt; according to his text I am “in a very strange position”, as a result. I
</em><br>
<em>&gt; suppose, if one has a very sincere belief in the insurmountable intellect of
</em><br>
<em>&gt; the human, then the prospect of creating our betters would be, to some
</em><br>
<em>&gt; extent, belittling. The scientific method has, for most of a millennium,
</em><br>
<em>&gt; decentralized humans from the center of the universe. Go back to Kepler and
</em><br>
<em>&gt; have a look. AI is the last step in the process. What exactly will make this
</em><br>
<em>&gt; next step not happen?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I believe that one valid perspective on humanity is that we are part of the
</em><br>
<em>&gt; universe's self awareness. This is a great honour and an amazing thing, to
</em><br>
<em>&gt; be sure, but just a part. Possibly only part of a beginning. If I were
</em><br>
<em>&gt; convinced of myself as occupying a preeminent central end-point, I could
</em><br>
<em>&gt; thus feel somewhat miffed upon displacement. Getting beaten by your kids at
</em><br>
<em>&gt; &lt;insert game of choice&gt; is something like the way I will feel when it
</em><br>
<em>&gt; happens. A mixture of fear, pride and accomplishment.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We will be known as ‘the old ones' by our progeny, who will take on forms we
</em><br>
<em>&gt; can only guess at, and leave for the stars. Seeing the technology as an aid
</em><br>
<em>&gt; to human communication only is a simple extension of what has been happening
</em><br>
<em>&gt; anyway - because we've been -so far -unable to allow AI to happen. Yes, I
</em><br>
<em>&gt; believe human capability will be enhanced - it's why we are doing AI in a
</em><br>
<em>&gt; multitude of flavours. But when a sentient AI emerges, believing that human
</em><br>
<em>&gt; enhancement is all that is going to happen would require the AI to be
</em><br>
<em>&gt; shackled and zombied, to keep us as ‘top dog'. History, I think, has proven
</em><br>
<em>&gt; that sort of imposed power struggle not to work in the long run.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We need a devil's advocate - look what it's done - I'm trawling prose from
</em><br>
<em>&gt; my neurons. Not a bad thing, really. Jaron has made a good thing out of
</em><br>
<em>&gt; taking awkward and novel positions. In this case, I think it's a touch
</em><br>
<em>&gt; specious - No Sale.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We're going to get out nifty human enhancers and tools and as well, it's OK
</em><br>
<em>&gt; with me just to help construct a God, and not to be one. He thinks it's
</em><br>
<em>&gt; religion to believe AI is possible, I think it's religion to hope that it
</em><br>
<em>&gt; can't.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Colin
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0886.html">Eugene Leitl: "RE: Hidden M-Brains"</a>
<li><strong>Previous message:</strong> <a href="0884.html">Reason: "RE: Hidden M-Brains"</a>
<li><strong>In reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0902.html">J. R. Molloy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#885">[ date ]</a>
<a href="index.html#885">[ thread ]</a>
<a href="subject.html#885">[ subject ]</a>
<a href="author.html#885">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:34 MST
</em></small></p>
</body>
</html>
