<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: sentient rights (was RE: Battleground God)</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: sentient rights (was RE: Battleground God)">
<meta name="Date" content="2002-02-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: sentient rights (was RE: Battleground God)</h1>
<!-- received="Fri Feb 22 01:27:59 2002" -->
<!-- isoreceived="20020222082759" -->
<!-- sent="Fri, 22 Feb 2002 00:30:47 -0800" -->
<!-- isosent="20020222083047" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: sentient rights (was RE: Battleground God)" -->
<!-- id="3C7601B7.2020104@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="200202220034.g1M0Yqv11658@finney.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20sentient%20rights%20(was%20RE:%20Battleground%20God)"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Fri Feb 22 2002 - 01:30:47 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3318.html">the animated silicon love doll: "Re: EXTROPY: The Journal of Transhumanist Solutions --	re-launchedtoday"</a>
<li><strong>Previous message:</strong> <a href="3316.html">Lee Daniel Crocker: "Re: lane crossover"</a>
<li><strong>In reply to:</strong> <a href="3285.html">hal@finney.org: "Re: sentient rights (was RE: Battleground God)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3328.html">Anders Sandberg: "Re: sentient rights (was RE: Battleground God)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3317">[ date ]</a>
<a href="index.html#3317">[ thread ]</a>
<a href="subject.html#3317">[ subject ]</a>
<a href="author.html#3317">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<a href="mailto:hal@finney.org?Subject=Re:%20sentient%20rights%20(was%20RE:%20Battleground%20God)">hal@finney.org</a> wrote:
<br>
<p><em>&gt; Anders writes:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;The principles do not seem to be enough to constrain an ethical system;
</em><br>
<em>&gt;&gt;they do not form a set of ethical axioms or constrain the basis for
</em><br>
<em>&gt;&gt;extropian ethics. They certainly have ethical content, but this content
</em><br>
<em>&gt;&gt;deals more with desirability of different things than the core
</em><br>
<em>&gt;&gt;&quot;mechanics&quot; of an ethical system. 
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But doesn't Extropianism give us a handle by which to judge the
</em><br>
<em>&gt; desirability of different world outcomes?  And doesn't this, in itself,
</em><br>
<em>&gt; constitute an ethical framework?
</em><br>
<p><p>Actually, without criteria as to what is and is not an increase 
<br>
of &quot;extropy&quot; and a better handle on why this is the greatest 
<br>
good, I don't see how it gives a way to judge the desirability 
<br>
of different outcomes except in a few areas.  To broaden it will 
<br>
imo require a broader (more detailed) version of what we wish 
<br>
the future to look like and why than is present currently in the 
<br>
Extropian community generally.  I think a lot of us are &quot;working 
<br>
on it&quot; in our various ways formally and informally.
<br>
<p>Generally, the ability to judge relative desirability can only 
<br>
exist within a fairly grounded idea of what the good consists of 
<br>
and how it applies to various situations.  It is not a 
<br>
free-standing ability.  The  to arrive at a choice between 
<br>
alternatives is a consequence of an ethical system rather than 
<br>
its foundation.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; It is true that it does tell us how to get there.  Even if we agree that
</em><br>
<em>&gt; extropy is a desirable goal, we may not agree about what are the best
</em><br>
<em>&gt; practical decisions on a day to day basis.
</em><br>
<em>&gt;
</em><br>
<p><p>I assume there is a missing &quot;not&quot; in the first sentence. 
<br>
Extropy is a quality/capacity not a &quot;goal&quot;.  Increasing extropy 
<br>
is a goal but not necessarily the only important goal or the one 
<br>
that fully subsumes all others.  The 7 Extropian principles are 
<br>
qualities and trends mostly and are not sufficient to fully 
<br>
flesh out a system of ethics.
<br>
<p>&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;Personally I would say that this is not a flaw. Extropianism rather
</em><br>
<em>&gt;&gt;inherits the ethical underpinnings of its parent philosophies of
</em><br>
<em>&gt;&gt;libertarianism and humanism (a kind of philosophical object
</em><br>
<em>&gt;&gt;inheritance); it is compatible with most versions of them, and does not
</em><br>
<em>&gt;&gt;as expressed in the principles have to redo all the immense work that
</em><br>
<em>&gt;&gt;has been done on expressing ethics and politics elsewhere. It is a bit
</em><br>
<em>&gt;&gt;like how Robert Nozick simply starts _Anarchy, State, Utopia_ by simply
</em><br>
<em>&gt;&gt;assuming certain rights - the book is not about deriving them, it is
</em><br>
<em>&gt;&gt;what conclusions can be made *after* they have been derived. 
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<p><p>Well, &quot;delegation&quot; might be a clearer analogy than &quot;inheritance&quot; 
<br>
as we delegate most ethical decisions and general biases to 
<br>
something other than what today exists as part of Extropianism. 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;I disagree that immense work has been done on the basis of 
<br>
ethical systems.  A lot of work has been done on the basis of 
<br>
just assuming a particular set of ethical roots somehow existed 
<br>
or made sense or were axiomatic.  As more and more of the root 
<br>
context changes we will find that the ethical root presumptions 
<br>
must be re-examined and re-grounded.
<br>
<p>&nbsp;
<br>
<em>&gt; I am not so comfortable thinking that we can graft conventional
</em><br>
<em>&gt; libertarianism onto Extropianism, or that we can start with libertarian
</em><br>
<em>&gt; ethics as a foundation for our Extropian ethical system.  Haven't Max
</em><br>
<em>&gt; and others attempted to distance themselves from a strict libertarianism
</em><br>
<em>&gt; in order to open the movement to a wider range of political philosophies?
</em><br>
<em>&gt;
</em><br>
<p><p>Me either.  We would be starting something with a shaky 
<br>
foundation (true of all current ethical systems not just this 
<br>
one) that more or less works given current biases and context 
<br>
and expect it to hold when the context shifts rapidly or even to 
<br>
guide us in shifting that context.  It is very unlikely to be up 
<br>
to the job.
<br>
<p>&nbsp;
<br>
<p><em>&gt;&gt;One can try combining different ethical theories with extropianism and
</em><br>
<em>&gt;&gt;see what happens. I would say that utilitarianism and extropianism are
</em><br>
<p><em>&gt;&gt;not a very successful combination; such an extropian utilitarianism
</em><br>
<em>&gt;&gt;would either have to be based on maximizing extropy or have to show that
</em><br>
<em>&gt;&gt;increasing personal extropy and increasing utility are identical. In any
</em><br>
<em>&gt;&gt;case it would tend to run over indiviuals in the pursuit of
</em><br>
<em>&gt;&gt;maximization, and it seems hard to combine with the self organization
</em><br>
<em>&gt;&gt;principle in the old version of the principles. A rights based form of
</em><br>
<em>&gt;&gt;extropianism seems far more consistent, although we still have to find a
</em><br>
<em>&gt;&gt;derivation of rights that convinces. 
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; One of the big question marks in the Principles which we did not explore
</em><br>
<em>&gt; much is whether they should be seen as collective or individual.  When we
</em><br>
<em>&gt; seek to maximize extropy, as defined by the Principles, are we trying
</em><br>
<em>&gt; to do so each of us individually for ourselves, or for society and the
</em><br>
<em>&gt; world as a whole?  Is my goal a world with maximal extropy, or is it a
</em><br>
<em>&gt; world in which I personally have maximized my potentials?  I don't see
</em><br>
<em>&gt; the Principles as giving a clear guideline for answering this question.
</em><br>
<em>&gt;
</em><br>
<p><p>I don't see any way to fully maximize my potential without 
<br>
maximizing the potential of the context (the world and other 
<br>
people) I find myself within. The boundary between this &quot;self&quot; 
<br>
and others appears to me to be more porous than many are 
<br>
culturally programmed to believe.
<br>
<p>&nbsp;
<br>
<em>&gt; This is perhaps the most fundamental ethical question we face.  It is
</em><br>
<em>&gt; the difference between being generous and being selfish; between being
</em><br>
<em>&gt; trustworthy and being a cheat; between being honest and lying for self
</em><br>
<em>&gt; benefit.  If I can benefit myself by harming another, without getting
</em><br>
<em>&gt; caught, should I do so?  It arguably maximizes my own potentials for
</em><br>
<em>&gt; extropy, but also arguably reduces the net extropy for the two of us.
</em><br>
<em>&gt; 
</em><br>
<p><p>Generous and selfish are not fundamental ethical philosophical 
<br>
constructs.  They are quite sloppy and value-laden terms.  The 
<br>
beg the more fundamental questions of what the &quot;good&quot; is and to 
<br>
what degree it is contextual and so on.  Most of the questions 
<br>
in that paragraph are based on free-floating assumptions.
<br>
<p><p><em>&gt; Although Extropianism is often seen as an individualistic philosophy, I
</em><br>
<em>&gt; think most of us would agree that from the ethical perspective, we care
</em><br>
<em>&gt; about more than our own personal benefit.  We want to see a world where
</em><br>
<em>&gt; the potentials promoted by Extropianism are available to as many people
</em><br>
<em>&gt; as possible.  I don't know if many of us would go so far as to say that
</em><br>
<em>&gt; we would sacrifice ourselves if it increased the net extropy of the world,
</em><br>
<em>&gt; but we are far from being dedicated only to our own selfish goals.
</em><br>
<em>&gt; 
</em><br>
<p><p>I don't draw that much of a distinction between what is good for 
<br>
me and what is good for humanity.  I don't believe they need to 
<br>
conflict generally.
<br>
<p><p><em>&gt; Of course in many cases these two extremes do not actually lead to
</em><br>
<em>&gt; different strategies for day to day life.  Often we can do good by
</em><br>
<em>&gt; doing well.  We behave in a trustworthy and honest and unselfish way,
</em><br>
<em>&gt; and in the long run we benefit directly and personally by these actions.
</em><br>
<em>&gt; So to some extent we can get away with ignoring the issue.
</em><br>
<em>&gt; 
</em><br>
<p><p>This is not &quot;ignoring the issue&quot;.  It is nothing that it is 
<br>
quite often a non-issue that human philosophers keep stubbing 
<br>
their ethical toes on.
<br>
<p><p><em>&gt; But then for each of us there will come times when we are tested and
</em><br>
<em>&gt; tempted.  You find someone's wallet with money in it; you are carrying a
</em><br>
<em>&gt; load of trash to the dump and find a secluded spot where you could toss
</em><br>
<em>&gt; it for free; you are offered to join an Internet pyramid scheme which
</em><br>
<em>&gt; will inevitably leave the latecomers with severe losses.  Then you have
</em><br>
<em>&gt; to decide whether your ethical system is just about you, or about the
</em><br>
<em>&gt; world as a whole.
</em><br>
<p><p>Such situations are really not terribly relevant to general 
<br>
ethical systems.  However, each of the proposed dilemna is no 
<br>
dilemna at all when the costs are worked and implications are 
<br>
worked out a few steps further than first inclination.  Of 
<br>
course it is needful to have a few supergoals broader than 
<br>
immediate seeming gratification.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3318.html">the animated silicon love doll: "Re: EXTROPY: The Journal of Transhumanist Solutions --	re-launchedtoday"</a>
<li><strong>Previous message:</strong> <a href="3316.html">Lee Daniel Crocker: "Re: lane crossover"</a>
<li><strong>In reply to:</strong> <a href="3285.html">hal@finney.org: "Re: sentient rights (was RE: Battleground God)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3328.html">Anders Sandberg: "Re: sentient rights (was RE: Battleground God)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3317">[ date ]</a>
<a href="index.html#3317">[ thread ]</a>
<a href="subject.html#3317">[ subject ]</a>
<a href="author.html#3317">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:40 MST
</em></small></p>
</body>
</html>
