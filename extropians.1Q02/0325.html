<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: RE: rambling question on AI</title>
<meta name="Author" content="Reason (reason@exratio.com)">
<meta name="Subject" content="RE: rambling question on AI">
<meta name="Date" content="2002-01-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: rambling question on AI</h1>
<!-- received="Sat Jan  5 01:37:14 2002" -->
<!-- isoreceived="20020105083714" -->
<!-- sent="Sat, 5 Jan 2002 00:35:26 -0800" -->
<!-- isosent="20020105083526" -->
<!-- name="Reason" -->
<!-- email="reason@exratio.com" -->
<!-- subject="RE: rambling question on AI" -->
<!-- id="EPEELOAJBJFJPKFALCGKMEGDCOAA.reason@exratio.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C36943C.F277F1F2@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Reason (<a href="mailto:reason@exratio.com?Subject=RE:%20rambling%20question%20on%20AI"><em>reason@exratio.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 05 2002 - 01:35:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0326.html">Amara Graps: "LANL Abstract: Engineering the Zero-Point Field and Polarizable Vacuum For Interstellar Flight"</a>
<li><strong>Previous message:</strong> <a href="0324.html">Joe Dees: "Re: The Golden-Egg-Laying Goose"</a>
<li><strong>In reply to:</strong> <a href="0316.html">Eliezer S. Yudkowsky: "Re: rambling question on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0336.html">Jacques Du Pasquier: "RE: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0336.html">Jacques Du Pasquier: "RE: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0341.html">Eliezer S. Yudkowsky: "Re: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0353.html">Randall Randall: "Re: rambling question on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#325">[ date ]</a>
<a href="index.html#325">[ thread ]</a>
<a href="subject.html#325">[ subject ]</a>
<a href="author.html#325">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--&gt; Eliezer S. Yudkowsky
<br>
<p><em>&gt; &gt; Why? It takes four months, five developers and a quarter of a million
</em><br>
<em>&gt; &gt; dollars to produce software that retails for half a million, including
</em><br>
<em>&gt; &gt; support. In most cases, this is the compromise version -- the
</em><br>
<em>&gt; full (and much
</em><br>
<em>&gt; &gt; more complex) vision isn't realized until a few years of new
</em><br>
<em>&gt; versions down
</em><br>
<em>&gt; &gt; the line. So the argument would be, if someone can dedicate
</em><br>
<em>&gt; resources to do
</em><br>
<em>&gt; &gt; that for another field, what is it about AI development that
</em><br>
<em>&gt; means you can't
</em><br>
<em>&gt; &gt; produce something that can be sold in the same timeframe?
</em><br>
<em>&gt;
</em><br>
<em>&gt; If AI development were not qualitatively more difficult than a
</em><br>
<em>&gt; *programming* task, the Singularity would have occurred long since (the
</em><br>
<em>&gt; early nineties would be my guess).
</em><br>
<p>I'm not convinced that any project is so intrinsically hard that you can't
<br>
find comparatively rapid substeps to producing something profitable (or at
<br>
least salable) on the way. If you can get non-stick frying pans out of the
<br>
space program, then I'm sure there's something you can get out of AI
<br>
development.
<br>
<p>How long did Cyg take to get to a point of being saleable? You could, for
<br>
the sake of argument, view that as an attempt at a first step (i.e.
<br>
producing the database) in a much longer ongoing project.
<br>
<p><em>&gt; &gt; With a broader view of the term &quot;product,&quot; alternatively, you
</em><br>
<em>&gt; could produce,
</em><br>
<em>&gt; &gt; say:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; a) knowledgable consultants to farm out to other AI ventures
</em><br>
<em>&gt; &gt; b) a single useful component that can be licensed to other AI ventures
</em><br>
<em>&gt; &gt; c) a book on AI development
</em><br>
<em>&gt; &gt; d) the material and contacts for a subscription-based newsletter for
</em><br>
<em>&gt; &gt; development companies
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; And so forth. Not that I'm convince there's a vast market of AI
</em><br>
<em>&gt; ventures out
</em><br>
<em>&gt; &gt; there, but I don't think that there's anything wrong with taking those
</em><br>
<em>&gt; &gt; directions.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If we'd wanted to go that route, we could have done Flare as a for-profit
</em><br>
<em>&gt; venture.  And if we'd wanted to go *that* route, I have a half-dozen good
</em><br>
<em>&gt; ideas for starting a for-profit corporation; they just happen to be
</em><br>
<em>&gt; totally unrelated to AI.
</em><br>
<p>Not that I'm criticizing your path, of course. I'm just trying to see what
<br>
people think about the sidelines, byproducts and other AI collectables that
<br>
could be derived during the creation of an AI itself.
<br>
<p>We should all be trying to get Flare slashdotted, by the way :) Some more
<br>
attention couldn't hurt.
<br>
<p>Funnily enough, I do have an idea for an AI startup, but it's AI in the game
<br>
sense of the term -- something I'm sure would make you upset ;)
<br>
<p><em>&gt; But there is a saying:  &quot;Life is what happens while you are making other
</em><br>
<em>&gt; plans.&quot;  And life has taught me that if you want to avoid this curse
</em><br>
<em>&gt; coming true of you, you had better avoid doing ANYTHING that does not
</em><br>
<em>&gt; DIRECTLY advance your long-term goal (in my case, the Singularity).  If
</em><br>
<em>&gt; I'd known this when I was sixteen, I would have been able to put in an
</em><br>
<em>&gt; additional two years or so of Singularity work by now.
</em><br>
<em>&gt;
</em><br>
<em>&gt; And furthermore, we don't dare run the risk of building a *good*,
</em><br>
<em>&gt; *profitable* product in a for-profit company.  This could easily be worse
</em><br>
<em>&gt; than building a bad product; &quot;life is what happens while you are making
</em><br>
<em>&gt; other plans&quot; would very quickly happen to us, and the &quot;interim product&quot;
</em><br>
<em>&gt; would become the company.  A spinoff of a real, direct-to-Singularity
</em><br>
<em>&gt; development effort is one matter; a genuine spinoff can be handed over to
</em><br>
<em>&gt; new programmers while the core development continues.  Building something
</em><br>
<em>&gt; easy and safe that isn't what you actually want to build, as your core
</em><br>
<em>&gt; development effort, is much more dangerous a distraction.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Furthermore, no matter how good an idea I have for a for-profit
</em><br>
<em>&gt; corporation, it still isn't going to have better than a fifty percent
</em><br>
<em>&gt; chance of success, because the ordinary failure rate for startups is
</em><br>
<em>&gt; ninety-five percent.
</em><br>
<p>I'd say it has a 95% chance of failure. If there's one thing that my time in
<br>
the Bay Area has taught me, it's that how good you are, how good your
<br>
products are, whether or not you have the Best Idea; none of these matter a
<br>
damn. The success or failure of your company is largely out of your hands
<br>
and lies in the variables over which you have no control.
<br>
<p>I'm on potential failure #3, and have been involved in many others as a
<br>
consultant. I've seen collections of lazy morons do amazingly well, and
<br>
incredibly smart, hardworking people with amazing ideas and buy-in from the
<br>
money men fail miserably.
<br>
<p><em>&gt; If I still thought that the Singularity was located
</em><br>
<em>&gt; in 2030, the way I did when I first got into all this, then I might be
</em><br>
<em>&gt; more inclined to try and start a for-profit corporation to get the funding
</em><br>
<em>&gt; et cetera, because there would actually be the time to take the company
</em><br>
<em>&gt; public and sell the stock and turn it into a private operating foundation,
</em><br>
<em>&gt; or to try again with a nonprofit if the for-profit route failed.  As it
</em><br>
<em>&gt; is, the possible horrendous time crunch only confirms the recommendation
</em><br>
<em>&gt; of my experience so far, and that experience is this: working directly on
</em><br>
<em>&gt; the Singularity is the only thing that got me anywhere in life, while
</em><br>
<em>&gt; working on other things in the name of &quot;practicality&quot; and &quot;doing something
</em><br>
<em>&gt; for the short term&quot; just wasted my time.
</em><br>
<p>Eh, can't say I agree with your Singularity date, but that's all well and
<br>
fine. It's not as if you're lazing around waiting for it coz you think it's
<br>
soon (like some people I can think of). I'd be happy to be proven wrong on
<br>
the timing count, but I don't think that any of us can afford to count on it
<br>
happening as soon as you think it will.
<br>
<p>As I've said before, we all need to be out there shouting.
<br>
<p>Reason
<br>
<a href="http://www.exratio.com/">http://www.exratio.com/</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0326.html">Amara Graps: "LANL Abstract: Engineering the Zero-Point Field and Polarizable Vacuum For Interstellar Flight"</a>
<li><strong>Previous message:</strong> <a href="0324.html">Joe Dees: "Re: The Golden-Egg-Laying Goose"</a>
<li><strong>In reply to:</strong> <a href="0316.html">Eliezer S. Yudkowsky: "Re: rambling question on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0336.html">Jacques Du Pasquier: "RE: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0336.html">Jacques Du Pasquier: "RE: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0341.html">Eliezer S. Yudkowsky: "Re: rambling question on AI"</a>
<li><strong>Reply:</strong> <a href="0353.html">Randall Randall: "Re: rambling question on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#325">[ date ]</a>
<a href="index.html#325">[ thread ]</a>
<a href="subject.html#325">[ subject ]</a>
<a href="author.html#325">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:32 MST
</em></small></p>
</body>
</html>
