<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: RE: The Politics of Transhumanism</title>
<meta name="Author" content="Smigrodzki, Rafal (SmigrodzkiR@msx.upmc.edu)">
<meta name="Subject" content="RE: The Politics of Transhumanism">
<meta name="Date" content="2002-01-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: The Politics of Transhumanism</h1>
<!-- received="Fri Jan 18 13:44:06 2002" -->
<!-- isoreceived="20020118204406" -->
<!-- sent="Fri, 18 Jan 2002 15:46:29 -0500" -->
<!-- isosent="20020118204629" -->
<!-- name="Smigrodzki, Rafal" -->
<!-- email="SmigrodzkiR@msx.upmc.edu" -->
<!-- subject="RE: The Politics of Transhumanism" -->
<!-- id="EB5DDEEFC7B4D411AD3B00508BDFF3E20231916F@1upmc-msx7.isdip.upmc.edu" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="The Politics of Transhumanism" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Smigrodzki, Rafal (<a href="mailto:SmigrodzkiR@msx.upmc.edu?Subject=RE:%20The%20Politics%20of%20Transhumanism"><em>SmigrodzkiR@msx.upmc.edu</em></a>)<br>
<strong>Date:</strong> Fri Jan 18 2002 - 13:46:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1312.html">Brian D Williams: "Re: Socio-sexual complication"</a>
<li><strong>Previous message:</strong> <a href="1310.html">Mikael Johansson: "Re: SILLINESS Re: Anders response to &quot;Politics of Transhumanism&quot;"</a>
<li><strong>Maybe in reply to:</strong> <a href="1049.html">natashavita@earthlink.net: "The Politics of Transhumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1378.html">Smigrodzki, Rafal: "RE: The Politics of Transhumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1311">[ date ]</a>
<a href="index.html#1311">[ thread ]</a>
<a href="subject.html#1311">[ subject ]</a>
<a href="author.html#1311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Answer to Anders,
<br>
<p>I think our debate touches on two related topics: the core ethical concepts
<br>
espoused by persons sharing our mindset, and the methods we envision as
<br>
means to bring about the changes we are dreaming of.
<br>
<p>You are right pointing out that a cohesive ethical system is, for a movement
<br>
with political aspirations, quite useful, if not indispensable, and the
<br>
means to an end are just means. You and I agree (to a large extent) on the
<br>
ethical principles that form the basis for our actions. However, when I
<br>
suggest an ethics-free use of the word &quot;transhumanism&quot; I have the following
<br>
goal in mind - our means (the use of technology to voluntarily change
<br>
humanity), can and will be accepted by persons and movements with ethical
<br>
principles differing from ours. It is likely that these will be groups more
<br>
similar to us than to Rifkinites, who are opposed to us as a matter of
<br>
principle. Yet, on the other hand, our potential allies in the support of
<br>
technology will have enough ethical disagreements with us to prevent the
<br>
formation of a single movement. 
<br>
<p>By formulating a strategy based on shared means (technology), rather than
<br>
trying to package ethics, politics *and* technology as a single
<br>
all-encompassing world view, it might be possible to achieve our goals
<br>
faster. It is easier to build and maintain narrowly-focused alliances, with
<br>
a lot of leeway for members. Let's say, libertarian-minded technophiles and
<br>
patient-advocacy groups - both want continued scientific progress, including
<br>
cloning technologies, but it might be pretty difficult to make them agree on
<br>
how much state involvement in health care is needed, if any. A
<br>
technology-based alliance of this kind would have a much better chance of
<br>
success against the unholy alliance of the church and luddites than any
<br>
memetically pure brand of transhumanism.
<br>
<p>I think your reformulation of my example of Rifkinite and church alliance
<br>
was not correct. You were describing the danger of our goals being subverted
<br>
and marginalized by other members of a political coalition, but this not the
<br>
danger inherent in alliances with shared (sub)goals. As Fabio pointed out,
<br>
it is likely that 21st century politics will be dominated by a huge rift
<br>
between technophiles on one side, and luddites of many kinds on the other.
<br>
Each side will be comprised of many disparate movements, some of them
<br>
sharing almost nothing except their attitude towards technology. Joining the
<br>
technophile alliance will not jeopardize our hopes for technological
<br>
progress - we would not sit in the same organization as Rifkinites, and
<br>
would not be pressured to make painful compromises within the alliance, as
<br>
long as you do not insist on conformity to a particular world-view. On the
<br>
contrary, when sitting accross the parliamentary aisle from the luddites, we
<br>
could better defend ourselves from them if we have many allies.
<br>
<p>This is why I do believe there is utillity in an (almost) value-free
<br>
formulation of a strategy (whether you call it transhumanism, or whatever),
<br>
separately from the full ethical, and philosophical system(s), such as
<br>
extropianism.
<br>
<p>Fabio already mentioned that transhumanism without technology is just plain
<br>
vanilla humanism. I agree with him. But I am willing to change my mind if
<br>
you can you tell me what is the special ingredient that the &quot;trans&quot; brings
<br>
in, except technology.
<br>
<p>-------
<br>
As Mark Walker pointed out, technological transformation is
<br>
really just one part of a triad of ideas
<br>
(<a href="http://www.markalanwalker.com/what.htm">http://www.markalanwalker.com/what.htm</a> : &quot;1. The Technology
<br>
Thesis: Within a hundred years humanity will possess the
<br>
technology to reengineer Homo sapiens.  2. The Ideal Thesis: The
<br>
goal in the reengineering task is to perfect ourselves. 3. The
<br>
Ethical Thesis: We ought to employ technology to realize this
<br>
ideal.&quot;). The technology part is just a means to an end, and if
<br>
you leave out this end transhumanism becomes arbitrary. It
<br>
cannot be a motivator for anything else than promoting cool
<br>
toys.  Transhumanism is commonly criticized as being mere
<br>
technophilia, and seeing the core of transhumanism as technology
<br>
reinforces this. There is nothing wrong with liking technology,
<br>
but aren't we aiming higher than that? Saying that tech can
<br>
change us doesn't say what changes are desirable or not.
<br>
<p>### Sometimes it is better to argue for the ethics and technology
<br>
separately, as I pointed out above.
<br>
-------
<br>
<p>If somebody brings up nazi ideas in quantum physics, they are
<br>
clearly not speaking in the right forum, and hence excluding
<br>
them doesn't have to be based on a value statement. But what if
<br>
the nazi is speaking about an issue in a suitable forum, like a
<br>
political one? Can you exclude him for being evil in your
<br>
opinion?
<br>
<p>### Yes, of course!
<br>
<p>------
<br>
&nbsp;In that case, what about freedom of speech for people
<br>
with unpopular opinions? (Of course, in privately run forums I
<br>
would say the proprietor has the right to set up the debate
<br>
limits as he or she wishes, but there is still a great deal of
<br>
difference between somebody who bases his actions on clear
<br>
principles and somebody who acts depending on some unknowable
<br>
whim)
<br>
<p>### As long as your clients (=participants in the discussion and others you
<br>
want to influence) agree with your whims, it's OK, and most persons agree on
<br>
the excluision of nazis).
<br>
<p>-----
<br>
<p>I can, given my view that transhumanism is indeed based in
<br>
humanism, firmly say that a nazi post (even when dealing with
<br>
the subject) in a transhumanist forum is wrong in the same way:
<br>
nazism is fundamentally incompatible with transhumanism.
<br>
<p>### It is indeed better to argue from a cohesive set of ethical principles,
<br>
but the critical element is the acceptance of these principles by your
<br>
audience - if they don't, you are wasting your breath. But even if you
<br>
disagree on ethics, you can still sometimes agree on methods and
<br>
intermediate goals. You can build a value-unspecified transhumanist
<br>
alliance, keep out the nazis because no nice person likes them, and work on
<br>
technology, with ethical disagreements deferred.
<br>
<p>------
<br>
<p><p>Of course one can work together with people with fundamentally
<br>
different core values - often it is necessary. But if you do not
<br>
have core values that reach beyond a liking for certain
<br>
technology you will find yourself subverted and your work
<br>
becoming used to further agendas far different from your own.
<br>
<p>### This is not what I meant - I am not for collaboration with enemies, just
<br>
collaboration with groups having reasonably compatible intermediate-range
<br>
goals. 
<br>
<p>------
<br>
<p><p>On what grounds? Because the word has a bad ring? Because you
<br>
say so? What makes &quot;Transhumanists against Eugenics&quot; more valid
<br>
than &quot;Transhumanists against Democracy?&quot;. In your view there is
<br>
no reason to favor one over the other, except political
<br>
expediency.
<br>
<p>### I am afraid you implied here that I might have no ethical convictions
<br>
except a worship for expediency. This is incorrect. However, as long as
<br>
expediency does not grossly conflict with ethics, it is expediency that
<br>
should direct the building of alliances, not insistence on all-inclusive
<br>
systems.
<br>
<p>-------
<br>
<p>&nbsp;I would say that there is very good reasons to favor
<br>
the first, not just out of expediency but because coercive
<br>
policies tend to hinder human development and can easily be
<br>
abused, and that democracy in most of its forms are far more
<br>
humanistic than any other government.
<br>
<p>### Exactly my opinion, too. 
<br>
<p>-------
<br>
<p><em>&gt; Second, and I think this is a more severe problem, is that trying to
</em><br>
<em>&gt; appeal to a lot of people by having more diluted values or ideology will
</em><br>
<em>&gt; mean that you get more people importing their own favorite ideologies
</em><br>
<em>&gt; into the movement and more people who don't get understand whatever
</em><br>
<em>&gt; central values there are and are more into it for the community or
</em><br>
<em>&gt; networking.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ### You can always have a restricted-entry organization for the special
</em><br>
<em>&gt; people, and a free-entry club for the proles. The two together can achieve
</em><br>
<em>&gt; more, without spoiling the experience for anybody (at least initially).
</em><br>
<p>Inner and Outer circles seldom work, since they tend to get out
<br>
of sync (as well as the usual sociopsychological problems of
<br>
in-groups and out-groups, power struggles and &quot;my conspiracy is
<br>
better than yours&quot;). The &quot;elite&quot; may have the core values and
<br>
ideology, but without them the other organisation will start
<br>
drifting ideologically on its own.
<br>
<p>### If the alliance you are in starts moving in the wrong direction, you can
<br>
try to push it back, or leave. It's preferable to having no allies, and
<br>
being crushed by your enemies.
<br>
<p>------
<br>
<p>A good example is the swedish liberal party Folkpartiet. When
<br>
asked, their chief ideologist gave us quite transhumanist and
<br>
libertarian answers to a number of questions. At the same time,
<br>
the politicians of the party have been protecting liberty by
<br>
supporting bans on behaviors that may be dangerous (like going
<br>
by car without seatbelt, harsh rules against drug use and
<br>
prostitution), more regulation of the markets in the interests
<br>
of equality and freedom (including the state monopoly on alcohol
<br>
sales), and supported many very restrictive laws on research in
<br>
genetics. There is a total discrepancy between the &quot;inner party&quot;
<br>
and the &quot;outer party&quot; that actually does the political work.
<br>
This is what not taking ideology seriously leads to.
<br>
<p>### This is what &quot;listening to the will of the people&quot; leads to. I agree
<br>
that diluting values for the sake of mass appeal is wrong, but avoidance of
<br>
cooperation for the sake of total purity is just as counterproductive.
<br>
Joining narrow, value-free alliances is sometimes the optimal course of
<br>
action.
<br>
<p>-------
<br>
<p><em>&gt;  As an example, compare this list now with how it was several
</em><br>
<em>&gt; years back in terms of actual idea production: the huge increase in
</em><br>
<em>&gt; diversity of people on the list has not led to an increase in quality or
</em><br>
<em>&gt; even quantity of ideas. Some of the old issues of Extropy are composed
</em><br>
<em>&gt; to a large extent of threads from the list, with amazing insight and
</em><br>
<em>&gt; creativity.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ### But then, the low-lying fruit has been picked already. How much more
</em><br>
can
<br>
<em>&gt; you say about the right way of approaching the Singularity without new
</em><br>
data?
<br>
<em>&gt; New arrivals cannot keep inventing the wheel all over again, and building
</em><br>
a
<br>
<em>&gt; spaceship takes time.
</em><br>
<p>Actually, many of the ideas that were discussed were hardly
<br>
low-lying fruits: transhumanist architecture, utility fogs, idea
<br>
futures, reputation systems etc. 
<br>
<p>And there is plenty of important stuff this side of the
<br>
singularity: how to shape societies, economies, institutions,
<br>
legal systems and careers to handle the predicted dynamic high
<br>
tech society? How to handle the problem of destruction from
<br>
replicating technology? What ethical, aesthetic and cultural
<br>
principles to promote in order to produce a transhumanist
<br>
society? How would a transhumanist society even work? - these
<br>
questions have hardly been developed, new data is arriving daily
<br>
and they ought to be high priority for all of us. 
<br>
<p>### Well, nobody is preventing anybody from making seminal contributions
<br>
here. Having lots of people on the list does not impair the original
<br>
member's ability to continue with high-quality contributions. And filtering
<br>
out the chatter is quite easy. 
<br>
<p>-------
<br>
<em>&gt;  But I question
</em><br>
<em>&gt; the point in having a million members in WTA or ExI if their membership
</em><br>
<em>&gt; doesn't *mean* anything. A far more successful strategy is to create a
</em><br>
<em>&gt; real world view (and a world-view is far more than a view of
</em><br>
<em>&gt; technology!), make the intellectuals and cultural leaders recognize it
</em><br>
<em>&gt; and then watch the mainstream move in your direction. It has worked
</em><br>
<em>&gt; well in the past.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ### Why not take both roads?
</em><br>
<p>I want to invest effort rationally. They payoff in the
<br>
intellectual sphere is far greater than in the mainstream
<br>
sphere. If I can convince one intellectual (in Hayek's sense of
<br>
the group of people in society that process and spread ideas),
<br>
then he will go on convincing other intellectuals and spreading
<br>
the idea to the masses. Intellectuals certainly listen to the
<br>
masses and do pick up ideas, but usually the memeflow is in the
<br>
other direction. This means that the same effort in spreading an
<br>
idea is likely to produce a far greater (and faster replicating)
<br>
return if I concentrate on the cultural leaders.
<br>
<p>### This is right, but sooner or later (hopefully sooner) you *do* want to
<br>
have a hundred million people supporting your ideas. As long as ExI has the
<br>
same ethical principles, membership will mean the same - a commitment to the
<br>
free growth of humanity beyond today's limits. Alliances with sufficiently
<br>
similar groups (as in &quot;transhumanists&quot; of all ethical stripes) can get you
<br>
there faster.
<br>
<p>-----
<br>
Answer to Mark Walker;
<br>
<p>A pure form of the technology thesis is simply the idea that technology can
<br>
be used to transform humans. This is what I think Anders is rejecting when
<br>
he says that this should not be understood as the central meme of
<br>
transhumanism. Technology, after all, might be used to make humans better
<br>
slaves, or instruments of a fascist state. (Just to be clear, this is not
<br>
transhumanism).
<br>
<p>### How about defining transhumanism as &quot;non-coercive technologically-driven
<br>
change (not perfectioning ) of humanity&quot;?
<br>
<p>The phrase &quot;perfecting humanity&quot; invites all kinds of trouble. Since the
<br>
idea of &quot;perfection&quot; is highly ambiguous, it is better kept out of
<br>
definitions.
<br>
<p>On the other hand, saying &quot;non-coercive&quot; is much less ambiguous, and clearly
<br>
excludes fascism, slavery, while still leaving it open for persons who do
<br>
not share the political views of most extropians.
<br>
<p>------
<br>
<p>&nbsp;Your analysis of a single meme smuggles in the idea that
<br>
Person Engineering Technology (PET) is to be used to move towards an
<br>
ideal--I assume that this is what you mean by &quot;improvement&quot;, and
<br>
furthermore, there is a gesture to ethics, I assume this is what you mean by
<br>
&quot;right&quot;. The technology thesis without the ethical and ideal thesis is
<br>
amoral and blind. Without the technology thesis, the ideal and ethical
<br>
theses without are impotent. I don't think there is a central meme of these
<br>
three. What is the central meme of the concept of a bachelor? Is it more
<br>
important to be male or unmarried? The question verges on unintelligibility,
<br>
as does the question of which of this triad is the central meme. Mark.
<br>
<p>### The technology meme might not an independent concept, but it is the only
<br>
new one, differentiating transhumanism from other views.
<br>
<p>Rafal
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1312.html">Brian D Williams: "Re: Socio-sexual complication"</a>
<li><strong>Previous message:</strong> <a href="1310.html">Mikael Johansson: "Re: SILLINESS Re: Anders response to &quot;Politics of Transhumanism&quot;"</a>
<li><strong>Maybe in reply to:</strong> <a href="1049.html">natashavita@earthlink.net: "The Politics of Transhumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1378.html">Smigrodzki, Rafal: "RE: The Politics of Transhumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1311">[ date ]</a>
<a href="index.html#1311">[ thread ]</a>
<a href="subject.html#1311">[ subject ]</a>
<a href="author.html#1311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:35 MST
</em></small></p>
</body>
</html>
