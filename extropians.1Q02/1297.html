<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Paper: A.I and Penrose</title>
<meta name="Author" content="hal@finney.org (hal@finney.org)">
<meta name="Subject" content="Re: Paper: A.I and Penrose">
<meta name="Date" content="2002-01-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Paper: A.I and Penrose</h1>
<!-- received="Fri Jan 18 10:23:25 2002" -->
<!-- isoreceived="20020118172325" -->
<!-- sent="Fri, 18 Jan 2002 10:18:43 -0800" -->
<!-- isosent="20020118181843" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Paper: A.I and Penrose" -->
<!-- id="200201181818.g0IIIhc21855@finney.org" -->
<!-- inreplyto="Paper: A.I and Penrose" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> <a href="mailto:hal@finney.org?Subject=Re:%20Paper:%20A.I%20and%20Penrose"><em>hal@finney.org</em></a><br>
<strong>Date:</strong> Fri Jan 18 2002 - 11:18:43 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1298.html">Harvey Newstrom: "RE: Transgender marriage"</a>
<li><strong>Previous message:</strong> <a href="1296.html">Steve Nichols: "Traditional AI can never be sentient"</a>
<li><strong>Maybe in reply to:</strong> <a href="1174.html">Spudboy100@aol.com: "Paper: A.I and Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1297">[ date ]</a>
<a href="index.html#1297">[ thread ]</a>
<a href="subject.html#1297">[ subject ]</a>
<a href="author.html#1297">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; <a href="http://xxx.lanl.gov/PS_cache/physics/pdf/0102/0102024.pdf">http://xxx.lanl.gov/PS_cache/physics/pdf/0102/0102024.pdf</a>
</em><br>
<em>&gt; Abstract
</em><br>
<em>&gt; It has been commonly argued, on the basis of Godel's theorem and related 
</em><br>
<em>&gt; mathematical results, that true artificial intelligence cannot exist. Penrose 
</em><br>
<em>&gt; has further deduced from the existence of human intelligence that fundamental 
</em><br>
<em>&gt; changes in physical theories are needed. I provide an elementary 
</em><br>
<em>&gt; demonstration that these deductions are mistaken. Is real articial 
</em><br>
<em>&gt; intelligence possible? Are present-day theories of physics suficient for a 
</em><br>
<em>&gt; reductionist explanation of consciousness? 
</em><br>
<p>Penrose's argument has been refuted so many ways it is amazing that anyone
<br>
even bothers any more.  However I don't think this particular counter-
<br>
argument works.  It amounts to concern over Penrose's reasoning where
<br>
he proposes to stump the AI by giving it what amounts to its own Godel
<br>
sentence.  One problem with Penrose's plan is that a real-world AI is
<br>
not self-contained but would interact with the world; Penrose proposes
<br>
to fix this by providing the AI with a simulated world, making it become
<br>
self-contained and non-interactive, and giving it a well defined Godel
<br>
sentence.  The author challenges this fix, writing:
<br>
<p>&nbsp;&nbsp;&nbsp;Penrose [2] gives a number of examples, that appear to show that it
<br>
&nbsp;&nbsp;&nbsp;is easy to construct the requisite non-interactive subroutine using
<br>
&nbsp;&nbsp;&nbsp;the interactive program as a component.
<br>
<p>&nbsp;&nbsp;&nbsp;However, there is a big problem in figuring out how to present the
<br>
&nbsp;&nbsp;&nbsp;input to the program, to tell it what theorem is to be proved. Now
<br>
&nbsp;&nbsp;&nbsp;the program, which we can call an artificial mathematician, is in the
<br>
&nbsp;&nbsp;&nbsp;position of a research scientist whose employer specifies a problem
<br>
&nbsp;&nbsp;&nbsp;to be worked on. To be effective, such a researcher must be able
<br>
&nbsp;&nbsp;&nbsp;to question the employer's orders at any point in the project. The
<br>
&nbsp;&nbsp;&nbsp;researcher's questions will depend on the details of the progress of
<br>
&nbsp;&nbsp;&nbsp;the research. (&quot;What you suggested didn't quite work out. Did you
<br>
&nbsp;&nbsp;&nbsp;intend me to look at the properties of XXYZ rather than XYZ?&quot;) As
<br>
&nbsp;&nbsp;&nbsp;every scientist knows, if the researcher does not have the freedom
<br>
&nbsp;&nbsp;&nbsp;to ask unanticipated questions, the whole research program may fail
<br>
&nbsp;&nbsp;&nbsp;to achieve its goals.
<br>
<p>&nbsp;&nbsp;&nbsp;Therefore to construct the non-interactive program needed by Penrose
<br>
&nbsp;&nbsp;&nbsp;one must discover the questions the artificial mathematician will
<br>
&nbsp;&nbsp;&nbsp;ask and attach a device to present the answers in sequence. The
<br>
&nbsp;&nbsp;&nbsp;combination of the original computer and the answering machine is
<br>
&nbsp;&nbsp;&nbsp;the entity to which Turing's halting theorem is to be applied.
<br>
<p>The author, John Collins, goes on to show that this strategy of providing
<br>
answers in advance won't work because each time you change the set of
<br>
answers you change the system, hence the Godel sentence, hence you have to
<br>
start over from the beginning with a different proof challenge to the AI.
<br>
<p>The problem with this reasoning is that this claim that the AI must be
<br>
able to ask question seems false.  It is given a fully self-contained
<br>
mathematical formula which it is asked to evaluate.  There is no scope
<br>
for ambiguity or confusion in this problem.  It is not provided in
<br>
some loose language like English; it is in hard mathematical symbols.
<br>
This is different from Collins' model where the AI must ask questions to
<br>
clarify his problem just like a scientist given some research problem by
<br>
his employer.
<br>
<p>I've worked on many mathematical problems, challenges and contests over
<br>
the years, and they are self-contained.  You don't get to ask questions;
<br>
in fact in national contests where the problems are provided in writing,
<br>
there is typically no one around who would be remotely qualified to
<br>
answer any questions about the problems.  And these problems are often
<br>
described much less formally than the Godel statement which Penrose
<br>
would propose to provide.
<br>
<p>So Collins' claim that the AI would have to be able to ask questions
<br>
about its problem, and that this would require answers to be prepared,
<br>
which would change the system in a never-ending cycle, does not seem a
<br>
strong refutation of Penrose's program.
<br>
<p>Hal
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1298.html">Harvey Newstrom: "RE: Transgender marriage"</a>
<li><strong>Previous message:</strong> <a href="1296.html">Steve Nichols: "Traditional AI can never be sentient"</a>
<li><strong>Maybe in reply to:</strong> <a href="1174.html">Spudboy100@aol.com: "Paper: A.I and Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1297">[ date ]</a>
<a href="index.html#1297">[ thread ]</a>
<a href="subject.html#1297">[ subject ]</a>
<a href="author.html#1297">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:35 MST
</em></small></p>
</body>
</html>
