<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="Colin Hales (colin@versalog.com.au)">
<meta name="Subject" content="Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Sat Jan 12 13:07:54 2002" -->
<!-- isoreceived="20020112200754" -->
<!-- sent="Sat, 12 Jan 2002 10:47:13 +1100" -->
<!-- isosent="20020111234713" -->
<!-- name="Colin Hales" -->
<!-- email="colin@versalog.com.au" -->
<!-- subject="Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="000601c19afa$4b7e1460$0100a8c0@Pc2" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Colin Hales (<a href="mailto:colin@versalog.com.au?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>colin@versalog.com.au</em></a>)<br>
<strong>Date:</strong> Fri Jan 11 2002 - 16:47:13 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0872.html">steve: "Re: MEDIA: NOVA on Gamma Ray Bursters"</a>
<li><strong>Previous message:</strong> <a href="0870.html">Spike Jones: "Re: MEDIA: NOVA on Gamma Ray Bursters"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0873.html">steve: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0873.html">steve: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0885.html">Jacques Du Pasquier: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0902.html">J. R. Molloy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="0941.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1019.html">John Grigg: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1035.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1124.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1196.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1198.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1392.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#871">[ date ]</a>
<a href="index.html#871">[ thread ]</a>
<a href="subject.html#871">[ subject ]</a>
<a href="author.html#871">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This is a dec 29 Guardian article on Jaron Lanier. Boy I wish we had more
<br>
'eccentics' like this around. We need 'em. He's well worth following. One of
<br>
the great 'sleeping bear pokers'.
<br>
<p>The Guardian Profile -Jaron Lanier - The virtual visionary
<br>
<a href="http://www.guardian.co.uk/Archive/Article/0,4273,4326550,00.html">http://www.guardian.co.uk/Archive/Article/0,4273,4326550,00.html</a>
<br>
<p>However, I'm a bit mystified by his attitude on AI.  Maybe my logic is down
<br>
the toilet. I can't tell, maybe you can.
<br>
My thoughts, written after I read the article, I dump here.
<br>
===============
<br>
Jaron Lanier is a regular at www.edge.org &lt;<a href="http://www.edge.org">http://www.edge.org</a>&gt;. He’s always
<br>
very challenging and seems to make sense. However, I don’t understand his
<br>
ideas about the limits of technology. We, humans, are technology. Just
<br>
because we’re constructed with DNA or any method you’d care to consider in
<br>
no way invalidates another method for creation of intelligence. If it were
<br>
possible to invalidate other methods we’d already know how to make it,
<br>
making the whole ‘problem’ moot!
<br>
<p>I am having trouble understanding how he could come to this position by
<br>
means of logic, unless he sees far deeper into everything than me. I am
<br>
willing to accept this, but I’d like to see some meat on the argument. All
<br>
through the history of technological development reality, in my view, has
<br>
outstripped the imaginations of the pundits. The trend is obvious. The
<br>
possibilities are endless. Why would this kind of grey luddite view be view
<br>
be put?
<br>
<p>Putting AI as an engineering goal is precisely what I’m doing. Thus
<br>
according to his text I am “in a very strange position”, as a result. I
<br>
suppose, if one has a very sincere belief in the insurmountable intellect of
<br>
the human, then the prospect of creating our betters would be, to some
<br>
extent, belittling. The scientific method has, for most of a millennium,
<br>
decentralized humans from the center of the universe. Go back to Kepler and
<br>
have a look. AI is the last step in the process. What exactly will make this
<br>
next step not happen?
<br>
<p>I believe that one valid perspective on humanity is that we are part of the
<br>
universe’s self awareness. This is a great honour and an amazing thing, to
<br>
be sure, but just a part. Possibly only part of a beginning. If I were
<br>
convinced of myself as occupying a preeminent central end-point, I could
<br>
thus feel somewhat miffed upon displacement. Getting beaten by your kids at
<br>
&lt;insert game of choice&gt; is something like the way I will feel when it
<br>
happens. A mixture of fear, pride and accomplishment.
<br>
<p>We will be known as ‘the old ones’ by our progeny, who will take on forms we
<br>
can only guess at, and leave for the stars. Seeing the technology as an aid
<br>
to human communication only is a simple extension of what has been happening
<br>
anyway - because we’ve been -so far -unable to allow AI to happen. Yes, I
<br>
believe human capability will be enhanced - it’s why we are doing AI in a
<br>
multitude of flavours. But when a sentient AI emerges, believing that human
<br>
enhancement is all that is going to happen would require the AI to be
<br>
shackled and zombied, to keep us as ‘top dog’. History, I think, has proven
<br>
that sort of imposed power struggle not to work in the long run.
<br>
<p>We need a devil’s advocate - look what it’s done - I’m trawling prose from
<br>
my neurons. Not a bad thing, really. Jaron has made a good thing out of
<br>
taking awkward and novel positions. In this case, I think it’s a touch
<br>
specious - No Sale.
<br>
<p>We’re going to get out nifty human enhancers and tools and as well, it’s OK
<br>
with me just to help construct a God, and not to be one. He thinks it’s
<br>
religion to believe AI is possible, I think it’s religion to hope that it
<br>
can’t.
<br>
<p><p>Colin
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0872.html">steve: "Re: MEDIA: NOVA on Gamma Ray Bursters"</a>
<li><strong>Previous message:</strong> <a href="0870.html">Spike Jones: "Re: MEDIA: NOVA on Gamma Ray Bursters"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0873.html">steve: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0873.html">steve: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0885.html">Jacques Du Pasquier: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0902.html">J. R. Molloy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="0941.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1019.html">John Grigg: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1035.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1124.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1196.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1198.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Maybe reply:</strong> <a href="1392.html">Steve Nichols: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#871">[ date ]</a>
<a href="index.html#871">[ thread ]</a>
<a href="subject.html#871">[ subject ]</a>
<a href="author.html#871">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:34 MST
</em></small></p>
</body>
</html>
