<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Consciousness: A Useless Hypothesis</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Consciousness: A Useless Hypothesis">
<meta name="Date" content="2002-01-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Consciousness: A Useless Hypothesis</h1>
<!-- received="Sat Jan 19 14:36:07 2002" -->
<!-- isoreceived="20020119213607" -->
<!-- sent="Sat, 19 Jan 2002 13:35:22 -0800" -->
<!-- isosent="20020119213522" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Consciousness: A Useless Hypothesis" -->
<!-- id="006d01c1a131$344cc380$b85c2a42@vaio" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="000b01c1a11a$3101aea0$e0165e0c@flrjs" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Consciousness:%20A%20Useless%20Hypothesis"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 19 2002 - 14:35:22 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1387.html">Colin Hales: "RE: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Previous message:</strong> <a href="1385.html">Natasha Vita-More: "Re: Extropic Opportunity"</a>
<li><strong>In reply to:</strong> <a href="1376.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1405.html">John Clark: "Re: Consciousness: A Useless Hypothesis"</a>
<li><strong>Reply:</strong> <a href="1405.html">John Clark: "Re: Consciousness: A Useless Hypothesis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1386">[ date ]</a>
<a href="index.html#1386">[ thread ]</a>
<a href="subject.html#1386">[ subject ]</a>
<a href="author.html#1386">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ghost in the Machine:
<br>
What Neuroscientists and Computer Scientists Can Learn from Each Other
<br>
<a href="http://www.doubletwist.com/news/columns/article.jhtml?section=weekly01&amp;name">http://www.doubletwist.com/news/columns/article.jhtml?section=weekly01&amp;name</a>loy&gt; <br>
weekly0130
<br>
Think of your brain as a kind of computer? Think again. As neuroscientists
<br>
learn more about the way the brain works, computer scientists learn how to
<br>
improve machines.
<br>
Dr. Terrence Sejnowski, director of the Computational Neurobiology
<br>
Laboratory at the Salk Institute, agrees that the properties of the brain
<br>
can likely be duplicated in artificial devices, although he regards
<br>
questions of consciousness with a decidedly unphilosophical bent of mind.
<br>
&quot;My own suspicion is that words like 'consciousness' and 'qualia' will go
<br>
the way of words like 'phlogistem' and 'vitalism.'&quot;
<br>
<p>From: &quot;John Clark&quot; &lt;<a href="mailto:jonkc@worldnet.att.net?Subject=Re:%20Consciousness:%20A%20Useless%20Hypothesis">jonkc@worldnet.att.net</a>&gt;
<br>
<em>&gt; I have no idea what Interactive sentience could possibly mean and I
</em><br>
<em>&gt; wouldn't be at all surprised if you didn't either.
</em><br>
<p>You're just trying to be difficult I think.
<br>
When several people interact with each other, we thereby confirm our
<br>
sentience, so that's interactive sentience. So we don't need to &quot;guess&quot; that
<br>
we're sentient.
<br>
<p><em>&gt; I can interact with your
</em><br>
<em>&gt; body, your behavior and your intelligence but I can never interact
</em><br>
<em>&gt; with your sentience.
</em><br>
<p>Sentience usually means feeling or sensation as distinguished from
<br>
perception and thought. People interact with each other's sentience all the
<br>
time.
<br>
<p><em>&gt; Huh? Are you arguing that I'm intelligent when asleep?
</em><br>
<p>Of course not. When you're asleep, so is your intelligence.
<br>
<p><em>&gt; Not useless at all, it helps us form a mental model of other human beings
</em><br>
<em>&gt; and that helps us predict their behavior and that helps our genes get
</em><br>
passed
<br>
<em>&gt; on to the next generation.
</em><br>
<p>Nonsense. There's no such thing as &quot;consciousness&quot; and the models it helps
<br>
us form are all wrong.
<br>
<p><em>&gt; Every human being alive takes it as a given that
</em><br>
<em>&gt; intelligent behavior equates with consciousness, including you
</em><br>
<p>Wrong! I do not equate intelligent behavior with &quot;consciousness&quot; and you're
<br>
being childish to assert that I do.
<br>
<p><em>&gt; except when
</em><br>
<em>&gt; you're arguing on the Extropian list that is; that's why you don't talk to
</em><br>
people
<br>
<em>&gt; about philosophy when they're asleep
</em><br>
<p>I don't talk to people about philosophy at all, because it's a waste of
<br>
time.
<br>
<p><em>&gt; you know you're unlikely to get a
</em><br>
<em>&gt; very high-brow response.
</em><br>
<p>I don't care about &quot;high-brow&quot; responses, John.
<br>
<p><em>&gt; Perhaps I really am the only conscious
</em><br>
<em>&gt; being in the universe
</em><br>
<p>Solipsism is for children.
<br>
<p><em>&gt; but nobody, including you, could function in daily
</em><br>
<em>&gt; life if they thought that, so even if it's false I must accept the axiom
</em><br>
that if
<br>
<em>&gt; something acts intelligently then it is conscious.
</em><br>
<p>Accept whatever &quot;axiom&quot; you like. It doesn't change anything.
<br>
&quot;Consciousness&quot; is a useless hypothesis just like phlogiston and vitalism
<br>
are.
<br>
If something acts intelligently, that indicates that it may be intelligent.
<br>
That's all.
<br>
<p><em>&gt; You quite wisely think that something that
</em><br>
<em>&gt; produced the ASCII sequence that I have must be conscious
</em><br>
<p>Wrong! I think you're intelligent (although you may act quite unwisely).
<br>
<p><em>&gt; proving
</em><br>
<em>&gt; my point that when push comes to shove even you believe in my
</em><br>
<em>&gt; axiom of existence, everybody does, no exceptions this side of a
</em><br>
<em>&gt; loony bin.
</em><br>
<p>What &quot;axiom of existence&quot;? I don't believe in anything.
<br>
<p>---   ---   ---   ---   ---
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego, human values, scientific relinquishment, malevolent AI,
<br>
non-sensory experience, SETI
<br>
<p>We  move into a better future in proportion as the scientific method
<br>
accurately identifies incorrect thinking.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1387.html">Colin Hales: "RE: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Previous message:</strong> <a href="1385.html">Natasha Vita-More: "Re: Extropic Opportunity"</a>
<li><strong>In reply to:</strong> <a href="1376.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1405.html">John Clark: "Re: Consciousness: A Useless Hypothesis"</a>
<li><strong>Reply:</strong> <a href="1405.html">John Clark: "Re: Consciousness: A Useless Hypothesis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1386">[ date ]</a>
<a href="index.html#1386">[ thread ]</a>
<a href="subject.html#1386">[ subject ]</a>
<a href="author.html#1386">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:35 MST
</em></small></p>
</body>
</html>
