<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Wed Jan 16 13:08:52 2002" -->
<!-- isoreceived="20020116200852" -->
<!-- sent="Wed, 16 Jan 2002 12:08:11 -0800" -->
<!-- isosent="20020116200811" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="011701c19ec9$8af1c4c0$935c2a42@jrmolloy" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20020116145425.GB26493@panoptic.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Jan 16 2002 - 13:08:11 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1134.html">Mike Lorrey: "Re: hushmail: Can't say I didn't warn them..."</a>
<li><strong>Previous message:</strong> <a href="1132.html">Mike Lorrey: "Re: hushmail: Can't say I didn't warn them..."</a>
<li><strong>In reply to:</strong> <a href="1113.html">Dossy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1168.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1168.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1133">[ date ]</a>
<a href="index.html#1133">[ thread ]</a>
<a href="subject.html#1133">[ subject ]</a>
<a href="author.html#1133">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: &quot;John Clark&quot; &lt;<a href="mailto:jonkc@worldnet.att.net?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jonkc@worldnet.att.net</a>&gt;
<br>
<em>&gt; It took bumbling evolution nearly
</em><br>
<em>&gt; 4 billion years and a astronomical amount of death to build a brain as
</em><br>
<em>&gt; complex as an earthworm's, it took intelligence only about 50 years to
</em><br>
<em>&gt; do the same thing. I conclude it would be far far easier to make a
</em><br>
<em>&gt; sentient creative computer than a non sentient one.
</em><br>
<p>I agree that it would be easier for an intelligent computer to create
<br>
worthwhile products than for an unintelligent computer to do so. But
<br>
intelligence is not sentience, and responding to sense impressions (sentience)
<br>
doesn't necessarily entail intelligence (the ability to solve problems and
<br>
correctly answer questions).
<br>
<p><em>&gt;     &gt;The poetry-writing programs do not *claim* to be sentient.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I can rectify that oversight with one line of code.
</em><br>
<p>Of course *you* can. The question is, can *they*.
<br>
<p>Incidentally, we don't have to &quot;guess&quot; that we are aware and responsive. We
<br>
can confirm this by interacting intelligently with other people. Solipsism is
<br>
for kids, the scientific method is for adults.
<br>
<p>----------------------
<br>
<p>From: &quot;Dossy&quot; &lt;<a href="mailto:dossy@panoptic.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">dossy@panoptic.com</a>&gt;
<br>
<em>&gt; Please define &quot;creativity&quot; in a non-circular fashion, if possible.
</em><br>
<p>Please remit $10.00 for each requested definition, federal reserve notes if
<br>
possible.
<br>
To create means to make, to put together in such as way as to render a new
<br>
thing (as every schoolchild should know).
<br>
<p><em>&gt; Otherwise, it seems that you define creativity merely as the ability
</em><br>
<em>&gt; to create (as the dictionary does), in which case:  are bacteria
</em><br>
<em>&gt; &quot;creative&quot;?
</em><br>
<p>Obviously bacteria can be creative, in the strict sense of the word.
<br>
<p><em>&gt; Is reproduction (sexual or asexual) considered a
</em><br>
<em>&gt; &quot;creative&quot; ability?
</em><br>
<p>I'd consider it an adjunct of a creative process, yes.
<br>
<p><em>&gt; Would you consider offspring the product of
</em><br>
<em>&gt; it's parent (or parents) creativity?
</em><br>
<p>Some parents are more creative about their offspring than are others. G.
<br>
Gordon Liddy, for example, went to considerable and creative lengths to find a
<br>
woman who could produce the kind of children (strong, athletic, intelligent,
<br>
and healthy) that he wanted. (He settled for a tall math teacher, IIRC.)
<br>
<p><em>&gt; Can one have sight without being sentient?
</em><br>
<p>You mean like a camera? Sure, many people don't know what they're looking at.
<br>
<p><em>&gt;  Does having senses
</em><br>
<em>&gt; imply being sentient, or asked differently, do machines that
</em><br>
<em>&gt; purport to have senses (vision, smell, hearing, etc.) that
</em><br>
<em>&gt; are clearly not &quot;senient&quot; by common agreement, truly not have
</em><br>
<em>&gt; the senses that they claim to have?
</em><br>
<p>What machine claims (or purports) to have senses? Or do you mean that people
<br>
claim that some machines have senses?
<br>
<p><em>&gt; Isn't sensory perception composed of two things: sensory datum
</em><br>
<em>&gt; placed in a frame of reference of one's self-awareness and awareness
</em><br>
<em>&gt; of one's surrounding environment?
</em><br>
<p>Perception is always sensory. Non-sensory perception is meaningless (or only
<br>
meaningful circularly). Perception isn't a &quot;thing,&quot; it's a process whereby a
<br>
representation of a component (or components) of reality are rendered into a
<br>
model which constitutes understanding. &quot;One's self-awareness&quot; unnecessarily
<br>
fragments one. Notice, if you will, that when &quot;one&quot; is divided into itself and
<br>
its awareness, it is no longer &quot;one.&quot; In reality, one IS awareness.
<br>
<p><em>&gt; Sensory data without the ability
</em><br>
<em>&gt; to contemplate (at least at a sub-conscious level) what the data
</em><br>
<em>&gt; implies is simply data.
</em><br>
<p>Good. Now consider the ability to contemplate without sensory data. Without
<br>
sensory data, no contemplation occurs. (Imagination re-orders previously
<br>
garnered sensory data.) You are what you think. All that you are arises with
<br>
thought. Those last two sentences comprise the first two sentences of the
<br>
Dhammapada. Pure awareness, with no content whatever, constitutes the mirror
<br>
that reflects reality and is sometimes referred to as &quot;nirvana&quot; -- the
<br>
elimination of all contamination from the perfect mirror of awareness is
<br>
enlightenment (which is another of the ninety-nine names of nirvana or
<br>
nothingness), and in this process, the observer is the observed. Consequently,
<br>
the pure awareness abiding in your brain is identical to the pure awareness
<br>
abiding in Buddha's brain, and from this has arisen all sorts of
<br>
misconceptions about reincarnation, because total awareness is total
<br>
awareness, regardless from what brain it emerges. Something goes beyond words,
<br>
and to find it the brain needs to leave language behind and to discover
<br>
meditation, which means direct experience of reality, the perception of
<br>
immediate existence.
<br>
<p><em>&gt; An algorithm which influences a machine's
</em><br>
<em>&gt; behavior based on it's sensory data would appear to give the machine
</em><br>
<em>&gt; some kind of awareness of the physical world in which it's
</em><br>
<em>&gt; interacting -- isn't this a form of low-level sentience?
</em><br>
<p>You can think of it as levels of sentience, or you can consider sentience as
<br>
an absolute with varying degrees of purity. As water can be pure H2O or it can
<br>
be mineral water saltwater, alkaline water, lemon-flavored water, and so on.
<br>
So human perception can be colored by emotional content or by its connection
<br>
to other layers of sensory input and tandem cognitive systems. One of the
<br>
advantages of parallel processing is fault tolerance. Serial processors crash
<br>
or halt when the series is disrupted or interupted, but parallel processors
<br>
can keep chugging along even in very chaotic environments. By superlative
<br>
sentience I mean to indicate perception beyond which no greater accuracy is
<br>
possible. It's perfect perception whose topography exactly coincides with and
<br>
maps upon reality.
<br>
<p><em>&gt; &gt; Superlative sentience (total awareness) reveals that the highest use
</em><br>
<em>&gt; &gt; of thought is to allow us to stop thinking (while being wide awake),
</em><br>
<em>&gt; &gt; so that we can appreciate the epiphenomenon of self-awareness.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Don't all machines currently enjoy superlative intelligence, then?
</em><br>
<p>Machines have superlative intelligence perhaps (until they break), but not
<br>
superlative sentience (and their &quot;enjoyment&quot; is purely mechanical).
<br>
<p><em>&gt; Just because they don't express their appreciation for self-awareness
</em><br>
<em>&gt; doesn't mean they aren't appreciating it.
</em><br>
<p>Indeed, when one expresses appreciation, the appreciation is slightly
<br>
diminished by the effort of expression, and by the noise that expression
<br>
interjects into the gestalt. Two people can appreaciate a magnificent sunset
<br>
over cocktails... until one of them spoils it by commenting on how beautiful
<br>
it is.
<br>
Nevertheless, I don't expect that machines appreciate their self-awareness
<br>
merely because they remain mute, because even while remaining silent,
<br>
enlightened humans demonstrate their awareness by the way they live, by the
<br>
way they pass knowingly through the noise and haste of the world, and by the
<br>
way they touch life with compassionate discipline/disciplined compassion.
<br>
<p><em>&gt;  The problem is that we
</em><br>
<em>&gt; try to anthropomorphise machines and try to insist that because
</em><br>
<em>&gt; the sentience they enjoy isn't the same as the sentience we enjoy,
</em><br>
<em>&gt; therefore it's not sentience.
</em><br>
<p>No, the problem is that we make problems out of everything. Pure sentience is
<br>
by its very nature spontaneous, non-contrived, unplanned, a by-product of
<br>
evolution.
<br>
While spontaneously playing with his young son, a man serendipitously noticed
<br>
that the words &quot;now&quot; and &quot;here&quot; when combined spell &quot;nowhere,&quot; and he suddenly
<br>
understood how the immediate is connected to the timeless. A machine could do
<br>
that only by transcending the mechanical, predictable, constrained limits that
<br>
define machines. Humans stop being machines when we overstep all the habits of
<br>
our thought, and come to our senses.
<br>
<p><em>&gt;  Just as for a long time, we couldn't
</em><br>
<em>&gt; accept that animals could be just as sentient as humans are
</em><br>
<p>But of course humans are animals too. What makes us different is that we don't
<br>
know what we're going to be when we grow up. Kittens predictably become cats,
<br>
and puppies become dogs, colts become horses. In contrast, children become
<br>
firefighters, lawyers, doctors, chefs, scientists, and diverge into other
<br>
specialties. Our big brains make us different, and knowing that makes even
<br>
more difference. Since we can't objectively/quantitatively measure sentience
<br>
that is not correlated to behavior, and since behavior is connected to
<br>
genetics, we might misinterpret this to mean that genetics and evolution
<br>
determine sentient levels. However, the variability and flexibility of human
<br>
behavior provides a buffer between biology and psychology. We've decided that
<br>
the human animal is more sentient than other animals primarily because it's
<br>
humans who will fabricate other robotic animals rather than other animals that
<br>
fabricate humans.
<br>
<p><em>&gt; probably for the same reason (as well as the fact that they lacked
</em><br>
<em>&gt; the proper language to convey their sentience to us humans).
</em><br>
<p>I think the differences between humans and other animals are less than the
<br>
differences between humans and machines. What makes machines special is that
<br>
they can become more like humans quicker and more completely than other
<br>
animals can.
<br>
<p>&quot;You'll learn to like robots.
<br>
They'll be nicer than human beings.&quot;
<br>
--Hans Moravec
<br>
<p>From: &quot;Dossy&quot; &lt;<a href="mailto:dossy@panoptic.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">dossy@panoptic.com</a>&gt;
<br>
<em>&gt; On 2002.01.15, J. R. Molloy &lt;<a href="mailto:jr@shasta.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jr@shasta.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; and of course, evolution is not sentient,
</em><br>
<em>&gt;
</em><br>
<em>&gt; Would you care to defend that assertion?
</em><br>
<p>If you don't think it's a true assertion, then let evolution defend itself.
<br>
<p><em>&gt; mechanical clocks are also
</em><br>
<em>&gt; &quot;creative&quot; when they display the time they are instructed to
</em><br>
<em>&gt; keep, which is nonsensical
</em><br>
<p>However nonsensical it may be for clocks to create the time they are
<br>
instructed to keep, it is nevertheless what they do. Clocks do, indeed, create
<br>
the time of day. Clock time is entirely an abstract invention of the human
<br>
brain, and without clocks, there would be no time measurement. In the same
<br>
way, numbers are abstractions invented by the human brain.
<br>
<p><em>&gt; Creativity implies (to me) an external
</em><br>
<em>&gt; influence that affects the product that is created.
</em><br>
<p>Sounds like a good description of evolution (to me).
<br>
<p><em>&gt; Worse, lay-people would find it very hard to agree that a
</em><br>
<em>&gt; robot in an automobile manufacturing plant, &quot;creating&quot; the same
</em><br>
<em>&gt; component over and over, posesses creativity.
</em><br>
<p>Such a robot may &quot;possess&quot; creativity while not exercising it, if such a robot
<br>
is programmed to function below its potential abilities. Likewise, some people
<br>
never realize their creative potential.
<br>
<p><em>&gt; I don't think sentience is easier to create than creativity, but
</em><br>
<em>&gt; I don't think that creativity necessarily precedes sentience.
</em><br>
<p>Look at what you've written... &quot;easier to create than creativity&quot;
<br>
Earlier you were complaining about &quot;circular&quot; definitions, and now you've
<br>
written a perfectly circular self-contradiction. That which creates is
<br>
self-evidently already creative, and so creativity already exists whenever
<br>
anything at all acts to create. Hence, by definition, creativity precedes all
<br>
of creation. To posit sentience which precedes creativity is to invoke the
<br>
supernatural.
<br>
<p><em>&gt; The reason why it appears to us (humans) that it is easier to
</em><br>
<em>&gt; achieve creativity than it is to achieve sentience is because
</em><br>
<em>&gt; we know so very little about sentience.
</em><br>
<p>I think the reason we know so little about sentience is that it's so easy to
<br>
create (fabricate and confabulate) explanations based on imagination rather
<br>
than to do the hard science necessary to discover the underlying principles of
<br>
sentience.
<br>
<p><em>&gt; I think until we get a much firmer grasp of what sentience
</em><br>
<em>&gt; really is and what it consists of, we'll never actually produce
</em><br>
<em>&gt; truly creative machines.
</em><br>
<p>I don't know about &quot;we&quot; but according to experts in the field, truly creative
<br>
machines have already emerged. Google on &quot;Automatic Creation of
<br>
Human-Competitive Programs&quot;
<br>
<p>---   ---   ---   ---   ---
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego, human values, scientific relinquishment, malevolent AI,
<br>
non-sensory experience, SETI
<br>
<p>We  move into a better future in proportion as the scientific method
<br>
accurately identifies incorrect thinking.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1134.html">Mike Lorrey: "Re: hushmail: Can't say I didn't warn them..."</a>
<li><strong>Previous message:</strong> <a href="1132.html">Mike Lorrey: "Re: hushmail: Can't say I didn't warn them..."</a>
<li><strong>In reply to:</strong> <a href="1113.html">Dossy: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1168.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1168.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1133">[ date ]</a>
<a href="index.html#1133">[ thread ]</a>
<a href="subject.html#1133">[ subject ]</a>
<a href="author.html#1133">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:34 MST
</em></small></p>
</body>
</html>
