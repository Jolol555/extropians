<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="Steve Nichols (steve@multisell.com)">
<meta name="Subject" content="Re: Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Tue Jan 15 09:46:59 2002" -->
<!-- isoreceived="20020115164659" -->
<!-- sent="Tue, 15 Jan 2002 16:50:47 -0000" -->
<!-- isosent="20020115165047" -->
<!-- name="Steve Nichols" -->
<!-- email="steve@multisell.com" -->
<!-- subject="Re: Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="001c01c19de4$d5ebf6c0$d20987d9@leeds.ac.uk" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="200201151310.g0FDA4C27744@tick.javien.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Steve Nichols (<a href="mailto:steve@multisell.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>steve@multisell.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 15 2002 - 09:50:47 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1036.html">Smigrodzki, Rafal: "RE: SciFi Trivia Query: Blue People?"</a>
<li><strong>Previous message:</strong> <a href="1034.html">Smigrodzki, Rafal: "RE: The Politics of Transhumanism"</a>
<li><strong>Maybe in reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1089.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1089.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1035">[ date ]</a>
<a href="index.html#1035">[ thread ]</a>
<a href="subject.html#1035">[ subject ]</a>
<a href="author.html#1035">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Date: Mon, 14 Jan 2002 09:13:16 -0800
<br>
From: James Rogers &lt;<a href="mailto:jamesr@best.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jamesr@best.com</a>&gt;
<br>
Subject: Re: Jaron Lanier Got Up My Shnoz on AI
<br>
<p>On 1/14/02 7:35 AM, &quot;Steve Nichols&quot; &lt;<a href="mailto:steve@multisell.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">steve@multisell.com</a>&gt; wrote:
<br>
<em>&gt; J.R. Molloy wrote:
</em><br>
<em>&gt;&gt; It looks as though Lanier confuses intelligence with sentience. We
</em><br>
already
<br>
<em>&gt;&gt; have AI, as reported by John Koza almost two years ago in _Genetic
</em><br>
<em>&gt;&gt; Programming and Evolvable Machines_, Volume 1, Number 1/2 (ISSN:
</em><br>
1389-2576).
<br>
<em>&gt;&gt; Self-awareness, or sentience, is an epiphenomenon that emerges from
</em><br>
massively
<br>
<em>&gt;&gt; parallel computational complexity such as the human brain engenders.
</em><br>
<p><p><em>&gt;While sentience may be emergent, massive parallelism will have nothing to
</em><br>
do
<br>
<em>&gt;with it.  The brain is massively parallel because it was convenient in the
</em><br>
<em>&gt;evolutionary scheme of things, not because it is of intrinsic importance to
</em><br>
<em>&gt;sentience.  Anything doable in massive parallelism is doable on a serial
</em><br>
<em>&gt;(i.e. &quot;less massively parallel&quot;) processor.
</em><br>
<p>Stuff can be SIMULATED in serial (cos the mathematics seems to boil
<br>
down to statistical mathematics) but this doesn't mean quality of massively
<br>
parallel and serial are IDENTICAL, so maybe for real-time speed serial
<br>
won't work.
<br>
<p><p><em>&gt;&gt; There is no evidence for emergentism, and the philosophical case for
</em><br>
<em>&gt;&gt; epiphenomenalism is weak at best. Complexity does not equate to
</em><br>
infinite-state
<br>
<em>&gt;&gt; (self organising circuitry) since finite-state, hard wired systems can be
</em><br>
<em>&gt;&gt; equally complex. Sentience, abstract thought, is only possible once a
</em><br>
circuit
<br>
<em>&gt;&gt; has lost its external clock (primal eye) and become analog(ous to
</em><br>
<em>&gt;&gt; infinite-state).
</em><br>
<p><p><em>&gt;I agree that complexity does not equate to infinite-state, but I don't see
</em><br>
<em>&gt;where J.R. was saying that it does.  However, saying that abstract thought
</em><br>
<em>&gt;is only possible on clockless logic seems to be just plain wrong.  Even
</em><br>
with
<br>
<em>&gt;clockless logic computation doesn't happen by magic, but what I really
</em><br>
don't
<br>
<em>&gt;understand is where the mathematics even requires it or treats it as
</em><br>
<em>&gt;different from clocked logic.  Some elucidation would be useful.
</em><br>
<p>No, JR wasn't saying that, but BRAINS are self-organising in hardware, not
<br>
just soft-programmable. Computers aren't sentient, E1-brains are! I am not
<br>
saying absolutely that sentience/ abstract thought is only theoretically
<br>
possible
<br>
on clockless logic (lost clock! Not even designed clockless) ... but you
<br>
can't argue
<br>
that it has only ever be obseved on this type of circuit!!!! Mathematics is
<br>
just
<br>
analogy, a fiction ... I am more interested in the biology and evolutionary
<br>
history
<br>
of how the E1-brain actually works ... nets don't model very neatly into
<br>
math
<br>
anyway cos never reach perfect rest states.
<br>
<p>&quot;Abstract&quot; or &quot;taken away from&quot; thought needs a lost or abstract/ phantom
<br>
sens(or)gan ... the primal eye ... which is the biological external clock in
<br>
E2
<br>
brains. Has to be. I won't argue about it here as am busy putting
<br>
applications
<br>
from MVT into practice ... this is the breakthru technology that will
<br>
establish
<br>
boundaries between human and after-human philosophy.
<br>
<p><em>&gt;BTW, the link following that paragraph didn't seem to work.
</em><br>
<p>Oooppps. Got syntax wrong: <a href="http://www.multi.co.uk/primal.htm">http://www.multi.co.uk/primal.htm</a>
<br>
<p><em>&gt;Cheers,
</em><br>
<p><em>&gt;- -James Rogers
</em><br>
<p>www.steve-nichols.com Posthuman Political Alliance
<br>
*******************************
<br>
Chaturanga! The Mother of All War Games
<br>
Ancestor of common chess (La Dame Enragee variant)
<br>
*************************************
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1036.html">Smigrodzki, Rafal: "RE: SciFi Trivia Query: Blue People?"</a>
<li><strong>Previous message:</strong> <a href="1034.html">Smigrodzki, Rafal: "RE: The Politics of Transhumanism"</a>
<li><strong>Maybe in reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1089.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1089.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1035">[ date ]</a>
<a href="index.html#1035">[ thread ]</a>
<a href="subject.html#1035">[ subject ]</a>
<a href="author.html#1035">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:34 MST
</em></small></p>
</body>
</html>
