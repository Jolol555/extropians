<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Safety &amp; Security [was: The Politics of Transhumanism]</title>
<meta name="Author" content="Robert J. Bradbury (bradbury@aeiveos.com)">
<meta name="Subject" content="Safety &amp; Security [was: The Politics of Transhumanism]">
<meta name="Date" content="2002-01-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Safety &amp; Security [was: The Politics of Transhumanism]</h1>
<!-- received="Mon Jan 21 08:49:47 2002" -->
<!-- isoreceived="20020121154947" -->
<!-- sent="Mon, 21 Jan 2002 07:49:45 -0800 (PST)" -->
<!-- isosent="20020121154945" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Safety &amp; Security [was: The Politics of Transhumanism]" -->
<!-- id="Pine.LNX.4.10.10201210646460.8399-100000@server.aeiveos.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="200201210806.g0L861V07407@spidey.speakeasy.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robert J. Bradbury (<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20Safety%20&amp;%20Security%20[was:%20The%20Politics%20of%20Transhumanism]"><em>bradbury@aeiveos.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 21 2002 - 08:49:45 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1492.html">Anders Sandberg: "Re: gabber, ebm, future pop (was: Re: an introduction.)"</a>
<li><strong>Previous message:</strong> <a href="1490.html">Alex Ramonsky: "Re: a health dilemma."</a>
<li><strong>In reply to:</strong> <a href="1471.html">max@maxmore.com: "Re: The Politics of Transhumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1481.html">estropico >: "Re: The Politics of Transhumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1491">[ date ]</a>
<a href="index.html#1491">[ thread ]</a>
<a href="subject.html#1491">[ subject ]</a>
<a href="author.html#1491">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mon, 21 Jan 2002 <a href="mailto:max@maxmore.com?Subject=Re:%20Safety%20&amp;%20Security%20[was:%20The%20Politics%20of%20Transhumanism]">max@maxmore.com</a> wrote:
<br>
<p><em>&gt; I'll just say (again) that extropy involves self-direction
</em><br>
<em>&gt; and open society (two extropian principles). Libertarian views fit
</em><br>
<em>&gt; with those principles extremely well. But those principles do not
</em><br>
<em>&gt; exclusively require a libertarian view. While they certainly do
</em><br>
<em>&gt; exclude highly statist views (which presumably would be allowed in the
</em><br>
<em>&gt; WTA), they are compatible with non-libertarian views where those are
</em><br>
<em>&gt; clearly intended to support self-direction and maintain an open society.
</em><br>
[snip]
<br>
<em>&gt; I believe you are referring to the idea that we can use technology to
</em><br>
<em>&gt; alter the human condition. I agree that such a view can and probably
</em><br>
<em>&gt; will be combined with socio-political views that are neither
</em><br>
<em>&gt; libertarian nor even individualistic or democratic. Nationalist,
</em><br>
<em>&gt; racist, collectivist, and even religious forms of transhumanism seem
</em><br>
<em>&gt; possible.
</em><br>
[snip] 
<br>
<em>&gt; My own preference is for us to build pro-freedom forms of
</em><br>
<em>&gt; tranhumanism, especially the extropian approach (self-direction, open
</em><br>
<em>&gt; society) so that we don't *need* to ally with unsavory forms of
</em><br>
<em>&gt; transhumanism.
</em><br>
<p>I think there are perhaps three vectors this may move along that may
<br>
define relative positions that people may choose.  A PBS special
<br>
last night, pointed out that in Maslow's Hierarchy of Needs has
<br>
safety &amp; security coming right above basic biological needs (water,
<br>
food, temperature range, etc.)  As we can expect robust nanotechnology
<br>
to eliminate most concerns with regard to the biological needs, then
<br>
safety &amp; security would become the &quot;primary&quot; need.  Safety &amp; security
<br>
come back to trust.  Do you trust your water supply, do you trust your
<br>
tire manufacturer, do you trust the accounting firm and board of
<br>
companies you invest in, do you trust individuals from foreign nations,
<br>
do you trust those closest to you, etc.  [The local news in Seattle today
<br>
has a woman being arrested for assaulting her significant other with her
<br>
automobile.]
<br>
<p>One vector may be the &quot;Jeremiah Johnson&quot; Vector.
<br>
<a href="http://www.amazon.com/exec/obidos/ASIN/6304457324/104-8047170-0219941">http://www.amazon.com/exec/obidos/ASIN/6304457324/104-8047170-0219941</a>
<br>
In this vector, individuals, make their own laws, are responsible
<br>
for their own resources, provide their own security, etc.  It is
<br>
perhaps the ultimate libertarian perspective.  This may be the
<br>
ideal vector for people with high Aperger's Quotients.  Most probably
<br>
these people go live in the Oort cloud where they have plenty of
<br>
warning for anyone approaching them.
<br>
<p>Another vector is the &quot;Delegated Trust&quot; Vector.
<br>
This is not much different from the current state of society.  Most
<br>
individuals are happy to delegate the creation of trust to various
<br>
levels of law and government.  We do not want to have to deal with
<br>
the details of knowing that our water, tires, investments, etc. are
<br>
trustable.  We would rather structure our society that to a large
<br>
degree there are structures that produce implicit trust.  However,
<br>
as recent examples (911, Enron, the Seattle news) show, the &quot;weakest
<br>
link&quot; in this is people.  How does one produce safety &amp; security in
<br>
a society in which people are the greatest threat?  One sub-vector
<br>
may be building sufficient &quot;safety&quot; &amp; &quot;intelligence&quot; into potentially
<br>
dangerous objects that people cannot easily use them dangerously.
<br>
Planes inherently avoid buildings, cars will not start when they
<br>
detect alcohol in the air surrounding the driver, cars refuse to
<br>
be driven into people.  This is in some sense the spirit of Asimov's
<br>
&quot;Laws of Robotics&quot; (<a href="http://www.androidworld.com/prod22.htm">http://www.androidworld.com/prod22.htm</a>) extended
<br>
to non-robots.
<br>
<p>However, people are clever and can certainly find ways around the
<br>
safety built into their environment.  So for the ultimate &quot;trust&quot;
<br>
sub-vector people would have to be implanted with physical, perhaps
<br>
even mental &quot;governors&quot;.  These would not allow one to execute physical
<br>
actions (i.e. blocks at the primary motor cortex level) that could
<br>
be threats to others.  This might be extended to levels where one
<br>
cannot even &quot;conceive&quot; thoughts that are threat to others (or yourself).
<br>
<p>The final vector is the &quot;Open Source&quot; (transparent society) Vector.
<br>
In this situation the minds of individuals are completely laid bare
<br>
for outside examination.  Minds would be examined to ensure they
<br>
are sound -- i.e. cannot suffer epileptic siezures while driving
<br>
a car or plane and have sufficient internal restraint mechanisms
<br>
that they would simply *never* be able to use vehicles of expression
<br>
for their emotions.  One might have organizations verify that
<br>
individuals are trustable (delegating trust verification), or one
<br>
might be required to do it oneself (Jeremiah Johnson verification).
<br>
One could in these circumstances only allow individuals who place
<br>
product and shareholder investment safety as their *first* priorities
<br>
to serve as executives, and on the boards, of public corporations.
<br>
<p>I think if people think about these vectors they will see that
<br>
they all may serve as appropriate environments for transhumanism
<br>
provided people are free to choose which one they may live in.
<br>
If we kept this in mind, then some of the debates on the list
<br>
might be a lot less fractious.  Instead of trying to make one of
<br>
these vectors the &quot;right&quot; vector, it may make more sense to
<br>
accept they may all be appropriate for different types of
<br>
&quot;intelligences&quot;.
<br>
<p>The questions then become how to safely get from our current
<br>
state of affairs to a multi-vector solar system *and* how
<br>
to handle the security and trust relationships between these
<br>
vectors and with individuals who cross from one vector to another?
<br>
<p>Robert
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1492.html">Anders Sandberg: "Re: gabber, ebm, future pop (was: Re: an introduction.)"</a>
<li><strong>Previous message:</strong> <a href="1490.html">Alex Ramonsky: "Re: a health dilemma."</a>
<li><strong>In reply to:</strong> <a href="1471.html">max@maxmore.com: "Re: The Politics of Transhumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1481.html">estropico >: "Re: The Politics of Transhumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1491">[ date ]</a>
<a href="index.html#1491">[ thread ]</a>
<a href="subject.html#1491">[ subject ]</a>
<a href="author.html#1491">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:35 MST
</em></small></p>
</body>
</html>
