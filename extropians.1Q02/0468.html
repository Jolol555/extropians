<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Premature deaths [was: extropians-digest V7 #4]</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Premature deaths [was: extropians-digest V7 #4]">
<meta name="Date" content="2002-01-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Premature deaths [was: extropians-digest V7 #4]</h1>
<!-- received="Mon Jan  7 04:57:24 2002" -->
<!-- isoreceived="20020107115724" -->
<!-- sent="Mon, 07 Jan 2002 03:59:12 -0800" -->
<!-- isosent="20020107115912" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Premature deaths [was: extropians-digest V7 #4]" -->
<!-- id="3C398D90.8030006@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Pine.LNX.4.10.10201060130090.27552-100000@server.aeiveos.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Premature%20deaths%20[was:%20extropians-digest%20V7%20#4]"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 07 2002 - 04:59:12 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0469.html">John Grigg: "Re: Magic Medicine, maybe not"</a>
<li><strong>Previous message:</strong> <a href="0467.html">scerir: "Re: Quoting Nietzsche is a perilous business"</a>
<li><strong>In reply to:</strong> <a href="0435.html">Robert J. Bradbury: "Premature deaths [was: extropians-digest V7 #4]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0451.html">Dossy: "my own 9/11 conspiracy theory  (was Re: extropians-digest V7 #4)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#468">[ date ]</a>
<a href="index.html#468">[ thread ]</a>
<a href="subject.html#468">[ subject ]</a>
<a href="author.html#468">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robert J. Bradbury wrote:
<br>
<p><em>&gt; On Sun, 6 Jan 2002, Tom Andrys wrote:
</em><br>
<p><em>&gt; 
</em><br>
<em>&gt; Now, from an extropic perspective, I would argue we should seek
</em><br>
<em>&gt; the &quot;greatest good&quot; -- the survival of the most individuals.
</em><br>
<em>&gt; (One could also argue that one wants to promote the survival of
</em><br>
<em>&gt; the &quot;best&quot; or most creative individuals -- but that gets into
</em><br>
<em>&gt; some *extremely* subjective subject areas and potentially even
</em><br>
<em>&gt; eugenics so I'm not going to go there.)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'll simply state for the purposes of this discussion that &quot;more&quot;
</em><br>
<em>&gt; individuals are better than &quot;fewer&quot; individuals because it increases
</em><br>
<em>&gt; complexity and that is extropian.  (Those of you reading this may
</em><br>
<em>&gt; note some subtle frictions between extropianism and transhumanism
</em><br>
<em>&gt; when considering whether trans- or post-humanism at least along some
</em><br>
<em>&gt; paths is likely to generate the greatest complexity (extropicness),
</em><br>
<em>&gt; i.e. you could have two &quot;post-human&quot; situations, equally &quot;complex&quot;,
</em><br>
<em>&gt; one of which involves a large number of individuals and one of which
</em><br>
<em>&gt; involves a single meta-mind.
</em><br>
<em>&gt;
</em><br>
<p><p>A question is whether more truly increases complexity, truly 
<br>
increases variety or mainly increases amplitude of all the 
<br>
various &quot;signals&quot; humanity puts out.
<br>
<p>&nbsp;
<br>
<em>&gt; So, from a rational standpoint (given the above premises) the goal
</em><br>
<em>&gt; should be to minimize premature death.  We all have finite resources
</em><br>
<em>&gt; (time, money, etc.).  So the question becomes how to maximize
</em><br>
<em>&gt; the minimization of premature death given our limited resources.
</em><br>
<em>&gt; 
</em><br>
<p><p>&lt;snip&gt;
<br>
<p><em>&gt; 
</em><br>
<em>&gt; If the answer is yes, then we cannot fault recent attempts
</em><br>
<em>&gt; at creating &quot;good days to die&quot; (other than to object to the fact
</em><br>
<em>&gt; that &quot;we&quot; (Westerners) were the ones dying.   If the answer is no, then
</em><br>
<em>&gt; we have to make the case that living and surviving is of much greater
</em><br>
<em>&gt; value than (a) the &quot;stories&quot; of ones life (e.g. the Klingon perspective)
</em><br>
<em>&gt; or (b) what one has contributed during ones life (a somewhat human
</em><br>
<em>&gt; perspective considering contributions of Einstein, Feynman, Darwin,
</em><br>
<em>&gt; etc.) [I think this translates into the concept that after one
</em><br>
<em>&gt; ceases to make &quot;significant&quot; contributions, ones life is devalued.]
</em><br>
<em>&gt; { Side-bar: This may be a quite interesting concept as it involves
</em><br>
<em>&gt; the concept of the depreciation of human lives.  I know some (the
</em><br>
<em>&gt; humanist gaggle) might object to this but from an extropian perspective
</em><br>
<em>&gt; it may have merit -- if you aren't &quot;contributing&quot; to the society
</em><br>
<em>&gt; what rights do you have to &quot;occupy&quot; a place in it. }
</em><br>
<em>&gt; (You know -- survival of the fittest and all that...)
</em><br>
<em>&gt;
</em><br>
<p><p>So, when AI gets to the point that many of our intellectual 
<br>
contributions are paltry and worthless in comparison, should we 
<br>
quietly go into that night?  What should happen when we can 
<br>
&quot;contribute&quot; no longer without a massive upgrade?  What happens 
<br>
if we think perhaps that we won't be ourselves if we take the 
<br>
upgrade as some inevitably will think?  Should these simply die 
<br>
and be deprived of all the goodies too?
<br>
<p>&nbsp;
<br>
<em>&gt; Returning to the issue -- how does one prevent premature deaths
</em><br>
<em>&gt; at the lowest cost?  I am asserting that *IT DOES NOT MATTER*
</em><br>
<em>&gt; what caused those deaths.  What matters is the relative costs
</em><br>
<em>&gt; of reducing such deaths.  Taking an alternate position means
</em><br>
<em>&gt; one must argue the relative &quot;acceptability&quot; of deaths.  E.g. *These*
</em><br>
<em>&gt; deaths are bad and should be prevented while *those* deaths, well,
</em><br>
<em>&gt; they are not so important and we will choose to ignore them.
</em><br>
<em>&gt;
</em><br>
<p><p>So if you can only decrease one set of many deaths and even the 
<br>
decrease may potentially lead to other deaths then what do you 
<br>
do?  It is a very slippery slope we stand close to, leading 
<br>
straight to many ideologically motivated hells on earth in the past.
<br>
<p>&nbsp;
<br>
<em>&gt; So to maximize the extropic vector, extropians should be asking
</em><br>
<em>&gt; the question &quot;How do I save the most lives at the lowest cost?&quot;.
</em><br>
<em>&gt; (Or alternatively, stepping deeply into the swamp, make the
</em><br>
<em>&gt; case that some lives are more valuable than others -- and
</em><br>
<em>&gt; suggest policies that promote saving those &quot;specific&quot; lives.)
</em><br>
<em>&gt;
</em><br>
<p><p><p>Even at the express cost of other supposedly &quot;less valuable&quot; 
<br>
lives?
<br>
<p>&nbsp;
<br>
<em>&gt; I will go on record here (and probably be crucified for it)
</em><br>
<em>&gt; that I do believe that some lives are inherently more valuable
</em><br>
<em>&gt; than others.  There *are* some lives that *will* save more lives
</em><br>
<em>&gt; than they destroy (e.g. Winston Churchill vs. Josef Stalin).
</em><br>
<em>&gt; But I also question whether it is possible to identify the lives
</em><br>
<em>&gt; with greatest value in advance with sufficient certainty to be
</em><br>
<em>&gt; &quot;picking&quot; them.  So one is rolling dice when one attempts to
</em><br>
<em>&gt; follow this path.
</em><br>
<em>&gt;
</em><br>
<p><p>I think we get into serious trouble very quickly unless we at 
<br>
least act as if we believe in the inherent worth of all human 
<br>
lives.  For if we do not, then it is all too easy to justify 
<br>
misery and even death for some in order to maximize the safety 
<br>
and lives of other &quot;important&quot; ones.  The inherent worth 
<br>
argument is not perhaps altogether logically supported but it 
<br>
does help avoid some very dangerous thoughts and policies as 
<br>
long as it is held.
<br>
<p>&nbsp;
<br>
<em>&gt; But, *if* one can come up with reasonable statistical measures
</em><br>
<em>&gt; that suggest that some political paths or leaders will save more lives
</em><br>
<em>&gt; than they eliminate -- then I would argue that in such situations
</em><br>
<em>&gt; that militant actions, even terrorism, in support of such paths
</em><br>
<em>&gt; are potentially justified.
</em><br>
<em>&gt;
</em><br>
<p><p>Here you have stepped fully over to the Dark Side!  :-(
<br>
Once the possibility that what one believes in most is most 
<br>
maximized by killing others is acknowledged then there are 
<br>
relatively few checks on the amount of misery that might befall 
<br>
humankind from the logical, oh so logical, extensions of and 
<br>
working out of this idea.  Why, if only a few hundred thousand 
<br>
humans survive all the way to say creating a Sysop (not to pick 
<br>
on that scenario at all) then one could argue that that is 
<br>
infinitely better than letting all those billions live who were 
<br>
bent on interfering to the point where the extinction of all 
<br>
humanity was to high a risk.  Or could one?
<br>
<p><p>&nbsp;
<br>
<em>&gt; In response to my arguments that early on, American revolutionaries
</em><br>
<em>&gt; were &quot;terrorists&quot;, some have claimed that they only assaulted
</em><br>
<em>&gt; (in relative terms) &quot;military&quot; targets.  In response, particularly
</em><br>
<em>&gt; to those arguing the fine points of the Geneva Convention, I must
</em><br>
<em>&gt; propose -- if one feels one will never &quot;triumph&quot; without taking
</em><br>
<em>&gt; the &quot;pain &amp; suffering&quot; to the general population opposing your
</em><br>
<em>&gt; position -- is not the use of such tactics justified?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Barbara Steisand, in Yentl, sang a song &quot;Papa, can you hear me?&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It would appear to me that this question is one that must be answered
</em><br>
<em>&gt; definitively in the west -- we must answer both those people currently
</em><br>
<em>&gt; disenfranchised as well as those who might someday be (from the Fukuyama
</em><br>
<em>&gt; posthumanist perspective).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It seems necessary that we remain aware of the need to maintain
</em><br>
<em>&gt; a dialog.  Once people have concluded &quot;they are not heard&quot;, it is but
</em><br>
<em>&gt; a small step to ignore any &quot;civilized&quot; protocols as to how &quot;conversations&quot;
</em><br>
<em>&gt; should be conducted.
</em><br>
<em>&gt;
</em><br>
<p><p>Yes.  I agree
<br>
<p>&nbsp;
<br>
<em>&gt; With regard to the prevention of premature deaths it becomes a
</em><br>
<em>&gt; question of whether listening (and responding) is less costly
</em><br>
<em>&gt; (from an extropic perspctive of preventing premature deaths)
</em><br>
<em>&gt; than proceeding on our along previous paths that assumed we were
</em><br>
<em>&gt; relatively secure.  Another way of looking at this is -- will
</em><br>
<em>&gt; each $ spent on &quot;Homeland Security&quot; save more or less lives
</em><br>
<em>&gt; than each $ given to the NIH (or the DoD, or the NSF, etc.).
</em><br>
<em>&gt; (The same discussion applies to other countries as well.)
</em><br>
<em>&gt;
</em><br>
<p><p>Homeland Security does not impress me as being really about 
<br>
&quot;security&quot;.  It strikes great fear in me because I believe its 
<br>
principle use will be to control and oppress the people.  The 
<br>
changes of laws and procedures already passed and pending when 
<br>
enforced as a &quot;fight against terrorism&quot; and thus almost 
<br>
sacrosanct and with relatively little oversight and control, has 
<br>
near limitless potential to be used to tyrannize the country and 
<br>
to protect established power elites.  If we want to maximize 
<br>
human life and human potential we must maximize freedom.  More 
<br>
and more elaborate control will not do the trick.  At this 
<br>
critical juncture we cannot afford to spend a decade or two in a 
<br>
global witchhunt.  Do everything we can to find culprits and to 
<br>
protect ourselves yes, but not at the price of removing the 
<br>
freedom and access to information and free movement of goods, 
<br>
people and ideas that the innovation to get us to Singularity is 
<br>
so very dependent on.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0469.html">John Grigg: "Re: Magic Medicine, maybe not"</a>
<li><strong>Previous message:</strong> <a href="0467.html">scerir: "Re: Quoting Nietzsche is a perilous business"</a>
<li><strong>In reply to:</strong> <a href="0435.html">Robert J. Bradbury: "Premature deaths [was: extropians-digest V7 #4]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0451.html">Dossy: "my own 9/11 conspiracy theory  (was Re: extropians-digest V7 #4)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#468">[ date ]</a>
<a href="index.html#468">[ thread ]</a>
<a href="subject.html#468">[ subject ]</a>
<a href="author.html#468">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:33 MST
</em></small></p>
</body>
</html>
