<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Fri Jan 18 21:37:24 2002" -->
<!-- isoreceived="20020119043724" -->
<!-- sent="Fri, 18 Jan 2002 17:32:22 -0800" -->
<!-- isosent="20020119013222" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="00d801c1a0a2$98aff8e0$c55d2a42@jrmolloy" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="000f01c1a03d$dac9ec00$c80b5e0c@flrjs" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Fri Jan 18 2002 - 18:32:22 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1342.html">J. R. Molloy: "Re: Skeptics and extropians"</a>
<li><strong>Previous message:</strong> <a href="1340.html">Spudboy100@aol.com: "all your banana is are ours!- Kurzweil"</a>
<li><strong>In reply to:</strong> <a href="1286.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1348.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1348.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1341">[ date ]</a>
<a href="index.html#1341">[ thread ]</a>
<a href="subject.html#1341">[ subject ]</a>
<a href="author.html#1341">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: &quot;John Clark&quot; &lt;<a href="mailto:jonkc@worldnet.att.net?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jonkc@worldnet.att.net</a>&gt;
<br>
<em>&gt; Let me get this straight, first you say &quot;intelligence is not sentience&quot;
</em><br>
<em>&gt; and then you say we know other people are sentient because
</em><br>
<em>&gt; &quot; We  can confirm this by interacting intelligently with other people&quot;
</em><br>
<em>&gt; and you see no contradiction in that?
</em><br>
<p>There is no contradiction in confirming sentience via interacting with others.
<br>
The operative word is *interacting* -- the level of intelligence is secondary.
<br>
(Likewise, we dismiss solipsism via peer review.)
<br>
<p><em>&gt;       &gt;&gt;Me:
</em><br>
<em>&gt;       &gt;&gt;I think general problem solving is indistinguishable from
</em><br>
<em>&gt;       &gt;&gt;intelligence and intelligence inevitably implies consciousness.
</em><br>
<em>&gt;
</em><br>
<em>&gt;     &gt; (((((((( LOL ))))))))))
</em><br>
<em>&gt;
</em><br>
<em>&gt; Why?
</em><br>
<p>Because intelligence implies &quot;consciousness&quot; in the same way that fire implies
<br>
&quot;phlogiston.&quot;
<br>
<p>--------------------------
<br>
<p>More from: John Clark
<br>
<em>&gt; 1) What problem can be solved by a parallel computer but can not
</em><br>
<em>&gt; in principle be solved by a very fast serial computer ?
</em><br>
<p>Sounds like a question for a parallel computer.
<br>
<p><em>&gt; 2) is there any reason to think that an AI would have to run on a serial
</em><br>
computer?
<br>
<p>There's probably less reason to think that an AI would have to run on a serial
<br>
computer than to think that it would have to run on a parallel computer, since
<br>
natural intelligence runs on parallel computers.
<br>
<p><em>  &gt;  &gt;My old z80 is slower by a magnitude than a P4, but is not a jot more
</em><br>
<em>  &gt;  &gt;or less sentient!
</em><br>
<p><em>&gt; You seem very sure, how did you find out?
</em><br>
<p>That's easy: They both failed to claim that they are sentient.
<br>
<p>------------------------
<br>
<p>From: &quot;James Rogers&quot; &lt;<a href="mailto:jamesr@best.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jamesr@best.com</a>&gt;
<br>
<em>&gt; Again, the computational process is irrelevant.  Equality of outcome
</em><br>
<em>&gt; demonstrates equivalence.
</em><br>
<p>While that is true for fully optimized systems (and I find your analysis thus
<br>
far exquisitely incisive), I'd add that equality of outcome does not
<br>
demonstrate equivalence when particular systems are deliberately impeded or
<br>
hindered. For example, a human who is drugged may do math no better than a
<br>
horse, but that doesn't mean the human brain cannot excel the equestrian brain
<br>
in mathematics. So, when it comes to low standards, equality of outcome may
<br>
actually indicate that someone is manipulating the results and/or the
<br>
performance of the processes in question.
<br>
When AI demonstrates human-competitive original thought, then it will no
<br>
longer be mechanical. It will be A-life.
<br>
<p>---   ---   ---   ---   ---
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego, human values, scientific relinquishment, malevolent AI,
<br>
non-sensory experience, SETI
<br>
<p>We  move into a better future in proportion as the scientific method
<br>
accurately identifies incorrect thinking.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1342.html">J. R. Molloy: "Re: Skeptics and extropians"</a>
<li><strong>Previous message:</strong> <a href="1340.html">Spudboy100@aol.com: "all your banana is are ours!- Kurzweil"</a>
<li><strong>In reply to:</strong> <a href="1286.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1348.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="1348.html">John Clark: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1341">[ date ]</a>
<a href="index.html#1341">[ thread ]</a>
<a href="subject.html#1341">[ subject ]</a>
<a href="author.html#1341">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:35 MST
</em></small></p>
</body>
</html>
