<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>extropians: Re: Jaron Lanier Got Up My Shnoz on AI</title>
<meta name="Author" content="Steve Nichols (steve@multisell.com)">
<meta name="Subject" content="Re: Jaron Lanier Got Up My Shnoz on AI">
<meta name="Date" content="2002-01-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Jaron Lanier Got Up My Shnoz on AI</h1>
<!-- received="Mon Jan 14 08:31:10 2002" -->
<!-- isoreceived="20020114153110" -->
<!-- sent="Mon, 14 Jan 2002 15:35:29 -0000" -->
<!-- isosent="20020114153529" -->
<!-- name="Steve Nichols" -->
<!-- email="steve@multisell.com" -->
<!-- subject="Re: Jaron Lanier Got Up My Shnoz on AI" -->
<!-- id="000601c19d11$1dfe6260$e38b193e@leeds.ac.uk" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="200201141310.g0EDA4h07316@tick.javien.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Steve Nichols (<a href="mailto:steve@multisell.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI"><em>steve@multisell.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 14 2002 - 08:35:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0942.html">Smigrodzki, Rafal: "RE: so few true iconoclasts...."</a>
<li><strong>Previous message:</strong> <a href="0940.html">Smigrodzki, Rafal: "RE: A Boring Movie"</a>
<li><strong>Maybe in reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0948.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0948.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#941">[ date ]</a>
<a href="index.html#941">[ thread ]</a>
<a href="subject.html#941">[ subject ]</a>
<a href="author.html#941">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;Date: Sun, 13 Jan 2002 11:01:21 -0800
</em><br>
<em>&gt;From: &quot;J. R. Molloy&quot; &lt;<a href="mailto:jr@shasta.com?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">jr@shasta.com</a>&gt;
</em><br>
<em>&gt;Subject: Re: Jaron Lanier Got Up My Shnoz on AI
</em><br>
<p>From: &quot;Colin Hales&quot; &lt;<a href="mailto:colin@versalog.com.au?Subject=Re:%20Jaron%20Lanier%20Got%20Up%20My%20Shnoz%20on%20AI">colin@versalog.com.au</a>&gt;
<br>
<em>&gt;&gt; He thinks it's
</em><br>
<em>&gt;&gt; religion to believe AI is possible, I think it's religion to hope that it
</em><br>
<em>&gt;&gt; can't.
</em><br>
<p><em>&gt;It looks as though Lanier confuses intelligence with sentience. We already
</em><br>
<em>&gt;have AI, as reported by John Koza almost two years ago in _Genetic
</em><br>
Programming
<br>
<em>&gt;and Evolvable Machines_, Volume 1, Number 1/2 (ISSN: 1389-2576).
</em><br>
<em>&gt;Self-awareness, or sentience, is an epiphenomenon that emerges from
</em><br>
massively
<br>
<em>&gt;parallel computational complexity such as the human brain engenders.
</em><br>
<p>There is no evidence for emergentism, and the philosophical case for
<br>
epiphenomenalism is weak at best. Complexity does not equate to
<br>
infinite-state (self organising circuitry) since finite-state, hard wired
<br>
systems can be equally complex. Sentience, abstract thought, is only
<br>
possible once a circuit has lost its external clock (primal eye) and
<br>
become analog(ous to infinite-state). www.multi.co.uk/primal.htm
<br>
<p><em>&gt; If
</em><br>
<em>&gt;artificial sentience (AS) emerges, it may complicate the business of
</em><br>
machine
<br>
<em>&gt;intelligence by causing autonomous robots to waste computing time in
</em><br>
<em>&gt;contemplation. So, I think you're right to suggest that robots will be
</em><br>
<em>&gt;designed to remain zombies... super-intelligent, but not self-aware,
</em><br>
because
<br>
<em>&gt;there's no money in creating machines that enjoy life as much as
</em><br>
<em>&gt;contemplatives do.
</em><br>
<p>This may well be true, except that many scientists are theory driven and
<br>
not commercially motivated. Also, who knows what side benefits might
<br>
accrue from MVT-based conscious machines?
<br>
<p>www.steve-nichols.com
<br>
Posthuman Organisation
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0942.html">Smigrodzki, Rafal: "RE: so few true iconoclasts...."</a>
<li><strong>Previous message:</strong> <a href="0940.html">Smigrodzki, Rafal: "RE: A Boring Movie"</a>
<li><strong>Maybe in reply to:</strong> <a href="0871.html">Colin Hales: "Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0948.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<li><strong>Reply:</strong> <a href="0948.html">James Rogers: "Re: Jaron Lanier Got Up My Shnoz on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#941">[ date ]</a>
<a href="index.html#941">[ thread ]</a>
<a href="subject.html#941">[ subject ]</a>
<a href="author.html#941">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Nov 01 2002 - 13:37:34 MST
</em></small></p>
</body>
</html>
