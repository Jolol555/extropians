<!-- received="Sat Jun 27 14:47:17 1998 MDT" -->
<!-- sent="Sat, 27 Jun 1998 16:47:12 -0400 (EDT)" -->
<!-- name="Daniel Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Ethics, Egoism &amp; Rationality" -->
<!-- id="Pine.SUN.3.91.980627131141.3140A-100000@tangelo.phys.unm.edu" -->
<!-- inreplyto="8025f9b5.359521e5@aol.com" -->
<title>extropians: Re: Ethics, Egoism &amp; Rationality</title>
<h1>Re: Ethics, Egoism &amp; Rationality</h1>
Daniel Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Sat, 27 Jun 1998 16:47:12 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2762">[ date ]</a><a href="index.html#2762">[ thread ]</a><a href="subject.html#2762">[ subject ]</a><a href="author.html#2762">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<li> <b>Previous message:</b> <a href="2761.html">Daniel Fabulich: "Re: Ethics"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<li> <b>Reply:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Sat, 27 Jun 1998 Shakehip@aol.com wrote:<br>
<p>
<i>&gt; I think we're going in circles here.    For an ethical theory to be true it</i><br>
<i>&gt; has to compared either to the "ends" or a "universal truth" - -</i><br>
<i>&gt; </i><br>
<i>&gt; In order for there to be a universal right or wrong, we'd have to ask if</i><br>
<i>&gt; ethics can be derived from the laws of "nature" (18th Century Philosophy) or</i><br>
<i>&gt; "god".   Then we could become natural talmudisists and begin implying  things.</i><br>
<p>
This is true.  For this reason, I've been maintaining a consequentialist<br>
rationality.<br>
<p>
<i>&gt; On the other hand, if our ethical system is relative to our percpetion of the</i><br>
<i>&gt; ends, then all ethical systems would be relative.    Obviously the ethical</i><br>
<i>&gt; system of an egoist vs. altruist would be quite different.</i><br>
<p>
Not necessarily, and it's because of the generalization principle.  If it<br>
is rational for me to be an egoist, then it is also rational for you to be<br>
an egoist.  However, if we were both egoists, we would both be worse off; <br>
this is bad, according to egoism and a consequentialist value system.  So<br>
what we find is that egoism fails to meet the requirements of<br>
generalization according to egoism's own value system; for this reason,<br>
egoism is fundamentally irrational. <br>
<p>
It's like the Prisoner's Dilemma: egoism demands that we both incriminate<br>
each other; utilitarianism demands that we both keep silent. <br>
Utilitarianism provides better results, so it is rational, according to<br>
consequentialism. <br>
<p>
<i>&gt; One - - rationality as implied by an ethical system    (This presumes that</i><br>
<i>&gt; what is right is rational and what is wrong is irrational.)</i><br>
<p>
This would be circular, as we are attempting to determine what is ethical<br>
by deriving it from rationality.<br>
<p>
<i>&gt; Two - - rationality as defined by the means vs. ends   (This presumes that</i><br>
<i>&gt; what works and leads to the "sum" is rational.)</i><br>
<p>
If we define "well-being" as the "sum," then I think this is the<br>
rationality which I tend to espouse.<br>
<p>
<i>&gt; Three - - axiomatic rationality as defined by a system of universal truths</i><br>
<i>&gt; (This presumes that the "answer" has already been given, and human logic has</i><br>
<i>&gt; to conform to it, or be lead astray.)</i><br>
<p>
Depends on what you mean by axioms.  For example, some axioms really *are*<br>
undeniable while remaining consistent; A=A leaps to mind.  Indeed, I think<br>
the generalization principle may be a similar axiom.<br>
<p>
Is consequentialism undeniable?  It may be.  Consider another value<br>
system, based on act types or motivations.  What act types are good?  What<br>
act types are bad?  What's a good/bad motivation?  I can't even imagine a<br>
value system which does not evaluate these in terms of their effects: that<br>
"having a good motive" means that you intend to improve well-being, or<br>
that a bad act type is one which reduces well-being.  These are all<br>
consequentialist value systems, however.  What other sorts of value<br>
systems could we even begin to consider? <br>
<p>
<i>&gt; </i><br>
<i>&gt; So in conclusion - - you have to qualify the term ethics or rationality by</i><br>
<i>&gt; stating what's the goal of your system of ethics or rationality.    The other</i><br>
<i>&gt; person may then respond by asking why.   If he does, that means there's an</i><br>
<i>&gt; assumption that your system is part of a larger system (be it ethical, the</i><br>
<i>&gt; laws of science, the universe, human nature, etc. etc.) and then you have to</i><br>
<i>&gt; decide whether you wish to accept this presumption, and if so, justify your</i><br>
<i>&gt; own system relative to that.   </i><br>
<i>&gt; </i><br>
<p>
OK.  I'm using a rationality which states that an action is rational to<br>
the extent that it is the one most likely to result in improved<br>
well-being. <br>
<p>
<i>&gt; In conclusion, I really don't like the world ethics, because it is a loaded</i><br>
<i>&gt; word with little meaning.   I prefer to qualify it with "ethical continuity" -</i><br>
<i>&gt; - thieves and liars too have there own system of ethics.. hence implying, if</i><br>
<i>&gt; they abide by it, they are "ethical".</i><br>
<p>
This is *not* true if we make the presumption I did at the beginning of<br>
this discussion: that the right ethical theory is the rational one. <br>
Within this context, I don't think that an ethical theory which condones<br>
professional thieves is right; if it is rational for one man to be a<br>
thief, then it is rational for anyone and everyone to be a thief.  Since<br>
it is not rational for everyone to become a thief (because everyone would<br>
be worse off, as measured by themselves), this ethical theory is wrong,<br>
and not rational. <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<li> <b>Previous message:</b> <a href="2761.html">Daniel Fabulich: "Re: Ethics"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<li> <b>Reply:</b> <a href="2763.html">Michael Nielsen: "Re: Moore's law"</a>
<!-- reply="end" -->
</ul>
