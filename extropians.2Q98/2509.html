<!-- received="Mon Jun 22 14:02:08 1998 MDT" -->
<!-- sent="Mon, 22 Jun 1998 21:59:15 +0200" -->
<!-- name="den Otter" -->
<!-- email="neosapient@geocities.com" -->
<!-- subject="Re: &gt;H ART: The Truman Show" -->
<!-- id="3.0.3.32.19980622125520.007497fc@econ.berkeley.edu" -->
<!-- inreplyto="&gt;H ART: The Truman Show" -->
<title>extropians: Re: &gt;H ART: The Truman Show</title>
<h1>Re: &gt;H ART: The Truman Show</h1>
den Otter (<i>neosapient@geocities.com</i>)<br>
<i>Mon, 22 Jun 1998 21:59:15 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2509">[ date ]</a><a href="index.html#2509">[ thread ]</a><a href="subject.html#2509">[ subject ]</a><a href="author.html#2509">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2510.html">davelook: "Re: Creationists"</a>
<li> <b>Previous message:</b> <a href="2508.html">Robin Hanson: "Economists Optimistic Re Population"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2513.html">Anders Sandberg: "Re: &gt;H ART: The Truman Show"</a>
<li> <b>Reply:</b> <a href="2513.html">Anders Sandberg: "Re: &gt;H ART: The Truman Show"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Michael Nielsen wrote:<br>
<p>
<i>&gt; Is it ethical to contain an AI in a limited world? This is an especially</i><br>
<i>&gt; interesting question if one takes the point of view that the most likely</i><br>
<i>&gt; path to Artificial Intelligence is an approach based on evolutionary</i><br>
<i>&gt; programming.</i><br>
<i>&gt; </i><br>
<i>&gt; Is it ethical to broadcast details of an AI's "life" to other</i><br>
<i>&gt; researchers or interested parties?</i><br>
<i>&gt; </i><br>
<i>&gt; Is it ethical to profit from the actions of an AI?</i><br>
<p>
Since AIs will presumably be made without emotions, or at least with<br>
a much more limited number of emotions than humans, you don't have<br>
to worry about their "feelings". Also, one of the first things you<br>
would ask an AI is to develop uploading &amp; computer-neuron interfaces,<br>
so that you can make the AI's intelligence part of your own. This would<br>
pretty much solve the whole "rights problem" (which is largely<br>
artificial anyway), since you don't grant rights to specific parts<br>
of your brain. A failure to integrate with the AIs asap would <br>
undoubtedly result in AI domination, and human extinction.<br>
 <br>
P.s: I'm almost certain that our ethics will become obsolete with<br>
the rise of SI, they are simply too much shaped by our specific<br>
evolution etc.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2510.html">davelook: "Re: Creationists"</a>
<li> <b>Previous message:</b> <a href="2508.html">Robin Hanson: "Economists Optimistic Re Population"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2513.html">Anders Sandberg: "Re: &gt;H ART: The Truman Show"</a>
<li> <b>Reply:</b> <a href="2513.html">Anders Sandberg: "Re: &gt;H ART: The Truman Show"</a>
<!-- reply="end" -->
</ul>
