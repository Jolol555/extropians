<!-- received="Sun May  3 20:34:23 1998 MDT" -->
<!-- sent="Sun, 3 May 1998 12:27:28 +0000" -->
<!-- name="Warrl kyree Tale'sedrin" -->
<!-- email="warrl@mail.blarg.net" -->
<!-- subject="Re: Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work" -->
<!-- id="199805040234.TAA11127@animal.blarg.net" -->
<!-- inreplyto="Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work" -->
<title>extropians: Re: Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work</title>
<h1>Re: Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work</h1>
Warrl kyree Tale'sedrin (<i>warrl@mail.blarg.net</i>)<br>
<i>Sun, 3 May 1998 12:27:28 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1280">[ date ]</a><a href="index.html#1280">[ thread ]</a><a href="subject.html#1280">[ subject ]</a><a href="author.html#1280">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1281.html">Warrl kyree Tale'sedrin: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Previous message:</b> <a href="1279.html">Warrl kyree Tale'sedrin: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Maybe in reply to:</b> <a href="1255.html">Paul Hughes: "Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; From:          Paul Hughes &lt;planetp@aci.net&gt;</i><br>
 <br>
<i>&gt; Dan Fabulich wrote:</i><br>
<i>&gt; </i><br>
<i>&gt; Moore's Law continues unabated, probabilistically yielding human-level AI</i><br>
<i>&gt; within 20 years.</i><br>
<p>
Moore's Law will *never* (pragmatically never) yield human-level AI.<br>
<p>
It will probably yield the processing power necessary to support such <br>
an AI; but no matter how many times the price/performance ratio of <br>
microcircuitry doubles, that doubling produces no software.<br>
<p>
I suppose that in theory if you left a sufficient number of computers <br>
capable (hardware-wise) of human-level AI lying around long enough, <br>
eventually one of them would be programmed to such an AI by the <br>
random influence of radiation; but I don't consider this an <br>
acceptably efficient programming technique.<br>
<p>
  Because of scalability it is also reasonable to expect<br>
<i>&gt; human-level AI before circuit density reaches levels equivalent to the human</i><br>
<i>&gt; brain. It's also reasonable that transhumans will gain access to substantial</i><br>
<i>&gt; improvements in neuro-enhacement and neuro-interface technology over the same</i><br>
<i>&gt; time period.</i><br>
<i>&gt; </i><br>
<i>&gt; Like cells in a muti-cellular organism, the internet is already allowing</i><br>
<i>&gt; multiple groups of humans to coordinate across geographic boundaries at a level</i><br>
<i>&gt; of coherence and complexity never before possible.  As networks, interface</i><br>
<i>&gt; software, virtual worlds and bandwidth improve, this trend can only continue.</i><br>
<i>&gt; When you add in the slow but steady improvement of neuro-enhancement</i><br>
<i>&gt; technologies, forthcoming 3rd and 4th generation smart drugs, wearable</i><br>
<i>&gt; computers, implantable interface technologies, personality software</i><br>
<i>&gt; agents/avatars, the human becomes transhuman on a scale never before</i><br>
<i>&gt; achievable.  More importantly these transhumans will be able to coordinate and</i><br>
<i>&gt; collective act in multi-faceted spontaneous networks mimicking a collective,</i><br>
<i>&gt; synergistic intelligence much greater than any individual transhuman.</i><br>
<i>&gt; </i><br>
<i>&gt; As this trend continues, computer intelligence will be continually increasing.</i><br>
<i>&gt; Up and until human-level AI is achieved, there is no reason why transhumans</i><br>
<i>&gt; cannot integrate these quasi-sentient AI's into their own intelligence</i><br>
<i>&gt; networks.</i><br>
<i>&gt; </i><br>
<i>&gt; At some point Human-level AI's are built.  Lets assume that they immediately</i><br>
<i>&gt; organize themselves around the sole purpose of taking over the world.  At first</i><br>
<i>&gt; they will be small in number.  Certainly not near the the number of their</i><br>
<i>&gt; human/transhuman counter-parts also attempting to rule the world.  Their goal</i><br>
<i>&gt; of course will be two-fold.  To increase their own intelligence and to create</i><br>
<i>&gt; as many copies of themselves as possible.  But to increase their own</i><br>
<i>&gt; intelligence they will need to do more than simply re-write their sofware.</i><br>
<i>&gt; They will also have to improve their hardware substrate.</i><br>
<i>&gt; </i><br>
<i>&gt; At some point both transhumans and Hyper-AI's will have to utilize</i><br>
<i>&gt; nanotechnology in their evolution towards greater complexity and intelligence.</i><br>
<i>&gt; </i><br>
<i>&gt; The question is who will reach what phases at what time?  And will the combined</i><br>
<i>&gt; forces of networked enhanced trans-humans be able to maintain a greater degree</i><br>
<i>&gt; of collective intelligence over networked AI's until uploading is reached?</i><br>
<i>&gt; </i><br>
<i>&gt; I think the answer to this question is far from being answered.</i><br>
<i>&gt; </i><br>
<i>&gt; Assuming transhumans can become post-human in similar nanotech substrates at or</i><br>
<i>&gt; before super-AI's, the war between  Hyper-AI's and Transhumans becomes moot.</i><br>
<i>&gt; Because at that point they will be us and we will be them - we will be made of</i><br>
<i>&gt; the same underlying nanotechnology.</i><br>
<i>&gt; </i><br>
<i>&gt; Comments, critiques?</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; Paul Hughes</i><br>
<i>&gt; planetp@aci.net</i><br>
<i>&gt; <a href="http://www.aci.net/planetp">http://www.aci.net/planetp</a></i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
US$500 fee for receipt of unsolicited commercial email. USC 47.5.II.227<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1281.html">Warrl kyree Tale'sedrin: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Previous message:</b> <a href="1279.html">Warrl kyree Tale'sedrin: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Maybe in reply to:</b> <a href="1255.html">Paul Hughes: "Hyper-AI's vs Transhumans  was: ECON The Abolition Of Work"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
