<!-- received="Mon Apr 27 21:20:04 1998 MDT" -->
<!-- sent="28 Apr 1998 16:17:56 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Sentience" -->
<!-- id="3.0.5.32.19980427224011.00a12c80@dgf4.mail.yale.edu" -->
<!-- inreplyto="Mon, 27 Apr 1998 20:09:32 -0600" -->
<title>extropians: Re: Sentience</title>
<h1>Re: Sentience</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>28 Apr 1998 16:17:56 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#988">[ date ]</a><a href="index.html#988">[ thread ]</a><a href="subject.html#988">[ subject ]</a><a href="author.html#988">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0989.html">The SHO master c.c.: "Re: Christian Society"</a>
<li> <b>Previous message:</b> <a href="0987.html">Dan Fabulich: "Re: Microsoft"</a>
<li> <b>In reply to:</b> <a href="0984.html">Tony Belding: "Sentience"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
tlbelding@htcomp.net (Tony Belding) writes:<br>
<p>
<i>&gt; Anders Sandberg &lt;asa@nada.kth.se&gt; wrote:</i><br>
<i>&gt; </i><br>
<i>&gt; AS&gt; I realize that their complexity is less than the chemical networks of</i><br>
<i>&gt; AS&gt; many bacteria, so I don't feel too bad about them. But this may become</i><br>
<i>&gt; AS&gt; a real problem in the future - the other graduate students here (me</i><br>
<i>&gt; AS&gt; included) are quite interested in creating a sentinent system if</i><br>
<i>&gt; AS&gt; possible, and once we start to get close to that, then we are going to</i><br>
<i>&gt; AS&gt; need to think much more about ethics.</i><br>
<i>&gt; </i><br>
<i>&gt; So, what do you think about rule-based AI projects, like Cyc?</i><br>
<p>
Well, I am biased since I do neural nets, mingle with connectionists<br>
and read neuroscience, but I think rule-based AI is too brittle to<br>
work in the real world. It is great within a clean domain, but runs<br>
into trouble when the complexity is too large. Of course, I think this<br>
is also a property of our own high level thinking: it only works when<br>
our low-level systems have cleaned away all the disruptive complexity<br>
from our sensory information. Most of the real work is filtering,<br>
categorizing and abstracting, not thinking.<br>
<p>
<i>&gt; I've thought about what kind of philosophical /purpose/ or role such artifical</i><br>
<i>&gt; sentient beings could fill.  They would, in practical terms, be a branch of</i><br>
<i>&gt; humanity.  They would be products of our culture, our civilization --</i><br>
<i>&gt; essentially humans in different form.  No identity of their own.</i><br>
<p>
Yes and no. They would not be true aliens, but they wouldn't be yet<br>
another form of humans (unless designed that way). Even a small<br>
difference in basic motivations would make them quite alien, and if<br>
they also have other differences (such as new forms of perception or<br>
no bodies) I think they would diverge quite quickly - while likely<br>
enriching humanity with a different point of view.<br>
<p>
<i>&gt; But, it now seems unlikely that our galaxy is teeming with aliens</i><br>
<i>&gt; just waiting for us to come and meet them.  We need to create our own aliens.</i><br>
<p>
Or become them. <br>
<p>
<i>&gt; I would like to find an Earth-like planet somewhere, or maybe terraform a</i><br>
<i>&gt; planet, and create a race of beings to inhabit it.  Drop the first generation</i><br>
<i>&gt; on the planet's surface with nothing: no language, no tools, no experience. </i><br>
<i>&gt; Then sit back and watch as they build their own civilization from nothing: a</i><br>
<i>&gt; slow and painful process, no doubt.  But, everything they had would be theirs,</i><br>
<i>&gt; not something borrowed from us.  They could develop a complete identity of</i><br>
<i>&gt; their own.</i><br>
<p>
An interesting and somewhat cruel experiment. [ARISTOI SPOLIER ALERT!]<br>
This is what the villains in Walter John William's _Aristoi_ do; one<br>
of the more interesting questions in the book is the ethics of doing<br>
this - is it needless cruelty or giving life?<br>
<p>
<i>&gt; What happens when a highly sophisticated, non-sentient AI can pass the Turing</i><br>
<i>&gt; Test?  How do you convince most people that a machine is non-sentient when it</i><br>
<i>&gt; can so convincingly /pretend/ to be?</i><br>
<p>
How do you convince other people that John K Clark is non-sentinent<br>
when he is so convincing?<br>
<p>
IMHO, if it quacks like a duck and walks like a duck, it is a duck or<br>
at least a good approximation. :-)<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0989.html">The SHO master c.c.: "Re: Christian Society"</a>
<li> <b>Previous message:</b> <a href="0987.html">Dan Fabulich: "Re: Microsoft"</a>
<li> <b>In reply to:</b> <a href="0984.html">Tony Belding: "Sentience"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
