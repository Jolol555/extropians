<!-- received="Sun Apr 12 09:47:54 1998 MDT" -->
<!-- sent="Sun, 12 Apr 1998 08:49:59 -0700" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: extropians-digest V2 #445" -->
<!-- id="199804120036.RAA03121@animal.blarg.net" -->
<!-- inreplyto="extropians-digest V2 #445" -->
<title>extropians: Re: extropians-digest V2 #445</title>
<h1>Re: extropians-digest V2 #445</h1>
J. R. Molloy (<i>jr@shasta.com</i>)<br>
<i>Sun, 12 Apr 1998 08:49:59 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#319">[ date ]</a><a href="index.html#319">[ thread ]</a><a href="subject.html#319">[ subject ]</a><a href="author.html#319">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0320.html">Yak Wax: "Re: Definitions for Transhumanism"</a>
<li> <b>Previous message:</b> <a href="0318.html">PaR: "RE: META: Re: [Meta] - Attachment problem???"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt;Date: Sat, 11 Apr 1998 15:48:48 +0400</i><br>
(MSD)<br>
<i>&gt;From: Eugene Leitl</i><br>
&lt;eugene@liposome.genebee.msu.su&gt;<br>
<i>&gt;Subject: Re: Definitions for</i><br>
Transhumanism<br>
<i>&gt;</i><br>
<i>&gt;On Thu, 9 Apr 1998, Randy Smith wrote:</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; I like it, Scott, and that's not to</i><br>
disparage the other definitions<br>
<i>&gt;&gt; others may have offered, but it kind</i><br>
of ties in with a Randy-Smith<br>
<i>&gt;&gt; truism:  many, if not most, humans</i><br>
are, in some fundamental way,<br>
<i>&gt;&gt; unhappy. That ultimate state of</i><br>
self-actualization would seemingly<br>
<i>&gt;</i><br>
<i>&gt;If we were not unhappy, there would be</i><br>
zero impetus to change. No impetus<br>
<i>&gt;to change in an coevolutionary context</i><br>
guarantees failure before long.<br>
<i>&gt;Hence this is no surprise that the</i><br>
majority of us is not happy. I am<br>
<i>&gt;pretty happy to be unhappy, actually.</i><br>
Saves one from being an<br>
<i>&gt;beautifically smiling evolutionary cul</i><br>
de sac.<br>
<p>
Pardon me for butting in, but IMHO the<br>
impetus for change ought to come from<br>
happy, not unhappy people, because<br>
unhappy people may tend to harbor<br>
feelings of envy, spite, or vengeance.<br>
It becomes difficult to trust the<br>
motives of unhappy people. Happy people,<br>
in contrast, already know what it takes<br>
to live life successfully, and can<br>
therefore transmit the knowledge to<br>
others. Happy, self-actualized folks<br>
want to change the world so that 'more'<br>
people can live happily and<br>
successfully.<br>
<p>
Examples of unhappy people who wanted to<br>
change the world: Napoleon, Hitler,<br>
Stalin, Mussolini (and his<br>
granddaughter), Marx, Mao Zedong, etc.<br>
<p>
Examples of happy, self-realized,<br>
enlightened people who set out to change<br>
the world include Buddha, Lao Tzu,<br>
Krishna, Gurdjieff, Socrates, Galileo,<br>
Max More, etc.<br>
<p>
Those who plan to change the world<br>
either want to share their own happiness<br>
or they want revenge and requital. I'll<br>
put my money on blissful, joyful,<br>
prosperous pundits rather than on<br>
miserable losers and sore heads.<br>
Furthermore, people who know how to<br>
effect change stand the best chance of<br>
enjoying happiness in their own lives. I<br>
believe many people remain unhappy<br>
because they don't know how to change<br>
themselves -- never mind change the<br>
world.<br>
<p>
<i>&gt;&gt; would think when one controls matter</i><br>
on a nanotech scale,<br>
<i>&gt;&gt; self-actualization is only a matter</i><br>
of twiddling brain biochemistry.<br>
<p>
Perhaps so, but then your happiness<br>
depends on continued twiddling of brain<br>
biochemistry forever. Then you become an<br>
addict (not to say a slave) to twiddled<br>
biochemistry.<br>
<p>
<i>&gt;&gt; There would seem to be gene survival</i><br>
advantages in the unhappy and<br>
<i>&gt;&gt; self-actualization-seeking human.</i><br>
<p>
Then again, going extinct doesn't afford<br>
much opportunity for happiness. No one,<br>
AFAIK, has ever demonstrated that<br>
self-actualization succumbs to seeking.<br>
It rather arises when seeking ends.<br>
<p>
<i>&gt;&gt; As far as utilizing "rational</i><br>
technologies" to acheive<br>
<i>&gt;&gt; self-actualization" ends, I guess it</i><br>
is a transition from the<br>
<i>&gt;&gt; "spiritual technologies" previously</i><br>
used, eh?<br>
<p>
Reason without spirit may lead to<br>
apathy; spirit without reason usually<br>
leads to lunacy. Although I neither<br>
decry nor applaud apathy (good bumper<br>
sticker there), I have no use for lunacy<br>
either. I suspect that<br>
self-actualization constitutes more of<br>
an attainment than an achievement... it<br>
has to do with giving yourself<br>
permission to get over all the nonsense<br>
they taught you in school.<br>
<p>
<i>&gt;&gt; I have heard that many cryonicists</i><br>
(and I understand that many<br>
<i>&gt;&gt; extropians are cryos or wannabe</i><br>
cryos) see cryonics as a chance at<br>
<i>&gt;&gt; another life, one in which they can</i><br>
fulfill their goals<br>
<i>&gt;&gt; (self-actualize).  Comments?</i><br>
<i>&gt;</i><br>
<i>&gt;Unless we can get out of the Darwin</i><br>
box, which is probably impossible, you<br>
<i>&gt;can't remain in the state of eternal</i><br>
bliss. We can homeostate us to max<br>
<i>&gt;out the kick we get from being a rat</i><br>
the rat race, though.<br>
<p>
Oops! Sorry. I didn't know that Eugene<br>
and Randy used the term /self-actualize/<br>
to mean /fulfill their goals/. I had<br>
supposed that self-actualization meant<br>
transcending goal-oriented existence. It<br>
appears to me that as a mere human I<br>
can't now comprehend what life will<br>
render to transhumans who survive the<br>
Singularity. But that suits me fine,<br>
since the transhumans will undoubtedly<br>
fully comprehend what life means to<br>
humans. Just as the human embryo<br>
undergoes  fish-like and reptilian<br>
phases, so transhumans will likely go<br>
through a human-like phase during their<br>
formation.<br>
<p>
Cheers,<br>
<p>
J R<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0320.html">Yak Wax: "Re: Definitions for Transhumanism"</a>
<li> <b>Previous message:</b> <a href="0318.html">PaR: "RE: META: Re: [Meta] - Attachment problem???"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
