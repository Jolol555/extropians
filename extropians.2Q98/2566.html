<!-- received="Tue Jun 23 17:54:09 1998 MDT" -->
<!-- sent="Tue, 23 Jun 1998 20:01:57 -0400 (EDT)" -->
<!-- name="Hiro Protagonist" -->
<!-- email="hiro@protagonist.net" -->
<!-- subject="Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)" -->
<!-- id="199806232307.RAA20813@maxwell.kumo.com" -->
<!-- inreplyto="358EE746.BB0@geocities.com" -->
<title>extropians: Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)</title>
<h1>Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)</h1>
Hiro Protagonist (<i>hiro@protagonist.net</i>)<br>
<i>Tue, 23 Jun 1998 20:01:57 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2566">[ date ]</a><a href="index.html#2566">[ thread ]</a><a href="subject.html#2566">[ subject ]</a><a href="author.html#2566">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2567.html">Daniel Fabulich: "Re: Special Relativity"</a>
<li> <b>Previous message:</b> <a href="2565.html">Scott Badger: "Re: AI's and Emotions"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2584.html">Anders Sandberg: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<li> <b>Reply:</b> <a href="2584.html">Anders Sandberg: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; Emotions are important for us because they help us to survive. AIs</i><br>
<i>&gt; don't need to fend for themselves in a difficult environment; they</i><br>
<p>
Without the motive to do so, no entity needs to develop imagination. <br>
Without imagination and volition, we'll never have true AI. That is what<br>
is at the heart of the kind of intelligence we posess, and it cannot be<br>
hardwired into a system, it must evolve through complex feedback from an<br>
external environment.  Without obstacles to overcome and problems to<br>
solve, the most fundamental being the continuation of its own mind-state<br>
through 'difficult situations', no AI will ever be anything more than a<br>
deterministic expert system, i.e., not intelligent as we apply the term to<br>
ourselves. <br>
<p>
<i>&gt; get all the energy, protection &amp; imput they need from humans and</i><br>
<i>&gt; other machines. All they have to do is solve puzzles (of biology,</i><br>
<i>&gt; programming etc). If you program it with an "urge" to solve puzzles</i><br>
<i>&gt; (just like your PC has an "urge" to execute your typed orders), it</i><br>
<p>
What fundamentally distinguishes such a machine from your PC, in that<br>
case?<br>
<p>
<i>&gt; trauma, then there is no reason to worry about it's well-being</i><br>
<i>&gt; (for it's own sake). AIs can almost certainly be made this way, </i><br>
<i>&gt; with no more emotions than a PC. </i><br>
<p>
They almost certainly can NOT.<br>
<p>
In fact, I expect it will be impossible to create a virtual world of<br>
sufficient complexity to allow an AI 'baby' to achieve conceptual<br>
awareness at all. Certainly far more complex than to create the AI 'baby'<br>
itself. One would probably have to wire up the baby with enough sensory<br>
organs to allow it to accumulate a rich enough sensory and perceptual<br>
experience, with plenty of feedback mechanisms, and let it free in the<br>
real world if one expected it to get anywhere in its cognitive growth. <br>
<p>
<i>&gt; Clearly a difficult matter, but it always comes down to "firepower"</i><br>
<i>&gt; in the end (can you blackmail the other into doing something he</i><br>
<i>&gt; doesn't like?-- that's the question).</i><br>
<p>
Might != Right<br>
<p>
'Right' implies what is 'right' for the entity in question, what is in<br>
accordance with its nature. In the case of free-willed, rational,<br>
conceptually conscious entities, what's right is unrestricted freedom of<br>
thought, expression, creation, and trade. Might is almost always exactly<br>
the opposite of what's 'right' for such entities. It disables them from<br>
operating in accordance with their basic nature and negates the whole<br>
point of their existence in the first place.<br>
<p>
<i>&gt; AI with delusions of grandeur is more productive, then there</i><br>
<i>&gt; will always be some folks that will make it. Terrorists or</i><br>
<i>&gt; dictators could make "evil" AIs on purpose, there might be</i><br>
<p>
If it was intelligent, it could choose whether or not it wanted to be<br>
'evil', i.e. act in violation of, and against, it's own basic nature, or<br>
'good', acting in accordance with its nature as a volitional, conceptually<br>
conscious entity. You couldn't 'make' an AI evil any more than you can<br>
'make' a child evil, or good. If the term 'inteligence' has any meaning at<br>
all in this context besides being able to beat Karpov at chess, then the<br>
thing would do as it bloody well pleased.<br>
<p>
<i>&gt; nukes or the internet. For the first time in history, there will</i><br>
<i>&gt; be beings that are (a lot) smarter and faster than us. If this</i><br>
<i>&gt; goes unchecked, mankind will be completely at the mercy of </i><br>
<i>&gt; machines with unknown (unkowable?) motives. Gods really.</i><br>
<p>
Well, seeing that the world currently seems to be full of 'might is right'<br>
ignoramuses like you, perhaps that wouldn't be all that bad. Us Gods do<br>
get lonely on this barren planet.<br>
<p>
Hiro<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2567.html">Daniel Fabulich: "Re: Special Relativity"</a>
<li> <b>Previous message:</b> <a href="2565.html">Scott Badger: "Re: AI's and Emotions"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2584.html">Anders Sandberg: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<li> <b>Reply:</b> <a href="2584.html">Anders Sandberg: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<!-- reply="end" -->
</ul>
