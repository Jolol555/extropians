<!-- received="Tue Jun 30 09:03:35 1998 MDT" -->
<!-- sent="Tue, 30 Jun 1998 11:03:01 EDT" -->
<!-- name="VirgilT7@aol.com" -->
<!-- email="VirgilT7@aol.com" -->
<!-- subject="Re: Information" -->
<!-- id="3.0.5.16.19980629021035.2ac7c06c@shell3.ba.best.com" -->
<!-- inreplyto="Information" -->
<title>extropians: Re: Information</title>
<h1>Re: Information</h1>
<i>VirgilT7@aol.com</i><br>
<i>Tue, 30 Jun 1998 11:03:01 EDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2850">[ date ]</a><a href="index.html#2850">[ thread ]</a><a href="subject.html#2850">[ subject ]</a><a href="author.html#2850">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2851.html">QueeneMUSE@aol.com: "Fwd:  Virtual Worlds 98"</a>
<li> <b>Previous message:</b> <a href="2849.html">Jim Barnebee: "Re: The end of Privacy"</a>
<li> <b>Maybe in reply to:</b> <a href="2840.html">John K Clark: "Information"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
In a message dated 6/30/98 12:30:28 AM Eastern Daylight Time, johnkc@well.com<br>
writes:<br>
<p>
&lt;&lt; ... They had perfectly <br>
 respectable evidence, copies of the newspapers, and their belief was even <br>
 true (the war ended on Nov. 11) but was it knowledge?  I'm not sure it <br>
 matters what it was because the war was definitely  over and their belief was<br>
 true.&gt;&gt;<br>
<p>
Did it matter much to them after they found out that the war really WAS over?<br>
Probably not.  Did they know the war was over on Nov. 11 before they received<br>
other confirmation of it?  Absolutely not.  The war could've ended several<br>
days later and on November 11th they still would have thought it to be ended<br>
then.  Therefore, they did not know.  I'm not sure what the point of the story<br>
is though.  Like I said, we really don't require knowledge to function, just a<br>
series of luckily true beliefs (like the men in the boat were lucky) or a<br>
series of handy false beliefs.  But perhaps the possession of knowledge is a<br>
good in itself.<br>
                 <br>
 <br>
 &lt;&lt; Making predictions and manipulating the world is the most we can hope for,<br>
 nobody has seen deep reality. Our brain just reacts to the electro-chemical <br>
 signals from nerves connected to a transducer called an eye. Our computers  <br>
 react to the electronic signals from wires connected to a transducer called  <br>
 an TV camera. &gt;&gt;<br>
<p>
Your first statement goes well beyond making predictions and manipulating the<br>
world.  It says something deeper about the reality of the world.  So, I think<br>
simply to make the argument that we can only hope for predictions and theories<br>
of manipulation you must actually refute that argument (rather like the<br>
subjectivist who claims that it's true that there is no objective form of<br>
truth).  And I'm a bit suspicious of comparisons of the brain to the computer,<br>
by the way.  They're well and good up to a point of course.  But every era has<br>
seen its own favorite form of comparison, from a mechanical comparison (in the<br>
18th and 19th centuries) to a "switchboard" comparison (early 20th century)<br>
and now a computer comparison, and all have in one way or another taken the<br>
analogy too far.  Our brains are different from computers not merely in terms<br>
of the quantity of connections but in organization and quality.  They don't<br>
react to stimuli in the same way a computer does, because stimuli to a<br>
computer does not produce any mental content whereas in the brain it sometimes<br>
does.<br>
<p>
 &lt;&lt; Our brain uses theories to explain these signals, so would intelligent  <br>
 computers. Theories explain how some sense sensations relate to other sense <br>
 sensations. For example we receive information from our eyes,  we interpret <br>
 that information as a rock moving at high speed and heading toward a large <br>
 plate glass window, we invent a theory that predicts that very soon we will <br>
 receive another sensation, this time from our ears, that we will describe as <br>
 the sound of breaking glass. Soon our prediction is confirmed so the theory <br>
 is successful, but we should remember that the sound of broken glass is not<br>
 broken glass, the look of broken glass is not broken glass, the feel of <br>
 broken glass is not broken glass. What "IS" broken glass? It must have stable<br>
 properties of some sort or I wouldn't be able to identify it as a "thing",  <br>
 I don't know what those ultimate stable properties are, but I know what they<br>
 are not, they are not sense sensations.  I have no idea what glass "IS". <br>
 The sad truth is, I can point to "things" but I don't know what a thing "IS" <br>
 and I 'm not even sure that I  know what "IS" is, and an intelligent computer<br>
 would be in exactly the same boat I am.&gt;&gt;             <br>
                            <br>
I think though that physics has taken us a long ways towards understanding<br>
what a thing is, and that we understand the meaning of "is" in its existential<br>
sense rather well; and if we don't then I think that we can understand what it<br>
means, especially given our frequent use of it.   <br>
 <br>
<p>
&lt;&lt; Definitions should be consistent and are useful when communicating ideas<br>
with <br>
 other people but when it comes down to it, they're just words about words <br>
 that are defined by still more words and round and round we go. Examples are <br>
 far more important.&gt;&gt;<br>
<p>
Definitions are derived ultimately I think from examples, but I also think<br>
that to truly understand why the examples are relevant and important we must<br>
extract definitions and meaning from them on a conscious, not merely<br>
unconscious level.  To not play close attention to the concepts we take for<br>
granted is to fall into a pit of ignorance and stagnation.  Given the many<br>
concepts taken for granted that fell apart when finally subjected to close<br>
scrutiny, I think this only makes sense.<br>
          <br>
 <br>
&lt;&lt; Give me an example, I don't care how wild or exotic, of a way to prove that<br>
 there is something more fundamental than information.&gt;&gt;<br>
<p>
Well... we'd proceed from an explanation showing information to really be a<br>
set of facts about something to an explanation showing that facts refer to<br>
aspects of the world to a conclusion that aspects of the world "cause" the<br>
existence of facts and information, and that therefore information is caused<br>
by that which information is about, and that therefore there is something more<br>
fundamental than information.<br>
 <br>
 <br>
 &lt;&lt; But nothing can provide anything but information.&gt;&gt;<br>
<p>
What about food, or light, or oxygen?<br>
                   <br>
 <br>
 &lt;&lt; You are not a brain in a skull as you'd assumed you are a brain in a vat. <br>
 The day after you were born your brain was removed and placed in a artificial<br>
 nutriment bath. You have no sense organs but the parts of your brain that  <br>
 would have received information from them now receive input from a vast <br>
 digital computer providing you with a virtual reality. &gt;&gt;<br>
<p>
Hilary Putnam's old brain in a vat story eh?  Well here's the thing.  I don't<br>
see how such a story can be disproven.  Not yet anyway.  This doesn't mean<br>
that it's impossible to disprove, only that there doesn't seem to be any way<br>
to do so at the moment.  Perhaps as we become more aware of the assumptions<br>
and structures involved in our thought, we'll stumble upon a contradiction in<br>
it.  In any event, all we really have to show to defeat skepticism is show how<br>
knowledge is possible =despite= stories like the above.  This is along the<br>
lines of Nozick's explanations vs. arguments distinction.  <br>
<p>
 <br>
&lt;&lt; Prove I'm wrong and you've proven there is something more fundamental than <br>
 information. But you can't. &gt;&gt;<br>
<p>
Proving the story right or wrong doesn't necessarily have anything to do with<br>
proving anything more fundamental than information.<br>
<p>
&lt;&lt; Metaphor? I seems just about as exact and concrete as things get. The cell <br>
 certainly acts like it understands what the nucleotide triplet CAU means, <br>
 it does things differently when it receives the message and that's what  <br>
 information is supposed to do, we do the same thing. Don't take my word for <br>
 it, go to the laboratory and ask the cell what CAU means and it will always <br>
 tell you exactly the same thing, histidine&gt;&gt;<br>
<p>
The cell doesn't really understand anything though.  It's merely responding to<br>
stimuli WITHOUT understanding either the stimuli or anything else.  It's not<br>
conscious.  You may as well talk of a paper "understanding" water when it<br>
blots it up.<br>
<p>
                 <br>
  &lt;&lt;        &gt;One computer no more communicates with another than the lightning<br>
<i>         &gt;communicates with a tree when it cuts it in half.  </i><br>
 <br>
 The effects of lightning are not repeatable, sometimes it blasts the tree in <br>
 3 parts, sometimes 4, sometimes it sets the tree on fire, sometimes it does <br>
 nothing at all, on the other hand CAU always causes the cell to do the same <br>
 thing, add histidine to a protein sequence. There is no evidence lightning <br>
 has ever built something complex, there is plenty of evidence that life and<br>
 computers have. Also lightning has only one letter and a language needs at <br>
 least two, the genetic code has 4.&gt;&gt;<br>
<p>
The effects are repeatable if the strength and angle of the bolt of lightning<br>
are the same, and the receiver of the "message" is the same, just as the<br>
results of a program (ignoring randomization functions) would be the same if<br>
the input were the same.  Lightning has many letters, formed by the different<br>
angles and strengths.  But obviously lightning does not "communicate" with any<br>
tree.  And, therefore, clearly, neither does any other non-conscious thing.<br>
                 <br>
 <br>
 &lt;&lt;Certainly. If I hand you a message that has meaning to you it will do <br>
 something to you, the message CAU means something to the ribosomes in a cell <br>
 making a protein and it does something to it.&gt;&gt;<br>
<p>
CAU doesn't mean anything to the ribosomes.  It causes ribosomes to react in a<br>
certain way, but so what?  If you hand me a message, AND I understand it, then<br>
it has meaning to me.  If I do not understand it, it has no meaning to me<br>
despite the fact that it causes certain reactions in my brain.  If meaning<br>
were simply anything that causes a reaction in something else, then I wouldn't<br>
have to understand the message for the message to have meaning.  But I do.<br>
Therefore understanding is necessary for meaning and is necessary for<br>
language.<br>
 <br>
<p>
<p>
<p>
Andrew<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2851.html">QueeneMUSE@aol.com: "Fwd:  Virtual Worlds 98"</a>
<li> <b>Previous message:</b> <a href="2849.html">Jim Barnebee: "Re: The end of Privacy"</a>
<li> <b>Maybe in reply to:</b> <a href="2840.html">John K Clark: "Information"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
