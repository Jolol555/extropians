<!-- received="Sat May  9 15:56:30 1998 MDT" -->
<!-- sent="09 May 1998 23:56:26 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Hyper-AI's vs Transhumans" -->
<!-- id="3.0.5.32.19980509165342.007f9a30@dgf4.mail.yale.edu" -->
<!-- inreplyto="Sat, 09 May 1998 09:45:41 -0400" -->
<title>extropians: Re: Hyper-AI's vs Transhumans</title>
<h1>Re: Hyper-AI's vs Transhumans</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>09 May 1998 23:56:26 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1541">[ date ]</a><a href="index.html#1541">[ thread ]</a><a href="subject.html#1541">[ subject ]</a><a href="author.html#1541">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1542.html">Anders Sandberg: "Re: Hyper-AI's vs Transhumans"</a>
<li> <b>Previous message:</b> <a href="1540.html">Anders Sandberg: "Re: An IQ Gene"</a>
<li> <b>In reply to:</b> <a href="1538.html">Dan Clemmensen: "Re: Hyper-AI's vs Transhumans"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1829.html">Hara Ra: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Dan@Clemmensen.ShireNet.com (Dan Clemmensen) writes:<br>
<p>
<i>&gt; I nave now stated the 1998 version of the "spike",(the</i><br>
<i>&gt; "instantaneous" scenario) and Anders has restated the "swell"</i><br>
<i>&gt; (historically-rapid-but-not-instant scenario.) Anders' preferred</i><br>
<i>&gt; spot in the scenario space is:</i><br>
<i>&gt; --transition initiation team size: a large subset of the research community,</i><br>
<i>&gt;  or perhaps society as a whole.</i><br>
<i>&gt; --transition time: "historically rapid" (a decade?)</i><br>
<i>&gt; --post-transition SI population: large(?)</i><br>
<i>&gt; </i><br>
<i>&gt; This is in contrast to the "spike":</i><br>
<i>&gt; --transition initiation team size: 1 human, or at most a few.</i><br>
<i>&gt; --transition time: days or weeks</i><br>
<i>&gt; --post-transition SI population: single (perhaps incorporating humans</i><br>
<i>&gt;   and/or transhumans with apparent autonomy)</i><br>
<p>
A good summary. I indeed believe in a large SI population,<br>
although I hold open the possibility of borganisms and functional<br>
soups.<br>
<p>
<i>&gt; It may be useful to try to agree on the essence of the difference,</i><br>
<i>&gt; and perhaps on our points of agreement also. I think the essence</i><br>
<i>&gt; of the difference centers on the nature of intelligence</i><br>
<i>&gt; augmentation (IA).</i><br>
<i>&gt; </i><br>
<i>&gt; The "spike" assumes that a human-computer collaboration can yield</i><br>
<i>&gt; an effective intelligence amplification without first solving</i><br>
<i>&gt; other hard problems in the many fields of knowledge related to</i><br>
<i>&gt; intelligence. The spike further assumes that the resulting augmented</i><br>
<i>&gt; intelligence can further improve itself by identifying and relieving</i><br>
<i>&gt; its constraints, perhaps by solving some of those hard problems.</i><br>
<i>&gt; In my paper on the subject, I focus on rapid augmentation of the</i><br>
<i>&gt; computer capacity available to the collaboration.</i><br>
<i>&gt; </i><br>
<i>&gt; By contrast, the "swell" argues that the problems are in fact hard</i><br>
<i>&gt; and that many of them must be solved before IA can occur. Perhaps</i><br>
<i>&gt; solving a human-computer interface problem can yield a modest IA,</i><br>
<i>&gt; but this is not sufficient to rapidly solve the next problem: you'll</i><br>
<i>&gt; still need a lab full of human specialists for each problem. I will not</i><br>
<i>&gt; generally be possible for a group of (say) human interface specialists</i><br>
<i>&gt; to discover an IA technique based on a new human interface and then</i><br>
<i>&gt; apply the IA to discover another IA technique in another field (say</i><br>
<i>&gt; computer networking.) Instead, the human interface IA technique will</i><br>
<i>&gt; be diseminated, and a computer networking group will apply it.</i><br>
<i>&gt; Anders, please correct this if it's wrong. </i><br>
<p>
Sounds about right again. <br>
<p>
In some sense the spike scenario assumes that IA can improve general<br>
intelligence and that it can fairly quickly gain the skills needed to<br>
apply it to new areas. The swell scenario assumes IA methods mainly<br>
amplify specific intelligence or skills rather than general<br>
intelligence (even if the method is applicable to most of them).<br>
<p>
<i>&gt; Thus, IMO the central difference is that the "spike" assumes the</i><br>
<i>&gt; discovery of an IA technique that boosts intelligence enough so</i><br>
<i>&gt; that the resulting augmented intelligence can rapidly discover another</i><br>
<i>&gt; such technique. The "swell" assumes that no such event will occur, and</i><br>
<i>&gt; each IA discovery is non-singularity event: it is either incremental,</i><br>
<i>&gt; or it requires a large external resource input, or it is otherwise</i><br>
<i>&gt; rate-constrained.</i><br>
<p>
Exactly. There can of course be cascades of discoveries, but in the<br>
end they run into constraints. After all, how easy is it to learn a<br>
whole new field (like nanotech) in order to get around a hardware<br>
problem? It might be quicker to involve a team of already educated<br>
nanotechnologists and give them access to IA (which hopefully is easy<br>
to use, one problem might be that IA becomes so personalized over time<br>
that one cannot simply give away one's interface to another, but the<br>
person needs to "grow into" it over some time).<br>
<p>
<i>&gt; The "swell" hypothesis has history on its side: we have in fact</i><br>
<i>&gt; discovered IA techniques in the past, (notably moveable type, the</i><br>
<i>&gt; computer, the GUI) and none of them resulted in a "spike". The</i><br>
<i>&gt; "spike" proponents believe that history cannot be a guide here:</i><br>
<i>&gt; the "spike" can only happen once.</i><br>
<p>
Yes. The spike is supported by the idea that IA techniques of this<br>
capacity as we now assume have not occured in the past.<br>
 <br>
<i>&gt; &gt; Perhaps a better discussion would be how we *practically* immanentize</i><br>
<i>&gt; &gt; the transcension? :-)</i><br>
<i>&gt; </i><br>
<i>&gt; The best I can do is to try to keep up with new advances in relevant</i><br>
<i>&gt; technical fields. For me, the most relevant fields are data communications,</i><br>
<i>&gt; computer architecture, distributed computing, human/computer interfaces,</i><br>
<i>&gt; nanotechnology, information storage and retrieval, and software development</i><br>
<i>&gt; tools. I'm very aware that others of us use radically different lists,</i><br>
<i>&gt; but IMO that's good. You can be in my SI if I can be in yours :-)</i><br>
<p>
It's a deal! :-)<br>
<p>
My list includes yours, with cognitive psychology, neuroscience and<br>
neural networks as additions. We all have our biases...<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1542.html">Anders Sandberg: "Re: Hyper-AI's vs Transhumans"</a>
<li> <b>Previous message:</b> <a href="1540.html">Anders Sandberg: "Re: An IQ Gene"</a>
<li> <b>In reply to:</b> <a href="1538.html">Dan Clemmensen: "Re: Hyper-AI's vs Transhumans"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1829.html">Hara Ra: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
