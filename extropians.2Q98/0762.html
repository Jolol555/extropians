<!-- received="Fri Apr 24 09:10:45 1998 MDT" -->
<!-- sent="Fri, 24 Apr 1998 17:08:18 +0200" -->
<!-- name="Henri Kluytmans" -->
<!-- email="hkl@stack.nl" -->
<!-- subject="Re: Ethics of being a Creator" -->
<!-- id="3.0.1.32.19980424170818.00687278@popserver.stack.nl" -->
<!-- inreplyto="Ethics of being a Creator" -->
<title>extropians: Re: Ethics of being a Creator</title>
<h1>Re: Ethics of being a Creator</h1>
Henri Kluytmans (<i>hkl@stack.nl</i>)<br>
<i>Fri, 24 Apr 1998 17:08:18 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#762">[ date ]</a><a href="index.html#762">[ thread ]</a><a href="subject.html#762">[ subject ]</a><a href="author.html#762">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0763.html">Anders Sandberg: "Re: future pets"</a>
<li> <b>Previous message:</b> <a href="0761.html">neosapient@geocities.com: "The aliens are coming (Was: Re: Contacting God)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0764.html">Anders Sandberg: "Re: Ethics of being a Creator"</a>
<li> <b>Reply:</b> <a href="0764.html">Anders Sandberg: "Re: Ethics of being a Creator"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Anders Sandberg wrote: <br>
<p>
<i>&gt;That sounds nice, but it might not be easy to do. </i><br>
<p>
Indeed, but I didn't say it would be easy.<br>
<p>
<i>&gt;First, some of the entities might suffer a gradual decline (like </i><br>
<i>&gt;humans with Alzheimer's disease), would it be nice to save backup </i><br>
<i>&gt;copies of their final, degraded state or should one save copies </i><br>
<i>&gt;from an earlier state? If so, why just one, why not several? </i><br>
<p>
When the creator has enough power to simulate a universe, he most <br>
also have enough power to merge the backup copies of earlier states <br>
with the later backups of the degraded states, and to construct <br>
from those multiple states a "healthy" state, containing all memories <br>
of the being. Of course one has to define what a "healthy" state is <br>
first.<br>
<p>
<p>
<i>&gt;Second, it might not even be clear to the creator which entities </i><br>
<i>&gt;are sentinent and which are not (there might be a lot of </i><br>
<i>&gt;intelligence hidden in the apparent chaos of type III CAs, </i><br>
<i>&gt;invisible until you look at the principal fourier components). </i><br>
<p>
OK, this is maybe the most difficult part. Indeed it's possible <br>
that the creator will not be able to detect all sentient beings. <br>
But I'm fairly sure he will be able to detect most of them. <br>
<p>
If sentient beings will develop (that are also able to selfreproduce) <br>
it is very likely they will transform their environment considerably. <br>
This process is exponential. (Look at how the human beings have <br>
already transformed our environment (Earth). And how we could likely <br>
transform are whole galaxy within a million years.)<br>
This reasoning presumes that reproducing sentient beings will at one <br>
time develop a technological civilization. I think however that this <br>
is quite likely. <br>
<p>
At a point in time the technological civilization will have transformed <br>
its environment a considerable amount, it should then be quite feasible <br>
to detect this pattern in the simulation. Now, the creator only has to <br>
play back the simulation and extract al the sentient beings of the <br>
earlier generations of this civilization. <br>
<p>
Of course, sentient beings that will not develop a technical <br>
civilization are much harder to detect. <br>
<p>
And how does one determine if a being is sentient enough to be <br>
worth being restored.<br>
<p>
<p>
<i>&gt;Third, the afterlife is rather underdetermined: how to</i><br>
<i>&gt;keep the entities from pain *there*?</i><br>
<p>
When the entities are restored in a separate simulation there <br>
is now no reason anymore not to communicate with them. So the <br>
creator could ask the sentient beings themselves if they are happy <br>
or not. Or even give them the capabilities to alter themselves <br>
in to a state they individually prefer.<br>
<p>
<p>
<i>&gt;Even when the creator has no idea about what sentient beings will</i><br>
<i>&gt;emerge? If you create a world top-down, in the genesis fashion ("Let</i><br>
<i>&gt;there be animals, to the following specifications... Let there be</i><br>
<i>&gt;chemistry to implement the animals, to the following</i><br>
<i>&gt;specifications...) it is fairly easy to say you are responsible for</i><br>
<i>&gt;the entities you create (but note that they might have free will,</i><br>
<i>&gt;which might give them some responsibility themselves). </i><br>
<p>
Indeed.<br>
<p>
<p>
<i>&gt;The unpredictability of Turing machines and complex systems is IMHO</i><br>
<i>&gt;the basis for our free will, and puts a limit on the amount of</i><br>
<i>&gt;responsibility we can place on any creator. </i><br>
<p>
So you're saying that a creator could have a certain degree of <br>
responsibility for the sentient beings created in his simulation.<br>
<p>
I'm not saying a creator must be hold responsible, I'm just saying <br>
he could be hold responsible. So then we are saying the same.<br>
<p>
<p>
<i>&gt;&gt; By the way, at Transvision98 we will show a television documentary </i><br>
<i>&gt;&gt; which will illustrate exactly this issue: "A creator of a simulation </i><br>
<i>&gt;&gt; containing sentient beings is being held responsible" :-&gt;</i><br>
<p>
<i>&gt;I look forward to it!</i><br>
<p>
Me too.<br>
<p>
=======================================================================&gt;<br>
<i>&gt;Hkl  ------&gt; Technology &amp; Future at           <a href="http://www.stack.nl/~hkl">http://www.stack.nl/~hkl</a></i><br>
Transcedo --&gt; Dutch Transhumanist Society   <a href="http://www.dse.nl/~transced">http://www.dse.nl/~transced</a><br>
Because the future is where we will spend the rest of our lives ...<br>
You see things and ask "Why?"  ;  I dream things and ask "Why not?"<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0763.html">Anders Sandberg: "Re: future pets"</a>
<li> <b>Previous message:</b> <a href="0761.html">neosapient@geocities.com: "The aliens are coming (Was: Re: Contacting God)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0764.html">Anders Sandberg: "Re: Ethics of being a Creator"</a>
<li> <b>Reply:</b> <a href="0764.html">Anders Sandberg: "Re: Ethics of being a Creator"</a>
<!-- reply="end" -->
</ul>
