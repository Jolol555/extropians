<!-- received="Tue Jun 23 17:49:27 1998 MDT" -->
<!-- sent="Tue, 23 Jun 1998 18:46:47 -0500" -->
<!-- name="Scott Badger" -->
<!-- email="wbadger@psyberlink.net" -->
<!-- subject="Re: AI's and Emotions" -->
<!-- id="199806232307.RAA20813@maxwell.kumo.com" -->
<!-- inreplyto="AI's and Emotions" -->
<title>extropians: Re: AI's and Emotions</title>
<h1>Re: AI's and Emotions</h1>
Scott Badger (<i>wbadger@psyberlink.net</i>)<br>
<i>Tue, 23 Jun 1998 18:46:47 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2565">[ date ]</a><a href="index.html#2565">[ thread ]</a><a href="subject.html#2565">[ subject ]</a><a href="author.html#2565">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2566.html">Hiro Protagonist: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<li> <b>Previous message:</b> <a href="2564.html">Jonathan Colvin: "Re: extropians-digest V3 #7"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2585.html">Anders Sandberg: "Re: AI's and Emotions"</a>
<li> <b>Reply:</b> <a href="2585.html">Anders Sandberg: "Re: AI's and Emotions"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
To Anders and Den:<br>
<p>
Just a couple points that came to mind on this topic.  I think perhaps that<br>
the term *emotion* is being used a bit loosely here.  It's true that people<br>
commonly use phrases like *I feel motivated* or *I feel like watching TV*.<br>
If a thought just seems to pop into my mind (i.e. I want ice cream), I will<br>
probably say *I feel like some ice cream* but it's really a cognition, not<br>
an emotion.  The basic emotions are typically thought to be anger,<br>
exhiliration, sadness, or fear.  But even these basic emotional states have<br>
questionable objective validity.<br>
<p>
The most widely supported theory of emotion suggests the following (1) we<br>
see the bear; (2) we cognitively interpret  the experience as threatening;<br>
(3) we become physically aroused; (4) we cognitively assign a label to the<br>
aroused state based on the context, our personal history, whether anyone<br>
else is watching, etc.; and (4) the label we choose (i.e. the meaning we<br>
assign to the arousal) subsequently dictates our behavior (i.e. we run, cry,<br>
wrestle, etc.).  The objective quality of these aroused states does not vary<br>
across the different emotions, though the subjective interpretation of them<br>
does.  The chemistry is the same.  We construct the rest.  The level of<br>
arousal we experience springs from the value and relevance we assign to the<br>
experience.<br>
<p>
I think Anders made a reference to DeMato's (sp?) book, Descartes Error, and<br>
his  assertion that emotions are necessary for good decision making.  That<br>
may be true but what aspect of emotions?  Can't they get in the way of good<br>
decision making as well?  I think so.  Emotions seem to be signals that what<br>
we're experiencing is likely to have either a positive or negative impact on<br>
our life.  I don't see why AI's couldn't use the assignment of value and the<br>
determination of  relevance to make good decisions without the need for<br>
aroused states.  It's strikes me as a largely vestigial mechanism.  Even so,<br>
I certainly don't want to lose my capacity for positive exhiliration (i.e. I<br>
love laughing).  I would hope that part of the transhuman condition would<br>
involve greater control over, rather than the elimination of emotional<br>
states.<br>
<p>
Once their programming abilities outstrip ours, won't it be up to AI's<br>
whether they want to have emotions or not?  I mean they'll probably figure<br>
it out before we do, don't you think?  If they choose to productively<br>
interact with human-types, they'll probably want to program themselves for<br>
behaviors that at least give the appearance of emotional reactions.  If I'm<br>
interacting with an AI and I'm depressed about something, our interaction<br>
will be more productive if the AI can accurately identify my emotional state<br>
and react empathetically (there, there, Dr. Badger...it'll be alright).<br>
Eventually, I may forget that it's just a programmed response (like most of<br>
mine are).<br>
<p>
Scott Badger<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2566.html">Hiro Protagonist: "Re: The AI revolution (Was: Re: &gt;H ART: The Truman Show)"</a>
<li> <b>Previous message:</b> <a href="2564.html">Jonathan Colvin: "Re: extropians-digest V3 #7"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2585.html">Anders Sandberg: "Re: AI's and Emotions"</a>
<li> <b>Reply:</b> <a href="2585.html">Anders Sandberg: "Re: AI's and Emotions"</a>
<!-- reply="end" -->
</ul>
