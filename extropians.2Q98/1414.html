<!-- received="Tue May  5 22:35:19 1998 MDT" -->
<!-- sent="Tue, 5 May 1998 23:30:20 -0500" -->
<!-- name="Scott Badger" -->
<!-- email="wbadger@psyberlink.net" -->
<!-- subject="Re: Sentience" -->
<!-- id="Version.32.19980505211845.00df9c40@mail.scruznet.com" -->
<!-- inreplyto="Sentience" -->
<title>extropians: Re: Sentience</title>
<h1>Re: Sentience</h1>
Scott Badger (<i>wbadger@psyberlink.net</i>)<br>
<i>Tue, 5 May 1998 23:30:20 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1414">[ date ]</a><a href="index.html#1414">[ thread ]</a><a href="subject.html#1414">[ subject ]</a><a href="author.html#1414">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1415.html">Lee Daniel Crocker: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Previous message:</b> <a href="1413.html">Lee Daniel Crocker: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Maybe in reply to:</b> <a href="1537.html">John K Clark: "Sentience"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1463.html">ChuckKuecker: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt;We need better definitions here..</i><br>
<p>
<p>
Yep.  Here's some.<br>
<p>
Here's one definition from the past for Intelligence<br>
<p>
     *The capacity to make adaptations for the <br>
      purpose of attaining a desired end; and the <br>
      power of autocritism.* (Terman, 1916)<br>
<p>
    *The aggregrate or global capacity of the <br>
    individual to act purposefully, to think rationally, <br>
    and to deal effectively with his environment.* <br>
    (Wechsler, 1958)<br>
 <br>
More recently...<br>
<p>
    *. . . a human intellectual competence must entail <br>
    a set of skills of problem solving - enabling the <br>
    individual to resolve genuine problems or difficulties <br>
    that she or he encounters, and, when appropriate, <br>
    to create an effective product - and must also entail <br>
    the potential for finding or creating problems - thereby <br>
    laying the groundwork for the acquisition of new <br>
    knowledge.* (Gardner, 1983)<br>
<p>
    * . . . mental activity in purposive adaptation to, shaping <br>
    of, and selection of real-world environment's relevant to <br>
    one's life.*  (Sternberg, 1986)<br>
<p>
Most theorists now agree that intelligence is <br>
hierarchical in that there is a general factor <br>
that plays a role in a large variety of cognitive <br>
tasks while more narrow group factors form a <br>
core of group factors.  These conceptualizations <br>
happened prior to the recent interest in <br>
Emotional Intelligence.  AI's will need<br>
<p>
The way my crappy dictionary defined sentience <br>
made it sound like anything that could interpret <br>
the environment through sensory inputs and was <br>
aware which makes consciousness and sentience <br>
sound pretty similar.  I had always thought the <br>
phrase *Sentient Species* was used to describe <br>
*Intelligent/Civilized* organisms.<br>
<p>
Consciousness and Intelligence are clearly <br>
distinguishable.  Consciousness strikes me <br>
as a necessary but insufficient precondition <br>
for intelligence.  I'm starting to lean toward <br>
believing that the odd sense of self that we <br>
possess was the incidental by-product of our <br>
larger and more complex brains and this <br>
glorious accident proved to be highly extropic, <br>
compelling us to create <br>
language, tools, agriculture, industry, technology, <br>
etc.  <br>
<p>
I think it was Alan Watts who first introduced me <br>
to the idea that our brains trick us into thinking that <br>
we have souls. Our enhanced abilities to recall <br>
the past and forsee the future lead us to spend <br>
mental time outside of the here and now.  We <br>
perceive ourselves as having this continuity when <br>
all that there really is is the present moment. I <br>
have since heard more neurologically sound <br>
arguments that lead to similar conclusions, i.e. <br>
that the sense of identity we experience is a <br>
complete illusion...the mind is what the brain does.<br>
<p>
The incidental by-product argument makes me <br>
wonder what might happen when a Super AI comes <br>
into being.  What sort of spontaneous artifact might <br>
arise as a function of this new level of complexity? <br>
Is Super AI going to be able to communicate with me<br>
better than I can communicate with my dog?<br>
<p>
As to how AI's might treat us if we are left in their <br>
dust, I would imagine that it would be somewhat <br>
similar to how we treat animals.  We can be very <br>
kind to animals we want to be kind to, we ignore <br>
others, and we can be very unkind to those we <br>
find bothersome.<br>
<p>
I hope we can all just get along.<br>
<p>
Scott Badger<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1415.html">Lee Daniel Crocker: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Previous message:</b> <a href="1413.html">Lee Daniel Crocker: "Re: Fear of Life (was Microsoft, Automation)"</a>
<li> <b>Maybe in reply to:</b> <a href="1537.html">John K Clark: "Sentience"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1463.html">ChuckKuecker: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
