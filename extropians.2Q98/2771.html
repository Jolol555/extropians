<!-- received="Sun Jun 28 00:31:38 1998 MDT" -->
<!-- sent="Sun, 28 Jun 1998 01:52:41 -0400 (EDT)" -->
<!-- name="Daniel Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Ethics, Egoism, and Rationality" -->
<!-- id="199806280459.VAA27784@well.com" -->
<!-- inreplyto="35957625.1AC4@piclab.com" -->
<title>extropians: Re: Ethics, Egoism, and Rationality</title>
<h1>Re: Ethics, Egoism, and Rationality</h1>
Daniel Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Sun, 28 Jun 1998 01:52:41 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2771">[ date ]</a><a href="index.html#2771">[ thread ]</a><a href="subject.html#2771">[ subject ]</a><a href="author.html#2771">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2772.html">Michelle Jones: "Re: voluntary end of privacy ?"</a>
<li> <b>Previous message:</b> <a href="2770.html">John K Clark: "Reversible Computers"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Sat, 27 Jun 1998, Lee Daniel Crocker wrote:<br>
<p>
<i>&gt; The prisoner's dilemma only applies to short-term interactions,</i><br>
<i>&gt; not repeated ones.  This is the mistake many non-egoists make with</i><br>
<i>&gt; their naive refutations of egoism: what they reject is not egoism</i><br>
<i>&gt; per se, but _short term_ egoism.  Most "selfish" acts that seem</i><br>
<i>&gt; evil do so not because they are selfish, but because they are not</i><br>
<i>&gt; selfish _in the long run_.  Criminal behavior, for example, may</i><br>
<i>&gt; lead to short-term gains, but in a world where most values are</i><br>
<i>&gt; achieved by interacting with others multiple times, crimials do</i><br>
<i>&gt; far more poorly than rational long-term egoists, who understand</i><br>
<i>&gt; that cooperative behavior is, in the long run, more profitable.</i><br>
<p>
Only in some cases.  I'd even say in MOST cases.  Indeed, as I pointed out<br>
earlier, egoism and utilitarianism agree at least 80% of the time.<br>
However, I still assert that even if egoists would only hurt people for<br>
profit if/when they could get away with it, (ie when there would be no<br>
long term negative consequences, or when the resulting improvement in long<br>
term well-being would outweigh the long term negative consequences,) we'd<br>
still be worse off if everybody was egoistic.<br>
<p>
<i>&gt; For extropians, for whom even mortality is a problem to be solved,</i><br>
<i>&gt; should be that much more inclined to think long term, and therefore</i><br>
<i>&gt; value behavior that benefits us throughout our immortal existence</i><br>
<i>&gt; and not just take a buck when we can.  Under these conditions,</i><br>
<i>&gt; egoism is superior to utilitarianism in every respect.</i><br>
<p>
While I agree with your point re: thinking about the long term, your<br>
argument falls apart unless you are asserting that there are never<br>
situations in which it is profitable (in the long term) to hurt others;<br>
situations in which you could steal and not get caught, defraud people and<br>
not feel the consequences, etc.  In every situation in which we could hurt<br>
people for long-term profit, egoism demands that each player<br>
"incriminate;" since egoism would demand sub-optimal consequences, egoism<br>
demands that we reject egoism under these circumstances.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2772.html">Michelle Jones: "Re: voluntary end of privacy ?"</a>
<li> <b>Previous message:</b> <a href="2770.html">John K Clark: "Reversible Computers"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
