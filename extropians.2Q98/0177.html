<!-- received="Wed Apr  8 21:16:31 1998 MDT" -->
<!-- sent="Wed, 08 Apr 1998 20:15:51 PDT" -->
<!-- name="Sonny B." -->
<!-- email="sonb@hotmail.com" -->
<!-- subject="Re: Beating a dead horse?(Was: Transhumanist Principles)" -->
<!-- id="01bd635c$f20fba60$0200a8c0@strongbox.phoenexus" -->
<!-- inreplyto="Beating a dead horse?(Was: Transhumanist Principles)" -->
<title>extropians: Re: Beating a dead horse?(Was: Transhumanist Principles)</title>
<h1>Re: Beating a dead horse?(Was: Transhumanist Principles)</h1>
Sonny B. (<i>sonb@hotmail.com</i>)<br>
<i>Wed, 08 Apr 1998 20:15:51 PDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#177">[ date ]</a><a href="index.html#177">[ thread ]</a><a href="subject.html#177">[ subject ]</a><a href="author.html#177">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0178.html">Michael Lorrey: "Re: Y2K once more"</a>
<li> <b>Previous message:</b> <a href="0176.html">Michael Lorrey: "Re: Transhumanist Declaration"</a>
<li> <b>Maybe in reply to:</b> <a href="0156.html">Michael Scarazzo: "Beating a dead horse?(Was: Transhumanist Principles)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt;Dan Fabulich, &lt;daniel.fabulich@yale.edu&gt;, writes:</i><br>
<i>&gt;&gt; Hal Finney wrote:</i><br>
<i>&gt;&gt; &gt;Based on this rather cautious principle, I would tentatively </i><br>
classify<br>
<i>&gt;&gt; &gt;the above procedures as moral, as long as they were done carefully </i><br>
so<br>
<i>&gt;&gt; &gt;that suffering was minimized.</i><br>
<i>&gt;&gt;</i><br>
<i>&gt;&gt; I'm dubious of this conclusion...  By this premise, all of the above </i><br>
would<br>
<i>&gt;&gt; necessarily be moral if they were created in such a way that they </i><br>
were<br>
<i>&gt;&gt; always (artificially) happy, no matter how difficult or otherwise </i><br>
painful<br>
<i>&gt;&gt; their circumstances...</i><br>
<i>&gt;</i><br>
<i>&gt;What is the difference between artificial happiness and the real thing?</i><br>
<i>&gt;Can someone be happy and still be in terribly difficult and painful</i><br>
<i>&gt;circumstances?  That seems a bit contradictory.</i><br>
<i>&gt;</i><br>
<i>&gt;Perhaps the real difficulty here is the difficulty of knowing what the</i><br>
<i>&gt;true mental state is.  Obviously, creating someone with a fixed smile</i><br>
<i>&gt;on their face is no indication that they are actually happy.  Even if </i><br>
we<br>
<i>&gt;have good general understanding of genetics it may be much longer </i><br>
before<br>
<i>&gt;we can say with confidence that a particular design will lead to a </i><br>
happy<br>
<i>&gt;being, one which does not suffer.</i><br>
<i>&gt;</i><br>
<i>&gt;Still, in terms of judging morality, I'd say we have to use our best</i><br>
<i>&gt;understanding of these matters, just as in other areas of uncertainty.</i><br>
<i>&gt;We may want to err on the side of caution, in which case creating </i><br>
beings<br>
<i>&gt;with drastically new mental structures could be considered immoral,</i><br>
<i>&gt;since we might unknowingly create a being who was constantly in </i><br>
terrible<br>
<i>&gt;pain, and who (of course) never volunteered to undergo that experience.</i><br>
<i>&gt;This would obviously hinder the growth of understanding the mind and</i><br>
<i>&gt;brain, but it would be wrong to gain knowledge at the cost of </i><br>
involuntary<br>
<i>&gt;suffering by others.</i><br>
<i>&gt;</i><br>
<i>&gt;Hal</i><br>
   <br>
   The idea of gain of knowledge at the painful expense of others is <br>
akin to the controversy of abortion.  To include issues of morality in a <br>
discussion where everyone is not in agreement with a moral, is a waste <br>
of time.  <br>
   I don't feel that we could ever know for sure whether or not our <br>
procedures/experiments are inflicting unnecessary pain on an individual.  <br>
In the name of advancement, it becomes necessary to take those "immoral" <br>
steps to whatever degree necessary before dedicating efforts to <br>
modification of experiments to decrease discomfort for the specimens.  I <br>
know the preceding statement may sound Hitlerian, but when push comes to <br>
shove, and life to death, how else do we humans operate in this world <br>
anyway?  <br>
   I propose that we could develop interfaces to allow ourselves to <br>
become the specimen being subjected to whatever stresses other impose on <br>
it.  Later on, we could, upon exit of such xfers, more accurately <br>
interpret what the specimens may be "feeling".<br>
<p>
Sonny<br>
<p>
<p>
______________________________________________________<br>
Get Your Private, Free Email at <a href="http://www.hotmail.com">http://www.hotmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0178.html">Michael Lorrey: "Re: Y2K once more"</a>
<li> <b>Previous message:</b> <a href="0176.html">Michael Lorrey: "Re: Transhumanist Declaration"</a>
<li> <b>Maybe in reply to:</b> <a href="0156.html">Michael Scarazzo: "Beating a dead horse?(Was: Transhumanist Principles)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
