<!-- received="Fri Jun 26 20:18:39 1998 MDT" -->
<!-- sent="Fri, 26 Jun 1998 20:18:50 -0600 (MDT)" -->
<!-- name="Michael Nielsen" -->
<!-- email="mnielsen@tangelo.phys.unm.edu" -->
<!-- subject="Re: Moore's law [WAS MEDIA: Forbes ..]" -->
<!-- id="Pine.SUN.3.91.980626200938.2012A-100000@tangelo.phys.unm.edu" -->
<!-- inreplyto="35942A46.4DA5B74F@clemmensen.shirenet.com" -->
<title>extropians: Re: Moore's law [WAS MEDIA: Forbes ..]</title>
<h1>Re: Moore's law [WAS MEDIA: Forbes ..]</h1>
Michael Nielsen (<i>mnielsen@tangelo.phys.unm.edu</i>)<br>
<i>Fri, 26 Jun 1998 20:18:50 -0600 (MDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2716">[ date ]</a><a href="index.html#2716">[ thread ]</a><a href="subject.html#2716">[ subject ]</a><a href="author.html#2716">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2717.html">Michael Nielsen: "Re: Information"</a>
<li> <b>Previous message:</b> <a href="2715.html">Dan Clemmensen: "Re: The End of Privacy ?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Fri, 26 Jun 1998, Dan Clemmensen wrote:<br>
<p>
<i>&gt; We will have to do better than that just to keep up with historical</i><br>
<i>&gt; trends in algorithm design. Most folks aren't aware of it, but</i><br>
<i>&gt; algorithm design historically has improved performance as much as</i><br>
<i>&gt; hardware improvements.</i><br>
<p>
Algorithm advances are far more problem-dependant than hardware.  If you're <br>
talking about sorting an unordered list, for example, not much has <br>
changed in a long while -- virtually all the advances can be attributed <br>
to hardware improvement.  On the other hand, the factoring of large <br>
integers has come on by algorithmic leaps and bounds over the past 25 <br>
years; hardware improvement has been a relatively negligible factor in <br>
the leaps and bounds taken in factoring.<br>
<p>
There is an amusing inverse to note here.  For sufficiently _hard_ <br>
problems, Moore's law makes essentially no difference.  The obvious way <br>
to look at this is that using Eratoshenes Sieve based factoring methods, <br>
we'd only be able to factor numbers 10 or 15 bits longer than we could <br>
back in the 1970s.<br>
<p>
The inverse is that if we can factor 130 digit numbers now, using much <br>
better (but still exponential) algorithms, then using the same algorithms <br>
on 1970s computers, we would still be able to factor roughly the same <br>
size numbers. <br>
<p>
In other words, algorithmic advances are virtually _all_ that matters <br>
for really hard problems.  For easy problems, it's hardware advances <br>
that count, at least, so long as Moore's law holds out.<br>
<p>
Michael Nielsen<br>
<p>
<a href="http://wwwcas.phys.unm.edu/~mnielsen/index.html">http://wwwcas.phys.unm.edu/~mnielsen/index.html</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2717.html">Michael Nielsen: "Re: Information"</a>
<li> <b>Previous message:</b> <a href="2715.html">Dan Clemmensen: "Re: The End of Privacy ?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
