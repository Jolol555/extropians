<!-- received="Tue May  5 05:16:35 1998 MDT" -->
<!-- sent="Mon, 04 May 1998 23:05:27 -0600" -->
<!-- name="Tony Belding" -->
<!-- email="tlbelding@htcomp.net" -->
<!-- subject="RE: ECON: the abolition of work" -->
<!-- id="199805050749.AAA23426@scruz.net" -->
<!-- inreplyto="3.0.5.32.19980429165555.00b26c40@dgf4.mail.yale.edu" -->
<title>extropians: RE: ECON: the abolition of work</title>
<h1>RE: ECON: the abolition of work</h1>
Tony Belding (<i>tlbelding@htcomp.net</i>)<br>
<i>Mon, 04 May 1998 23:05:27 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1353">[ date ]</a><a href="index.html#1353">[ thread ]</a><a href="subject.html#1353">[ subject ]</a><a href="author.html#1353">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1354.html">den Otter: "Re: ECON: the abolition of work"</a>
<li> <b>Previous message:</b> <a href="1352.html">Anders Sandberg: "Re: extropian galactic colonization"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On 29-Apr-98, Dan Fabulich wrote:<br>
<p>
<i>&gt;NOTE:  Upon rereading this post, I've come to the conclusion that we're</i><br>
<i>&gt;talking about slightly different things.  So I'll try to clarify wherever</i><br>
<i>&gt;possible.</i><br>
<p>
I think you are probably right about that.<br>
<p>
<i>&gt;Under my definition, "non-sentient AI" is oxymoronic.  My understanding of</i><br>
<i>&gt;what we were talking about were robots which would only do what they were</i><br>
<i>&gt;programmed to do.</i><br>
<p>
Hm...  To me, if it has to be "programmed" in the conventional sense, then<br>
it's not AI.  Programming an AI should be a process of simply telling it what<br>
you want, then the AI figures out how to do it.<br>
<p>
To me, the main thing that distinguishes sentience is the source of the<br>
robot's motivations.  A sentient robot, like any worker, ultimately works for<br>
its own benefit.  A non-sentient robot works for its owner.<br>
<p>
<i>&gt;It is profoundly unlikely (read: pigs will</i><br>
<i>&gt;fly) that that the RATIO of different types of goods robots and humans</i><br>
<i>&gt;could create in a day would be exactly equal, across the board for every</i><br>
<i>&gt;type of good.  (It's not even the same among individual humans!)  So humans</i><br>
<i>&gt;will certainly have comparative advantage in some goods.</i><br>
<p>
Eh?  I don't see anything certain about that.  I agree that the ratio will<br>
vary among different types of goods and services, but I assume that the<br>
advantage will practically always be in favor of the robots over old fashioned<br>
flesh-and-blood humans.<br>
<p>
<i>&gt;Well, yes.  So, here's my case for population growth, taken mostly from</i><br>
<i>&gt;Julian Simon's "The Ultimate Resource 2."</i><br>
<p>
<i>&gt;1)  Axiom.  Promoting the greatest happiness for the greatest number is an</i><br>
<i>&gt;important moral good.</i><br>
<p>
That is a very questionable axiom.  I would contend that we want to promote<br>
the greatest good for the greatest /fraction/ of people.  In other words, if<br>
you have 20 million people and 90% are happy, that's a better situation than<br>
six billion people of which 20% are happy.<br>
<p>
If you take a moral (and therefore arbitrary) position that a large<br>
population is better than a smaller one, with other things being equal, then<br>
you are naturally going to want the creation of more people -- including<br>
sentient robots.  But if you follow that to its logical conclusion, you are<br>
eventually going to run into hard limits: energy supplies, waste heat, raw<br>
matter supplies.  This is a serious concern, unless you can repeal the laws of<br>
physics.<br>
<p>
Another point is that there may be other moral imperatives to consider, which<br>
are more important than happiness.  Happiness is usually rooted in mere<br>
biology, and IMHO is a shallow goal for human beings.  But that is another<br>
discussion entirely.  It is probably outside the realm of economics.<br>
<p>
<i>&gt;5)  Therefore.  If resources do not run out, population growth will result</i><br>
<i>&gt;in greater wealth per capita.</i><br>
<p>
Ah!  But resources /do/ eventually run out.  Note also that the existence of<br>
AI can skew this assumption.  Population growth may create an increase in<br>
wealth per capita, but creation of AI workers can create a /greater/<br>
increase, especially since your AI robotic workers don't count as "capita"!<br>
<p>
If our goal is the greatest happiness for the greatest /fraction/ of the<br>
population, the quickest way to achive that is by adding non-consumer robots<br>
to the economy.  They don't expand the population, they don't consume or<br>
increase overall demand, they only produce.<br>
<p>
<i>&gt;When a resource becomes scarce, its price increases.  As a result of this,</i><br>
<i>&gt;fewer people buy the good, noting that it is not worth its price.  As the</i><br>
<i>&gt;price rises, we observe that the resource is conserved, by virtue of the</i><br>
<i>&gt;fact that fewer people consider the good worth its price, so fewer people</i><br>
<i>&gt;are prepared to  use it, waste it, etc.</i><br>
<p>
Yes.  And this also implies that the quality of life of those people is<br>
reduced.  It is true that we have good economic mechanisms for dealing with<br>
scarcity -- and no wonder!  That's what any economy is based upon.  Still,<br>
that doesn't mean scarcity is good for the economy.  For analogy, just imagine<br>
you have a hill-climbing motorcycle.  It's designed specially for climbing<br>
hills, and it's *good* at it.  That doesn't mean it will perform better every<br>
time you pit it against a steeper hill!<br>
<p>
<i>&gt;Note that we have to assume that people must work in order to get more</i><br>
<i>&gt;money, if this process is to succeed.  Otherwise, people will not bother to</i><br>
<i>&gt;seek cheaper alternatives.</i><br>
<p>
Say what?  I don't follow you.  You seem to think people who get their money<br>
by other means than working are inclined to waste it recklessly.  Of course,<br>
a few people actually do that, but then so do some people who work for their<br>
money.  Go figure.<br>
<p>
<i>&gt;When Julian Simon was writing, he argued that resources were actually</i><br>
<i>&gt;infinite, and that those who were arguing for finite "scarce" resources</i><br>
<i>&gt;were wrong.  This may not be true, as written.  However, it IS true that</i><br>
<i>&gt;the amount of resources which are available to us are determined primarily</i><br>
<i>&gt;by the technology which we develop, not by the remaining quantity of any</i><br>
<i>&gt;particular resource.</i><br>
<p>
I don't take such a rosy view.  First of all, there is a limit to the<br>
technology that can be developed.  All technology is based on the laws of<br>
science and our understanding of them.  When we fully understand those laws<br>
and have exploited them in every way that is practical, there will be no more<br>
technology to develop.  Then we will have access to all the resources than can<br>
be accessed.<br>
<p>
Advancing technology is something that only happens during very strange<br>
circumstances.  Right now we are in the middle of a technological revolution,<br>
a brief period of great change and upheaval.  Before this revolution began,<br>
about five thousand years ago, people lived a simple hunter-gatherer<br>
existence.  They had lived that way for tens of thousands of years in a<br>
*stable* condition.  After our technological revolution (which we call<br>
"civilization") is finished, we will reach another condition of stability in<br>
which there will be little change over many thousands of years. That stable<br>
condition will exist at an equilibrium point defined by both our final level<br>
of technology and our total available "land" resources.<br>
<p>
<i>&gt;are pretty certain about.  I don't anticipate any perpetual motion machines</i><br>
<i>&gt;in humanity's future.  However, technology is pretty sneaky, and engineers</i><br>
<i>&gt;are a crafty bunch.  So while we may not be able to get around this</i><br>
<i>&gt;particular limit, there are other mechanisms, other means of extracting</i><br>
<i>&gt;energy, which may do the trick for us.</i><br>
<p>
I don't like to bet our future on miracle technologies that aren't based upon<br>
any known laws of science.<br>
<p>
<i>&gt;I do not know if there is an ultimate limit to what technology can do for</i><br>
<i>&gt;us.  I suspect that there might be; but then, much of the evidence for</i><br>
<i>&gt;ultimate limits which we have seen in the past have eventually been</i><br>
<i>&gt;overcome.</i><br>
<p>
In my experience, few of those "ultimate limits" were based on hard science<br>
and hard numbers.  It may be misleading to draw lessons from those failed<br>
predictions.<br>
<p>
<i>&gt;6)  Observed.  Resources will not run out if we do not run out of useful</i><br>
<i>&gt;technology.</i><br>
<p>
That depends on how you define resources.  Imagine some oil is trapped deep<br>
in an underground shale deposit, so that it cannot be extracted economically.<br>
If a new technology allows you to get it, does that give us a new resource,<br>
or does it merely allow us to *deplete* a resource that we always had?<br>
<p>
Most new technology falls into this category: it allows us *access* to more<br>
and more resources.  But the hard limit still remains: there is only so much<br>
oil locked in the earth.  Likewise, our solar system only contains a certain<br>
amount of raw matter, and the sun only produces a relatively fixed energy<br>
output.<br>
<p>
<i>&gt;Under this understanding, yes.  However, I was answering a different point</i><br>
<i>&gt;when I composed this.  First, I was asked how the poor would keep their</i><br>
<i>&gt;jobs in the face of automation.</i><br>
<p>
It is a serious concern.<br>
<p>
<i>&gt;I answered that so long as the robots were sentient, more jobs would be</i><br>
<i>&gt;needed, so we could expect that humans would keep their jobs.</i><br>
<p>
IMHO, that could be a cure worse than the disease.  It's make-work!  It<br>
reminds me of a silly SF novel I read several years ago.  Some crackpot<br>
tinkerer had invented cheap fusion power, and it created such abundance that<br>
the economy was inverted: people had to *consume* for a living.  Every day the<br>
drudgery of having to consume your quota of goods and services!  Finally some<br>
genius (though he was actually drunk at the time) figured out a solution.  He<br>
programmed his robots to consume!  At first he was accused of *wasting* goods<br>
and services (why did they care?), but then he showed that he had programmed<br>
the robots to *enjoy* consuming these things.  So, the problem was solved:<br>
the robots could produce goods and services, and they could consume the<br>
excess, so humans were able to simply take what they wanted.<br>
<p>
It was absurd, of course.  The common-sense solution would have been to cut<br>
back on production.  (The author weaseled out of that by hinting it was<br>
impossible to cut back production, but without ever explaining why.)  What<br>
you are proposing is a variation on the same story.  You're talking about<br>
creating more workers to produce more goods, and also consume them, thus<br>
creating a demand for more workers, so the cycle continues.  It seems so<br>
pointless!<br>
<p>
Of course, that is somewhat how our economy has been *forced* to operate<br>
until now, since only living, breathing human beings are able to do much<br>
work.  It's part of the human condition.  But that's exactly what I want to<br>
FIX, not embrace as a model for the future.  We want to move beyond the<br>
human condition, not enshrine it.<br>
<p>
<i>&gt;Now, I must agree that increased non-sentient automation would lead to</i><br>
<i>&gt;decreased prices and increased abundance, as you say.  However, during the</i><br>
<i>&gt;transition period, wages and prices might not be as flexible as we might</i><br>
<i>&gt;like.  If wages fell faster than the price level, or if wages couldn't fall</i><br>
<i>&gt;with the price level (due to unions, minimum wage laws, etc.) then what</i><br>
<i>&gt;we'd find is people starving in an age of plenty.</i><br>
<p>
Yes.  Marx vindicated.  Of course, there must be some kind of economic<br>
adjustment to deal with this problem.  I just don't think you've hit upon it.<br>
<p>
<i>&gt;Having sentient robots would ease this transition a lot, because they would</i><br>
<i>&gt;create jobs in the process, rather than just filling them.</i><br>
<p>
Are they really easing the transition, or are they perpetuating the<br>
problem?  This reminds me of the battle over free market reforms in Russia.<br>
If you attempt economic shock therapy, the pain and dislocation can be<br>
tremendous.  On the other hand, if you try to "ease the transition" you may<br>
create an economic legacy that will drag down the whole system for decades to<br>
come.<br>
<p>
<i>&gt;And finally, in the spirit of the post above, who is to say that the</i><br>
<i>&gt;happiness of a sentient robot is not as great a moral goal as improving our</i><br>
<i>&gt;own happiness?</i><br>
<p>
Those sentient robots don't exist yet.  I'm all in favor of increasing the<br>
happiness of people who exist, but I don't see the point of creating more<br>
people only for the purpose of making them happy.  An unhappy person is a<br>
problem to be solved.  A happy person is a minor problem, since he presumably<br>
could be made even happier than he is now.  A non-existent person is a<br>
non-problem.<br>
<p>
<i>&gt;Presuming these robots would continue the human trend of</i><br>
<i>&gt;producing more than they consumed, (a trend from which I see no reason a</i><br>
<i>&gt;sentient robot would break,) adding sentient robots to our population would</i><br>
<i>&gt;have the same effect, if not an amplified effect, as increasing our</i><br>
<i>&gt;population would.</i><br>
<p>
There you have it.  You feel increasing our population is a good thing.  I<br>
don't.  Look, maybe I haven't stated this clearly enough:  I feel that<br>
uncontrolled population growth is the ONLY serious problem facing our<br>
civilization in the long run.  PEOPLE are replicators with an exponential<br>
growth rate, and they will eventually over-run any fixed resources.  Creating<br>
sentient robots is like throwing gasoline on a fire.  RE: Malthus<br>
<p>
<i>&gt;Well, it goes like this: as Lorrey will tell you, "There Ain't No Such</i><br>
<i>&gt;Thing As A Free Lunch."  Even if we do decrease the price level to</i><br>
<i>&gt;something absurdly low, we should still expect to make micropayments in</i><br>
<i>&gt;order to receive our daily bread.</i><br>
<p>
That depends on the accounting cost of recording and tabulating those<br>
micro-payments.  Somebody once calculated that phone companies could make more<br>
money by charging a flat monthly fee for long-distance service.  Their billing<br>
costs would be reduced tremendously, and just think of all the business they<br>
would get!  But of course, the phone companies didn't listen.<br>
<p>
<i>&gt;Alternately, engines like advertising</i><br>
<i>&gt;could take over, but advertising applies only to people who COULD buy other</i><br>
<i>&gt;goods; if you're not working, then you have no income, and so advertising</i><br>
<i>&gt;to you would be pointless.</i><br>
<p>
Excuse me?  "...if you're not working, then you have no income..."<br>
<p>
There are certainly other ways to get income, rather than by working!  The<br>
whole heart of my economic concept is that most people who are workers today<br>
should become capitalists: sellers of capital instead of sellers of labor<br>
services.<br>
<p>
<i>&gt;So I put forward that work must happen in order to keep things running.</i><br>
<i>&gt;Maybe very LITTLE work needs to happen (maybe people could be paid a living</i><br>
<i>&gt;salary for a tiny service, like some of the work <a href="http://www.distributed.net">http://www.distributed.net</a></i><br>
<i>&gt;is doing), but work must happen, because it takes a little work in order to</i><br>
<i>&gt;feed you; even if it's just a very little amount of work.</i><br>
<p>
Well, there's no point in quibbling over whether work will be abolished<br>
completely or merely reduced to a trivial role.  I don't honestly expect work<br>
to disappear totally.  Nothing changes that fast, that completely.  Even if it<br>
makes no economic sense, there is tradition and nostalgia to deal with.  But I<br>
don't see how labor can continue to be the hub around which our economy<br>
rotates.<br>
<p>
Let me ask: Assuming we have AI robots, why must there be work in order to<br>
feed me?  If we have robots, they can raise food, they can process it, bring<br>
it to me, and even cook it for me.  I can pay for the food using income from<br>
my investments. Where is the work?<br>
<p>
<i>&gt;If wages and prices were fully flexible, then I'd probably just agree with</i><br>
<i>&gt;you, argue that increased automation will decrease the compensation for</i><br>
<i>&gt;labor but at the same time make that compensation exponentially more</i><br>
<i>&gt;valuable, resulting in lots of people living on low wages and getting rich</i><br>
<i>&gt;in the process.  I have made that argument here before.</i><br>
<p>
NO WAGES.  You want lots of people living on NO WAGES, but getting their money<br>
from other sources of income.<br>
<p>
<i>&gt;&gt;From a purely economic standpoint, my definition of sentience is very easy:</i><br>
<i>&gt;&gt;a sentient being is one who /wants/ things.  A consumer.</i><br>
<i>&gt;</i><br>
<i>&gt;How is this different from an AI that "pretends" to want things?  ;)</i><br>
<p>
The difference is that you can tell your non-sentient AI to *stop* pretending<br>
to want things, and it will do so.<br>
<p>
<i>&gt;&gt;Maybe art shouldn't even be done for economic reasons!  Perhaps art should</i><br>
<i>&gt;&gt;be the province of non-workers who make their living by other means, so they</i><br>
<i>&gt;&gt;can indulge their creative urges without worrying about the bottom line.</i><br>
<i>&gt;</i><br>
<i>&gt;Whoever is feeding the artist has to worry about the bottom line.</i><br>
<p>
Not if the artist is getting his income from some other source.<br>
<p>
Thought experiment: Imagine you are H. Ross Perot.  Imagine that your many<br>
investments earn you well over a million dollars PER DAY.  You decide to spend<br>
your time composing music, because you like it.  There is no reason for you to<br>
care whether your songs will sell or not.  They aren't going to put bread on<br>
your table: it's simply not a concern.<br>
<p>
<i>&gt;&gt;There are certainly other ways they can do that, rather than by working.</i><br>
<i>&gt;</i><br>
<i>&gt;Such as?  Some economists DEFINE the creation of wealth as economic "work."</i><br>
<p>
The only definition of work that I care about is "the sale of labor<br>
services".  There are other economic resources you can sell, besides labor.<br>
To wit: land, capital, and entrepreneurial ability.  I'm particularly<br>
interested in people selling capital, since capital is what's displacing labor<br>
in the marketplace.<br>
<p>
<i>&gt;What will they invest without wealth?  Where will they get the wealth if</i><br>
<i>&gt;they're not working?</i><br>
<p>
They'll just have to get help from somebody.  That might mean public<br>
assistance, or it might mean some other way.  Every society through history<br>
has faced the problem of what to do with people who are unable (if only<br>
temporarily) to contribute to the economy.  It's a problem that predates<br>
civilization: even Neanderthals cared for their infirm.  I don't have any<br>
magical answers to that ancient problem.  But every society seems to come up<br>
with some way to muddle through it.<br>
<p>
Today we have Social Security.  I personally don't like it.  It's<br>
redistribution of wealth by brute force, blatant socialist social<br>
engineering that offends my libertarian sensibilities.  Still, it seems to be<br>
a popular program, and it has been going for decades.  If nothing else works,<br>
the coming economic dislocations can be addressed with heavy-handed government<br>
intervention: tax the wealthy and pay "seed money" to the poor.  That's<br>
exactly what it will come down to, unless somebody works out a better plan.<br>
Unpleasant as such a system might seem, I think it would be preferable to<br>
creating make-work and a population explosion of sentient robots.<br>
<p>
<i>&gt;You think managing finite resources is fun?</i><br>
<p>
It's not the sale of labor services.  Besides, a lot of folks seem to think<br>
managing resources is fun.  Witness all the computer games with such a theme:<br>
Civilization, The Settlers, Sim City, etc.<br>
<p>
<pre>
--
   Tony Belding
   <a href="http://hamilton.htcomp.net/tbelding/">http://hamilton.htcomp.net/tbelding/</a>
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1354.html">den Otter: "Re: ECON: the abolition of work"</a>
<li> <b>Previous message:</b> <a href="1352.html">Anders Sandberg: "Re: extropian galactic colonization"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
