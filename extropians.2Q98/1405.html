<!-- received="Tue May  5 21:23:21 1998 MDT" -->
<!-- sent="Tue, 5 May 1998 22:23:15 -0500 (CDT)" -->
<!-- name="ChuckKuecker" -->
<!-- email="ckuecker@mcs.net" -->
<!-- subject="Re:  sentience (was: Re: ECON The Abolition Of Work)" -->
<!-- id="2.2.32.19980505222437.875e59bc@popmail.mcs.net" -->
<!-- inreplyto="sentience (was: Re: ECON The Abolition Of Work)" -->
<title>extropians: Re:  sentience (was: Re: ECON The Abolition Of Work)</title>
<h1>Re:  sentience (was: Re: ECON The Abolition Of Work)</h1>
ChuckKuecker (<i>ckuecker@mcs.net</i>)<br>
<i>Tue, 5 May 1998 22:23:15 -0500 (CDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1405">[ date ]</a><a href="index.html#1405">[ thread ]</a><a href="subject.html#1405">[ subject ]</a><a href="author.html#1405">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1406.html">ChuckKuecker: "Re: Christian Society"</a>
<li> <b>Previous message:</b> <a href="1404.html">ChuckKuecker: "RE: extropian galactic colonization"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 11:34 5/5/98 -0700, you wrote:<br>
<i>&gt;</i><br>
<i>&gt;Wouldn't the functionalist perspective suggest that consciousness is not</i><br>
<i>&gt;an "incidental" by-product, but rather an "inevitable" one?  In other</i><br>
<i>&gt;words, you automatically get consciousness when you have the kind of</i><br>
<i>&gt;complex system Damien is describing.  Any system which has a sufficiently</i><br>
<i>&gt;rich representation of itself and the world is conscious - that is what</i><br>
<i>&gt;consciousness is.</i><br>
<p>
I think the determination is where the organism has an internalized sense of<br>
being - it 'knows' it is an individual, separate from the world outside.<br>
This is easily felt when one works with animals - but it is terribly hard to<br>
define a test to prove this. I 'know' I am conscious - but how can I prove I<br>
am not a cunningly written 'Eliza' program? <br>
<p>
<i>&gt;One problem with this suggestion is that it implies that a relatively</i><br>
<i>&gt;simple computer program, say CYC with its thousands of interrelated</i><br>
<i>&gt;facts about the world, would be conscious to some degree.  Such a</i><br>
<i>&gt;program is far from being able to pass the Turing test, and we might</i><br>
<i>&gt;not be comfortable setting the bar for consciousness so much lower than</i><br>
<i>&gt;that for human equivalent intelligence.  But on the other hand, it</i><br>
<i>&gt;appears in nature that conscious awareness is in fact much easier to</i><br>
<i>&gt;produce than human intelligence, so perhaps this is not so objectionable</i><br>
<i>&gt;after all.</i><br>
<i>&gt;</i><br>
<p>
There is the key - awareness. A computer program filled with facts may not<br>
actually be aware of the length of the Nile, but it can tell you that fact<br>
on query.<br>
<p>
Chuck Kuecker<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1406.html">ChuckKuecker: "Re: Christian Society"</a>
<li> <b>Previous message:</b> <a href="1404.html">ChuckKuecker: "RE: extropian galactic colonization"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
