<!-- received="Sun Apr 26 13:25:13 1998 MDT" -->
<!-- sent="26 Apr 1998 21:24:58 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Ethics of being a Creator" -->
<!-- id="199804261854.CAA09673@pop1.pacific.net.sg" -->
<!-- inreplyto="Sat, 25 Apr 1998 21:19:42 +0200" -->
<title>extropians: Re: Ethics of being a Creator</title>
<h1>Re: Ethics of being a Creator</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>26 Apr 1998 21:24:58 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#905">[ date ]</a><a href="index.html#905">[ thread ]</a><a href="subject.html#905">[ subject ]</a><a href="author.html#905">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0906.html">Verdop: "Re: German extropians"</a>
<li> <b>Previous message:</b> <a href="0904.html">Verdop: "Re: German extropians"</a>
<li> <b>In reply to:</b> <a href="0841.html">Henri Kluytmans: "Re: Ethics of being a Creator"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Henri Kluytmans &lt;hkl@stack.nl&gt; writes:<br>
<p>
<i>&gt; Anders Sandberg wrote:</i><br>
<i>&gt; &gt;Huh? This doesn't follow. I can set up a big game of life simulation</i><br>
<i>&gt; &gt;(or something similar, perhaps Tierra) right now on this computer, but</i><br>
<i>&gt; &gt;even if I discovered intelligent entities inside it after a while I</i><br>
<i>&gt; &gt;wouldn't know what to do with them. Sure, that huge stretch of digital</i><br>
<i>&gt; &gt;code is an intelligent entity, but I have no idea of how it works, how</i><br>
<i>&gt; &gt;to merge its memories (which might be impossible even in principle for</i><br>
<i>&gt; &gt;an Alzheimer-like case, where the memory substrate would be</i><br>
<i>&gt; &gt;non-isomorphic over time) or what it would consider "healthy" ("Poor</i><br>
<i>&gt; &gt;humans, guts riddled with bacteria. I'll resurrect them completely</i><br>
<i>&gt; &gt;without any bacteria, then they will be healthy and happy!").</i><br>
<i>&gt; </i><br>
<i>&gt; I think al this can be solved in principle. The question is only </i><br>
<i>&gt; how much time it requires.</i><br>
<p>
It is also important to compare this to what is available to the<br>
creator. An infinite superbeing might not have any problems, but here<br>
we are talking about more modest superbeings like what we might become<br>
in the future. I think there is a very real possibility that the<br>
simulation can become so complex that the creator will have a hard<br>
time understanding it and dealing with the emergent moral dilemmas. It<br>
might be fairly easy to set up a huge cellular automaton with a fixed<br>
rule set, and extremely much harder to discern what is *really* going<br>
on and how to deal with it. Remember that the fate of class IV CA<br>
rules is Turing-uncomputable, which means we cannot predict it easier<br>
than running the automaton itself.<br>
<p>
<i>&gt; I expect it will not be that difficult for the creator to </i><br>
<i>&gt; detect sentient lifeforms in simulations. For example it </i><br>
<i>&gt; is also not so difficult for humans to detect selfreplicating </i><br>
<i>&gt; systems and moving systems in the "game of life". Of course </i><br>
<i>&gt; these current universes are much to small to create sentient </i><br>
<i>&gt; or even intelligent beings. </i><br>
<p>
We are good at recognizing moving systems because we have evolved in a<br>
world where this is essential. Self replication is much harder, so far<br>
it has required fairly careful study or very simple worlds (like the<br>
parity automaton, where everything self-replicates). If the automaton<br>
internally organizes itself as a 16-dimensional fourier component<br>
space we will have a lot of trouble figuring out what is going on,<br>
what is sentinent and what it is doing.<br>
<p>
<i>&gt; &gt;Even if I happen to be a posthuman jupiter brain, I will still be</i><br>
<i>&gt; &gt;limited in my knowledge about the behavior of complex systems such as</i><br>
<i>&gt; &gt;simulated universes.</i><br>
<i>&gt; </i><br>
<i>&gt; But you could learn...</i><br>
<p>
Up to the limits set by complexity; even given an arbitrary number of<br>
examples of class IV automates I would not become better at predicting<br>
the behavior of a general class IV automaton (unless Penrose is right<br>
and the CT hypothesis doesn't hold for some systems, but I don't<br>
believe in that). Of course, if I just limit myself to a certain kind<br>
of worlds I might become a good creator for that kind, but I have<br>
greater aspirations than that.<br>
<p>
<i>&gt; Systems in "game of life" worlds can alter their surroundings. </i><br>
<i>&gt; When they do this in an indirect way, this could be considered </i><br>
<i>&gt; using tools. I don't see why tools can't also exist in "game of life" </i><br>
<i>&gt; worlds.</i><br>
<p>
What is a tool, what is an object and what is a creature? Very hard to<br>
distinguish in this case, and likely impossible in other cases.<br>
<p>
<i>&gt; I didn't assume it should be very easy. But it shouldn't be to hard </i><br>
<i>&gt; to communicate with other intelligent sentient beings. We will have </i><br>
<i>&gt; enough in common. It should be just as hard as communicating with </i><br>
<i>&gt; any other intelligent sentient lifeform.</i><br>
<p>
I think you have a view of intelligence as fundamentally convergent -<br>
all intelligent beings will have things in common. I doubt it -<br>
intelligent evolved in a different world will have other ways of<br>
perceiving it, motivation and planning, and this might make<br>
communication nearly impossible. <br>
<p>
[spoiler for Greg Egan's Diaspora!] As an example, Greg Egan invented<br>
a form of intelligent life living in the 16-dimensional fourier<br>
component space created by the growth of Wang-tile equivalent<br>
polysaccharides forming large sheets in the ocean on an alien planet<br>
(yes, they are my favorite aliens so far :-). What can we discuss? We<br>
live in fundamentally different worlds (different even on the<br>
ontological level!), have a different physics, interact with the world<br>
in different ways (no light, just touch) and doesn't even share the<br>
same kind of time (as a sheet splits, history splits). What can we<br>
discuss with them? [Spolier end]<br>
<p>
<i>&gt; &gt;(like Tierrans, with a world consisting of computing</i><br>
<i>&gt; &gt;nodes and nonlocal memory indexed by templates and energy appearing if</i><br>
<i>&gt; &gt;you do certain things but not other things)? </i><br>
<i>&gt; </i><br>
<i>&gt; Interesting, where can I find more about these Tierrans?</i><br>
<p>
Tom Ray has written an amazing alife system called Tierra, and is now<br>
working on a net version of it. If there ever emerge intelligent life<br>
in the Tierra-world we might call them Tierrans. There are likely<br>
links to the project from the various alife sites on the net, it is<br>
fairly famous.<br>
<p>
<i>&gt; &gt;I think it can be done, but it would be extremely hard to do, and </i><br>
<i>&gt; &gt;the process might be rather painful for the entities again (imagine </i><br>
<i>&gt; &gt;being resurrected all alone in a weird caricature of the real world </i><br>
<i>&gt; &gt;where *something* tries to communicate with you - and if you die, </i><br>
<i>&gt; &gt;you are immediately resurrected).</i><br>
<i>&gt; </i><br>
<i>&gt; The idea was they would be resurrected together with other </i><br>
<i>&gt; individuals form their world. And why should the resurrection </i><br>
<i>&gt; world be made a weird caricature of their real world. It could </i><br>
<i>&gt; just as well be made as familiar as possible to their real world.</i><br>
<p>
OK, I resurrect everybody into a world exactly like ours, with the<br>
slight change that miracles occurs so that nobody dies or stays<br>
dead. I think most people would regard that as a weird caricature. The<br>
big problem is how to communicate - the creator might have to try out<br>
all kinds of weird schemes ("What if I send serial messages? No, they<br>
just eat them. Parallel messages? Oops, they died again. And they seem<br>
to have killed my remote-manipulated Avatar...").<br>
<p>
Apropos dealing with simulated worlds and the relationship<br>
creator-creation, Egan's _Permutation City_ has some half-baked<br>
ideas. This is really virgin ethical territory, with links to<br>
computation theory, xenobiology and Conway knows what else. Fun!<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0906.html">Verdop: "Re: German extropians"</a>
<li> <b>Previous message:</b> <a href="0904.html">Verdop: "Re: German extropians"</a>
<li> <b>In reply to:</b> <a href="0841.html">Henri Kluytmans: "Re: Ethics of being a Creator"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
