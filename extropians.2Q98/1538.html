<!-- received="Sat May  9 14:37:11 1998 MDT" -->
<!-- sent="Sat, 09 May 1998 09:45:41 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="Dan@Clemmensen.ShireNet.com" -->
<!-- subject="Re: Hyper-AI's vs Transhumans" -->
<!-- id="199805092012.NAA29663@well.com" -->
<!-- inreplyto="Hyper-AI's vs Transhumans" -->
<title>extropians: Re: Hyper-AI's vs Transhumans</title>
<h1>Re: Hyper-AI's vs Transhumans</h1>
Dan Clemmensen (<i>Dan@Clemmensen.ShireNet.com</i>)<br>
<i>Sat, 09 May 1998 09:45:41 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1538">[ date ]</a><a href="index.html#1538">[ thread ]</a><a href="subject.html#1538">[ subject ]</a><a href="author.html#1538">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Previous message:</b> <a href="1537.html">John K Clark: "Sentience"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Reply:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Reply:</b> <a href="1541.html">Anders Sandberg: "Re: Hyper-AI's vs Transhumans"</a>
<li> <b>Reply:</b> <a href="1829.html">Hara Ra: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Anders Sandberg wrote:<br>
<i>&gt; </i><br>
[SNIPPED a cogent discussion from Anders, supporting his view that<br>
the development fo superintelligence will not be instantanous.]<br>
<p>
I nave now stated the 1998 version of the "spike",(the "instantaneous"<br>
scenario) and Anders has restated the "swell" (historically-rapid-but-not-instant<br>
scenario.) Anders' preferred spot in the scenario space is:<br>
--transition initiation team size: a large subset of the research community,<br>
 or perhaps society as a whole.<br>
--transition time: "historically rapid" (a decade?)<br>
--post-transition SI population: large(?)<br>
<p>
This is in contrast to the "spike":<br>
--transition initiation team size: 1 human, or at most a few.<br>
--transition time: days or weeks<br>
--post-transition SI population: single (perhaps incorporating humans<br>
  and/or transhumans with apparent autonomy)<br>
<p>
It may be useful to try to agree on the essence of the difference,<br>
and perhaps on our points of agreement also. I think the essence<br>
of the difference centers on the nature of intelligence<br>
augmentation (IA).<br>
<p>
The "spike" assumes that a human-computer collaboration can yield<br>
an effective intelligence amplification without first solving<br>
other hard problems in the many fields of knowledge related to<br>
intelligence. The spike further assumes that the resulting augmented<br>
intelligence can further improve itself by identifying and relieving<br>
its constraints, perhaps by solving some of those hard problems.<br>
In my paper on the subject, I focus on rapid augmentation of the<br>
computer capacity available to the collaboration.<br>
<p>
By contrast, the "swell" argues that the problems are in fact hard<br>
and that many of them must be solved before IA can occur. Perhaps<br>
solving a human-computer interface problem can yield a modest IA,<br>
but this is not sufficient to rapidly solve the next problem: you'll<br>
still need a lab full of human specialists for each problem. I will not<br>
generally be possible for a group of (say) human interface specialists<br>
to discover an IA technique based on a new human interface and then<br>
apply the IA to discover another IA technique in another field (say<br>
computer networking.) Instead, the human interface IA technique will<br>
be diseminated, and a computer networking group will apply it.<br>
Anders, please correct this if it's wrong. <br>
<p>
Thus, IMO the central difference is that the "spike" assumes the<br>
discovery of an IA technique that boosts intelligence enough so<br>
that the resulting augmented intelligence can rapidly discover another<br>
such technique. The "swell" assumes that no such event will occur, and<br>
each IA discovery is non-singularity event: it is either incremental,<br>
or it requires a large external resource input, or it is otherwise<br>
rate-constrained.<br>
<p>
The "swell" hypothesis has history on its side: we have in fact<br>
discovered IA techniques in the past, (notably moveable type, the<br>
computer, the GUI) and none of them resulted in a "spike". The<br>
"spike" proponents believe that history cannot be a guide here:<br>
the "spike" can only happen once.<br>
<p>
Newcomers who are interested in this may wish to read Damien's<br>
book "The Spike." You'll have to mail-order it from Australia,<br>
but that's what the web is for, isn't it?<br>
<p>
<i>&gt; </i><br>
<i>&gt; Perhaps a better discussion would be how we *practically* immanentize</i><br>
<i>&gt; the transcension? :-)</i><br>
<i>&gt; </i><br>
<p>
The best I can do is to try to keep up with new advances in relevant<br>
technical fields. For me, the most relevant fields are data communications,<br>
computer architecture, distributed computing, human/computer interfaces,<br>
nanotechnology, information storage and retrieval, and software development<br>
tools. I'm very aware that others of us use radically different lists,<br>
but IMO that's good. You can be in my SI if I can be in yours :-)<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Previous message:</b> <a href="1537.html">John K Clark: "Sentience"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Reply:</b> <a href="1539.html">Dan Fabulich: "Re: Sentience"</a>
<li> <b>Reply:</b> <a href="1541.html">Anders Sandberg: "Re: Hyper-AI's vs Transhumans"</a>
<li> <b>Reply:</b> <a href="1829.html">Hara Ra: "Re: Sentience"</a>
<!-- reply="end" -->
</ul>
