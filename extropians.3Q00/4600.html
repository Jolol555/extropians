<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Zero Powers (zero_powers@hotmail.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sat Sep  9 05:04:53 2000" -->
<!-- isoreceived="20000909110453" -->
<!-- sent="Sat, 09 Sep 2000 04:04:29 PDT" -->
<!-- isosent="20000909110429" -->
<!-- name="Zero Powers" -->
<!-- email="zero_powers@hotmail.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="F112Mb1s7nlT2NqFJ3s0000753a@hotmail.com" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> Zero Powers (<A HREF="mailto:zero_powers@hotmail.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;F112Mb1s7nlT2NqFJ3s0000753a@hotmail.com&gt;"><EM>zero_powers@hotmail.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat Sep 09 2000 - 05:04:29 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4601.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4599.html">Eugene Leitl: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5528.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4600">[ date ]</A>
<A HREF="index.html#4600">[ thread ]</A>
<A HREF="subject.html#4600">[ subject ]</A>
<A HREF="author.html#4600">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
From: Eliezer S. Yudkowsky &lt;<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;F112Mb1s7nlT2NqFJ3s0000753a@hotmail.com&gt;">sentience@pobox.com</A>&gt;
<BR>
<P><EM>&gt;Zero Powers wrote:
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Well, back to the heart of my initial question.  Is friendliness toward
</EM><BR>
<EM>&gt; &gt; humans a supergoal, a subgoal, or even a goal at all?  I assume 
</EM><BR>
<EM>&gt;(possibly
</EM><BR>
<EM>&gt; &gt; incorrectly) you will claim it to be a supergoal.  If that is the case, 
</EM><BR>
<EM>&gt;how
</EM><BR>
<EM>&gt; &gt; do you keep a sentient AI focused on that goal once it begins to ask
</EM><BR>
<EM>&gt; &gt; existential questions?
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;If the existential questions don't have answers, I don't see why the SI 
</EM><BR>
<EM>&gt;asking
</EM><BR>
<EM>&gt;them would pose a problem.  If there is no objective morality, then the
</EM><BR>
<EM>&gt;existential questions don't have answers.  If there is objective morality,
</EM><BR>
<EM>&gt;then the initial suggestions will get junked anyway.
</EM><BR>
<P>Could be we are getting tripped up on each other's semantics.  I don't 
<BR>
believe there is such thing as a question without an answer.  There may be 
<BR>
no &quot;objective&quot; morality in the sense that one morality will work for every 
<BR>
intelligent being at all times and all places.  But, for each individual, 
<BR>
and in each circumstance, there is certainly a morality which works best.  
<BR>
It may not necessarily be &quot;objective&quot; per se, but it is real nonetheless.
<BR>
<P>I believe at some point AI will say to itself, &quot;What is the best course of 
<BR>
endeavor for me, considering the kind of being I am?&quot;  I highly doubt it 
<BR>
will answer that question by saying &quot;The best thing for me to do is obey the 
<BR>
commands of these ignoramus humans, because that's what they tell me to do.&quot;
<BR>
<P>When you say &quot;the initial suggestions will get junked anyway&quot; if there is an 
<BR>
objective morality, then you are pretty much conceding that ultimately 
<BR>
there'll be little assurance of human-friendly AI, right?
<BR>
<P><EM>&gt;Remember, an SI isn't going to be tormented by the pointlessness of it all
</EM><BR>
<EM>&gt;because it doesn't have the be-tormented-by-the-pointlessness-of-it-all
</EM><BR>
<EM>&gt;hardware.
</EM><BR>
<P>What makes you think our torment at pointlessness resides in the hardware?  
<BR>
Seems pretty obvious to me its in the *software*.  In terms of hardware, 
<BR>
ours isn't much different than monkeys.  Somehow I just don't see them as 
<BR>
suffering torment over pointlessness.
<BR>
<P>-Zero
<BR>
<P>Learn how your computer can earn you money while you sleep!
<BR>
<A HREF="http://www.ProcessTree.com/?sponsor=38158">http://www.ProcessTree.com/?sponsor=38158</A>
<BR>
<P>_________________________________________________________________________
<BR>
Get Your Private, Free E-mail from MSN Hotmail at <A HREF="http://www.hotmail.com">http://www.hotmail.com</A>.
<BR>
<P>Share information about yourself, create your own public profile at 
<BR>
<A HREF="http://profiles.msn.com">http://profiles.msn.com</A>.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4601.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4599.html">Eugene Leitl: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5528.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4600">[ date ]</A>
<A HREF="index.html#4600">[ thread ]</A>
<A HREF="subject.html#4600">[ subject ]</A>
<A HREF="author.html#4600">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:34 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
