<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Emlyn (emlyn@one.net.au)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Fri Sep 29 07:15:04 2000" -->
<!-- isoreceived="20000929131504" -->
<!-- sent="Sat, 30 Sep 2000 00:10:38 +1000" -->
<!-- isosent="20000929141038" -->
<!-- name="Emlyn" -->
<!-- email="emlyn@one.net.au" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="007701c02a1f$0bf51de0$893265cb@squashy2000" -->
<!-- inreplyto="01ba01c029e9$97902920$c5bc473f@jrmolloy" -->
<STRONG>From:</STRONG> Emlyn (<A HREF="mailto:emlyn@one.net.au?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;007701c02a1f$0bf51de0$893265cb@squashy2000&gt;"><EM>emlyn@one.net.au</EM></A>)<BR>
<STRONG>Date:</STRONG> Fri Sep 29 2000 - 08:10:38 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="6054.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6052.html">Emlyn: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6037.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6070.html">Spike Jones: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6148.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6053">[ date ]</A>
<A HREF="index.html#6053">[ thread ]</A>
<A HREF="subject.html#6053">[ subject ]</A>
<A HREF="author.html#6053">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<EM>&gt; Eugene Leitl writes,
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt; Your reasoning is based on a slow, soft Singularity, where both the
</EM><BR>
<EM>&gt; &gt; machines and humans converge, eventually resulting in an amalgamation,
</EM><BR>
<EM>&gt; &gt; advancing slowly enough so that virtually everybody can follow. While
</EM><BR>
<EM>&gt; &gt; it may happen that way, I don't think it to be likely. I would like to
</EM><BR>
<EM>&gt; &gt; hear some convincing arguments as to why you think I'm mistaken.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; I can't think you're mistaken, since this thread entails nothing that can
</EM><BR>
<EM>&gt; presently be tested. My current readings in robotics persuade me that the
</EM><BR>
most
<BR>
<EM>&gt; successful engineers will build machines which can do useful things,
</EM><BR>
rather than
<BR>
<EM>&gt; try to build humanoid robots, just to prove it can be done. Similarly, I
</EM><BR>
don't
<BR>
<EM>&gt; find a fast technological singularity as useful as a convergence of
</EM><BR>
augmented
<BR>
<EM>&gt; humans with their Mind Children. IOW, the only usefulness of a fast TS
</EM><BR>
would be
<BR>
<EM>&gt; to escape or leave behind Homo sapiens (those nasty war mongers).
</EM><BR>
<P>I think I missed a bunch of posts, no idea why, damned ISP (they'll be first
<BR>
against the wall when the singularity comes, don't worry about that).
<BR>
Anyway, this slow singularity thing has got me beat. Doesn't the idea
<BR>
contradict the definition? Exponential (or double exponential or whatever
<BR>
people are calling it, where the rate of acceleration increases), doesn't
<BR>
really have a slow option.
<BR>
<P>Also, I am intrigued by the idea of questioning the usefulness of a fast
<BR>
singularity. Pretty much, the idea of technological singularity is that it
<BR>
is fast, by definition, after a certain point (and most likely fairly
<BR>
invisible before that point), and it's not the result of committee decision
<BR>
making; it's just going to happen, as an emergent property of decentralised
<BR>
technological and scientific research/world economy/some other stuff I've
<BR>
missed, in place in the world right now.
<BR>
<P>The options appear to be
<BR>
1 - Draconian crack down on everything technological across the entire world
<BR>
(the tournique on the neck option), or
<BR>
2 - Put on your flippers and flying goggles, it's party time!
<BR>
<P>However, 2 isn't quite as out of control as it might appear; there is some
<BR>
hope that we can figure out at least the initial conditions we would favour
<BR>
going into the spike (whatever good that does us), then guide things in that
<BR>
direction. That's one of the basic reasons for being for the transhumanist
<BR>
movement, is it not? Caveat: some THers don't believe in the mighty deity
<BR>
that is the Spike; they have other goals.
<BR>
<P>Emlyn
<BR>
(Talking of Spike, he really did dissapear, cold turkey no less! Scary!)
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="6054.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6052.html">Emlyn: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6037.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6070.html">Spike Jones: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6148.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6053">[ date ]</A>
<A HREF="index.html#6053">[ thread ]</A>
<A HREF="subject.html#6053">[ subject ]</A>
<A HREF="author.html#6053">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:23 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
