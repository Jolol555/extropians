<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Robin Hanson (rhanson@gmu.edu)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep  7 10:24:31 2000" -->
<!-- isoreceived="20000907162431" -->
<!-- sent="Thu, 07 Sep 2000 12:26:05 -0400" -->
<!-- isosent="20000907162605" -->
<!-- name="Robin Hanson" -->
<!-- email="rhanson@gmu.edu" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="4.2.0.58.20000907115629.00c19470@mason.gmu.edu" -->
<!-- inreplyto="200009071520.IAA19522@finney.org" -->
<STRONG>From:</STRONG> Robin Hanson (<A HREF="mailto:rhanson@gmu.edu?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;4.2.0.58.20000907115629.00c19470@mason.gmu.edu&gt;"><EM>rhanson@gmu.edu</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 07 2000 - 10:26:05 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4499.html">Brent Allsop: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4497.html">scerir: "C.M. Cipolla &amp; basic laws of stupidity"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4495.html">hal@finney.org: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4498">[ date ]</A>
<A HREF="index.html#4498">[ thread ]</A>
<A HREF="subject.html#4498">[ subject ]</A>
<A HREF="author.html#4498">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Hal Finney wrote:
<BR>
<EM>&gt;our minds are composed of multiple agents, cooperating and competing.
</EM><BR>
<EM>&gt;Each has its own skills and abilities, but also its own desires and
</EM><BR>
<EM>&gt;agenda.  ...
</EM><BR>
<EM>&gt;The interesting question is whether AIs will be designed with a similar
</EM><BR>
<EM>&gt;mental organization.  Will they be beset by the inconsistencies and
</EM><BR>
<EM>&gt;contradictions of our human minds with all their parts?  Apparently it
</EM><BR>
<EM>&gt;was the best evolution could do.  Can we do better?
</EM><BR>
<P>A good question.  The ability to do abstract reasoning has only recently
<BR>
been invented, and it clearly is tacked onto a brain that learned to make
<BR>
choices without it.  But given the ability to do abstract reasoning it
<BR>
seems tempting to have just one abstract goal, and then give some central
<BR>
module control over how much moment-to-moment influence to grant to
<BR>
other lower level modules focused on more particular goals.
<BR>
<P>In particular if the abstract goal were the evolutionary one of &quot;induce
<BR>
as many long-term descendants as possible&quot;, such agents would seem to
<BR>
have an ideal ability to adapt to new environments in an evolutionary
<BR>
competition.
<BR>
<P>Humans do have an abstract reasoning module, and that module often tries
<BR>
to give the impression that it is in fact in such control over the rest
<BR>
of the mind.  But in fact I think our conscious minds are more like the
<BR>
PR department of our minds - they try to put a good spin on the decisions
<BR>
that are made, but are not actually in much control over those decisions.
<BR>
<P>Robin Hanson  <A HREF="mailto:rhanson@gmu.edu?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;4.2.0.58.20000907115629.00c19470@mason.gmu.edu&gt;">rhanson@gmu.edu</A>  <A HREF="http://hanson.gmu.edu">http://hanson.gmu.edu</A>
<BR>
Asst. Prof. Economics, George Mason University
<BR>
MSN 1D3, Carow Hall, Fairfax VA 22030-4444
<BR>
703-993-2326  FAX: 703-993-2323
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4499.html">Brent Allsop: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4497.html">scerir: "C.M. Cipolla &amp; basic laws of stupidity"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4495.html">hal@finney.org: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4498">[ date ]</A>
<A HREF="index.html#4498">[ thread ]</A>
<A HREF="subject.html#4498">[ subject ]</A>
<A HREF="author.html#4498">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:29 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
