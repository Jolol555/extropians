<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Thoughts, elite, future morality (was &quot;ye are</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Thoughts, elite, future morality (was &quot;ye are gods&quot;)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Thoughts, elite, future morality (was &quot;ye are gods&quot;)</H1>
<!-- received="Fri Sep 29 18:36:04 2000" -->
<!-- isoreceived="20000930003604" -->
<!-- sent="Fri, 29 Sep 2000 17:38:17 -0700" -->
<!-- isosent="20000930003817" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Thoughts, elite, future morality (was &quot;ye are gods&quot;)" -->
<!-- id="39D535F9.A7E728F0@objectent.com" -->
<!-- inreplyto="009e01c025d5$762daae0$3d6165cb@squashy2000" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Thoughts,%20elite,%20future%20morality%20(was%20&quot;ye%20are%20gods&quot;)&In-Reply-To=&lt;39D535F9.A7E728F0@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Fri Sep 29 2000 - 18:38:17 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="6126.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6124.html">Dan Fabulich: "Re: Lanier's losing his edge?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5547.html">Emlyn: "Re: Ye Are Gods"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5455.html">Michael LaTorra: "Re: Ye Are Gods"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6125">[ date ]</A>
<A HREF="index.html#6125">[ thread ]</A>
<A HREF="subject.html#6125">[ subject ]</A>
<A HREF="author.html#6125">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Emlyn wrote ( a very good set of ideas I'm finally getting back to) :
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;Samantha wrote:
</EM><BR>
<EM>&gt; &gt; On average, as a point of fact, there is not a person on this list who
</EM><BR>
<EM>&gt; &gt; doesn't &quot;know better&quot; than the vast majority of the world's population
</EM><BR>
<EM>&gt; &gt; about a great many things.  I am sorry if it breaks local taboos to
</EM><BR>
<EM>&gt; &gt; point this out. Intelligence is not distributed evenly.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; ...and most of those people probably know at least one thing better than
</EM><BR>
<EM>&gt; every person on this list. Scott Adams says, in the Dilbert Principle, that
</EM><BR>
<EM>&gt; people are idiots. Even the smart people are only smart at certain times and
</EM><BR>
<EM>&gt; in limited ways, and are for the most part fools. Maybe that's a stupid
</EM><BR>
<EM>&gt; reference; I must be an idiot.
</EM><BR>
<P>If you insist.  But I don't think you are an idiot.  Perhaps a little
<BR>
overly cynical, but not an idiot.  I do not agree with the statement
<BR>
that even smart people are only smart at certain times and in limited
<BR>
ways.  Generally, people who are smarter than average are, well, smarter
<BR>
than average and on more than a few limited things.  Also it depends on
<BR>
how you use &quot;smarter&quot;.  People who actually work at being rational
<BR>
andbalanced and who have developed the habit of questioning and testing
<BR>
even deeply cherished beliefs are &quot;smarter&quot; than those that have not and
<BR>
do not.  I would much rather have those people have a large vote on
<BR>
important matters than folks who might believe more exactly what they
<BR>
have been taught or spend every free minute drinking beer and watching
<BR>
TV or the equivalent.
<BR>
<P>When it comes to technology related decisions the choice is even more
<BR>
clear.  We cannot afford for people who know nothing of technology,
<BR>
could care less and are even anti-technology to control technology and
<BR>
thus our futures. 
<BR>
<P><P><EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Do you actually ask for broad consensus for your own work, for every
</EM><BR>
<EM>&gt; &gt; design and implementation decision?  No?  Is that only because what you
</EM><BR>
<EM>&gt; &gt; are doing doesn't affect many people or is it also because most people
</EM><BR>
<EM>&gt; &gt; wouldn't have any idea what they were talking about if they tried to
</EM><BR>
<EM>&gt; &gt; advise you on your work?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; No, I don't ask for concensus under such conditions. Mostly because it
</EM><BR>
<EM>&gt; doesn't affect many people, at least not in any way that they don't have
</EM><BR>
<EM>&gt; control over; like, if I build some or all of a business website, the
</EM><BR>
<EM>&gt; algorithm for importing log files into a database doesn't really affect a
</EM><BR>
<EM>&gt; whole lot of people. Possibly such choices might effect people through the
</EM><BR>
<EM>&gt; time it will take to implement them; if so, I'll go talk about it.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Eventually this work will affect some people, particularly at a critical
</EM><BR>
<EM>&gt; point; when it comes time to make it part of the production system. The main
</EM><BR>
<EM>&gt; people it affects will be the system owners, and the effects possibly are
</EM><BR>
<EM>&gt; quite important. So in that case, I certainly do seek consensus.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Really?  Even from people who do not have the skills necessary to
<BR>
evaluate the decision?  If so, how does that help anyone?
<BR>
<P>&nbsp;
<BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Should the human race only be allowed to advance in steps that were all
</EM><BR>
<EM>&gt; &gt; approved by the broad consensus?  Should a poll have been taken before
</EM><BR>
<EM>&gt; &gt; we allowed that the sun is the central body of the solar system rather
</EM><BR>
<EM>&gt; &gt; than earth?  Oh, you say, we don't need to get a consensus for facts.
</EM><BR>
<EM>&gt; &gt; But then why do you need a consensus to bring major advances into play
</EM><BR>
<EM>&gt; &gt; that 98% of the world's people never will understand well and that the
</EM><BR>
<EM>&gt; &gt; majority are singularly unqualified to pass judgement upon?
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; You're right; the existence of this ignorant 98% is obviously anathema to
</EM><BR>
<EM>&gt; the advance of humanity as a whole.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>I didn't say that.  I do say letting the ignorant drive decisions that
<BR>
they have no means to understand is grossly wrong and tremendously
<BR>
dangerous.  
<BR>
&nbsp;
<BR>
<EM>&gt; &gt; I ask these things to open conversation rather than to say &quot;You are
</EM><BR>
<EM>&gt; &gt; wrong.&quot;  I actually sympathize with some of your concern.  But I don't
</EM><BR>
<EM>&gt; &gt; see how waiting for consensus is a sign of proper diligence or will
</EM><BR>
<EM>&gt; &gt; actually help humanity at all.  Call it elitist if it makes you feel
</EM><BR>
<EM>&gt; &gt; better, but I believe recognizing the paucity of intelligence is simple
</EM><BR>
<EM>&gt; &gt; honesty.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; People piss me off too. Still, we all live here (in the universe); it's good
</EM><BR>
<EM>&gt; when we can get along.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>And when we can't?  Who decides?  
<BR>
&nbsp;
<BR>
<EM>&gt; Obviously I don't subscribe to this idea that the alleged 98% bozo factor
</EM><BR>
<EM>&gt; should be lead by the natural leaders in the top 2% (amongst which I imagine
</EM><BR>
<EM>&gt; you would count yourself). Possibly it's because I am worried that I'm more
</EM><BR>
<EM>&gt; borderline, and might not make the cut! I wouldn't like that much, and I can
</EM><BR>
<EM>&gt; empathise with others who feel the same way.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>You can be quite bright and still not be a good leader.  I am not
<BR>
talking about a dictatorship of the elite or some such nonsense.  I am
<BR>
talking about not leading the uneducated and unqualified make decisions
<BR>
just because they are there and we have some notion that everyone should
<BR>
decide everything.  I think it would be quite irresponsible to let this
<BR>
notion determine our future.  There isn't a cut on IQ or something like
<BR>
that.  I brought up this because I thought I was hearing from you that
<BR>
&quot;everyone&quot; should decide major technological questions.  I am attempting
<BR>
to point out that isn't necessarily a good idea even if you could
<BR>
implement it.  
<BR>
&nbsp;
<BR>
<EM>&gt; &gt; I also believe that failing to acknowledge one's intelligence and
</EM><BR>
<EM>&gt; &gt; ability to help choose and produce the future can be a false modesty
</EM><BR>
<EM>&gt; &gt; that keeps one from being fully and responsibly engaged.  Failing to
</EM><BR>
<EM>&gt; &gt; step up and do what you can taking full responsibility is required of a
</EM><BR>
<EM>&gt; &gt; great number of us if human beings are to have a viable, much less
</EM><BR>
<EM>&gt; &gt; joyously abundant, future.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I'm not sending us out to the fields to be farmers.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Good!  Now why was that the response?   (not quite getting it)
<BR>
&nbsp;
<BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; This is a time of unparalleled change, and will look like a walk in the
</EM><BR>
<EM>&gt; park
</EM><BR>
<EM>&gt; &gt; &gt; next to the times to come. It is a time for humility in our approach,
</EM><BR>
<EM>&gt; and
</EM><BR>
<EM>&gt; &gt; &gt; special concern for the other beings that inhabit the planet; as it
</EM><BR>
<EM>&gt; becomes
</EM><BR>
<EM>&gt; &gt; &gt; easier for the few to ignore the wishes of the many, it becomes no more
</EM><BR>
<EM>&gt; &gt; &gt; tolerable to do so.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; It is precisely because of HUGE concern for the needs of all humanity
</EM><BR>
<EM>&gt; &gt; that many of us became scientists and technologists and it is out of
</EM><BR>
<EM>&gt; &gt; that concern that we dream large dreams and see to what  extent they can
</EM><BR>
<EM>&gt; &gt; become reality. We would be irresponsible, having been gifted or having
</EM><BR>
<EM>&gt; &gt; acquired such ability if we did not use it.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I'm not sending us out to the fields to be farmers.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Good...
<BR>
&nbsp;
<BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; The cutting edge of any species is the edge.  It is not the consesus
</EM><BR>
<EM>&gt; &gt; masses. Why condemn the edge for being the edge?  It is there that
</EM><BR>
<EM>&gt; &gt; advance will happen that lifts the whole.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Too cool. I'm all for that. Count me in! I'm not sending us out to the
</EM><BR>
<EM>&gt; fields to be farmers.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>OK.
<BR>
&nbsp;
<BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; Also, we are playing with fire - well, actually fire is a baby's toy
</EM><BR>
<EM>&gt; &gt; &gt; compared to the stuff we are messing with now. It's not a good time to
</EM><BR>
<EM>&gt; get
</EM><BR>
<EM>&gt; &gt; &gt; complacent and arrogant - &quot;we are as gods, ha ha ha!&quot;. It's time to be
</EM><BR>
<EM>&gt; more
</EM><BR>
<EM>&gt; &gt; &gt; humble than ever, to be open-system, to take in information from our
</EM><BR>
<EM>&gt; &gt; &gt; environment. It's been discussed on the list just how dangerous some of
</EM><BR>
<EM>&gt; the
</EM><BR>
<EM>&gt; &gt; &gt; coming technologies are (ai, nanotech, etc), and if you go over the
</EM><BR>
<EM>&gt; posts,
</EM><BR>
<EM>&gt; &gt; &gt; you'll see that most of the danger is attributed to use of that
</EM><BR>
<EM>&gt; technology
</EM><BR>
<EM>&gt; &gt; &gt; by humans infected with the God meme. People who think that they know
</EM><BR>
<EM>&gt; better
</EM><BR>
<EM>&gt; &gt; &gt; than everyone else, who feel justified in producing externalities (like
</EM><BR>
<EM>&gt; grey
</EM><BR>
<EM>&gt; &gt; &gt; goo).
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Humility taken so far is for people who will deny their own strength AND
</EM><BR>
<EM>&gt; &gt; their huge responsibility.  It is not a strategy that helps anyone.
</EM><BR>
<EM>&gt; &gt; Seeing the huge potentials for change is not something that makes me the
</EM><BR>
<EM>&gt; &gt; least bit complacent.  It scares the heebie-jeebies out of me quite
</EM><BR>
<EM>&gt; &gt; often.  But it is where the power and future of this species lie.  Those
</EM><BR>
<EM>&gt; &gt; of us who are the forerunners, the intellectual scouts, the builders of
</EM><BR>
<EM>&gt; &gt; bridges between today and tomorrow, including those of us who
</EM><BR>
<EM>&gt; &gt; cross-check that we are keeping our wits about us, certainly cannot
</EM><BR>
<EM>&gt; &gt; afford to be complacent.  But that doesn't mean we should stand aside or
</EM><BR>
<EM>&gt; &gt; be frightened to look and to attempt to chart a path forward that makes
</EM><BR>
<EM>&gt; &gt; the most sense and enables the best outcomes.  After all, if we don't
</EM><BR>
<EM>&gt; &gt; make the attempt, then can we expect to take care of our default?  If
</EM><BR>
<EM>&gt; &gt; not us, who?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Humility is not fear. It's probably the opposite.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Yes, we need as many voices and viewpoints as can be fruitfully
</EM><BR>
<EM>&gt; &gt; employed.  Yes, we are talking about some of the most serious things
</EM><BR>
<EM>&gt; &gt; anyone has ever contemplated and our euphoria should be tempered with
</EM><BR>
<EM>&gt; &gt; quite a bit of sobriety.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; One thing that worries me is that we are quite good and coming up with
</EM><BR>
<EM>&gt; &gt; technology.  We are not nearly so good at creating a unifying vision (or
</EM><BR>
<EM>&gt; &gt; sets of visions) that will more likely shape the use and unfolding of
</EM><BR>
<EM>&gt; &gt; the technology for the maximum good.  If we don't create a vision or set
</EM><BR>
<EM>&gt; &gt; of positive visions to guide us then the technology will more than
</EM><BR>
<EM>&gt; &gt; likely greatly magnify all the good and bad tendencies in the world
</EM><BR>
<EM>&gt; &gt; today.  I doubt that that is survivable.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; On first reading, that sounded suspiciously like consensus seeking. But I
</EM><BR>
<EM>&gt; think what you mean, is that someone needs to create a future vision for
</EM><BR>
<EM>&gt; people to rally behind, so that we have some framework for moving into the
</EM><BR>
<EM>&gt; future to full potential, whilst identifying potential problems and avoiding
</EM><BR>
<EM>&gt; traps. I think that's probably the motivation for Transhumanism, in a
</EM><BR>
<EM>&gt; nutshell.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Lets see if I can make clearer what I was trying to say. There is a
<BR>
subtle difference between consensus seeking that is relatively passive
<BR>
and consensus building which takes pulling peoples dreams and ideas out
<BR>
and facilitating weaving them into a tapestry that a consensus can get
<BR>
excited by and work for.  It is the second that is most woefully needed
<BR>
today.  The vision does not come from on high exclusively handed down to
<BR>
the masses.  It includes the major dreams and leitmotifs to enroll many
<BR>
different kinds of people.
<BR>
&nbsp;&nbsp;&nbsp;
<BR>
<EM>&gt; I support this. I support transhumanism. I'd even call myself a
</EM><BR>
<EM>&gt; transhumanist. &quot;Emlyn, you're a transhumanist. Nyah nyah!&quot;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; What I'm talking about, in all these ravings and ramblings about humility,
</EM><BR>
<EM>&gt; is the essense of transhumanism. As a vision, it is optimistic, it's forward
</EM><BR>
<EM>&gt; thinking, it's possibly individualistic. Also, it's about people, and
</EM><BR>
<EM>&gt; humanity, even as it seeks to leave humanity behind.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>AMEN.  I agree 100% and I thank you for pointing it out.
<BR>
<P><EM>&gt; I'm not talking about &quot;banning&quot; technologies; who's going to decide what to
</EM><BR>
<EM>&gt; ban? I am interested in respecting the rest of humanity when we make
</EM><BR>
<EM>&gt; changes.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>Agreed.  But what does that respect consists of and what does it not
<BR>
consists of.  That is an interesting (and difficult) question.
<BR>
<P><EM>&gt; What does that mean in concrete terms, applied to technology? It means that
</EM><BR>
<EM>&gt; while scientific &amp; technological progress is good, we must be careful about
</EM><BR>
<EM>&gt; applications of technology.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; For instance, nanotech is a good idea, and ought to be developed. Being able
</EM><BR>
<EM>&gt; to heal ourselves, repair ourselves, modify our selves, through nanotech, it
</EM><BR>
<EM>&gt; also good (excellent!). Being able to modify other people, well, that's not
</EM><BR>
<EM>&gt; so good. Releasing self replicators into the general environment without
</EM><BR>
<EM>&gt; safeguards; not so good. Modifying the environment that others inhabit; not
</EM><BR>
<EM>&gt; good, without some mechanism for consensus. That doesn't mean that we'd
</EM><BR>
<EM>&gt; better not develop the technology. It means that we have to develop and
</EM><BR>
<EM>&gt; promote a morality to go with it, about respecting other people.
</EM><BR>
<EM>&gt;
</EM><BR>
<P><P>I agree that we need to develop the morality.  Very, very much so.  But
<BR>
I am not sure in practice what respecting other people's rights includes
<BR>
and does not include.  Does it include the right to believe the world is
<BR>
not as it is, to out and out deny reality and to force others to obey
<BR>
decisions based on that denial and subsequent fantasies?  For it should
<BR>
go both ways.  If we can't force our notions on them they should not be
<BR>
able to force theirs on us.
<BR>
<P>A thought experiment.  I am not seriously advocating this but I think it
<BR>
bears thinking about.  What if 98% of the world (or some sizeable
<BR>
fraction of humanity) is seriously broken in some physical/psychological
<BR>
way and the technology exists to fix this and is even free?  What if
<BR>
most of these folks, in their brokenness, refuse this technology?  What
<BR>
if their broken condition is actually doing serious injury to
<BR>
themselves, to the environment and to others.  Do we have the right to
<BR>
put a mickey in the water or nanobots that will perform the fix in the
<BR>
environment?   I would say no. But it is not a simple situation.  
<BR>
<P>Here is another.  We are at the Singularity or close enough that the
<BR>
transhuman folks are radically different from and vastly more capable
<BR>
than the &quot;mere&quot; humans.   In most fields mere humans are simply unable
<BR>
to compete. This is causing considerable friction.  We transhumans have
<BR>
more than adequate resources to take care of the mere humans.  But many
<BR>
of them hate and despise us and actively seek our destruction.  Many
<BR>
feel our very existence is such an affront to their sensibilities that
<BR>
we cannnot be tolerated.  They are a danger to themselves and one
<BR>
another if not to us.  .  Do we:
<BR>
<P>a) pop them into a VR tank where they can live in whatever fantasy they
<BR>
wish for as long as they wish and change their minds whenever they want? 
<BR>
<P>voluntary or not?
<BR>
<P>would we put them in involuntarily if that was the only way they could
<BR>
survive without being forced by reality to change in ways that are
<BR>
utterly repugnant to them?
<BR>
<P>b) ignore them and simply defend ourselves against assaults?
<BR>
<P>c) leave them on Earth and head off elsewhere?
<BR>
<P><P>&nbsp;
<BR>
<EM>&gt; Also, AI is good; intelligence augmentation is fantastic. Creating a self
</EM><BR>
<EM>&gt; modifying super intelligence is good. Turning it on, and plugging it into
</EM><BR>
<EM>&gt; the world's computer systems, without asking everyone else if that'd be ok
</EM><BR>
<EM>&gt; by them, that's not good. That's very naughty. That's could be called
</EM><BR>
<EM>&gt; sociopathic.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>So, do you think the masses of people would ever agree to let this loose
<BR>
under any circumstances?  Or would the vast majority call for its
<BR>
immediate destruction?  To educate a fully self-learning AI of great
<BR>
power requires huge amounts of input.  If you don't get it from the Net
<BR>
where will you get it?  I agree it is questionable to plug it in.  It is
<BR>
also questionable to try to make the decision a case of majority vote. 
<BR>
It is questionable to not plug it in also. 
<BR>
<P><P><EM>&gt; Working on GM food is good. Great! Designing crops to feed more people,
</EM><BR>
<EM>&gt; excellent. Designing crops with terminator genes, dodgy, but still ok,
</EM><BR>
<EM>&gt; maybe. Releasing self replicators into the general environment without
</EM><BR>
<EM>&gt; safeguards, not so good.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Actually GM food is absolutely essential.  Correct me if I'm wrong but
<BR>
some of those terminator genes were actually necessary for the integrity
<BR>
of certain types GM itself.  Some of the termination gene stuff was to
<BR>
prevent the mutant seeds FROM being full self-replicators.  Granted some
<BR>
of the motives behind that were more about greed.
<BR>
<P>On the other hand, self-replicators are created and released into the
<BR>
environment by natural processes all the time.  Many of them are quite
<BR>
dangerous.  We should definitely think long and hard about our own
<BR>
designed ones but I see no reason self-replication as such should be
<BR>
banned or is automatically bad.  Some types of problems and some goals
<BR>
we all find pretty wonderful cannot be addressed without
<BR>
self-replicating entities.
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;
<BR>
<EM>&gt; I could be very wrong about the technologies I've outlined above. That's the
</EM><BR>
<EM>&gt; point. I'm not about to appoint myself the arbiter of human morality for the
</EM><BR>
<EM>&gt; 21st century (although apparently I do have an opinion). I'd appreciate it
</EM><BR>
<EM>&gt; if others afforded the same respect to me.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>People who are concerned and capable should make decisions in this
<BR>
area.  It is not going to be easy.  Decisions that pull in as many
<BR>
people as possible who can contribute must be made though.  The future
<BR>
will not be what we want it simply by default and happenstance.  
<BR>
<P><P><EM>&gt; As an aside, I think it's funny that transhumanism, which purports to being
</EM><BR>
<EM>&gt; about moving away from humanity, is actually more about what it is,
</EM><BR>
<EM>&gt; fundamentally, to be human, than any other belief system/philosophy/vision
</EM><BR>
<EM>&gt; that I can think of. Its about us merging more fully with our tools,
</EM><BR>
<EM>&gt; believing more strongly in our ability to reshape the universe, believing in
</EM><BR>
<EM>&gt; ourselves rather than some unknowable greater force(s). What is more
</EM><BR>
<EM>&gt; essentially human, than the intimate relationship we have with our tools,
</EM><BR>
<EM>&gt; and our desire to reshape our environment using them? To lose that focus,
</EM><BR>
<EM>&gt; and that ability, makes us less human; so to strengthen it, makes us more
</EM><BR>
<EM>&gt; so. The posthumans of our vision, supposedly having left humanity behind,
</EM><BR>
<EM>&gt; will be paradoxically, maximally human. Possibly not organic, but 100%
</EM><BR>
<EM>&gt; natural, certainly.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P><P>Very well said!
<BR>
<P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="6126.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6124.html">Dan Fabulich: "Re: Lanier's losing his edge?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5547.html">Emlyn: "Re: Ye Are Gods"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5455.html">Michael LaTorra: "Re: Ye Are Gods"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6125">[ date ]</A>
<A HREF="index.html#6125">[ thread ]</A>
<A HREF="subject.html#6125">[ subject ]</A>
<A HREF="author.html#6125">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:27 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
