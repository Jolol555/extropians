<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Emlyn (emlyn@one.net.au)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sat Sep 30 00:27:54 2000" -->
<!-- isoreceived="20000930062754" -->
<!-- sent="Sat, 30 Sep 2000 17:23:28 +1000" -->
<!-- isosent="20000930072328" -->
<!-- name="Emlyn" -->
<!-- email="emlyn@one.net.au" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="007701c02aaf$5566d5a0$ef3765cb@squashy2000" -->
<!-- inreplyto="39D51372.A9624C3B@Innovation-On-Demand.com" -->
<STRONG>From:</STRONG> Emlyn (<A HREF="mailto:emlyn@one.net.au?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;007701c02aaf$5566d5a0$ef3765cb@squashy2000&gt;"><EM>emlyn@one.net.au</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat Sep 30 2000 - 01:23:28 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="6146.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6144.html">EvMick@aol.com: "Re: back off, im gay!"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6111.html">Ken Clements: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6158.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6167.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6145">[ date ]</A>
<A HREF="index.html#6145">[ thread ]</A>
<A HREF="subject.html#6145">[ subject ]</A>
<A HREF="author.html#6145">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<EM>&gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; &quot;Any Friendly behavior that follows the major use-cases - that avoids
</EM><BR>
<EM>&gt; &gt; destruction or modification of any sentient without that sentient's
</EM><BR>
<EM>&gt; &gt; permission, and that attempts to fulfill any legitimate request after
</EM><BR>
checking
<BR>
<EM>&gt; &gt; for unintended consequences - would count as at least a partial success
</EM><BR>
from
<BR>
<EM>&gt; &gt; an engineering perspective.&quot;
</EM><BR>
<EM>&gt; &gt;         -- from a work in progress
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; How can this work?  If someone tells me something that I did not know,
</EM><BR>
they have
<BR>
<EM>&gt; modified me (assuming I remember what they told me).  If an IA is required
</EM><BR>
not to
<BR>
<EM>&gt; modify me without my permission, it will have to refrain from telling me
</EM><BR>
anything
<BR>
<EM>&gt; I do not already know, because it will not be able to get my informed
</EM><BR>
consent to
<BR>
<EM>&gt; be told the thing to be told, without telling me the thing.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; What is a &quot;legitimate request&quot;?
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; How do you check for &quot;unintended consequences&quot; without running a
</EM><BR>
simulation of the
<BR>
<EM>&gt; entire Universe out to heat death?  Even in the short run, how will the AI
</EM><BR>
account
<BR>
<EM>&gt; for the impact of its own future actions in the matter without first
</EM><BR>
running a
<BR>
<EM>&gt; simulation of itself?
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; -Ken
</EM><BR>
<P>I guess AI will have to make a judgement call. That's the truly dangerous
<BR>
part.
<BR>
<P>Emlyn
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="6146.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6144.html">EvMick@aol.com: "Re: back off, im gay!"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6111.html">Ken Clements: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6158.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6167.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6145">[ date ]</A>
<A HREF="index.html#6145">[ thread ]</A>
<A HREF="subject.html#6145">[ subject ]</A>
<A HREF="author.html#6145">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:28 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
