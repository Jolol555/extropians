<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="hal@finney.org (hal@finney.org)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep  7 18:39:10 2000" -->
<!-- isoreceived="20000908003910" -->
<!-- sent="Thu, 7 Sep 2000 17:38:48 -0700" -->
<!-- isosent="20000908003848" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="200009080038.RAA21019@finney.org" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> <A HREF="mailto:hal@finney.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;200009080038.RAA21019@finney.org&gt;"><EM>hal@finney.org</EM></A><BR>
<STRONG>Date:</STRONG> Thu Sep 07 2000 - 18:38:48 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4525.html">QueeneMUSE@aol.com: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4523.html">J. R. Molloy: "Re: Hypnosis?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="4557.html">Robin Hanson: "Consciousness as PR (was: Why would AI want to be friendly?)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4524">[ date ]</A>
<A HREF="index.html#4524">[ thread ]</A>
<A HREF="subject.html#4524">[ subject ]</A>
<A HREF="author.html#4524">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Robin writes:
<BR>
<EM>&gt; Humans do have an abstract reasoning module, and that module often tries
</EM><BR>
<EM>&gt; to give the impression that it is in fact in such control over the rest
</EM><BR>
<EM>&gt; of the mind.  But in fact I think our conscious minds are more like the
</EM><BR>
<EM>&gt; PR department of our minds - they try to put a good spin on the decisions
</EM><BR>
<EM>&gt; that are made, but are not actually in much control over those decisions.
</EM><BR>
<P>Yes, I think that's very true.  Take the example offered by ct:
<BR>
<P>: Hands that 'argue' with each other
<BR>
:
<BR>
: <A HREF="http://news.bbc.co.uk/hi/english/in_depth/sci_tech/2000/festival_of_science/newsid_914000/914876.stm">http://news.bbc.co.uk/hi/english/in_depth/sci_tech/2000/festival_of_science/newsid_914000/914876.stm</A>
<BR>
:
<BR>
: [Anarchic hand patients seem to be aware of the actions 
<BR>
: of their anarchic hand but they disown them.]
<BR>
<P>The failure modes of the brain are odd and don't fit very well with our
<BR>
illusions and perceptions about how our minds work.
<BR>
<P>I suspect that most of what we perceive about our own consciousness
<BR>
is wrong.  It is like a visual/perceptual illusion, brought inward and
<BR>
made pervasive.  The entire mind is an optical illusion.
<BR>
<P>When we perceive things in the real world, we are forced to maintain
<BR>
a close relation to reality.  If we see a tawny jungle cat as a pile
<BR>
of brown leaves, we won't last very long.  So perceptual illusions are
<BR>
relatively rare.
<BR>
<P>However no such pressure operates in the mind.  There is little need to
<BR>
maintain an accurate picture of its internal workings.  Rather, what is
<BR>
needed is a convenient picture, one which facilitates survival even if
<BR>
it has little bearing to the truth.
<BR>
<P>Dennett has a model along these lines, in which consciousness is
<BR>
essentially an illusion, a lie created by our minds.  We can combine
<BR>
this with Minsky's &quot;society of mind&quot; and get the following picture
<BR>
(blue-sky speculation):
<BR>
<P>Imagine that our own consciousness really doesn't exist.  We don't think,
<BR>
we don't decide, we don't rule.  Rather, we have a collection of agents
<BR>
making the decisions.  Part of their job is to construct a fictional
<BR>
consciousness, a memory trace which is created after the fact and which
<BR>
presents a fictional but unified picture of the mind's activities.
<BR>
<P>The agents are the only true consciousnesses in our brain.  They aren't
<BR>
exactly conscious the way we are; they may not have long-term memories
<BR>
of their own.  But they are more conscious than the illusory self they
<BR>
construct, a Potemkin village consciousness, a shell which exists only
<BR>
to provide an illusion of unity.
<BR>
<P>We can even bring in the old idea that consciousness as we know it is
<BR>
a relatively recent invention, occuring at the dawn of civilization
<BR>
about 5000 years ago[*].  Only with the advent of a certain complexity
<BR>
of social interactions did the need to build this illusion become acute.
<BR>
The single body is modeled best as a single mind; there isn't one, so you
<BR>
create the illusion of one.  Nature never discards, she only extends.
<BR>
The subminds were probably there all along, and are the only presence
<BR>
in animals.
<BR>
<P>Well, I'm obviously getting a little carried away here.  The key idea is
<BR>
that introspection is a very poor guide to the nature of consciousness.
<BR>
Abnormal psychology, and the effects of drugs and trauma on the brain,
<BR>
all point to a much stranger picture.
<BR>
<P>Hal
<BR>
<P>[*] Julian Jaynes, <A HREF="http://www.amazon.com/exec/obidos/ASIN/0618057072/">http://www.amazon.com/exec/obidos/ASIN/0618057072/</A>
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4525.html">QueeneMUSE@aol.com: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4523.html">J. R. Molloy: "Re: Hypnosis?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="4557.html">Robin Hanson: "Consciousness as PR (was: Why would AI want to be friendly?)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4524">[ date ]</A>
<A HREF="index.html#4524">[ thread ]</A>
<A HREF="subject.html#4524">[ subject ]</A>
<A HREF="author.html#4524">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:31 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
