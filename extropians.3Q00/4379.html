<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="hal@finney.org (hal@finney.org)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Wed Sep  6 10:26:00 2000" -->
<!-- isoreceived="20000906162600" -->
<!-- sent="Wed, 6 Sep 2000 09:25:43 -0700" -->
<!-- isosent="20000906162543" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="200009061625.JAA15038@finney.org" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> <A HREF="mailto:hal@finney.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;200009061625.JAA15038@finney.org&gt;"><EM>hal@finney.org</EM></A><BR>
<STRONG>Date:</STRONG> Wed Sep 06 2000 - 10:25:43 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4380.html">Barbara Lamar: "Re: Bugs in Anarchy was: Bugs in Free-Markets."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4378.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4379">[ date ]</A>
<A HREF="index.html#4379">[ thread ]</A>
<A HREF="subject.html#4379">[ subject ]</A>
<A HREF="author.html#4379">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Brent writes,
<BR>
<P><EM>&gt; 	To me, free will is the ability to do research to discover
</EM><BR>
<EM>&gt; that which is the best, and then set such as a goal and seek after it,
</EM><BR>
<EM>&gt; whatever it turns out to be.  To the degree that you can reliably and
</EM><BR>
<EM>&gt; deterministically know and get what is truly the best the more you are
</EM><BR>
<EM>&gt; free.
</EM><BR>
<P>But can't you argue that this is not free will, but rather enslavement
<BR>
to this arbitrary goal of seeking the &quot;best&quot;?  (&quot;Best&quot; at what, anyway?)
<BR>
<P>Why should seeking this particular goal be entitled to be called &quot;free
<BR>
will&quot;, while being enslaved to some other goal, like maximizing your
<BR>
owner's return on investment, would not?
<BR>
<P>Hal
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4380.html">Barbara Lamar: "Re: Bugs in Anarchy was: Bugs in Free-Markets."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4378.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4379">[ date ]</A>
<A HREF="index.html#4379">[ thread ]</A>
<A HREF="subject.html#4379">[ subject ]</A>
<A HREF="author.html#4379">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:20 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
