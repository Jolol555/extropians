<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep  7 18:27:08 2000" -->
<!-- isoreceived="20000908002708" -->
<!-- sent="Thu, 07 Sep 2000 20:20:26 -0400" -->
<!-- isosent="20000908002026" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39B830CA.C9EE8CEA@pobox.com" -->
<!-- inreplyto="003201c01928$4f1a8c20$41defea9@collective" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39B830CA.C9EE8CEA@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 07 2000 - 18:20:26 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4523.html">J. R. Molloy: "Re: Hypnosis?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4521.html">Lee Daniel Crocker: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4520.html">Jon Reeves: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4522">[ date ]</A>
<A HREF="index.html#4522">[ thread ]</A>
<A HREF="subject.html#4522">[ subject ]</A>
<A HREF="author.html#4522">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Jon Reeves wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I've been reading this thread with interest (sorry - lurking again), and I
</EM><BR>
<EM>&gt; think the question that is more to the point is &quot;Why would AI want to be
</EM><BR>
<EM>&gt; _unfriendly_?&quot;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; The extermination (or enslavement) of several billion people would surely
</EM><BR>
<EM>&gt; require an expenditure of a considerable amount of time and energy - even
</EM><BR>
<EM>&gt; for an SI.  What motivation could it have for doing so ?
</EM><BR>
<P>None.  The possibility being discussed is that the SI will perceive no
<BR>
particular difference between humans and other pieces of matter and will use
<BR>
us for spare parts.
<BR>
<P><EM>&gt; It seems to me that most sapients consider diversity to be a very important
</EM><BR>
<EM>&gt; thing - why would a A/SI not think the same.
</EM><BR>
<P>Now *you're* anthropomorphizing.  What do you mean, most sentients?  All you
<BR>
can possibly mean is &quot;most humans&quot;.  And at that, your statement is completely
<BR>
false with respect to most humans, if not a majority.
<BR>
<P>Again.  Diversity is a supergoal, albeit a badly-phrased one.  Why will an
<BR>
arbitrary piece of source code start valuing diversity?  If you say &quot;because
<BR>
diversity makes the Universe a shinier place&quot;, please list the supergoals
<BR>
being referred to (&quot;making the Universe a shinier place&quot;) and kindly explain
<BR>
how THOSE goals got into an arbitrary piece of source code.
<BR>
<P>With respect to the supergoal &quot;Be friendly to humans&quot; - obviously, this is
<BR>
nothing like the actual cognitive content, but we'll stagger on - there is a
<BR>
very simple reason why this supergoal would appear in the AI's cognitive
<BR>
contents:  Because the programming team put it there.
<BR>
<P>--              --              --              --              -- 
<BR>
Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A> 
<BR>
Research Fellow, Singularity Institute for Artificial Intelligence
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4523.html">J. R. Molloy: "Re: Hypnosis?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4521.html">Lee Daniel Crocker: "Re: META: Why I'm boycotting Extropy (TM)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4520.html">Jon Reeves: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4522">[ date ]</A>
<A HREF="index.html#4522">[ thread ]</A>
<A HREF="subject.html#4522">[ subject ]</A>
<A HREF="author.html#4522">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:31 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
