<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Questioning transhumanism &amp; Futures</TITLE>
<META NAME="Author" CONTENT="Anders Sandberg (asa@nada.kth.se)">
<META NAME="Subject" CONTENT="Re: Questioning transhumanism &amp; Futures">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Questioning transhumanism &amp; Futures</H1>
<!-- received="Fri Jul  7 13:00:57 2000" -->
<!-- isoreceived="20000707190057" -->
<!-- sent="07 Jul 2000 21:01:39 +0200" -->
<!-- isosent="20000707190139" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Questioning transhumanism &amp; Futures" -->
<!-- id="b49aeft2298.fsf@sans04.nada.kth.se" -->
<!-- inreplyto="Fri, 07 Jul 2000 19:32:12 CEST&quot;" -->
<STRONG>From:</STRONG> Anders Sandberg (<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20Questioning%20transhumanism%20&amp;%20Futures&In-Reply-To=&lt;b49aeft2298.fsf@sans04.nada.kth.se&gt;"><EM>asa@nada.kth.se</EM></A>)<BR>
<STRONG>Date:</STRONG> Fri Jul 07 2000 - 13:01:39 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="0485.html">Brian Atkins: "[Fwd: [&gt;Htech] FC: Dangers of Bill Joy's nanotech-thinking, from  National Review]"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0483.html">QueeneMUSE@aol.com: "Re: italian interest"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0843.html">Robin Hanson: "Re: Questioning transhumanism &amp; Futures"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0843.html">Robin Hanson: "Re: Questioning transhumanism &amp; Futures"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#484">[ date ]</A>
<A HREF="index.html#484">[ thread ]</A>
<A HREF="subject.html#484">[ subject ]</A>
<A HREF="author.html#484">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&quot;Waldemar Ingdahl&quot; &lt;<A HREF="mailto:wingdahl@hotmail.com?Subject=Re:%20Questioning%20transhumanism%20&amp;%20Futures&In-Reply-To=&lt;b49aeft2298.fsf@sans04.nada.kth.se&gt;">wingdahl@hotmail.com</A>&gt; writes:
<BR>
<P><EM>&gt; Transhumanism often falls into the trap of discussing VERY remote
</EM><BR>
<EM>&gt; technologies, while completely neglecting the present. I think it is
</EM><BR>
<EM>&gt; because, if we're discussing the present topics like economics,
</EM><BR>
<EM>&gt; philosophy, sociology etc come into the forefront. But those are not
</EM><BR>
<EM>&gt; topics that people in general discuss at all- they are so mired in
</EM><BR>
<EM>&gt; what is considered &quot;practical&quot; and &quot;moral&quot; today that transhumanists
</EM><BR>
<EM>&gt; even adopt the stasist point of view towards them (comes with the
</EM><BR>
<EM>&gt; fact of a hegemony being present in these topics).
</EM><BR>
<P>Yes, I have noted this too (and often contributed to it - omega point
<BR>
physics is so much simpler than economics!). 
<BR>
<P>The problem is that most of us are not well educated in economics,
<BR>
philosophy and sociology, and that it often doesn't seem they are
<BR>
necessary. After all, the system largely works, doesn't it? We miss
<BR>
the obvious stuff just because it is right under our noses, and
<BR>
concentrate on the rest. But transhumanism is very much about
<BR>
questioning the way things have always been, *all* of the human
<BR>
condition - including how we relate to the current philosophical,
<BR>
political, social and economical systems. If we don't question things,
<BR>
try to come up with new solutions and then test them to see if they
<BR>
are better than the current ones we will be dependent on the solutions
<BR>
other groups produce, solutions which may not just be bad but also
<BR>
based on fundamentally incompatible values.
<BR>
<P>I find reading the journal &quot;Futures&quot; valuable, as there I often
<BR>
encounter radically different ideas about what a desirable future
<BR>
would be like. There have been papers discussing how to get *out* of
<BR>
this spiral of technological advancement and into some nice, &quot;more
<BR>
human&quot;, static world - an idea I find abhorrent as stated (because it
<BR>
implies that *everyone* must do it), but is widely accepted in many
<BR>
circles. If we don't learn to deal with the real world issues well
<BR>
from *our* philosophical point of view, the above view might well be
<BR>
what spreads into most economical and political solutions, badly
<BR>
cramping us. 
<BR>
<P>On the other hand, in the latest issue of the journal (Futures 32
<BR>
(2000) 603-612) there was also &quot;Millennium Project's draft scenarios
<BR>
for the next 1000 years&quot; by Jerome C. Glenn, which contains some
<BR>
long-range future scenarios from the Millennium Project. These three
<BR>
scenarios contained many elements we are used to: nanotech, AI,
<BR>
cyborgization, radical changes in the human condition. One of the
<BR>
scenarios was a very nice and somewhat Star Trek-esque united Earth in
<BR>
3000 (but with some problems), another was the extinction of humanity
<BR>
and the subsequent evolution of AI and the third dealt with a humanity
<BR>
splitting between people for or against radical technological
<BR>
changes. The interesting thing was that these ideas are now part of
<BR>
serious future studies, and they will percolate outwards from there.
<BR>
<P>This is of course great, but it gave me pause to find that in the list
<BR>
of factors most likely to affect the next 1000 years immortality was
<BR>
on the second last place!  Also, note the relative ranking here (I
<BR>
think the index is simply the product of the probability, importance
<BR>
and priority if they occur):
<BR>
<P>Ratings of the factors that may influence the next 1000 years 
<BR>
<P>Very long-range factors              Probability Importance Priority Index 
<BR>
<P>Human-environment dynamics (3)         4.114       4.163     4.095   70.133 
<BR>
Human genetics (11)                    4.302       3.951     4.098   69.655 
<BR>
Safe energy (4)                        3.753       4.250     4.341   69.240 
<BR>
Nanotechnology (5)                     4.311       3.814     3.930   64.618 
<BR>
Forms of movement (6)                  3.091       4.429     4.000   54.760 
<BR>
Increasing intelligence (13)           3.667       4.024     3.548   52.354 
<BR>
Occurrence climate change (2)          3.761       3.977     3.444   51.514 
<BR>
Control forces to destroy humanity (7) 2.891       4.341     3.788   47.539 
<BR>
Conscious-Technology (12)              3.545       3.548     3.738   47.015 
<BR>
Collective futures (9)                 3.111       3.744     3.476   40.487 
<BR>
Avoid climate change (1)               2.844       4.163     3.233   38.277 
<BR>
Gender relation (16)                   3.444       3.520     3.088   37.435 P
<BR>
Philosophy and mental maps (8)         3.000       3.538     3.308   35.111 
<BR>
Conscious evolution (14)               2.974       3.556     3.222   34.074 
<BR>
Space migration (18)                   3.093       2.977     3.651   33.618 
<BR>
Global ethical system (10)             2.930       3.100     3.525   32.018 
<BR>
Extraterrestrial contact (7)           2.359       3.876     2.811   25.702 
<BR>
Immortality (15)                       2.643       2.825     2.825   21.093 
<BR>
Interspecies communication (19)	       2.425       2.744     3.051   20.302
<BR>
<P>I think the ranking tells us much about general opinions on what is
<BR>
important.
<BR>
<P>Which of these factors are we discussing the most? Human genetics,
<BR>
nanotech, increasing intelligence, human extinction, conscious
<BR>
technology, conscious evolution, space migration, extraterrestrial
<BR>
contact, immortality and interspecies communication - yes. That mainly
<BR>
leaves out human-environment dynamics, safe energy, forms of movement,
<BR>
collective futures, climate change, gender relations, philosophy and
<BR>
global ethical systems. Sure, we have discussed all of these too, but
<BR>
with far less rigor (and in many cases with more rancor :-) - but it
<BR>
is almost half of what the Project considers important for this
<BR>
millennium! And this is an admittedly hubristic super-long-range
<BR>
study, a near-term study would almost certainly put a much greater
<BR>
weight on these issues.
<BR>
<P>To continue, there is another paper in that issue: (Futures 32 (2000)
<BR>
595-602) &quot;The twilight of the Baconian age and the future of humanity&quot;
<BR>
by Francisco Sagasti. This paper claims that the Baconian program is
<BR>
running out (it can be seen as the program Francis Bacon began 400
<BR>
years ago with his idea that technology and science can be used to
<BR>
improve the human condition, that progress is possible, desirable and
<BR>
nearly inevitable etc), both due to increased internal and external
<BR>
criticism (that is, the stuff we usually dismiss as &quot;luddites&quot;,
<BR>
&quot;conservatives&quot; and &quot;postmodernist fluff&quot;) and the fact that we are
<BR>
now approaching a state where we are changing the human condition
<BR>
itself through a very changed view of physics, new discoveries in
<BR>
ecology, biotechnology, psychology, anthropology, AI, virtual reality
<BR>
and whatnot that are undermining the old notions of the human as the
<BR>
center of the universe, or even an individual thing. The paper
<BR>
concludes that we need a new direction for the post-Baconian
<BR>
era. 
<BR>
<P>While I dislike the tone of the paper a bit I think it says something
<BR>
directly to us transhumanists. We are already thinking *partially* in
<BR>
this post-Baconian world, and we do have the chance to be the ones
<BR>
that explore it, set the agenda, come up with the influential myths!
<BR>
But to do that we have to give up the default assumptions of the old -
<BR>
without falling into a postmodern mist of relativism and hidden
<BR>
authority worship.
<BR>
<P>This was just two papers from a single issue, but both suggest that we
<BR>
1) have a problem and 2) that we have a wonderful opportunity! So
<BR>
let's start educating ourselves even more in everyday psychology and
<BR>
philosophy, in economics and ecology, in politics and physics. We need
<BR>
the practical *combinations*, good ideas like Idea Futures, WWW and
<BR>
tupperware marketing.
<BR>
<P><PRE>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20Questioning%20transhumanism%20&amp;%20Futures&In-Reply-To=&lt;b49aeft2298.fsf@sans04.nada.kth.se&gt;">asa@nada.kth.se</A>                            <A HREF="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</A>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0485.html">Brian Atkins: "[Fwd: [&gt;Htech] FC: Dangers of Bill Joy's nanotech-thinking, from  National Review]"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0483.html">QueeneMUSE@aol.com: "Re: italian interest"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0843.html">Robin Hanson: "Re: Questioning transhumanism &amp; Futures"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0843.html">Robin Hanson: "Re: Questioning transhumanism &amp; Futures"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#484">[ date ]</A>
<A HREF="index.html#484">[ thread ]</A>
<A HREF="subject.html#484">[ subject ]</A>
<A HREF="author.html#484">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:34:07 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
