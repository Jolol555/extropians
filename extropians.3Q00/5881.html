<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Robots, but philosophers (or, Hal-2001)</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Re: Robots, but philosophers (or, Hal-2001)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Robots, but philosophers (or, Hal-2001)</H1>
<!-- received="Wed Sep 27 02:47:44 2000" -->
<!-- isoreceived="20000927084744" -->
<!-- sent="Wed, 27 Sep 2000 01:49:26 -0700" -->
<!-- isosent="20000927084926" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Robots, but philosophers (or, Hal-2001)" -->
<!-- id="39D1B496.A6BEC7AD@objectent.com" -->
<!-- inreplyto="Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;39D1B496.A6BEC7AD@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 27 2000 - 02:49:26 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5882.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5880.html">eugene.leitl@lrz.uni-muenchen.de: "[&gt;Htech] Cashing in on biology  (fwd)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5856.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5926.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5926.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5881">[ date ]</A>
<A HREF="index.html#5881">[ thread ]</A>
<A HREF="subject.html#5881">[ subject ]</A>
<A HREF="author.html#5881">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Franklin Wayne Poley wrote:
<BR>
<EM>&gt; 
</EM><BR>
<P><EM>&gt; How about 2001, Hal? Could it be that by 2001, someone somewhere will
</EM><BR>
<EM>&gt; already have AI machinery to surpass human equivalency? 
</EM><BR>
<P>Not on this planet.  Maybe you want to call on Ashtar High Command or
<BR>
some such. :-)  They've been feeding us all of this tech anyway, don't
<BR>
ya know?  
<BR>
<P><P><P><EM>&gt;    In summary, here is the argument that AI now is at a stage comparable
</EM><BR>
<EM>&gt; to the man-on-the-moon program from a 1960 perspective. In other words, we
</EM><BR>
<EM>&gt; mostly need quantitative extensions of what we know now and the
</EM><BR>
<EM>&gt; qualititative aspect of this project is not overwhelming. That is, we can
</EM><BR>
<EM>&gt; now see the areas which require innovation or invention and we can
</EM><BR>
<EM>&gt; reasonably assume that the breakthroughs will be made. The sheer magnitude
</EM><BR>
<EM>&gt; of the project should not be a deterrent. If we know how to reach the
</EM><BR>
<EM>&gt; objective and it is worth while to do so, so what if it costs hundreds of
</EM><BR>
<EM>&gt; billions?
</EM><BR>
<P><P>Qualitative is not overwhelming?  This has to be a joke.  We have no
<BR>
idea what qualia even are among other &quot;qualitative&quot; problems of reaching
<BR>
human level intelligence.  We have relatively poor grasp of even higher
<BR>
level issues like concept formation and usage.  Lots of theory, no
<BR>
satisfying fully general and full powered learning programs.  No model
<BR>
we are even happy about for describing what humans do with
<BR>
percept-concept-more abstract concept chains.  Without this you will not
<BR>
get there.  Or is there something already done I am unaware of?  Any
<BR>
pointers appreciated.  
<BR>
<P>Many are pretty darn sure you cannot reach human level congnition
<BR>
without at least much closer to human level computational throughput. 
<BR>
Please show why these people, many of them experts who very much are at
<BR>
the vanguard of the quest, are wrong.  If they are right, please show a
<BR>
way that in 1 year (initial suggestion above) we will both get this
<BR>
incredible leap in computational hardware density AND make use of it
<BR>
with appropriate software based on the brand new theoretical
<BR>
breakthroughs we also get in this year.  While you are at it please send
<BR>
me some of the same drugs you are taking so I can also enjoy this
<BR>
fantasy as much as you are.
<BR>
<P>We will not spend hundreds of billions on a project that has no clear
<BR>
deliverables, that depends on tons of hardware and software that experts
<BR>
frankly do not know how to build and arguably cannot build without an
<BR>
several orders of magnitude increase in computational density per unit
<BR>
costs and several interlocking theoretical breakthroughs.  This is a
<BR>
ludicrous fantasy. 
<BR>
<P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5882.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5880.html">eugene.leitl@lrz.uni-muenchen.de: "[&gt;Htech] Cashing in on biology  (fwd)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5856.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5926.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5926.html">Franklin Wayne Poley: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5881">[ date ]</A>
<A HREF="index.html#5881">[ thread ]</A>
<A HREF="subject.html#5881">[ subject ]</A>
<A HREF="author.html#5881">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:13 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
