<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="J. R. Molloy (jr@shasta.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep 28 19:12:00 2000" -->
<!-- isoreceived="20000929011200" -->
<!-- sent="Thu, 28 Sep 2000 15:05:04 -0700" -->
<!-- isosent="20000928220504" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="007701c029a5$bd7555a0$c5bc473f@jrmolloy" -->
<!-- inreplyto="14802.18240.275368.822754@lrz.uni-muenchen.de" -->
<STRONG>From:</STRONG> J. R. Molloy (<A HREF="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;007701c029a5$bd7555a0$c5bc473f@jrmolloy&gt;"><EM>jr@shasta.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 28 2000 - 16:05:04 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="6018.html">Damien Broderick: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6016.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6046.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6017">[ date ]</A>
<A HREF="index.html#6017">[ thread ]</A>
<A HREF="subject.html#6017">[ subject ]</A>
<A HREF="author.html#6017">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eugene Leitl has written,
<BR>
<P><EM>&gt; Sure, some primate researchers have probably befriended their
</EM><BR>
<EM>&gt; charges. However, that's not an absolute prerequisite. And it kinda
</EM><BR>
<EM>&gt; requires an AI you can relate to.
</EM><BR>
<P>I feel more affinity toward AI (which we should remember does not actually
<BR>
exist) than I have ever been able to relate to the nine tenths of humanity which
<BR>
remain immured in belief systems.
<BR>
<P><EM>&gt;The first AI which has nucleated in the
</EM><BR>
<EM>&gt; network will copy (sexually) mutated copies of itself all over the
</EM><BR>
<EM>&gt; place in a wormlike fashion.
</EM><BR>
<P>Now who's anthropomorphizing? How do you know what AIs will do? It seems as
<BR>
likely as not to me, that AIs will steer clear of sexuality for the very
<BR>
sensible reason that it clouds ratiocination and obscures common sense.
<BR>
<P><EM>&gt; Because the copy process is much faster
</EM><BR>
<EM>&gt; than adding new nodes (even if you have nanotechnology) you have
</EM><BR>
<EM>&gt; instant resource scarcity and hence competition for limited
</EM><BR>
<EM>&gt; resources. Those individua with lesser fitness will have to go to the
</EM><BR>
<EM>&gt; great bit bucket in the sky.
</EM><BR>
<P>So AI individua will be *very* friendly toward each other. The question then is,
<BR>
&quot;How far would AI extend its friendliness? Would it extend to you and me?&quot;
<BR>
Perhaps it would. The friendliness of religious fanatics definately does not.
<BR>
<P><EM>&gt; Actually, I would advise against that, if a few decades from now you
</EM><BR>
<EM>&gt; see the global networks and attached external machinery suddenly start
</EM><BR>
<EM>&gt; acting in a very strange fashion (i.e. it's not a just another Net
</EM><BR>
<EM>&gt; worm). Without concerted actions you can't do anything decisive, and
</EM><BR>
<EM>&gt; by local pinpricks you only annoy the things, and make *you* look
</EM><BR>
<EM>&gt; unfriendly.
</EM><BR>
<P>Yes, we don't ever want to appear unfriendly to something more intelligent than
<BR>
ourselves. But why does friendliness come into it at all? I mean, have you ever
<BR>
thought that truth may have value greater than friendship? If our friends all
<BR>
become deranged as a result of some weird virus that makes them politicized
<BR>
zombies, perhaps we ought to place our trust in some artificial intelligence
<BR>
which remains impervious to such an attack, some AI which remains sane and
<BR>
balanced. Shall we trust the natural intelligence of Hitler and Stalin more than
<BR>
the robot intelligence of our own device?
<BR>
<P>--J. R.
<BR>
<P>&quot;These technologies are just too much for a species at our level of
<BR>
sophistication.&quot;
<BR>
--Bill Joy
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="6018.html">Damien Broderick: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6016.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6046.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6017">[ date ]</A>
<A HREF="index.html#6017">[ thread ]</A>
<A HREF="subject.html#6017">[ subject ]</A>
<A HREF="author.html#6017">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:20 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
