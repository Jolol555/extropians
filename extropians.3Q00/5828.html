<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Some thoughts on Politics</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Re: Some thoughts on Politics">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Some thoughts on Politics</H1>
<!-- received="Tue Sep 26 12:44:40 2000" -->
<!-- isoreceived="20000926184440" -->
<!-- sent="Tue, 26 Sep 2000 11:46:23 -0700" -->
<!-- isosent="20000926184623" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Some thoughts on Politics" -->
<!-- id="39D0EEFF.774C5D9E@objectent.com" -->
<!-- inreplyto="200009261607.JAA05098@finney.org" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Some%20thoughts%20on%20Politics&In-Reply-To=&lt;39D0EEFF.774C5D9E@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 26 2000 - 12:46:23 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5829.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5827.html">Michael S. Lorrey: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5817.html">hal@finney.org: "Re: Some thoughts on Politics"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5839.html">Michael S. Lorrey: "Re: Some thoughts on Politics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5828">[ date ]</A>
<A HREF="index.html#5828">[ thread ]</A>
<A HREF="subject.html#5828">[ subject ]</A>
<A HREF="author.html#5828">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<A HREF="mailto:hal@finney.org?Subject=Re:%20Some%20thoughts%20on%20Politics&In-Reply-To=&lt;39D0EEFF.774C5D9E@objectent.com&gt;">hal@finney.org</A> wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Corey asks:
</EM><BR>
<EM>&gt; &gt; Is the core idea of Extropy (as I understand it, summarized by &quot;Upward and
</EM><BR>
<EM>&gt; &gt; Outward&quot;) predicated on a libertarian philosophy?  Does one have to accept
</EM><BR>
<EM>&gt; &gt; all the other excess baggage that comes with libertarianism (i.e. absolute
</EM><BR>
<EM>&gt; &gt; freedom to own and use firearms, no centralized legal systems, decentralized
</EM><BR>
<EM>&gt; &gt; or no environmental regulations, no public investment from non-private
</EM><BR>
<EM>&gt; &gt; organizations, etc.) to be a true extropian?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I do think that libertarianism is a natural political philosophy
</EM><BR>
<EM>&gt; for an extropian to adopt.  Extropians believe in removing limits,
</EM><BR>
<EM>&gt; and libertarianism is that philosophy which puts the fewest limits on
</EM><BR>
<EM>&gt; people's actions.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Extropianism is about transcending limits.  Those limits might include
<BR>
limited notions of what is and is not for our good and limited notions
<BR>
of where the boundary of &quot;me&quot; ends and &quot;you&quot; begin.  Thought precedes
<BR>
action. Unlimited thought is not bound to any particular &quot;ism&quot;.  
<BR>
<P>&nbsp;
<BR>
<EM>&gt; Earlier I posed questions about how modern liberalism could coexist with
</EM><BR>
<EM>&gt; an extropian philosophy.  What is the meaning of a minimum wage law,
</EM><BR>
<EM>&gt; when there is a continuum of intelligences from AI through transhuman?
</EM><BR>
<EM>&gt; How can the basic idea of social equality exist in a world where some
</EM><BR>
<EM>&gt; beings think millions of times faster than others?  It seems to me that
</EM><BR>
<EM>&gt; a laissez faire attitude will work best in the future we anticipate.
</EM><BR>
<P>Social equality in the sense of equal rights to life and one's own
<BR>
pursuit of happiness must exist if you are to have peace.  Peace after
<BR>
extermination of all opponents last only as long as no one as stronger
<BR>
or stronger than you shows up.  It is not logical.  
<BR>
<P><P><EM>&gt; 
</EM><BR>
<EM>&gt; &gt; I ask this question as a believer in the concepts of expanding beyond what
</EM><BR>
<EM>&gt; &gt; are accepted as &quot;common&quot; limitations - overcoming such barriers as aging
</EM><BR>
<EM>&gt; &gt; pathologies and death, limitations of the physical body (strength, endurance,
</EM><BR>
<EM>&gt; &gt; etc.), limitations of input bandwidth and storage, gravity wells, the speed of
</EM><BR>
<EM>&gt; &gt; light...  All of these things that we can and SHOULD overcome.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Facetiously I said, &quot;we tell people that in 30 years everyone will be
</EM><BR>
<EM>&gt; an immortal superman and they say, ho hum.  But suggest that someone
</EM><BR>
<EM>&gt; ought to be able to work for less than the minimum age, and all hell
</EM><BR>
<EM>&gt; breaks loose.&quot;  Seriously, I can't understand how you can accept the
</EM><BR>
<EM>&gt; massive changes which the concepts above entail, while still being
</EM><BR>
<EM>&gt; married to modern social government concepts.
</EM><BR>
<P><P>I am not &quot;married&quot; to either current concepts or yours or libertarian
<BR>
ones.  I do believe the idea that all beings should benefit to the
<BR>
limits of what benefit they are willing to accept is much more appealing
<BR>
that the notion that only &quot;me and mine&quot; should benefit if we stumble on
<BR>
the next great thing first.  All the dreams and struggles of humanity to
<BR>
date have brought us to this point.  Wrong turns and stupid ideas and
<BR>
all.  Perhaps it is all only fertilizer, only fodder for the Great AI to
<BR>
come.  But I am not ready to assume that is the only or the best dream
<BR>
or to assume we have no say in the matter.  I am not sure some times if
<BR>
the race has a desire for transcendence or simply a death wish.
<BR>
<P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5829.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5827.html">Michael S. Lorrey: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5817.html">hal@finney.org: "Re: Some thoughts on Politics"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5839.html">Michael S. Lorrey: "Re: Some thoughts on Politics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5828">[ date ]</A>
<A HREF="index.html#5828">[ thread ]</A>
<A HREF="subject.html#5828">[ subject ]</A>
<A HREF="author.html#5828">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:11 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
