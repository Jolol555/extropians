<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Eugene Leitl (eugene.leitl@lrz.uni-muenchen.de)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep 28 03:40:32 2000" -->
<!-- isoreceived="20000928094032" -->
<!-- sent="Thu, 28 Sep 2000 01:14:35 -0700 (PDT)" -->
<!-- isosent="20000928081435" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene.leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="14802.65003.972175.948161@lrz.uni-muenchen.de" -->
<!-- inreplyto="00be01c028b4$94b6b4c0$d0bc473f@jrmolloy" -->
<STRONG>From:</STRONG> Eugene Leitl (<A HREF="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;14802.65003.972175.948161@lrz.uni-muenchen.de&gt;"><EM>eugene.leitl@lrz.uni-muenchen.de</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 28 2000 - 02:14:35 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5960.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5958.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5917.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6035.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5959">[ date ]</A>
<A HREF="index.html#5959">[ thread ]</A>
<A HREF="subject.html#5959">[ subject ]</A>
<A HREF="author.html#5959">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
J. R. Molloy writes:
<BR>
<P><EM> &gt; Well, excuuuuuse me. I guess I missed the &quot;SysOp&quot; lecture. I must have been in
</EM><BR>
<P>That's strange, because I recall Eli giving you pointers to it. And
<BR>
you being gung-ho for friendly AIs it should give you lots of
<BR>
arguments.
<BR>
<P><EM> &gt; South Dakota that day. So how does that relate to AI friendliness? The robot is
</EM><BR>
<EM> &gt; mine because I bought it. Robots are robots because they behave robotically. So
</EM><BR>
<P>How can you own something which is significantly smarter than you? It
<BR>
owns you, not you it. Robots only behave robotically if they're so
<BR>
primitive they're only good for making cars, and such. Any robot which
<BR>
is going to be able to protect you from anything superhumanly smart
<BR>
and fast is going to be flexible, and hence indistinguishable from the
<BR>
enemy. It certainly may not act predictably, because that would make
<BR>
it exploitable.
<BR>
<P><EM> &gt; they can't own humans. That robot came into being any way it could. It's a given
</EM><BR>
<P>I fail to see the logic. You're describing a fantasy creature,
<BR>
incredibly powerful as docile. Even djinns are that not.
<BR>
<P><EM> &gt; for the purpose of discussing why AI would want to be friendly. The question
</EM><BR>
<EM> &gt; isn't how AI comes into being; it's why it would want to be friendly.
</EM><BR>
&nbsp;
<BR>
Unfortunately, the method which makes the AI powerful automatically
<BR>
makes it less than friendly. If it's friendly, it's less than useful.
<BR>
<P><EM> &gt; &gt; I'm beginning to think that you're rather good at trolling. No one
</EM><BR>
<EM> &gt; &gt; can't be that dense nondeliberately.
</EM><BR>
<EM> &gt; 
</EM><BR>
<EM> &gt; Sad to learn you think that way. But I don't recall you proposing any
</EM><BR>
<EM> &gt; constructive ideas about making AI friendly. So, to demonstrate that *you* are
</EM><BR>
<P>Because I can't think of any. And I'm trying rather hard. Because so
<BR>
much is at stake I'd rather have lots of iron-clad reasons why AIs
<BR>
will wind up being friendly instead of the other way round.
<BR>
<P><EM> &gt; not trolling, please let us in on your formula for insuring that AI would want
</EM><BR>
<EM> &gt; to be friendly. If you don't think that AI would want to be friendly, that
</EM><BR>
<EM> &gt; suggests that you believe AI should not be attempted at all. In that case, how
</EM><BR>
<EM> &gt; do you propose to keep AI from emerging?
</EM><BR>
&nbsp;&nbsp;
<BR>
<EM> &gt; PS: &quot;no one can't be that dense&quot; is a double negative.
</EM><BR>
<P>Good thing we're not arguing formal logic here.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5960.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5958.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5917.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6035.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5959">[ date ]</A>
<A HREF="index.html#5959">[ thread ]</A>
<A HREF="subject.html#5959">[ subject ]</A>
<A HREF="author.html#5959">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:18 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
