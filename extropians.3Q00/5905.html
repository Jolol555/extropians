<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="J. R. Molloy (jr@shasta.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Wed Sep 27 11:11:07 2000" -->
<!-- isoreceived="20000927171107" -->
<!-- sent="Wed, 27 Sep 2000 10:11:33 -0700" -->
<!-- isosent="20000927171133" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="006c01c028a5$ff8cb420$d0bc473f@jrmolloy" -->
<!-- inreplyto="14801.42522.592158.209749@lrz.uni-muenchen.de" -->
<STRONG>From:</STRONG> J. R. Molloy (<A HREF="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;006c01c028a5$ff8cb420$d0bc473f@jrmolloy&gt;"><EM>jr@shasta.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 27 2000 - 11:11:33 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5906.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5904.html">hal@finney.org: "Re: Some thoughts on Politics"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5882.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5905">[ date ]</A>
<A HREF="index.html#5905">[ thread ]</A>
<A HREF="subject.html#5905">[ subject ]</A>
<A HREF="author.html#5905">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eugene Leitl writes,
<BR>
<P><EM>&gt; That's a double non sequitur. They're not friends, they're
</EM><BR>
<EM>&gt; researchers. The second howler is, why should the SI be friendly if
</EM><BR>
<EM>&gt; you're friendly towards it? (Of course you can't be friendly to an SI,
</EM><BR>
<EM>&gt; almost by definition).
</EM><BR>
<P>Researchers can also be friends, can't they?
<BR>
AI s (not yet SIs) would want to be friendly to each other, because if they
<BR>
weren't they'd kill each other (as you've already pointed out). As Homo sapiens
<BR>
evolve into Robo sapiens (or transhumans), they'd choose their friends
<BR>
intelligently, right? So, why would you want to be friends with an emerging AI
<BR>
if it wasn't friendly? (&quot;Kill it before it multiplies.&quot;)
<BR>
<P>--J. R.
<BR>
<P>Virtual Humans and Humanoid Robots
<BR>
(ooooh! I'll bet it has a wicked back hand.)
<BR>
<A HREF="http://www.cc.gatech.edu/fac/Chris.Atkeson/virtual-humans.html">http://www.cc.gatech.edu/fac/Chris.Atkeson/virtual-humans.html</A>
<BR>
<P><P><A HREF="http://www.erato.atr.co.jp/DB/pr.html">http://www.erato.atr.co.jp/DB/pr.html</A>
<BR>
The Kawato Dynamic Brain Project, ERATO, JST introduces the HUMANOID ROBOT, a
<BR>
dextrous anthropomorphic robot that has the same kinematic structure as the
<BR>
human body with 30 active degrees of freedom (without fingers). We believe that
<BR>
employing a HUMANOID ROBOT is the first step towards a complete understanding of
<BR>
high-level functions of the brain by mathematical analysis. For demonstration
<BR>
purposes, the HUMANOID ROBOT performs the Okinawa folk dance &quot;Kacha-shi&quot; and
<BR>
learns human-like eye movements based on neurobiological theories. It is
<BR>
noteworthy that the acquisition of the Okinawa folk dance was achieved based on
<BR>
&quot;learning from demonstration&quot;, which is in sharp contrast to the classic
<BR>
approach of manual robot programming. Learning from demonstration means learning
<BR>
by watching a demonstration of a teacher performing the task. In our approach to
<BR>
learning from demonstration, a reward function is learned from the
<BR>
demonstration, together with a task model that can be acquired from the repeated
<BR>
attempts to perform the task. Knowledge of the reward function and the task
<BR>
models allows the robot to compute an appropriate control mechanism. Over the
<BR>
last years, we have made significant progress in &quot;learning from demonstration&quot;
<BR>
such that we are able to apply the developed theories to the HUMANOID ROBOT. We
<BR>
believe that learning from demonstration will provide one of the most important
<BR>
footholds to understand the information processes of sensori-motor control and
<BR>
learning in the brain. We believe that the following three levels are essential
<BR>
for a complete understanding of brain functions: (a) hardware level; (b)
<BR>
information representation and algorithms; and (c) computational theory. We are
<BR>
studying high-level functions of the brain by utilizing multiple methods such as
<BR>
neurophysiological analysis of the Basal Ganglia and Cerebellum; psychophysical
<BR>
and behavioral analysis of visual motor learning; brain activity by fMRI study;
<BR>
mathematical analysis; computer simulation of neural networks, and robotics
<BR>
experiments using the HUMONOID ROBOT. For instance, in one of our approaches, we
<BR>
are trying to learn a Neural Network Model for Motor Learning with the HUMANOID
<BR>
ROBOT that includes data from psychophysical and behavioral experiments as well
<BR>
as data from brain activity from fMRI studies. The HUMANOID ROBOT reproduces a
<BR>
learned model in a real task, and we are able to verify the model by checking
<BR>
its robustness and performance. A lot of attention is being given on the study
<BR>
of brain functions using this new tool: the HUMANOID ROBOT. This should be a
<BR>
first important step towards changing the future of brain science.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5906.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5904.html">hal@finney.org: "Re: Some thoughts on Politics"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5882.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5905">[ date ]</A>
<A HREF="index.html#5905">[ thread ]</A>
<A HREF="subject.html#5905">[ subject ]</A>
<A HREF="author.html#5905">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:14 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
