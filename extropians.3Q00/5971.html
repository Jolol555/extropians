<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Frontiers of Friendly AI</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Frontiers of Friendly AI">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Frontiers of Friendly AI</H1>
<!-- received="Thu Sep 28 09:44:26 2000" -->
<!-- isoreceived="20000928154426" -->
<!-- sent="Thu, 28 Sep 2000 11:45:16 -0400" -->
<!-- isosent="20000928154516" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Frontiers of Friendly AI" -->
<!-- id="39D3678C.39389E09@pobox.com" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Frontiers%20of%20Friendly%20AI&In-Reply-To=&lt;39D3678C.39389E09@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 28 2000 - 09:45:16 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5972.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5970.html">Brian D Williams: "Re: Classism"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5980.html">Dan Fabulich: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5980.html">Dan Fabulich: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5985.html">Bryan Moss: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="6018.html">Damien Broderick: "Re: Frontiers of Friendly AI"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5971">[ date ]</A>
<A HREF="index.html#5971">[ thread ]</A>
<A HREF="subject.html#5971">[ subject ]</A>
<A HREF="author.html#5971">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
For those of you wondering about the kind of questions that I *would* regard
<BR>
as valid...
<BR>
<P><P>** Q1)
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stage:  Mid-term and late-term seed AI.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Context:  Let's say you design a seed AI with what looks like a Friendly
<BR>
goal system; i.e., it regards all subtasks - including optimizing itself, and
<BR>
rewriting a particular piece of code, and playing chess, and so on - as
<BR>
subgoals of subgoals of subgoals which eventually terminate in the
<BR>
Friendliness supergoal.  In fact, the &quot;subgoals&quot; have no programmatic status -
<BR>
they are simply commonly used way-stations along the projection that leads to
<BR>
the supergoal.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Possible problem:  On a moment-to-moment basis, the vast majority of
<BR>
tasks are not materially affected by the fact that the supergoal is
<BR>
Friendliness.  The optimal strategy for playing chess is not obviously
<BR>
affected by whether the supergoal is Friendliness or hostility.  Therefore,
<BR>
the system will tend to accumulate learned complexity for the subgoals, but
<BR>
will not accumulate complexity for the top of the goal chain - Friendliness,
<BR>
and any standard links from Friendliness to the necessity for self-enhancement
<BR>
or some other standard subgoal, will remain crystalline and brittle.  If most
<BR>
of the de facto complexity rests with the subgoals, then is it likely that
<BR>
future superintelligent versions of the AI's self will grant priority to the
<BR>
subgoals?
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Solution:  I'll post again in a bit, but I'm more interested in seeing
<BR>
whether anyone can come up with the answer independently.
<BR>
<P><P>** Q2)
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stage:  The earliest, most primitive versions of the seed AI.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Possible problem:  There is an error in the goal system, or the goal
<BR>
system is incomplete.  Either you had to simplify at first because the
<BR>
primitive AI couldn't understand all the referents, or you (the programmer)
<BR>
changed your mind about something.  How do you get the AI to let you change
<BR>
the goal system?  Obviously, changing the goal system is an action that would
<BR>
tend to interfere with whatever goals the AI currently possesses.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Solution:  Again, I'd like to let this hang out for a bit - maybe we'll
<BR>
get a more productive discussion than the current one.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bonus problem:  Suppose that you screw up badly enough that the AI not
<BR>
only attempts to preserve the original goals, but also realizes that it (the
<BR>
AI) must do so surreptitiously in order to succeed.  Can you think of any
<BR>
methods that might help identify such a problem?
<BR>
<P><P>** Grading
<BR>
<P>No ad-hoc patches, please - remember, the final system has to be coherent, and
<BR>
you won't be able to think up ad-hoc patches for everything in advance.  Your
<BR>
answer should take the form of a fundamental feature of the cognitive
<BR>
architecture or the programming methodology.
<BR>
<P>--              --              --              --              -- 
<BR>
Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A> 
<BR>
Research Fellow, Singularity Institute for Artificial Intelligence
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5972.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5970.html">Brian D Williams: "Re: Classism"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5980.html">Dan Fabulich: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5980.html">Dan Fabulich: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5985.html">Bryan Moss: "Re: Frontiers of Friendly AI"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="6018.html">Damien Broderick: "Re: Frontiers of Friendly AI"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5971">[ date ]</A>
<A HREF="index.html#5971">[ thread ]</A>
<A HREF="subject.html#5971">[ subject ]</A>
<A HREF="author.html#5971">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:18 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
