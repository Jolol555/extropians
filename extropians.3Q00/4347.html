<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly? (Was: Congrat</TITLE>
<META NAME="Author" CONTENT="Eugene Leitl (eugene.leitl@lrz.uni-muenchen.de)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)</H1>
<!-- received="Wed Sep  6 04:03:43 2000" -->
<!-- isoreceived="20000906100343" -->
<!-- sent="Wed, 6 Sep 2000 00:39:06 -0700 (PDT)" -->
<!-- isosent="20000906073906" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene.leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)" -->
<!-- id="14773.62618.697435.937842@lrz.uni-muenchen.de" -->
<!-- inreplyto="009b01c017af$ea592400$52bc473f@jrmolloy" -->
<STRONG>From:</STRONG> Eugene Leitl (<A HREF="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?%20(Was:%20Congratulations%20to%20Eli,Brian%20%20...)&In-Reply-To=&lt;14773.62618.697435.937842@lrz.uni-muenchen.de&gt;"><EM>eugene.leitl@lrz.uni-muenchen.de</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 06 2000 - 01:39:06 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4348.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4346.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4327.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="4434.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4434.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4347">[ date ]</A>
<A HREF="index.html#4347">[ thread ]</A>
<A HREF="subject.html#4347">[ subject ]</A>
<A HREF="author.html#4347">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
J. R. Molloy writes:
<BR>
<P><EM> &gt; We don't really have any reason to presume that SIs would not emerge from
</EM><BR>
<EM> &gt; genetic programming projects, do we? As AIs compete with each other, winners
</EM><BR>
<P>We have every reason to presume that an SI won't come from explicit
<BR>
programming by humans. 
<BR>
<P># make SI
<BR>
make: *** No rule to make target `SI'.  Stop.
<BR>
<P>Witness the software industry: certainly not something evolving along
<BR>
a straight log plot. (Nor does hardware industry, look at the growth
<BR>
of nonlocal memory bandwidth). The only currently visible pathway
<BR>
towards robust AI is stealing from biology, reproducing the
<BR>
development of the brain in machina, or breeding a something exploting
<BR>
a given hardware architecture optimally by evolutionary algorithms.
<BR>
<P><EM> &gt; would evolve with higher and higher IQs. Those intelligent agents (IAs) that
</EM><BR>
<EM> &gt; display unfriendly tendencies could simply be terminated. This is a tremendous
</EM><BR>
<P>1) Undecidedability, dude. 2) Containment. If the thing is useful, it
<BR>
is dangerous. If it is useful, and can be built and/or reverse
<BR>
engineered easily enough it will be used. If it will be used in
<BR>
large enough numbers for a long enough time, the thing either will
<BR>
express its hidden malignant tendency or mutate into a potentially
<BR>
dangerous shape. There is zilch you can do about it.
<BR>
<P>AIs are very useful, since actual human intellects are scarce,
<BR>
expensive and slow to produce, and evolutionary algorithms are by far
<BR>
the simplest way to produce robust, open-ended intelligence. Look into
<BR>
the mirror.
<BR>
<P><EM> &gt; advantage of working with Mind Children, because you can't (legally or
</EM><BR>
<EM> &gt; ethically) do this with biological children. As the evolution of AI moves toward
</EM><BR>
<EM> &gt; SI, all you need to do to preclude unfriendliness is to cull to herd, so to
</EM><BR>
<EM> &gt; speak.
</EM><BR>
<P>[insert derisive laughter here]
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4348.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4346.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4327.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="4434.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4434.html">J. R. Molloy: "Re: Why would AI want to be friendly? (Was: Congratulations to Eli,Brian  ...)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4347">[ date ]</A>
<A HREF="index.html#4347">[ thread ]</A>
<A HREF="subject.html#4347">[ subject ]</A>
<A HREF="author.html#4347">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:17 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
