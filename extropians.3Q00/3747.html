<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Borganization</TITLE>
<META NAME="Author" CONTENT="Dan Fabulich (daniel.fabulich@yale.edu)">
<META NAME="Subject" CONTENT="Borganization">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Borganization</H1>
<!-- received="Tue Aug 29 19:52:25 2000" -->
<!-- isoreceived="20000830015225" -->
<!-- sent="Tue, 29 Aug 2000 21:53:22 -0400 (EDT)" -->
<!-- isosent="20000830015322" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Borganization" -->
<!-- id="Pine.GSO.4.10.10008292152340.3167-100000@morpheus.cis.yale.edu" -->
<STRONG>From:</STRONG> Dan Fabulich (<A HREF="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Borganization&In-Reply-To=&lt;Pine.GSO.4.10.10008292152340.3167-100000@morpheus.cis.yale.edu&gt;"><EM>daniel.fabulich@yale.edu</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Aug 29 2000 - 19:53:22 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3748.html">John  M Grigg: "RE: My techno-archaology weekend..."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3746.html">Dan Fabulich: "Death Symbols was: Dystopian Fearmongers Strike Again"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3752.html">Eliezer S. Yudkowsky: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3752.html">Eliezer S. Yudkowsky: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3760.html">Matt Gingell: "Re: Borganization"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="3772.html">phil osborn: "Re: Borganization"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="3786.html">Spudboy100@aol.com: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3861.html">Don Klemencic: "RE: Borganization"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3747">[ date ]</A>
<A HREF="index.html#3747">[ thread ]</A>
<A HREF="subject.html#3747">[ subject ]</A>
<A HREF="author.html#3747">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
My biological body, as such, will die.  It may be the case that I can
<BR>
store a copy of it elsewhere, and use that copy to reconstruct me when
<BR>
my current body fails.  But even if that happens, the copy will not be
<BR>
exact; the bodies will be different.
<BR>
<P>The information stored in the body, of course, need not die.  It can
<BR>
be replicated exactly, backed up, preserved.  The information has, if
<BR>
not an infinite lifespan, then a very very long one.
<BR>
<P>If you think that you are your current body, if you think that you die
<BR>
if your body dies, (even if there's another copy on hand or ready to
<BR>
go,) then the fact that the information stored in your body can be
<BR>
preserved will not lead you to think that you have a chance at
<BR>
immortality.
<BR>
<P>With that having been said, people have taken great pains to achieve a
<BR>
lot less and called that immortality.  Immortality in one's works, for
<BR>
example.  In one's family line.  In the memories of others.  While I'm
<BR>
not suggesting that you HAVE to call it &quot;immortality&quot; if I make a copy
<BR>
of all the information stored in your body, I think you do have to
<BR>
admit, it's the closest you'll ever be able to get.
<BR>
<P>This leads me to conclude that whether you believe that you are your
<BR>
current body or not, your best chance at immortality in the material
<BR>
world is the recording and storing of your body in a replicable form,
<BR>
because your current body will die.
<BR>
<P>When we can figure out how to do this, we'll be right near
<BR>
Singularity.
<BR>
<P>---------------
<BR>
<P>I've heard a number of different charts to a variety of different
<BR>
things that might be called &quot;Singularity.&quot;  There are large deviations
<BR>
between them; one of the largest rifts is the divide between those who
<BR>
think that we should build an AI to figure out how to do the relevant
<BR>
recording, (or, to be more precise, build a seed AI and hope that it
<BR>
performs the relevant recording), and those who think that we should
<BR>
try to upload ourselves without help from AIs; that, if we do employ
<BR>
AIs to help us, we should only use those AIs stupid enough to be
<BR>
completely controlled by us and to serve our bidding unflinchingly.
<BR>
<P>(We might also try a little bit of simple biological enhancement to
<BR>
hurry us along either path.)
<BR>
<P>Either route will require a lot of thought, and a lot of intelligence.
<BR>
We have market mechanisms and governments to coordiate this work for
<BR>
now; this might be sufficient to bring us a seed AI before we blow
<BR>
ourselves up, if seed AIs are pretty easy, but it's not enough if seed
<BR>
AIs are very hard.  Uploading is hard by everyone's estimates.
<BR>
<P>We'll get around to solving one or both of these problems eventually,
<BR>
but as far as I'M concerned, this problem has a time limit.  If this
<BR>
problem isn't solved within my lifetime, I have no use for the
<BR>
solution.  If it isn't solved before we blow ourselves up, then it's
<BR>
no use to anybody.
<BR>
<P>Other than biologically enhancing humans (non-PC, forbidden almost
<BR>
everywhere), acquiring funding (either by performing useful work or by
<BR>
begging for it, even begging the government), or actual lab work, what
<BR>
more can be done to bring one of these two about SOON?
<BR>
<P>The answer is borganization, in which one or more intelligent people
<BR>
get their heads together and think as a single entity of unified
<BR>
intelligence.  (Some cybernetics are probably required, but certainly
<BR>
not the clunky stuff you saw on Star Trek.)  The market and, to a
<BR>
lesser extent, the government, is designed to coordinate our efforts
<BR>
in this way, but it does so slowly and inefficiently.  Direct neural
<BR>
inputs and outputs coupled with even a mechanism as simplistic as an
<BR>
e-cash market would lead to thoughts and conclusions many times faster
<BR>
than our society can output.  Everything would happen faster,
<BR>
including our science.
<BR>
<P>If we're trying to build a seed, borganizing will get us there
<BR>
faster.  If we're trying to upload, borganizing will get us THERE
<BR>
faster, too.
<BR>
<P>Is borganizing easier (or faster) than simply uploading, or than
<BR>
building a seed?  I very much think so in the case of uploading, and I
<BR>
largely believe so in the case of building a seed.  Uploading already
<BR>
looks like it will be too hard a project to win the race against my
<BR>
death.  If it requires nanotech, then we risk that nanotech being
<BR>
abused before it can be used effectively to upload me.  If uploading
<BR>
does not require nanotech, then the sort of technologies which would
<BR>
be required for borganization seem to me to be enabling technologies
<BR>
for uploading.
<BR>
<P>As for building a seed, I happen to hold a fairly pessimistic view on
<BR>
the question of how long it will take before we get our seed; I worry
<BR>
that we won't get it before we blow ourselves up.  My pessimism aside,
<BR>
it should also be noted that borganization, if not called
<BR>
&quot;borganization,&quot; is also a substantially lower future shock level than
<BR>
seed AI, especially when you see it as a simple trend of accelerating
<BR>
communications.  This is mostly based on hunches, which is why I
<BR>
suggest that I only &quot;largely believe&quot; that borganizing will be easier
<BR>
than building a seed.
<BR>
<P>So, right now, I think borganization is my very best chance to survive
<BR>
the death of my body.  What do you think?
<BR>
<P>-Dan
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-unless you love someone-
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;-nothing else makes any sense-
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.e. cummings
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3748.html">John  M Grigg: "RE: My techno-archaology weekend..."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3746.html">Dan Fabulich: "Death Symbols was: Dystopian Fearmongers Strike Again"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3752.html">Eliezer S. Yudkowsky: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3752.html">Eliezer S. Yudkowsky: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3760.html">Matt Gingell: "Re: Borganization"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="3772.html">phil osborn: "Re: Borganization"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="3786.html">Spudboy100@aol.com: "Re: Borganization"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3861.html">Don Klemencic: "RE: Borganization"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3747">[ date ]</A>
<A HREF="index.html#3747">[ thread ]</A>
<A HREF="subject.html#3747">[ subject ]</A>
<A HREF="author.html#3747">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:36:46 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
