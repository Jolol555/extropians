<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Mostly stuff about software (was Homeless + Job</TITLE>
<META NAME="Author" CONTENT="James Rogers (jamesr@best.com)">
<META NAME="Subject" CONTENT="Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff about Software world)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff about Software world)</H1>
<!-- received="Mon Sep 25 12:24:38 2000" -->
<!-- isoreceived="20000925182438" -->
<!-- sent="Mon, 25 Sep 2000 06:11:47 -0700" -->
<!-- isosent="20000925131147" -->
<!-- name="James Rogers" -->
<!-- email="jamesr@best.com" -->
<!-- subject="Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff about Software world)" -->
<!-- id="00092506314900.00677@tachyon" -->
<!-- inreplyto="39CE9E60.B3517795@objectent.com" -->
<STRONG>From:</STRONG> James Rogers (<A HREF="mailto:jamesr@best.com?Subject=Re:%20Mostly%20stuff%20about%20software%20(was%20Homeless%20%2B%20Jobs,%20Lots%20of%20stuff%20about%20Software%20world)&In-Reply-To=&lt;00092506314900.00677@tachyon&gt;"><EM>jamesr@best.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Sep 25 2000 - 07:11:47 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5708.html">J. R. Molloy: "Re: GUNS: Why here? / Worse Than Death"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5706.html">Michael S. Lorrey: "Re: Capitalists and concentration camps"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5614.html">Samantha Atkins: "Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff  about Software world)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5821.html">Bryan Moss: "Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff about Software world)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5707">[ date ]</A>
<A HREF="index.html#5707">[ thread ]</A>
<A HREF="subject.html#5707">[ subject ]</A>
<A HREF="author.html#5707">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
On Sun, 24 Sep 2000, Samantha Atkins wrote:
<BR>
<EM>&gt;
</EM><BR>
<EM>&gt; I would be very curious how you would obsolete the attitudes and beliefs
</EM><BR>
<EM>&gt; that that big government grows out of with only technology.  Maybe
</EM><BR>
<EM>&gt; something that raises the general IQ across the board?
</EM><BR>
<P><P>Governments spend most of their time managing perceived scarcity of one
<BR>
sort or another.  Lacking scarcity or finding something to replace
<BR>
government &quot;management&quot; will do the trick.  At the very least it will put
<BR>
them on a rather shaky defensive ground.
<BR>
<P><P><EM>&gt; Of course we are still in the early days of hardware improvement and of
</EM><BR>
<EM>&gt; human/machine interaction.  I believe the day will come when you don't
</EM><BR>
<EM>&gt; explain a complex design requirement to the machine at any deeper level
</EM><BR>
<EM>&gt; than you would to a skilled human.  Getting there will require a lot of
</EM><BR>
<EM>&gt; work across multiple disciplines.
</EM><BR>
<P><P>This effectively requires an AI for the most part.  There is a lot of
<BR>
context and implied design parameters in even the simplest of
<BR>
applications, many of which tend to be valid largely from a human
<BR>
perspective. Creating the specification for something like a
<BR>
spreadsheet application would be a monstrous undertaking, and I think
<BR>
that one would need to specify things that would be considered
<BR>
&quot;obvious&quot; to human operators.  There are many aspects of design that
<BR>
are considered &quot;best choice&quot; on a rather subjective (i.e. arguable)
<BR>
basis.  Basically, I think the UI would suffer if it was generated by
<BR>
a computer, although the backend would probably come out just fine.
<BR>
For something like a database engine, I expect that it would be
<BR>
relatively easy to create a code generator that runs off a human level
<BR>
spec, but only because the tool/design space is relatively limited.
<BR>
<P><P><EM>&gt; &gt; The biggest problem with runtime code generators is debugging the
</EM><BR>
<EM>&gt; &gt; resulting mess. However, it has allowed me to work on the some
</EM><BR>
<EM>&gt; &gt; of the many interesting problems of self-observation. Designing methods to
</EM><BR>
<EM>&gt; &gt; resolve issues such as detecting complex and non-procedural
</EM><BR>
<EM>&gt; &gt; infinite loops (e.g. infinite loops caused by how the data interacts with
</EM><BR>
<EM>&gt; &gt; the code at runtime, without compile-time knowledge of what the data can
</EM><BR>
<EM>&gt; &gt; look like) has been fun.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; If the code-generator is well-designed / tested and builds in run-time
</EM><BR>
<EM>&gt; checks there is not quite so onerous a problem with debugging is there?
</EM><BR>
<EM>&gt; Some of the things you mention sound like good fun indeed.
</EM><BR>
<P><P>Very true.  It was a matter of &quot;getting from here to there&quot;.  I didn't
<BR>
start out with very many runtime checks at all.  Backtracking from the
<BR>
algorithm results back to the code generation system is not trivial.
<BR>
There is a lot to be learned by doing this type of stuff that one is
<BR>
not likely to run into in your average programming job.
<BR>
<P><P><EM>&gt; Good C programmers do not generally encapsulate data structure and the
</EM><BR>
<EM>&gt; functions for manipulating those data structures well or at least not in
</EM><BR>
<EM>&gt;  a way that enforces that encapsulation except by convention.
</EM><BR>
<P><P>True, but I don't see this as too important.  Convention can go a
<BR>
long way in this regard.  Nonetheless, it is one of the things I like about
<BR>
C++.
<BR>
<P><P><EM>&gt; Good C
</EM><BR>
<EM>&gt; programmers do not generally think through polymorphism/genericity.
</EM><BR>
<P><P>The *good* ones do when necessary.  I only go through the effort when I
<BR>
anticipate that I will want to reuse the code at a later date, as making
<BR>
it so does not produce the optimal code for the problem at hand.  The
<BR>
problem is that when I write nice OO C++, I &quot;see&quot; it in terms of the C
<BR>
equivalent but with a pretty wrapper. Some C++ compilers are nothing more
<BR>
than C precompilers.  It is not difficult for a competent C programmer to
<BR>
create the functional equivalent of any C++ construct, though it will
<BR>
probably be a little more verbose.
<BR>
<P><P><EM>&gt; And
</EM><BR>
<EM>&gt; good C and C++ programmers generally believe a lot of mystical claptrap
</EM><BR>
<EM>&gt; about their ability to manage memory without a formal GC.  And no, using
</EM><BR>
<EM>&gt; reference counting and &quot;discipline&quot; is NOT an acceptable solution.
</EM><BR>
<P><P>I both agree and disagree.  For most applications I agree that memory
<BR>
management is an issue, and there is nothing like a good GC when I am
<BR>
feeling lazy.  However, for some applications you *need* to do your own
<BR>
memory management, for any number of reasons.  GCs are a poor solution
<BR>
in a number of design spaces.  One of the things that annoys me about
<BR>
Java and that will forever relegate it to second-string status is that
<BR>
you have no control of the system resources.  I have very mature and
<BR>
powerful memory managers that I have written that I use for certain
<BR>
classes of applications, and also have pointer managers that I use for
<BR>
just about everything else when working in C/C++. I guess I object to
<BR>
being forced to use a one-size-fits-all solution to a problem.
<BR>
<P>I don't think C/C++ programmers need something to clean up their
<BR>
pointers.  Mechanisms to keep track of them for the programmer (with
<BR>
some transactional context) should be sufficient and will allow more
<BR>
flexibility and control.  GCs like the ones in Java force me to give up
<BR>
too much control in some contexts.  A garbage collector is an idealized
<BR>
solution, but it falls short when used in some real world applications.
<BR>
<P><P><EM>&gt; I pick Python/C++ (for delimited tight things)/Java (mostly because of
</EM><BR>
<EM>&gt; size of Java savvy population and prejudice although it has a few
</EM><BR>
<EM>&gt; worthwhile features)/Lisp/Scheme/Smalltalk.
</EM><BR>
<P><P>Python is very good; I really like it.  I use Java largely because it has
<BR>
become a defacto standard for some application spaces and it is tolerable
<BR>
for a lot of the stuff I get paid good money to do.  However, it has some
<BR>
weaknesses that I dislike a good bit.  What I am really waiting for is
<BR>
the day when Python starts to push Perl out of the Big Script domain.
<BR>
Perl should have stopped adding features at version 4.x.
<BR>
<P><P><EM>&gt;  All else being equal I will
</EM><BR>
<EM>&gt; reach for Python or Lisp first when attempting to model a problem with
</EM><BR>
<EM>&gt; Smalltalk running a close second.  If I am coding some tight data
</EM><BR>
<EM>&gt; structure I will go to C/C++ as a sort of universal assembler.
</EM><BR>
<P><P>The great thing about languages like Java/Python/et al is that they bind
<BR>
well into a C/C++ environment.  I frequently combine environments into
<BR>
one application to use the unique capabilities of each.  The ability to
<BR>
mix interpreted and compiled languages into the same binary is an
<BR>
incredibly powerful capability that hasn't been fully exploited in my
<BR>
opinion.  You really can build a chimera.
<BR>
<P><P><EM>&gt; Modeling and coding closer to the actual problem space is more
</EM><BR>
<EM>&gt; important. Grnated that many people using OO don't understand that.
</EM><BR>
<P><P>I agree with this, but it is not nearly as applicable to most of the
<BR>
software I work on as it may be too many programmers.  It depends on the
<BR>
design space of the project.  I do OOD only on rare occasion.
<BR>
<P><P><EM>&gt; Clusters are a tool for network topology and dependable service
</EM><BR>
<EM>&gt; delivery.  Again, they should not be visible (except at the lowest
</EM><BR>
<EM>&gt; levels) to the programming/application space.  If they are then
</EM><BR>
<EM>&gt; something is very wrong.
</EM><BR>
<P><P>Idealistically yes, realistically definitely not.  Clusters exist
<BR>
both for availability and performance reasons.  Resource and performance
<BR>
limitations must necessarily drive design in a manner that requires
<BR>
awareness of the underlying resource parameters. I don't think it is
<BR>
even possible to create an abstract clustering interface that would
<BR>
even remotely be considered efficient if the application programmer
<BR>
did not control the trajectory of their code. Without detailed
<BR>
knowledge of the application code that only the programmer would know,
<BR>
the cluster could actually cause a dramatic slow down in application
<BR>
performance. It is similar to the reasons that database kernels manage
<BR>
their own resources rather than having the OS do it; the OS isn't
<BR>
optimized for database engines because it has to work well for all
<BR>
applications and this can have an enormous impact on resource
<BR>
intensive applications. The differences in performance one would see
<BR>
for a similar situation on a cluster would be magnified by the
<BR>
relatively limited bandwidth and high latency between nodes.
<BR>
<P><P><EM>&gt; One of the things that make multi-threading and transactional integrity
</EM><BR>
<EM>&gt; hard is that most language environments give only a few blunt tools for
</EM><BR>
<EM>&gt; really addressing concurrency issues and most of the tools given have
</EM><BR>
<EM>&gt; gross impedance mismatches with the language.  We do not to this day
</EM><BR>
<EM>&gt; have good long-transaction models or tools.
</EM><BR>
<P><P>The problem is that the limitations are mathematical/fundamental; you
<BR>
can't fight them, you have to work with them.  I have found most of
<BR>
the thread API implementations to actually be fairly elegant, though
<BR>
there are a few turds in the bunch (e.g. Win32 threads).  The only
<BR>
thread model I don't like is the one in Java, largely because it makes
<BR>
you jump through some very inelegant hoops to do some types of
<BR>
complicated thread manipulation.
<BR>
<P>There are no good long-transaction models because the concept of a
<BR>
&quot;long-transaction model&quot; doesn't really make sense.  If most of your
<BR>
transactions are &quot;long&quot; then they aren't, and any model that would make
<BR>
guarantees on the performance of long transactions will grossly
<BR>
undermine the average performance of the system, which is hardly a net
<BR>
improvement.  Most database engines today can be configured to &quot;guarantee&quot;
<BR>
long-running transactions for those that really need it, but it often
<BR>
imposes a terrible performance cost to maintain the ACID properties of the
<BR>
transactions.
<BR>
<P>Note that there is no difference between long and short transactions,
<BR>
it is merely a convention for describing transaction length
<BR>
distribution. Current transaction models describe optimal systems
<BR>
regardless of absolute transaction length.  However, transactions that
<BR>
deviate significantly from the average transaction on a given system
<BR>
will always suffer degraded performance.  Since &quot;long transactions&quot;
<BR>
by definition deviate signficantly relative to the average transaction
<BR>
length distribution and are therefore rare, most DBMSs sacrifice the
<BR>
performance of long-running transactions for the sake of those
<BR>
that run closer to the average distribution, maximizing average
<BR>
performance. This is why many large database applications distribute their
<BR>
queries across multiple systems by average transaction type.  It is so that
<BR>
each system has a typically narrow distribution of transaction types
<BR>
(e.g. OLAP or OLTP) for optimal performance since neither will have
<BR>
&quot;long&quot; transactions to worry about.
<BR>
<P><P><EM>&gt; Again, most programmers should have no need to &quot;get&quot; cluster design.
</EM><BR>
<P><P>Only because they don't write cluster apps.
<BR>
<P><P><EM>&gt; In a well designed system there is little need for most application
</EM><BR>
<EM>&gt; programmers and even many system programmers to worry about all of these
</EM><BR>
<EM>&gt; issues much of the time.  A large part of successful systems programming
</EM><BR>
<EM>&gt; is keeping these issues out of the face of application programmers.
</EM><BR>
<P><P>Wishful thinking.  A good example is the modern RDBMS.  All the
<BR>
transaction management and data access complexity is hidden from the
<BR>
application programmer; they merely have to program the business
<BR>
logic.
<BR>
<P>Unfortunately, that is what happens all to often.  Yes, you can ignore the
<BR>
internal mechanisms of the engine, but it often comes at the expense of an
<BR>
order of magnitude or more of performance.  This is great if you
<BR>
have infinite resources at your disposal, but it crumbles badly when real
<BR>
limits exist.  There is no solution that will work optimally for all
<BR>
possible implementations, good or bad.  Fact is, most database systems
<BR>
are highly-tuned to provide very good performance across a great
<BR>
number of application spaces, yet programmers regularly ruin system
<BR>
performance because they have no clue as to how their code actually
<BR>
impacts the database and therefore run grossly suboptimal sets of
<BR>
operations against the engine.  For all database engines, there is a
<BR>
set of operations that will make it perform poorly.  The number of
<BR>
times programmers actually use this set of Very Bad operations in
<BR>
practice is far greater than predicted by the Million Monkey Theory.
<BR>
<P>This isn't a case of having interface that just isn't good enough.  It is
<BR>
a case of their being fundamental limits to how much stupidity and
<BR>
ignorance that software can cover for.  Even the most elegant and robust
<BR>
algorithms can give a poor showing if used poorly.
<BR>
<P><P><EM>&gt; Cut,paste, modify sucks big-time and produces krap systems.  Components
</EM><BR>
<EM>&gt; are more difficult to write and can't be written well in broken toy
</EM><BR>
<EM>&gt; languages.
</EM><BR>
<P><P>I didn't say it was necessarily good, just &quot;viable&quot;.
<BR>
<P><P><EM>&gt; Doing components well also requires some advances in our
</EM><BR>
<EM>&gt; ability to model some aspects of the semantics that we cannot model well
</EM><BR>
<EM>&gt; today.  I do not understand your comment about data awareness re
</EM><BR>
<EM>&gt; components.  From outside the component its data awareness is irrelevant
</EM><BR>
<EM>&gt; to the user as it gives a message/capability/functional interface only.
</EM><BR>
<EM>&gt; Would you want more than that?
</EM><BR>
<P><P>What I meant was that components should work with essentially all
<BR>
conceivable data i.e. be able to adapt themselves to the data spaces
<BR>
that they are used to work on. A weakness with components is that they
<BR>
focus on the algorithms rather than the data.
<BR>
<P>You can more-or-less componentize simple algorithms like sorting
<BR>
because the data is simple in nature.  But for complex problems, such
<BR>
as a component that generically does cost-based routing through a
<BR>
complex web of heterogenous nodes (where each node may be a small
<BR>
world unto itself), generic component design becomes much trickier.
<BR>
The algorithms are simple, but the data can occur in very complex
<BR>
forms. This is the primary reason I think generic components as
<BR>
implemented today are weak. They are not able to adapt effectively to
<BR>
relatively simple algorithms that encompass very complex data spaces,
<BR>
only to complex algorithm spaces with simple data.  As a result, every
<BR>
problem with a complex data space becomes a custom software solution.
<BR>
<P>I think it is arguable that one would actually see greater cost
<BR>
savings in a great many applications from components designed to
<BR>
generically handle complex dataspaces than you would from components
<BR>
that are designed to handle complex algorithms.
<BR>
<P>User interface components are another thing altogether.
<BR>
<P><P><EM>&gt; &gt; But components don't really matter; I have strong doubts as to
</EM><BR>
<EM>&gt; &gt; whether components are a correct solution in the long-term anyway.
</EM><BR>
<EM>&gt; &gt; Components exist more to solve a human weakness in software
</EM><BR>
<EM>&gt; &gt; implementation than to solve any particular weakness intrinsic
</EM><BR>
<EM>&gt; &gt; to software design itself. I can't imagine why a smart machine would
</EM><BR>
<EM>&gt; &gt; use components to write software.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; That is like saying that standardized reuseable parts in hardware exist
</EM><BR>
<EM>&gt; only to solve particular weaknesses intrinsic to hardware design.
</EM><BR>
<P><P>The weakness is human. We use components because the computational
<BR>
effort required to maximally optimize every part of a design is too
<BR>
high.  Component reuse produces a less efficient design, but this is
<BR>
outweighed by cost savings in the development cycle.
<BR>
<P><P><EM>&gt; smart machine would use components in order to not reinvent/reimplement
</EM><BR>
<EM>&gt; the wheel every time it is needed, much as reasonably intelligent human
</EM><BR>
<EM>&gt; software designers also attempt to do. It is not possible to
</EM><BR>
<EM>&gt; think/design at increasingly more complex levels without reusing levels
</EM><BR>
<EM>&gt; of parts (components) already sufficiently mastered, generalized and
</EM><BR>
<EM>&gt; packaged.
</EM><BR>
<P><P>Again, this is a computational limitation. A sufficiently smart
<BR>
computer that can actually keep track of the intimate details of a
<BR>
billion little parts will have no need to use components. There is
<BR>
also a cost to adapting components to work together rather than
<BR>
writing a perfectly fitted piece.  Humans use components to reduce bug
<BR>
counts and to find/fix design flaws quicker. But for a computer that
<BR>
writes bug-free code the first time, every time, this won't be much of
<BR>
a feature.
<BR>
<P><P>-James Rogers
<BR>
&nbsp;<A HREF="mailto:jamesr@best.com?Subject=Re:%20Mostly%20stuff%20about%20software%20(was%20Homeless%20%2B%20Jobs,%20Lots%20of%20stuff%20about%20Software%20world)&In-Reply-To=&lt;00092506314900.00677@tachyon&gt;">jamesr@best.com</A>
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5708.html">J. R. Molloy: "Re: GUNS: Why here? / Worse Than Death"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5706.html">Michael S. Lorrey: "Re: Capitalists and concentration camps"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5614.html">Samantha Atkins: "Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff  about Software world)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5821.html">Bryan Moss: "Re: Mostly stuff about software (was Homeless + Jobs, Lots of stuff about Software world)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5707">[ date ]</A>
<A HREF="index.html#5707">[ thread ]</A>
<A HREF="subject.html#5707">[ subject ]</A>
<A HREF="author.html#5707">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:55 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
