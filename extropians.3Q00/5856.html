<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Robots, but philosophers (or, Hal-2001)</TITLE>
<META NAME="Author" CONTENT="Franklin Wayne Poley (culturex@vcn.bc.ca)">
<META NAME="Subject" CONTENT="Re: Robots, but philosophers (or, Hal-2001)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Robots, but philosophers (or, Hal-2001)</H1>
<!-- received="Tue Sep 26 16:56:16 2000" -->
<!-- isoreceived="20000926225616" -->
<!-- sent="Tue, 26 Sep 2000 15:56:18 -0700 (PDT)" -->
<!-- isosent="20000926225618" -->
<!-- name="Franklin Wayne Poley" -->
<!-- email="culturex@vcn.bc.ca" -->
<!-- subject="Re: Robots, but philosophers (or, Hal-2001)" -->
<!-- id="Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca" -->
<!-- inreplyto="Robots, but philosophers (or, Hal-2001)" -->
<STRONG>From:</STRONG> Franklin Wayne Poley (<A HREF="mailto:culturex@vcn.bc.ca?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca&gt;"><EM>culturex@vcn.bc.ca</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 26 2000 - 16:56:18 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5857.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5855.html">Franklin Wayne Poley: "Re: Aymara  language"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="5972.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="6126.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5856">[ date ]</A>
<A HREF="index.html#5856">[ thread ]</A>
<A HREF="subject.html#5856">[ subject ]</A>
<A HREF="author.html#5856">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
-------------------------------------------------------------------------------
<BR>
Machine Psychology:
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;<A HREF="http://users.uniserve.com/~culturex/Machine-Psychology.htm">http://users.uniserve.com/~culturex/Machine-Psychology.htm</A>&gt;
<BR>
-------------------------------------------------------------------------------
<BR>
<P><EM>&gt; Date: Tue, 26 Sep 2000 08:58:41 -0700
</EM><BR>
<EM>&gt; From: <A HREF="mailto:hal@finney.org?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca&gt;">hal@finney.org</A>
</EM><BR>
<EM>&gt; Reply-To: <A HREF="mailto:extropians@extropy.org?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca&gt;">extropians@extropy.org</A>
</EM><BR>
<EM>&gt; To: <A HREF="mailto:extropians@extropy.org?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;Pine.GSO.4.21.0009261554300.10384-100000@vcn.bc.ca&gt;">extropians@extropy.org</A>
</EM><BR>
<EM>&gt; Subject: Re: Robots, but philosophers
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Franklin writes:
</EM><BR>
<EM>&gt; &gt; Correct me if I am in error, but the attitude of this (Extropians) list is
</EM><BR>
<EM>&gt; &gt; that AI to surpass human equivalency is either here (in private and/or
</EM><BR>
<EM>&gt; &gt; military budgets) or almost here (within a decade). Minsky OTOH sees AI as
</EM><BR>
<EM>&gt; &gt; having a long way to go to get to that level. I'll forward a small sample
</EM><BR>
<EM>&gt; &gt; of my exchanges with him. 
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; There is a diversity of opinion, but I think only a small but vocal
</EM><BR>
<EM>&gt; minority expects to see AI so fast.  I suspect that more people would
</EM><BR>
<EM>&gt; agree with estimates roughly in line with Moravec's 2030-2040 time frame,
</EM><BR>
<EM>&gt; possibly as early as the 2020s.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Hal
</EM><BR>
<P>How about 2001, Hal? Could it be that by 2001, someone somewhere will
<BR>
already have AI machinery to surpass human equivalency? If anyone wants to
<BR>
review the lengthy exchange with Minsky, let me know off-list and I can
<BR>
give you access to the archives of
<BR>
EDTV-Robotics-State-Of-The-Art@egroups.com. What I am doing with that
<BR>
by-invitation-only list is to work out the script for a proposed ed tv
<BR>
program with a local (Vancouver) tv studio. Unless I am satisfied that the
<BR>
script covers the state-of-the-art (in the public domain anyway) I don't
<BR>
want to go ahead with it.
<BR>
&nbsp;&nbsp;&nbsp;In summary, here is the argument that AI now is at a stage comparable
<BR>
to the man-on-the-moon program from a 1960 perspective. In other words, we
<BR>
mostly need quantitative extensions of what we know now and the
<BR>
qualititative aspect of this project is not overwhelming. That is, we can
<BR>
now see the areas which require innovation or invention and we can
<BR>
reasonably assume that the breakthroughs will be made. The sheer magnitude
<BR>
of the project should not be a deterrent. If we know how to reach the
<BR>
objective and it is worth while to do so, so what if it costs hundreds of
<BR>
billions? 
<BR>
&nbsp;&nbsp;&nbsp;In my 1976 text (with Al Buss), &quot;Individual Differences&quot;, Chapter 3 is
<BR>
on Intelligence. Pages 41-43 give brief descriptions of 19 primary mental
<BR>
abilities. We can proceed by different models but the Thurstone-Cattell
<BR>
model has advantages for inter-disciplinary communication. Cattell's CAB
<BR>
uses a similar set of factors. If you measure all 19 factors you have a
<BR>
pretty good estimate of 'g' or general intelligence. If our machinery can
<BR>
competently churn through all those problems entailed in the 19 factors
<BR>
and surpass human equivalency, I think we have one helluvah machine. Maybe
<BR>
we will call it Hal!
<BR>
&nbsp;&nbsp;&nbsp;Minsky didn't like the psychometric approach. In the archives you will
<BR>
see that he says that's because it &quot;doesn't deal with underlying
<BR>
structures&quot;. He is correct. But AI is approached in different ways by
<BR>
different people. In his book, &quot;Society of Mind&quot; he says &quot;This book tries
<BR>
to explain how minds work&quot; (p. 17). I am not trying to explain how minds
<BR>
work. I am the laziest man in the whole wide world. I want machines to do
<BR>
my thinking for me. I want them to get the results of those problems
<BR>
presented to me and I don't care much how their artificial minds work as
<BR>
long as the do that.
<BR>
&nbsp;&nbsp;&nbsp;By illustration, arithmetic ability is used enough in the testing of
<BR>
real human intelligence that it comes out as a factor of its own. My
<BR>
little $5 calculator is a wizard at Factor N problems, a fact that I
<BR>
appreciate whenever I recall that when I started graduate school we used
<BR>
cumbersome Munroe calculators that clanked and crashed around and broke
<BR>
down every other day and were painfully slow. It doesn't matter to me if
<BR>
my $5 digital calculator solves N problems like a real human
<BR>
intelligence. I credit it with human equivalency. Besides, my mental
<BR>
arithmetic is such a rote procedure that you have to wonder if real
<BR>
human intelligence in general is any loftier than artificial humanoid
<BR>
intelligence. 
<BR>
&nbsp;&nbsp;&nbsp;So we go through the other 18 factors and we realize that AI machines
<BR>
already surpass human equivalency in many ways. They are superior to
<BR>
humans in Reasoning Factors (arithmetic/logic/mathematics) if we care to
<BR>
take the time to write programs for all of these disciplines. They are
<BR>
superior in various kinds of Memory Factors. They are superior in many
<BR>
kinds of Visualization tasks. It is with respect to the Verbal Factors
<BR>
that machines are most at a disadvantage. But even here consider that
<BR>
spelling is sometimes used in psychometrics and machines meet the human
<BR>
equivalency criterion in spelling, as they do in 'definitions'. As I
<BR>
posted yesterday, I think there are 4 areas where innovation/invention
<BR>
rather than sheer massive investment of time and labour MIGHT be required
<BR>
to build Hal-2001 so as to meet human equivalency criteria: (1) voice
<BR>
recognition in difficult circumstances, eg with lots of noise and a weak
<BR>
signal; (2) visual object recognition or itemization of objects in
<BR>
difficult circumstances, eg with lots of clutter and poorly defined
<BR>
borders to objects; (3) conversational ability; (4) reading ability, ie
<BR>
ability to deal with text-question-answer sequences.
<BR>
&nbsp;&nbsp;&nbsp;But note that in all 4 of these areas significant progress has been
<BR>
made. Maybe Hal-2001 exists already as a private or military project. If
<BR>
so, what does it mean? It means you could converse with it as you could
<BR>
with a human. You could ask it for expert advice in law, medicine,
<BR>
engineering and scores of other professions and it would give expert
<BR>
answers. Given that it is this learned, it could build replicas of itself
<BR>
if there is a need to do so. It can work on problems (like advancing
<BR>
military science or the space program) tirelessly, 24-hours a day and
<BR>
more-or-less error free and more competently than teams of human experts. 
<BR>
Given that learning abilities are already built into the psychometric
<BR>
model, it can add to its store of learning. In other words, it is a
<BR>
learning machine as well as an AI machine.
<BR>
&nbsp;&nbsp;&nbsp;What can't it do? It will probably fall short of human creativity vs.
<BR>
the most capable of humans. I would expect some creative output in the
<BR>
arts (Kurzweil gives examples in his writings) but I wouldn't expect plays
<BR>
to surpass those of Shakespeare. I don't expect a Robo-Mozart. However,
<BR>
given that those 4 areas above are the most difficult problem-areas in
<BR>
such a development I see no reason why such a machine could not be built
<BR>
now. And its value should justify hundreds of billions of dollars in
<BR>
R&amp;D. Indeed, Hal-2001 may exist already.
<BR>
<P>FWP
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5857.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5855.html">Franklin Wayne Poley: "Re: Aymara  language"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="5972.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Maybe reply:</STRONG> <A HREF="6126.html">hal@finney.org: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5856">[ date ]</A>
<A HREF="index.html#5856">[ thread ]</A>
<A HREF="subject.html#5856">[ subject ]</A>
<A HREF="author.html#5856">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:12 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
