<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Wed Sep 27 10:44:46 2000" -->
<!-- isoreceived="20000927164446" -->
<!-- sent="Wed, 27 Sep 2000 09:46:41 -0700" -->
<!-- isosent="20000927164641" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39D22471.7370E16B@objectent.com" -->
<!-- inreplyto="14801.43911.111486.347704@lrz.uni-muenchen.de" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39D22471.7370E16B@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 27 2000 - 10:46:41 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5897.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5895.html">Michael S. Lorrey: "Re: Capitalists and concentration camps"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5886.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5915.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5896">[ date ]</A>
<A HREF="index.html#5896">[ thread ]</A>
<A HREF="subject.html#5896">[ subject ]</A>
<A HREF="author.html#5896">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eugene Leitl wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Samantha Atkins writes:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;  &gt; Or you could start with humans and continuously augment (voluntarily)
</EM><BR>
<EM>&gt;  &gt; with first external but more and more integrated and then internal
</EM><BR>
<EM>&gt;  &gt; hardware and software.  This seems to me the best way to keep humans in
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; This method is
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; * slow
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; * technically demanding (biocompatibility; probably requires nanotechnology)
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; * has high ethical threshold and is risky (neurosurgery is no peanuts)
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; * attempts to integrate two very different paradigms: neuro and
</EM><BR>
<EM>&gt;   digital, which requires a very good understanding of the wet substrate
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>Sure.  But bit by bit it is something we are doing anyway.  All the
<BR>
hardware now has to be dragged out of the bag, briefcase, pocket and is
<BR>
very primitive.  This is changing.  Many expect humans to be online (at
<BR>
least white collar humans) pretty much continuously by 2009.  The
<BR>
wearable revolution is a precursor to the next step.  
<BR>
<P>The AI is at least as technically demanding.  Neurosurgery is one path. 
<BR>
We have a few steps to take before we get that far.  By the time we do
<BR>
medical nanotech (or something close) will help.  Over time we will
<BR>
integrate human brain / computational resources more and more
<BR>
symbiotically.  It is an inevitable evolutionary step. 
<BR>
<P>I would also point out that making humans smarter may well be necessary
<BR>
in order for us to be capable of making a fully functioning AI (or seed
<BR>
of one).
<BR>
<P><P><EM>&gt; It would work in principle, provided in the meantime no AI grown by
</EM><BR>
<EM>&gt; evolutionary algorithms emerges. (This is unlikely, because in 20-30
</EM><BR>
<EM>&gt; years we should have molecular circuitry, and hence enough computing
</EM><BR>
<EM>&gt; performance to breed an AI from scratch, while augmentation will have
</EM><BR>
<EM>&gt; made scarcely any headway in that time frame). Because of explosive
</EM><BR>
<EM>&gt; kinetics of the self-enhancing positive autofeedback process of the
</EM><BR>
<EM>&gt; AI, the cyborg wannabees would be just as left in the dust as
</EM><BR>
<EM>&gt; unaugmented people.
</EM><BR>
<P>Augmentation will have made a great deal of headway at least including
<BR>
fairly direct brain/computer interfaces which in principle opens up
<BR>
quite a bit of synergistic/symbiotic potential.  I would be very
<BR>
surprised if enhanced memory modules that are implantable and auxilliary
<BR>
logic processors were not available.
<BR>
<P><EM>&gt; 
</EM><BR>
<EM>&gt;  &gt; the loop and to end up with something human compatible and reasonably
</EM><BR>
<EM>&gt;  &gt; likely to be friendly and caring about humanity.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Assuming, the transition will be indeed so slow. Convergent evolution
</EM><BR>
<EM>&gt; would seem to require that ALife AI and uploaders would be
</EM><BR>
<EM>&gt; undistinguishable. Because uploaders would be probably slower to
</EM><BR>
<EM>&gt; converge initially due to evolutionary ballast, this probably means
</EM><BR>
<EM>&gt; that they will be blown away by ALife AI, if latter emerges at
</EM><BR>
<EM>&gt; relatively early step of the game.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Actually I am assuming the uploaders will be more compatible and
<BR>
friendly.  I am actually of the mind that we will not get full AI until
<BR>
humans are significantly more augumented.  This is largely because I am
<BR>
not sure we are bright enough and cooperative with one another to do the
<BR>
job, because full AI may require a decade or two of hardware advances,
<BR>
and because it requires significant theoretical advances as well as a
<BR>
lot deeper thinking about implications and outcomes. 
<BR>
<P>It is the AIs that will be playing a lot of catch up from both a
<BR>
computational complexity of their &quot;brain&quot;  and evolution trained set of
<BR>
algorithms for action and understanding in/of the material world.  We
<BR>
don't even know yet that the human level AI can be built in less than
<BR>
two to three decades.  We know we can variously augment humans and that
<BR>
there is great economic and creative advantage to doing so. The
<BR>
augmentation may be small or larger.  That we will have to see. 
<BR>
<P>&nbsp;
<BR>
<EM>&gt;  &gt; But what a great resources to hook into the WebMind or to have at the
</EM><BR>
<EM>&gt;  &gt; disposal of more capable AI!  Don't throw that work out.  It is a useful
</EM><BR>
<EM>&gt;  &gt; piece.  If nothing else it is a huge glob of training material.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; A search engine with Cyc functionality is indeed very useful, but only
</EM><BR>
<EM>&gt; as long as we can't create real AI. It *is* a useful piece, as it
</EM><BR>
<EM>&gt; demonstrates another failure of a given approach.
</EM><BR>
<P>No.  It is useful as a submodule and resource of real AI.  And it is
<BR>
certainly useful to us also.  It is not a &quot;failure&quot;.  It is simply a
<BR>
failure to produce full AI.  But every path explored is also a success
<BR>
if we learn from it and intelligently use what it did produce.
<BR>
<P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5897.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5895.html">Michael S. Lorrey: "Re: Capitalists and concentration camps"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5886.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5915.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5896">[ date ]</A>
<A HREF="index.html#5896">[ thread ]</A>
<A HREF="subject.html#5896">[ subject ]</A>
<A HREF="author.html#5896">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:14 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
