<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Brent Allsop (allsop@fc.hp.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Wed Sep  6 10:01:04 2000" -->
<!-- isoreceived="20000906160104" -->
<!-- sent="Wed, 6 Sep 2000 10:03:21 -0600 (MDT)" -->
<!-- isosent="20000906160321" -->
<!-- name="Brent Allsop" -->
<!-- email="allsop@fc.hp.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="200009061603.KAA02289@raptor.fc.hp.com" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> Brent Allsop (<A HREF="mailto:allsop@fc.hp.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;200009061603.KAA02289@raptor.fc.hp.com&gt;"><EM>allsop@fc.hp.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 06 2000 - 10:03:21 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4374.html">John Clark: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4372.html">Waldemar Ingdahl: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4373">[ date ]</A>
<A HREF="index.html#4373">[ thread ]</A>
<A HREF="subject.html#4373">[ subject ]</A>
<A HREF="author.html#4373">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eugene Leitl &lt;<A HREF="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;200009061603.KAA02289@raptor.fc.hp.com&gt;">eugene.leitl@lrz.uni-muenchen.de</A>&gt; responded:
<BR>
<P><EM>&gt; Jason Joel Thompson writes:
</EM><BR>
<P><EM>&gt;  &gt; The question remains (and I'll rephrase for clarity:)
</EM><BR>
<EM>&gt;  &gt; 
</EM><BR>
<EM>&gt;  &gt; Does truly superior intelligence require free will?
</EM><BR>
<P><EM>&gt; Can you tell random from pseudorandom, without further knowledge
</EM><BR>
<EM>&gt; about the generation source?
</EM><BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Good response!  What do you mean, Jason, by &quot;free will&quot;?
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To me, free will is the ability to do research to discover
<BR>
that which is the best, and then set such as a goal and seek after it,
<BR>
whatever it turns out to be.  To the degree that you can reliably and
<BR>
deterministically know and get what is truly the best the more you are
<BR>
free.  Anything, whether it be ignorance, inability, randomness or
<BR>
some perverted &quot;free will&quot; that causes you to &quot;do otherwise&quot; or
<BR>
whatever, that causes deviations from the absolute best destroys true
<BR>
free will or ability to get that which you really want.  To me, given
<BR>
this definition, almost anything sufficiently intelligent, and able to
<BR>
discover, change and adapt and improve, cannot help but have &quot;free
<BR>
will&quot;.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Even evolution has free will, because that which is more fit,
<BR>
is better, and hence that is what it chooses....  If it discovers
<BR>
that endo-skeletons are better (more fit) than exo-skeletons it starts
<BR>
chosing that...  No one can stop it and make it do otherwise, that's
<BR>
what makes it absolutely and deterministically free.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We are all deterministically and reliably going towards that
<BR>
which is the best for all, there is no possible way to &quot;chose&quot;
<BR>
anything less for chosing such makes no logical sense, if one is truly
<BR>
free.  If you chose that which you don't really want, you are not
<BR>
really free.  Therefore, once we arrive at the best, we will finally
<BR>
be perfectly free.  And really, no one or nothing ever has any choice,
<BR>
or ability to do otherwise right?
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Brent Allsop
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4374.html">John Clark: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4372.html">Waldemar Ingdahl: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4373">[ date ]</A>
<A HREF="index.html#4373">[ thread ]</A>
<A HREF="subject.html#4373">[ subject ]</A>
<A HREF="author.html#4373">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:19 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
