<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Darin Sunley (rsunley@escape.ca)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sun Sep 24 13:29:52 2000" -->
<!-- isoreceived="20000924192952" -->
<!-- sent="Sun, 24 Sep 2000 14:30:26 -0500" -->
<!-- isosent="20000924193026" -->
<!-- name="Darin Sunley" -->
<!-- email="rsunley@escape.ca" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="000801c0265d$e467dd40$0201a8c0@dcs" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> Darin Sunley (<A HREF="mailto:rsunley@escape.ca?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;"><EM>rsunley@escape.ca</EM></A>)<BR>
<STRONG>Date:</STRONG> Sun Sep 24 2000 - 13:30:26 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5586.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5584.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5599.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5601.html">Jason Joel Thompson: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5585">[ date ]</A>
<A HREF="index.html#5585">[ thread ]</A>
<A HREF="subject.html#5585">[ subject ]</A>
<A HREF="author.html#5585">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
-----Original Message-----
<BR>
From: <A HREF="mailto:hal@finney.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;">hal@finney.org</A> &lt;<A HREF="mailto:hal@finney.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;">hal@finney.org</A>&gt;
<BR>
To: <A HREF="mailto:extropians@extropy.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;">extropians@extropy.org</A> &lt;<A HREF="mailto:extropians@extropy.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;">extropians@extropy.org</A>&gt;
<BR>
Date: Sunday, September 24, 2000 2:03 PM
<BR>
Subject: Re: Why would AI want to be friendly?
<BR>
<P><P><EM>&gt;Not true.  I view a gun in the process of firing at me as a deterministic
</EM><BR>
<EM>&gt;process, but guess what, it's going to win.  Just because something is
</EM><BR>
<EM>&gt;deterministic doesn't mean that I can control it.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Think one level farther up. If a gun is in the process of firing at you, you
<BR>
have already completely failed to predict the behavior of the agent firing
<BR>
the gun. Now, obviously none of US can treat a human being as a
<BR>
deterministic process, but what if the gun is being fired by a simple robot?
<BR>
All it does is run in circles, and fire the gun from the same spot, at the
<BR>
same target, every 30 seconds or so. You can quite easily determine the
<BR>
pattern in that robot's behaivior and never be at risk from the gun. The
<BR>
difference between the behaivior of a human and that robot is nothing more
<BR>
then complexity. Given that humans are not infinitely complex, it is not an
<BR>
impossible task to discover the deterministic rules governing human
<BR>
behaivior.
<BR>
<P><EM>&gt;Believers in the omnipotence of AIs seem to think that for any given
</EM><BR>
<EM>&gt;person, in any given situation, there is some input they can be given
</EM><BR>
<EM>&gt;which will cause them to produce any desired output.  If I see a nun
</EM><BR>
<EM>&gt;in the middle of prayer in the chapel, there is something I can say to
</EM><BR>
<EM>&gt;her that will make her immediately start screeching like a chimp while
</EM><BR>
<EM>&gt;jumping around the room scratching herself.
</EM><BR>
<P>You know, given a trillion high fidelity simulations of that nun to test
<BR>
possible responses, I bet I could construct a sentence that would do just
<BR>
that. My first order approximation is that it would involve me claiming to
<BR>
be sent from God, combined with a thourough demonstration of omniscience
<BR>
with respect to her life up to that point, all of which is easily acheivable
<BR>
given those simulations, and an arbitrary amount subjective time to think
<BR>
about it.
<BR>
<P>Now, convincing her within 30 seconds could very well be impossible, just
<BR>
like you cannot overwrite 64 megabytes of memory with all 0s in less then 64
<BR>
million (or so) fetch-execute cycles. The n-dimensional Hamming distance
<BR>
between those two mind-states may be too far to bridge using only 30 seconds
<BR>
of vocal input. But if you eliminate the time constraint, and give me, say,
<BR>
6 months to get her to do a convincing chimp imitation, then again, given
<BR>
that simulation ability, I don't think it's an impossible task at all.
<BR>
<P>Darin Sunley
<BR>
<A HREF="mailto:rsunley@escape.ca?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000801c0265d$e467dd40$0201a8c0@dcs&gt;">rsunley@escape.ca</A>
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5586.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5584.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5599.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5601.html">Jason Joel Thompson: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5585">[ date ]</A>
<A HREF="index.html#5585">[ thread ]</A>
<A HREF="subject.html#5585">[ subject ]</A>
<A HREF="author.html#5585">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:48 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
