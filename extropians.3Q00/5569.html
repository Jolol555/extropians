<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Spudboy100@aol.com (Spudboy100@aol.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sun Sep 24 06:47:36 2000" -->
<!-- isoreceived="20000924124736" -->
<!-- sent="Sun, 24 Sep 2000 08:47:16 EDT" -->
<!-- isosent="20000924124716" -->
<!-- name="Spudboy100@aol.com" -->
<!-- email="Spudboy100@aol.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="8f.edd03d.26ff51d4@aol.com" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> <A HREF="mailto:Spudboy100@aol.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;8f.edd03d.26ff51d4@aol.com&gt;"><EM>Spudboy100@aol.com</EM></A><BR>
<STRONG>Date:</STRONG> Sun Sep 24 2000 - 06:47:16 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5570.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5568.html">Eugene Leitl: "Re: GUNS: Why here?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5569">[ date ]</A>
<A HREF="index.html#5569">[ thread ]</A>
<A HREF="subject.html#5569">[ subject ]</A>
<A HREF="author.html#5569">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&lt;&lt;What makes you think we'll be able to terminate a being which is orders of 
<BR>
magnitude more intelligent than we are?  And even if we could, what makes 
<BR>
you think AI will be bribable?  Why should it *care* whether it is 
<BR>
terminated?  Particularly when its existence consists mostly of slave labor?
<BR>
<P>Try putting yourself in the AI's shoes.  How would *you* react?  Me thinks 
<BR>
that if you start the human-AI relationship on the basis of fear, threats 
<BR>
and mistrust, it is the humans who will come out with the short end of the 
<BR>
stick.&gt;&gt;
<BR>
George Dyson, has it right when he views us as part of the machine, rather then a.i. being something totally away from the human realm. If you were a manufactured intelligence, perhaps you would desire feedback, tactilly from the world? Maybe that's a primary element of what a.i. needs to succeed? 
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5570.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5568.html">Eugene Leitl: "Re: GUNS: Why here?"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5569">[ date ]</A>
<A HREF="index.html#5569">[ thread ]</A>
<A HREF="subject.html#5569">[ subject ]</A>
<A HREF="author.html#5569">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:47 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
