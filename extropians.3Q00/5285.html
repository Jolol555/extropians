<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Fwd: Earthweb from transadmin</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: Fwd: Earthweb from transadmin">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Fwd: Earthweb from transadmin</H1>
<!-- received="Tue Sep 19 12:17:11 2000" -->
<!-- isoreceived="20000919181711" -->
<!-- sent="Tue, 19 Sep 2000 14:09:13 -0400" -->
<!-- isosent="20000919180913" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Fwd: Earthweb from transadmin" -->
<!-- id="39C7ABC9.95B2A061@pobox.com" -->
<!-- inreplyto="Pine.GSO.4.21.0009191206410.21639-100000@jane.itd.umich.edu" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Fwd:%20Earthweb%20from%20transadmin&In-Reply-To=&lt;39C7ABC9.95B2A061@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 19 2000 - 12:09:13 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5286.html">TriStateF@aol.com: "Re: Raising children, spouses, and friends"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5284.html">TriStateF@aol.com: "Re: Raising children, spouses, and friends"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5276.html">Alex Future Bokov: "Re: Fwd: Earthweb from transadmin"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5493.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5493.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5285">[ date ]</A>
<A HREF="index.html#5285">[ thread ]</A>
<A HREF="subject.html#5285">[ subject ]</A>
<A HREF="author.html#5285">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Alex Future Bokov wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Um, yes, that is the original debate, and the reason this thread has
</EM><BR>
<EM>&gt; EarthWeb in its name. To recap, Eli and I agree that the capabilities
</EM><BR>
<EM>&gt; of an AI as he envisions it would be a superset of the capabilities of
</EM><BR>
<EM>&gt; an EarthWeb like entity as I envision it. However, I'm arguing that an
</EM><BR>
<EM>&gt; EarthWeb is more easily acchievable, by definition friendly to human
</EM><BR>
<EM>&gt; goals, and possibly sufficient for preventing runaway techno-disaster.
</EM><BR>
<P>On the contrary; the Earthweb is only as friendly as it is smart.  I really
<BR>
don't see why the Earthweb would be benevolent.  Benevolent some of the time,
<BR>
yes, but all of the time?  The Earthweb is perfectly capable of making
<BR>
mistakes that are outright stupid, especially if it's an emotionally charged
<BR>
issue being considered for the first time.
<BR>
<P>I have no confidence in any decision-making process that uses humans as the
<BR>
sole intelligent components.  Period.  I know what goes into humans, and it
<BR>
isn't sugar and spice and everything nice.  I can have some confidence that a
<BR>
well-built Sysop is far too smart to make certain mistakes; I have no such
<BR>
confidence in humans.  Because we have no choice - because even inaction is
<BR>
still a decision - we must rely on human intelligence during the run-up to
<BR>
Singularity.  But I will not bet the planet on humans being able to
<BR>
intelligently wield the powers that become available beyond that point.
<BR>
<P>I shouldn't really be debating this.  You can't see, intuitively, that a
<BR>
superintelligence is solid and the Earthweb is air and shadow by comparision? 
<BR>
The Earthweb is pretty hot by human standards, but only by human standards. 
<BR>
It has no greater stability than the human species itself.  It may arguably be
<BR>
useful on the way to a solid attractor like the Sysop Scenario, but it can't
<BR>
possibly be anything more than a way-station.
<BR>
<P>An arguable argument would be that the Earthweb would be better capable of
<BR>
handling the run-up to a superintelligence scenario, perhaps by holding the
<BR>
planet together long enough to get genuine enhanced humans into play.  I think
<BR>
you'd still be wrong.  I think that realistically speaking, the construction
<BR>
of the first versions of the Earthweb would be followed by six billion people
<BR>
shouting their prejudices at top volume.  And yes, I've read _Earthweb_ and
<BR>
Robin Hanson's paper on idea futures and I still think so.
<BR>
<P>Collaborative filtering is actually much more powerful than the technologies
<BR>
depicted in _Earthweb_, and I think there's actually an excellent possibility
<BR>
that collaborative filtering will show up before the Singularity and maybe
<BR>
even play a major part in it.  But I'm not relying on collaborative filtering
<BR>
to swing public opinion in favor of the Singularity.  If it happens, great,
<BR>
but I can't rely on it.  At the end of the day, the memetic baggage of a
<BR>
planet just has too much inertia to be altered in such a short amount of
<BR>
time.  Back when I expected a Singularity in 2030, I was a lot more interested
<BR>
in Singularity memetics; as it is...
<BR>
<P>This isn't a game; we have to win as fast as possible, as simply as possible,
<BR>
and not be distracted by big complex strategies.  That's why I ditched the
<BR>
entire running-distributed-over-the-Internet plan and then ditched the
<BR>
open-source-AI-industry strategy; too many ways it could all go wrong.  The
<BR>
Earthweb scenario, if you try to visualize all the details, is even worse.
<BR>
<P><EM>&gt; Eliezer then pointed out that the decisions of EarthWeb would not be as
</EM><BR>
<EM>&gt; enforceable as those of an &gt;AI sysop. I don't understand the argument;
</EM><BR>
<EM>&gt; if humans/&gt;AI/some combination design nanotech, and then a general
</EM><BR>
<EM>&gt; purpose MatterOS to control it, why should enforcement of the operator's
</EM><BR>
<EM>&gt; will be any more problematic just because the will is the consensus of
</EM><BR>
<EM>&gt; human wills as represented by markets and reputations as opposed to being
</EM><BR>
<EM>&gt; the will of a single &gt;AI? Isn't the enforcement done by the MatterOS layer,
</EM><BR>
<EM>&gt; regardless of who is holding the reins?
</EM><BR>
<P>The MatterOS I visualize requires superintelligence; it is not literally an
<BR>
OS.  Furthermore, a MatterOS is too much power to be entrusted to any human or
<BR>
group of humans, even (or especially) an entire planetary group of humans -
<BR>
forget about power corrupting; even benevolent humans, including myself, are
<BR>
just not that smart.
<BR>
<P>Also, if the MatterOS isn't superintelligent, then as far as I can tell
<BR>
someone (e.g., me) writes a superintelligence and the superintelligence takes
<BR>
over.  Any MatterOS designed by beings without a codic cortex would
<BR>
undoubtedly be easy enough to break - we can't even get the real-world Java
<BR>
sandboxes right, and you want us to try it on a whole Solar System?  The first
<BR>
woodpecker that came along would wind up with root permissions.
<BR>
<P>--              --              --              --              -- 
<BR>
Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A> 
<BR>
Research Fellow, Singularity Institute for Artificial Intelligence
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5286.html">TriStateF@aol.com: "Re: Raising children, spouses, and friends"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5284.html">TriStateF@aol.com: "Re: Raising children, spouses, and friends"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5276.html">Alex Future Bokov: "Re: Fwd: Earthweb from transadmin"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5493.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5493.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5285">[ date ]</A>
<A HREF="index.html#5285">[ thread ]</A>
<A HREF="subject.html#5285">[ subject ]</A>
<A HREF="author.html#5285">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:31 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
