<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Mon Sep 25 16:54:56 2000" -->
<!-- isoreceived="20000925225456" -->
<!-- sent="Mon, 25 Sep 2000 15:56:32 -0700" -->
<!-- isosent="20000925225632" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39CFD820.8236F772@objectent.com" -->
<!-- inreplyto="00c301c02726$c9780360$9bbc473f@jrmolloy" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39CFD820.8236F772@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Sep 25 2000 - 16:56:32 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5745.html">J. R. Molloy: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5743.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5720.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5753.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5744">[ date ]</A>
<A HREF="index.html#5744">[ thread ]</A>
<A HREF="subject.html#5744">[ subject ]</A>
<A HREF="author.html#5744">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&quot;J. R. Molloy&quot; wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt; So, let us keep the masses ignorant heh?  Where have we heard that
</EM><BR>
<EM>&gt; &gt; before? So, we can get to the great and wondrous technological Advent if
</EM><BR>
<EM>&gt; &gt; only the unwashed never get wind of it?  This is a two-edged sword.
</EM><BR>
<EM>&gt; &gt; When the masses hear about it they will hear through voices of alarm and
</EM><BR>
<EM>&gt; &gt; most-likely uninformed voices calling for our heads and entrails as
</EM><BR>
<EM>&gt; &gt; traitors to all humanity.  Think about it.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; - samantha
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Thanks for the admonition. I think you've twisted the meaning of my comments. I
</EM><BR>
<EM>&gt; don't advocate keeping the masses ignorant. I simply don't want to waste any
</EM><BR>
<EM>&gt; more effort trying to convince the uneducated that Artificial Life is a
</EM><BR>
<EM>&gt; significant part of the emerging technological singularity (TS).
</EM><BR>
<EM>&gt; I don't know where you've heard any arguments in favor of keeping the masses
</EM><BR>
<EM>&gt; ignorant. Definitely not from me.
</EM><BR>
<EM>&gt; I've tried to tell many friends and acquaintances about the TS -- to no avail.
</EM><BR>
<EM>&gt; According to recent polls, nine out of ten Americans still believe in something
</EM><BR>
<EM>&gt; they call &quot;God&quot; so it doesn't make much sense to argue with them about the
</EM><BR>
<EM>&gt; advent of a genetically programmed superintelligence (a probable component of
</EM><BR>
<EM>&gt; the TS).
</EM><BR>
<P>I do get this.  And yet it still seems that even if we can't convince
<BR>
them its coming or get them to really understand what that means (though
<BR>
who knows?) if they are convinced, that we owe it to them to do our best
<BR>
to make sure they aren't run over and that they are actually benefitted
<BR>
(as a minimum).  
<BR>
<P><EM>&gt; 
</EM><BR>
<EM>&gt; When &quot;the masses&quot; hear about AI, SI, TS, etc. (as if they haven't already been
</EM><BR>
<EM>&gt; inundated with narratives about these topics in science fiction and television
</EM><BR>
<EM>&gt; scripts), in the context of real news reportage, I rather doubt that they will
</EM><BR>
<EM>&gt; call for &quot;heads and entrails.&quot; It seems more probable to me that they will react
</EM><BR>
<EM>&gt; as they did when news about the atom bomb was first broadcast (with pictures and
</EM><BR>
<EM>&gt; sound). They'll react with awe and fear and pride and superstition and a dozen
</EM><BR>
<EM>&gt; other emotions, and many will retreat further into their belief systems and
</EM><BR>
<EM>&gt; religiosity.
</EM><BR>
<EM>&gt; When first the world learns of the existence of viable Artificial Life (which
</EM><BR>
<EM>&gt; wants to be friendly, btw), it will matter not at all what they think about it.
</EM><BR>
<EM>&gt; What will matter is whether the thing itself is something awfully insane or
</EM><BR>
<EM>&gt; awfully enlightening.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Well, the extremes are both unlikely.  I would suspect it is somewhere
<BR>
in between, it will make its own mistakes.  But I find it very unlikely
<BR>
that the masses will not be manipulated against those &quot;selfish,
<BR>
egotistical scientists&quot; who let this thing loose in their midst.  
<BR>
&nbsp;
<BR>
<EM>&gt; When &quot;the masses&quot; heard about atomic energy, there were voices of alarm and
</EM><BR>
<EM>&gt; misinformation. Some called for the heads of the scientists who developed this
</EM><BR>
<EM>&gt; awesome power. Too late. The genie was out.
</EM><BR>
<EM>&gt; Presently, far more effort and expertise is being directed toward developing AI
</EM><BR>
<EM>&gt; than was ever engaged in developing atomic energy. All over the planet, dozens
</EM><BR>
<EM>&gt; of teams of computer scientists work day and night to be the first to build a
</EM><BR>
<EM>&gt; human level AI robot. Why? Because if it can be done, the thing will be worth
</EM><BR>
<EM>&gt; trillions and trillions of dollars. Imagine machines that can run factories and
</EM><BR>
<EM>&gt; hospitals as well as doing the markets (and of course, as Eliezer Yudkowsky
</EM><BR>
<EM>&gt; would be quick to point out, also building better AI robots). The stakes
</EM><BR>
<EM>&gt; involved in this project make other projects seem dull by comparison.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P><P>Sure.  But what of the humans who will be even more largely out of work
<BR>
and feel/be even more redundant?  How will you organize society so that
<BR>
these folks get taken care of so that they don't see this as a
<BR>
tremendous threat and possibly the end of their own means of survival?  
<BR>
<P><EM>&gt; What drives the search for AI is money, and money makes the world go 'round. So,
</EM><BR>
<EM>&gt; it really matters very little what anyone thinks about it.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>If that is and continues to be *all* that makes the world go 'round then
<BR>
we all end up on the trash-heap of history in the very short run.  A
<BR>
great motivation to do the R&amp;D isn't it?
<BR>
<P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5745.html">J. R. Molloy: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5743.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5720.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5753.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5744">[ date ]</A>
<A HREF="index.html#5744">[ thread ]</A>
<A HREF="subject.html#5744">[ subject ]</A>
<A HREF="author.html#5744">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:01 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
