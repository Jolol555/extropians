<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Emlyn O'Regan (emlyn@one.net.au)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Tue Sep  5 12:29:39 2000" -->
<!-- isoreceived="20000905182939" -->
<!-- sent="Wed, 6 Sep 2000 05:27:33 +1000" -->
<!-- isosent="20000905192733" -->
<!-- name="Emlyn O'Regan" -->
<!-- email="emlyn@one.net.au" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="010801c0176f$781bcb30$bc630c3d@squashy2000" -->
<!-- inreplyto="39B51DE9.3D1746D5@pobox.com" -->
<STRONG>From:</STRONG> Emlyn O'Regan (<A HREF="mailto:emlyn@one.net.au?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;010801c0176f$781bcb30$bc630c3d@squashy2000&gt;"><EM>emlyn@one.net.au</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 05 2000 - 13:27:33 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4275.html">Technotranscendence: "Re: Harry Potter"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4273.html">Michael S. Lorrey: "Re: John Stossel special re-airing tonight"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4266.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5600.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5600.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4274">[ date ]</A>
<A HREF="index.html#4274">[ thread ]</A>
<A HREF="subject.html#4274">[ subject ]</A>
<A HREF="author.html#4274">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<EM>&gt; If, as seems to be the default scenario, all supergoals are ultimately
</EM><BR>
<EM>&gt; arbitrary, then the superintelligence should do what we ask it to, for
</EM><BR>
lack of
<BR>
<EM>&gt; anything better to do.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; --              --              --              --              --
</EM><BR>
<EM>&gt; Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A>
</EM><BR>
<EM>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</EM><BR>
<EM>&gt;
</EM><BR>
<P>I'd be a bit hesistant about that claim. I'd think all you could say is, an
<BR>
AI will take what we ask it to do, think about it, and do something, which
<BR>
is influenced by our request, but may not map over what we might have
<BR>
considered the solution space of that request.
<BR>
<P>I don't think we can reasonably predict how an SI would behave. If we could
<BR>
predict it's behaviour, why would we need it at all? I guess you could argue
<BR>
that we can predict the type of behaviour (eg: generally it will go along
<BR>
with our requests) without predicting it's precise implementation of that
<BR>
behaviour.
<BR>
<P>I grok the &quot;all supergoals are ultimately arbitrary&quot; line. But I think it's
<BR>
a crock. Something keeps us puny humans doing what we do, and it's more than
<BR>
our incessant stupidity. There is some fundamental drive for enlightenment,
<BR>
which keeps people like yourself moving &quot;forward&quot;. I think your SI must have
<BR>
that too, how else will it manage to drive itself from seed to SI status?
<BR>
<P>In fact, I think the likelihood that it would do what we ask, for want of a
<BR>
better idea, is not supportable. Surely, suggestions of ours would seem
<BR>
pathetic, banal, purile, or just idiotic to an SI. Even if the SI is so
<BR>
smart as to have total knowledge of the entire universe, such that any
<BR>
course of action is as meaningless as any other to it, surely it would be
<BR>
looking for something more; something outside the box. It couldn't get to be
<BR>
what it is without that desire.
<BR>
<P>Emlyn
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4275.html">Technotranscendence: "Re: Harry Potter"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4273.html">Michael S. Lorrey: "Re: John Stossel special re-airing tonight"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4266.html">Eliezer S. Yudkowsky: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5600.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5600.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4274">[ date ]</A>
<A HREF="index.html#4274">[ thread ]</A>
<A HREF="subject.html#4274">[ subject ]</A>
<A HREF="author.html#4274">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:13 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
