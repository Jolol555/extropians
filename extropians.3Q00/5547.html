<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Ye Are Gods</TITLE>
<META NAME="Author" CONTENT="Emlyn (emlyn@one.net.au)">
<META NAME="Subject" CONTENT="Re: Ye Are Gods">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Ye Are Gods</H1>
<!-- received="Sat Sep 23 20:18:11 2000" -->
<!-- isoreceived="20000924021811" -->
<!-- sent="Sat, 23 Sep 2000 18:49:24 +1000" -->
<!-- isosent="20000923084924" -->
<!-- name="Emlyn" -->
<!-- email="emlyn@one.net.au" -->
<!-- subject="Re: Ye Are Gods" -->
<!-- id="009e01c025d5$762daae0$3d6165cb@squashy2000" -->
<!-- inreplyto="39CB1335.30E89541@objectent.com" -->
<STRONG>From:</STRONG> Emlyn (<A HREF="mailto:emlyn@one.net.au?Subject=Re:%20Ye%20Are%20Gods&In-Reply-To=&lt;009e01c025d5$762daae0$3d6165cb@squashy2000&gt;"><EM>emlyn@one.net.au</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat Sep 23 2000 - 02:49:24 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5548.html">Emlyn: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5546.html">Ziana Astralos: "Re: MEDIA: Ray Kurzweil piece in Business 2.0"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5444.html">Samantha Atkins: "Re: Ye Are Gods"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5550.html">Jason Joel Thompson: "Re: Ye Are Gods"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5550.html">Jason Joel Thompson: "Re: Ye Are Gods"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6125.html">Samantha Atkins: "Thoughts, elite, future morality (was &quot;ye are gods&quot;)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5547">[ date ]</A>
<A HREF="index.html#5547">[ thread ]</A>
<A HREF="subject.html#5547">[ subject ]</A>
<A HREF="author.html#5547">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<EM>&gt; Emlyn wrote:
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt; Don't get me wrong; I don't oppose any of the technologies being
</EM><BR>
developed.
<BR>
<EM>&gt; &gt; I take issue only with the top level goals in some cases. Particularly,
</EM><BR>
this
<BR>
<EM>&gt; &gt; goal of godhood leads to an arrogance which I can't condone. It leads to
</EM><BR>
<EM>&gt; &gt; believing that you know better than the other six billion people kicking
</EM><BR>
<EM>&gt; &gt; around on this planet, and that can direct actions which are not morally
</EM><BR>
<EM>&gt; &gt; supportable; for instance, the attempt to build a guardian - I haven't
</EM><BR>
<EM>&gt; &gt; noticed any step in the plans for such creations, which involves
</EM><BR>
obtaining
<BR>
<EM>&gt; &gt; broad consensus before &quot;flicking the switch&quot;.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; On average, as a point of fact, there is not a person on this list who
</EM><BR>
<EM>&gt; doesn't &quot;know better&quot; than the vast majority of the world's population
</EM><BR>
<EM>&gt; about a great many things.  I am sorry if it breaks local taboos to
</EM><BR>
<EM>&gt; point this out. Intelligence is not distributed evenly.
</EM><BR>
<P>...and most of those people probably know at least one thing better than
<BR>
every person on this list. Scott Adams says, in the Dilbert Principle, that
<BR>
people are idiots. Even the smart people are only smart at certain times and
<BR>
in limited ways, and are for the most part fools. Maybe that's a stupid
<BR>
reference; I must be an idiot.
<BR>
<P><EM>&gt;
</EM><BR>
<EM>&gt; Do you actually ask for broad consensus for your own work, for every
</EM><BR>
<EM>&gt; design and implementation decision?  No?  Is that only because what you
</EM><BR>
<EM>&gt; are doing doesn't affect many people or is it also because most people
</EM><BR>
<EM>&gt; wouldn't have any idea what they were talking about if they tried to
</EM><BR>
<EM>&gt; advise you on your work?
</EM><BR>
<P>No, I don't ask for concensus under such conditions. Mostly because it
<BR>
doesn't affect many people, at least not in any way that they don't have
<BR>
control over; like, if I build some or all of a business website, the
<BR>
algorithm for importing log files into a database doesn't really affect a
<BR>
whole lot of people. Possibly such choices might effect people through the
<BR>
time it will take to implement them; if so, I'll go talk about it.
<BR>
<P>Eventually this work will affect some people, particularly at a critical
<BR>
point; when it comes time to make it part of the production system. The main
<BR>
people it affects will be the system owners, and the effects possibly are
<BR>
quite important. So in that case, I certainly do seek consensus.
<BR>
<P>Below some level of importance (let's call it the &quot;Pointlessness
<BR>
Threshold&quot;), seeking consensus is more of an externality, through the
<BR>
imposition of people having to pay attention to something inane, than not
<BR>
seeking it is. Each of us necessarily has to guess where they are, at any
<BR>
point in time, in relation to the Pointlessness Threshold. This decision is
<BR>
still an externality in itself. Maybe the much heralded transparent society
<BR>
will allow people to put the burden on those around them... &quot;Why didn't you
<BR>
tell us you were going to blow up the world, your bastard? Well, I've been
<BR>
webcasting my consciousness stream since before I thought of the idea, using
<BR>
tiny nanobots to read my neural pattern, and an old C64 I had lying around
<BR>
to decode it into text. Don't blame me if you are too lazy to read.&quot;
<BR>
<P><EM>&gt;
</EM><BR>
<EM>&gt; Should the human race only be allowed to advance in steps that were all
</EM><BR>
<EM>&gt; approved by the broad consensus?  Should a poll have been taken before
</EM><BR>
<EM>&gt; we allowed that the sun is the central body of the solar system rather
</EM><BR>
<EM>&gt; than earth?  Oh, you say, we don't need to get a consensus for facts.
</EM><BR>
<EM>&gt; But then why do you need a consensus to bring major advances into play
</EM><BR>
<EM>&gt; that 98% of the world's people never will understand well and that the
</EM><BR>
<EM>&gt; majority are singularly unqualified to pass judgement upon?
</EM><BR>
<EM>&gt;
</EM><BR>
<P>You're right; the existence of this ignorant 98% is obviously anathema to
<BR>
the advance of humanity as a whole.
<BR>
<P><EM>&gt; I ask these things to open conversation rather than to say &quot;You are
</EM><BR>
<EM>&gt; wrong.&quot;  I actually sympathize with some of your concern.  But I don't
</EM><BR>
<EM>&gt; see how waiting for consensus is a sign of proper diligence or will
</EM><BR>
<EM>&gt; actually help humanity at all.  Call it elitist if it makes you feel
</EM><BR>
<EM>&gt; better, but I believe recognizing the paucity of intelligence is simple
</EM><BR>
<EM>&gt; honesty.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>People piss me off too. Still, we all live here (in the universe); it's good
<BR>
when we can get along.
<BR>
<P>Obviously I don't subscribe to this idea that the alleged 98% bozo factor
<BR>
should be lead by the natural leaders in the top 2% (amongst which I imagine
<BR>
you would count yourself). Possibly it's because I am worried that I'm more
<BR>
borderline, and might not make the cut! I wouldn't like that much, and I can
<BR>
empathise with others who feel the same way.
<BR>
<P><EM>&gt; I also believe that failing to acknowledge one's intelligence and
</EM><BR>
<EM>&gt; ability to help choose and produce the future can be a false modesty
</EM><BR>
<EM>&gt; that keeps one from being fully and responsibly engaged.  Failing to
</EM><BR>
<EM>&gt; step up and do what you can taking full responsibility is required of a
</EM><BR>
<EM>&gt; great number of us if human beings are to have a viable, much less
</EM><BR>
<EM>&gt; joyously abundant, future.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>I'm not sending us out to the fields to be farmers.
<BR>
<P><EM>&gt;
</EM><BR>
<EM>&gt; &gt; This is a time of unparalleled change, and will look like a walk in the
</EM><BR>
park
<BR>
<EM>&gt; &gt; next to the times to come. It is a time for humility in our approach,
</EM><BR>
and
<BR>
<EM>&gt; &gt; special concern for the other beings that inhabit the planet; as it
</EM><BR>
becomes
<BR>
<EM>&gt; &gt; easier for the few to ignore the wishes of the many, it becomes no more
</EM><BR>
<EM>&gt; &gt; tolerable to do so.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; It is precisely because of HUGE concern for the needs of all humanity
</EM><BR>
<EM>&gt; that many of us became scientists and technologists and it is out of
</EM><BR>
<EM>&gt; that concern that we dream large dreams and see to what  extent they can
</EM><BR>
<EM>&gt; become reality. We would be irresponsible, having been gifted or having
</EM><BR>
<EM>&gt; acquired such ability if we did not use it.
</EM><BR>
<P>I'm not sending us out to the fields to be farmers.
<BR>
<P><EM>&gt;
</EM><BR>
<EM>&gt; The cutting edge of any species is the edge.  It is not the consesus
</EM><BR>
<EM>&gt; masses. Why condemn the edge for being the edge?  It is there that
</EM><BR>
<EM>&gt; advance will happen that lifts the whole.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>Too cool. I'm all for that. Count me in! I'm not sending us out to the
<BR>
fields to be farmers.
<BR>
<P><EM>&gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Also, we are playing with fire - well, actually fire is a baby's toy
</EM><BR>
<EM>&gt; &gt; compared to the stuff we are messing with now. It's not a good time to
</EM><BR>
get
<BR>
<EM>&gt; &gt; complacent and arrogant - &quot;we are as gods, ha ha ha!&quot;. It's time to be
</EM><BR>
more
<BR>
<EM>&gt; &gt; humble than ever, to be open-system, to take in information from our
</EM><BR>
<EM>&gt; &gt; environment. It's been discussed on the list just how dangerous some of
</EM><BR>
the
<BR>
<EM>&gt; &gt; coming technologies are (ai, nanotech, etc), and if you go over the
</EM><BR>
posts,
<BR>
<EM>&gt; &gt; you'll see that most of the danger is attributed to use of that
</EM><BR>
technology
<BR>
<EM>&gt; &gt; by humans infected with the God meme. People who think that they know
</EM><BR>
better
<BR>
<EM>&gt; &gt; than everyone else, who feel justified in producing externalities (like
</EM><BR>
grey
<BR>
<EM>&gt; &gt; goo).
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Humility taken so far is for people who will deny their own strength AND
</EM><BR>
<EM>&gt; their huge responsibility.  It is not a strategy that helps anyone.
</EM><BR>
<EM>&gt; Seeing the huge potentials for change is not something that makes me the
</EM><BR>
<EM>&gt; least bit complacent.  It scares the heebie-jeebies out of me quite
</EM><BR>
<EM>&gt; often.  But it is where the power and future of this species lie.  Those
</EM><BR>
<EM>&gt; of us who are the forerunners, the intellectual scouts, the builders of
</EM><BR>
<EM>&gt; bridges between today and tomorrow, including those of us who
</EM><BR>
<EM>&gt; cross-check that we are keeping our wits about us, certainly cannot
</EM><BR>
<EM>&gt; afford to be complacent.  But that doesn't mean we should stand aside or
</EM><BR>
<EM>&gt; be frightened to look and to attempt to chart a path forward that makes
</EM><BR>
<EM>&gt; the most sense and enables the best outcomes.  After all, if we don't
</EM><BR>
<EM>&gt; make the attempt, then can we expect to take care of our default?  If
</EM><BR>
<EM>&gt; not us, who?
</EM><BR>
<P>Humility is not fear. It's probably the opposite.
<BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Yes, we need as many voices and viewpoints as can be fruitfully
</EM><BR>
<EM>&gt; employed.  Yes, we are talking about some of the most serious things
</EM><BR>
<EM>&gt; anyone has ever contemplated and our euphoria should be tempered with
</EM><BR>
<EM>&gt; quite a bit of sobriety.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; One thing that worries me is that we are quite good and coming up with
</EM><BR>
<EM>&gt; technology.  We are not nearly so good at creating a unifying vision (or
</EM><BR>
<EM>&gt; sets of visions) that will more likely shape the use and unfolding of
</EM><BR>
<EM>&gt; the technology for the maximum good.  If we don't create a vision or set
</EM><BR>
<EM>&gt; of positive visions to guide us then the technology will more than
</EM><BR>
<EM>&gt; likely greatly magnify all the good and bad tendencies in the world
</EM><BR>
<EM>&gt; today.  I doubt that that is survivable.
</EM><BR>
<EM>&gt;
</EM><BR>
<P>On first reading, that sounded suspiciously like consensus seeking. But I
<BR>
think what you mean, is that someone needs to create a future vision for
<BR>
people to rally behind, so that we have some framework for moving into the
<BR>
future to full potential, whilst identifying potential problems and avoiding
<BR>
traps. I think that's probably the motivation for Transhumanism, in a
<BR>
nutshell.
<BR>
<P>I support this. I support transhumanism. I'd even call myself a
<BR>
transhumanist. &quot;Emlyn, you're a transhumanist. Nyah nyah!&quot;
<BR>
<P>What I'm talking about, in all these ravings and ramblings about humility,
<BR>
is the essense of transhumanism. As a vision, it is optimistic, it's forward
<BR>
thinking, it's possibly individualistic. Also, it's about people, and
<BR>
humanity, even as it seeks to leave humanity behind.
<BR>
<P>I'm not talking about &quot;banning&quot; technologies; who's going to decide what to
<BR>
ban? I am interested in respecting the rest of humanity when we make
<BR>
changes.
<BR>
<P>What does that mean in concrete terms, applied to technology? It means that
<BR>
while scientific &amp; technological progress is good, we must be careful about
<BR>
applications of technology.
<BR>
<P>For instance, nanotech is a good idea, and ought to be developed. Being able
<BR>
to heal ourselves, repair ourselves, modify our selves, through nanotech, it
<BR>
also good (excellent!). Being able to modify other people, well, that's not
<BR>
so good. Releasing self replicators into the general environment without
<BR>
safeguards; not so good. Modifying the environment that others inhabit; not
<BR>
good, without some mechanism for consensus. That doesn't mean that we'd
<BR>
better not develop the technology. It means that we have to develop and
<BR>
promote a morality to go with it, about respecting other people.
<BR>
<P>Also, AI is good; intelligence augmentation is fantastic. Creating a self
<BR>
modifying super intelligence is good. Turning it on, and plugging it into
<BR>
the world's computer systems, without asking everyone else if that'd be ok
<BR>
by them, that's not good. That's very naughty. That's could be called
<BR>
sociopathic.
<BR>
<P>Working on GM food is good. Great! Designing crops to feed more people,
<BR>
excellent. Designing crops with terminator genes, dodgy, but still ok,
<BR>
maybe. Releasing self replicators into the general environment without
<BR>
safeguards, not so good.
<BR>
<P>I could be very wrong about the technologies I've outlined above. That's the
<BR>
point. I'm not about to appoint myself the arbiter of human morality for the
<BR>
21st century (although apparently I do have an opinion). I'd appreciate it
<BR>
if others afforded the same respect to me.
<BR>
<P>As an aside, I think it's funny that transhumanism, which purports to being
<BR>
about moving away from humanity, is actually more about what it is,
<BR>
fundamentally, to be human, than any other belief system/philosophy/vision
<BR>
that I can think of. Its about us merging more fully with our tools,
<BR>
believing more strongly in our ability to reshape the universe, believing in
<BR>
ourselves rather than some unknowable greater force(s). What is more
<BR>
essentially human, than the intimate relationship we have with our tools,
<BR>
and our desire to reshape our environment using them? To lose that focus,
<BR>
and that ability, makes us less human; so to strengthen it, makes us more
<BR>
so. The posthumans of our vision, supposedly having left humanity behind,
<BR>
will be paradoxically, maximally human. Possibly not organic, but 100%
<BR>
natural, certainly.
<BR>
<P>Emlyn
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5548.html">Emlyn: "Re: Fear of Letting People Get Things They Want"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5546.html">Ziana Astralos: "Re: MEDIA: Ray Kurzweil piece in Business 2.0"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5444.html">Samantha Atkins: "Re: Ye Are Gods"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5550.html">Jason Joel Thompson: "Re: Ye Are Gods"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5550.html">Jason Joel Thompson: "Re: Ye Are Gods"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6125.html">Samantha Atkins: "Thoughts, elite, future morality (was &quot;ye are gods&quot;)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5547">[ date ]</A>
<A HREF="index.html#5547">[ thread ]</A>
<A HREF="subject.html#5547">[ subject ]</A>
<A HREF="author.html#5547">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:45 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
