<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: AI-State-Of-The-Art</TITLE>
<META NAME="Author" CONTENT="Franklin Wayne Poley (culturex@vcn.bc.ca)">
<META NAME="Subject" CONTENT="AI-State-Of-The-Art">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>AI-State-Of-The-Art</H1>
<!-- received="Wed Sep  6 17:11:50 2000" -->
<!-- isoreceived="20000906231150" -->
<!-- sent="Wed, 6 Sep 2000 16:13:43 -0700 (PDT)" -->
<!-- isosent="20000906231343" -->
<!-- name="Franklin Wayne Poley" -->
<!-- email="culturex@vcn.bc.ca" -->
<!-- subject="AI-State-Of-The-Art" -->
<!-- id="Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca" -->
<STRONG>From:</STRONG> Franklin Wayne Poley (<A HREF="mailto:culturex@vcn.bc.ca?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;"><EM>culturex@vcn.bc.ca</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 06 2000 - 17:13:43 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4429.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4427.html">Alex Future Bokov: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4428">[ date ]</A>
<A HREF="index.html#4428">[ thread ]</A>
<A HREF="subject.html#4428">[ subject ]</A>
<A HREF="author.html#4428">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
What I am trying to determine in this dialogue with Professor Minsky is
<BR>
the extent to which a profile of real, human intelligence can be matched
<BR>
by artificial, humanoid intelligence. Do we have the knowledge of how to
<BR>
do so now? Is it 'just' a matter of applying more labor and money to the
<BR>
knowledge we have or do we need to invent some new technologies? If we
<BR>
need to invent new technologies, what are they? Can anyone answer these
<BR>
questions?
<BR>
FWP
<BR>
<P>---------- Forwarded message ----------
<BR>
Date: Tue, 5 Sep 2000 17:01:48 -0700 (PDT)
<BR>
From: Franklin Wayne Poley &lt;<A HREF="mailto:fwpoley@vcn.bc.ca?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">fwpoley@vcn.bc.ca</A>&gt;
<BR>
Reply-To: <A HREF="mailto:EDTV-Robotics-State-Of-The-Art@egroups.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">EDTV-Robotics-State-Of-The-Art@egroups.com</A>
<BR>
To: <A HREF="mailto:EDTV-Robotics-State-Of-The-Art@egroups.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">EDTV-Robotics-State-Of-The-Art@egroups.com</A>
<BR>
Cc: <A HREF="mailto:minsky@media.mit.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">minsky@media.mit.edu</A>, <A HREF="mailto:brooks@ai.mit.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">brooks@ai.mit.edu</A>, <A HREF="mailto:kw@cyber.reading.ac.uk?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">kw@cyber.reading.ac.uk</A>,
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="mailto:hans.moravec@rover.ri.cmu.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">hans.moravec@rover.ri.cmu.edu</A>, <A HREF="mailto:raymond@kurzweiltech.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">raymond@kurzweiltech.com</A>,
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="mailto:conventions@mures.com.au?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">conventions@mures.com.au</A>, <A HREF="mailto:jfe@helpmate.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">jfe@helpmate.com</A>, <A HREF="mailto:don@jnd.org?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">don@jnd.org</A>,
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="mailto:elubofsk@cognex.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">elubofsk@cognex.com</A>, <A HREF="mailto:humanoids@usc.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">humanoids@usc.edu</A>
<BR>
Subject: [EDTV-Robotics-State-Of-The-Art] Real Human Mental Ability vs.
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;Artificial Humanoid Mental Ability: Profiles and the &quot;Human Equivalency&quot;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;Question
<BR>
<P>On Sun, 3 Sep 2000, Franklin Wayne Poley wrote:
<BR>
<P><EM>&gt; &gt; Date: Tue, 29 Aug 2000 21:46:22 -0400
</EM><BR>
<EM>&gt; &gt; From: Marvin Minsky &lt;<A HREF="mailto:minsky@media.mit.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">minsky@media.mit.edu</A>&gt;
</EM><BR>
<EM>&gt; &gt; To: Franklin Wayne Poley &lt;<A HREF="mailto:fwp@vcn.bc.ca?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">fwp@vcn.bc.ca</A>&gt;,
</EM><BR>
<EM>&gt; &gt;      <A HREF="mailto:EDTV-Robotics-State-Of-The-Art@egroups.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">EDTV-Robotics-State-Of-The-Art@egroups.com</A>, <A HREF="mailto:brooks@ai.mit.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">brooks@ai.mit.edu</A>,
</EM><BR>
<EM>&gt; &gt;      <A HREF="mailto:kw@cyber.reading.ac.uk?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">kw@cyber.reading.ac.uk</A>, <A HREF="mailto:hans.moravec@rover.ri.cmu.edu?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">hans.moravec@rover.ri.cmu.edu</A>,
</EM><BR>
<EM>&gt; &gt;      <A HREF="mailto:raymond@kurzweiltech.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">raymond@kurzweiltech.com</A>, <A HREF="mailto:conventions@mures.com.au?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">conventions@mures.com.au</A>, <A HREF="mailto:jfe@helpmate.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">jfe@helpmate.com</A>,
</EM><BR>
<EM>&gt; &gt;      <A HREF="mailto:don@jnd.org?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">don@jnd.org</A>
</EM><BR>
<EM>&gt; &gt; Subject: Re: Can HomeMate Surpass Human Equivalency in Measured
</EM><BR>
<EM>&gt; &gt;     Intelligence?
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; Franklin,
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; &gt;&quot;The only barrier today to a useful humanoid robot is money. We have
</EM><BR>
<EM>&gt; &gt; the
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; &gt;sensory perception, we have voice recognition and voice synthesis; we
</EM><BR>
<EM>&gt; &gt; have
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; &gt;sufficient computer power. We have all the tools.&quot; (p. 88).
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; Engelberger is flimflamming here. We have only some limited,
</EM><BR>
<EM>&gt; &gt; superficial, input-output systems, but vitually none of the reasoning
</EM><BR>
<EM>&gt; &gt; tools that are typical of a five-year-old.
</EM><BR>
<P>Real human intelligence is simulated by artificial humanoid intelligence.
<BR>
Those 19 factors of primary mental ability referred to below give us a
<BR>
pretty good estimate of 'g', general intelligence, along with some useful
<BR>
details. If anyone wants to study a practical application of this they can
<BR>
get a test kit for Cattell's CAB (Comprehensive Abilities Battery) which I
<BR>
have used in clinical practice. The factors are a composite of abilities
<BR>
so my &quot;common sense&quot; taxonomy of Visualization, Reasoning, Memory and
<BR>
Verbal is largely to facilitate inter-disciplinary communication.
<BR>
&nbsp;&nbsp;&nbsp;Perhaps AI cannot simulate the reasoning tools of a five-year-old
<BR>
because we are looking for a simulation of reasoning which is too
<BR>
&quot;esoteric&quot;. In other words we are bringing &quot;mentalism&quot; back into
<BR>
psychology which is what Watson's 1913 Psych Review paper tried to
<BR>
eliminate. I think Watson's position is valid for practical purposes like
<BR>
studying real human intelligence and artificial humanoid intelligence.
<BR>
&nbsp;&nbsp;&nbsp;Four of the 19 factors are readily categorized as Reasoning
<BR>
factors: Numerical Facility (N); Deduction (D); Induction (I); General
<BR>
Reasoning (R). My question (and it is a question) has to do with whether
<BR>
all of the field of arithmetic/logic/mathematics can be programmed
<BR>
(assuming enough worker hours for such a mega-project and a sufficiently
<BR>
powerful computer). Can anyone select any exercise in
<BR>
arithmetic/logic/mathematics, put it on the internet and say, &quot;Here is an
<BR>
exercise which cannot be programmed?&quot; 
<BR>
<P>(a) yes
<BR>
(b) no
<BR>
<P>(c) is for esoterics. Here one can say, &quot;Yes but....&quot;. The but part is for
<BR>
&quot;but this is just rote; it is not real reasoning&quot;. No it's not real human
<BR>
reasoning. It is artificial humanoid reasoning. Machines don't do their
<BR>
reasoning operations the same way as humans. Why should they? Moreover, is
<BR>
real human reasoning all that superior? I use very rote/mechanical methods
<BR>
when I am solving Factor N tasks. I do the same if I am solving a Factor I
<BR>
problem, eg &quot;What comes next in the series: 1 3 5 7 9 _ ?&quot; It becomes a
<BR>
moot point as to whether I am REALLY thinking with my &quot;real human
<BR>
intelligence&quot; but the machine is not with its &quot;artificial humanoid
<BR>
intelligence&quot;.
<BR>
&nbsp;&nbsp;&nbsp;So it comes back to the basic question as to whether anyone can give a
<BR>
specific example in arithmetic/logic/mathematics in which the artificial
<BR>
humanoid intelligence cannot simulate real human intelligence sufficiently
<BR>
well (like an arithmetic program) to meet &quot;human equivalency&quot; criteria.
<BR>
Some additional comments on the 6 &quot;Visualization&quot; factors below.
<BR>
<P><EM>&gt; Professor Minsky:
</EM><BR>
<EM>&gt;                   Mr. Engelberger's position is that robotics is not the
</EM><BR>
<EM>&gt; same field as AI and that he is able to say authoritatively as an expert
</EM><BR>
<EM>&gt; (indeed one of the 'founding fathers', with Devol, of modern
</EM><BR>
<EM>&gt; robotics) that robots can now do more than one would expect. However, he
</EM><BR>
<EM>&gt; has cautioned me in another email which I will get to later, re
</EM><BR>
<EM>&gt; overstating &quot;human equivalency&quot;. Those words of caution are being heeded
</EM><BR>
<EM>&gt; and I apologize if I gave the impression that he had put human equivalency
</EM><BR>
<EM>&gt; forward as his position. &quot;Human equivalency&quot; is an apt phrase coined by
</EM><BR>
<EM>&gt; Professor Moravec and I am using it for the Robotics-State-Of-The-Art
</EM><BR>
<EM>&gt; program as an interesting, publicly-appealing and unifying thread to tie
</EM><BR>
<EM>&gt; the whole program together (exectedly 1-2 hours). I am not pushing it as a
</EM><BR>
<EM>&gt; matter of what the state-of-the-art is, unless the facts (as revealed by
</EM><BR>
<EM>&gt; experts in interviews with Mr. Ingram) reveal otherwise. Thus it is the
</EM><BR>
<EM>&gt; FACTS which I must ascertain in order to prepare a script which lives up
</EM><BR>
<EM>&gt; to the name for this program. That is the purpose of this EDTV- list.
</EM><BR>
<EM>&gt;    I thank you for the examples you have given below. Those are exactly
</EM><BR>
<EM>&gt; the kinds of issues which the program must address, one by one. Let me
</EM><BR>
<EM>&gt; preface my comments on them by saying the obvious which is that indeed AI
</EM><BR>
<EM>&gt; is not robotics and robotics is not nanotechnology and none of the above
</EM><BR>
<EM>&gt; are alife. So there is a great broadening and deepening of the field.
</EM><BR>
<EM>&gt; By analogy I wonder how long it was before William James, the 'founding
</EM><BR>
<EM>&gt; father' of American psychology was unable to claim expertise on all
</EM><BR>
<EM>&gt; branches of scientific psychology? If he were living today, he couldn't
</EM><BR>
<EM>&gt; even come close. 
</EM><BR>
<EM>&gt;    It is quite an honour for me to be able to correspond with both the
</EM><BR>
<EM>&gt; founding father of robotics and the founding father of AI (yourself and
</EM><BR>
<EM>&gt; John McCarthy) at the same time. I hope we can come to an agreement with
</EM><BR>
<EM>&gt; the Ingram Studio so that both of you will be interviewees. I'd like to
</EM><BR>
<EM>&gt; focus here on human equivalency of the RESULTING PRODUCTS OF AI only. What
</EM><BR>
<EM>&gt; are the FACTS? To explain &quot;resulting products&quot; let me refer to pages 41-43
</EM><BR>
<EM>&gt; of my &quot;Individual Differences&quot; text (Gardner Press, 1976). I list 19
</EM><BR>
<EM>&gt; primary mental abilities from factor analytic studies going back to
</EM><BR>
<EM>&gt; Thurstone. I give brief descriptions of the factors and sample test items.
</EM><BR>
<EM>&gt; Cattell and colleagues figure most prominently in carrying forward this
</EM><BR>
<EM>&gt; work on intelligence testing and multi-factor studies from Spearman to
</EM><BR>
<EM>&gt; Thurstone to  Cattell to the next generation like Professor Hakstian at
</EM><BR>
<EM>&gt; UBC and now his students are the current generation. So here we have five
</EM><BR>
<EM>&gt; generations of people who have dedicated their life-time careers to real,
</EM><BR>
<EM>&gt; human intelligence. I say that because by this time it is as unlikely that
</EM><BR>
<EM>&gt; a significant new factor or even test item will be discovered as that a
</EM><BR>
<EM>&gt; new element will be discovered in chemistry. 
</EM><BR>
<EM>&gt;    Thus those 19 factors cover 90% + of what you would want to deal
</EM><BR>
<EM>&gt; with in measuring G, general intelligence. Now here is the important part
</EM><BR>
<EM>&gt; for Robotics-State-Of-The-Art.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; DO THE RESULTS OR PRODUCTS OF THESE TESTS MEET HUMAN EQUIVALENCY CRITERIA
</EM><BR>
<EM>&gt; WHEN SIMULATED BY AI ?  
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; The best example to give first is Factor N (Number Facility) on page 42.
</EM><BR>
<EM>&gt; This is arithmetic ability. Can't calculators meet the criterion of human
</EM><BR>
<EM>&gt; equivalency in arithmetic ability? They can certainly surpass my
</EM><BR>
<EM>&gt; arithmetic ability.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Moreover, it looks to me like the other 18 factors can be simulated as
</EM><BR>
<EM>&gt; well, when it comes to arriving at a result or product as we did with
</EM><BR>
<EM>&gt; Factor N. Does that not mean that AI has achieved human equivalency when
</EM><BR>
<EM>&gt; it is defined this way?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;  There still is no computer
</EM><BR>
<EM>&gt; &gt; vision system that you could put into an unprepared room and have it
</EM><BR>
<EM>&gt; &gt; recognize books, tables, chails, lamps, cups, and things like that.
</EM><BR>
<EM>&gt; &gt; 'perception' is not enough to be useful.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I have cc'd the Cognex Company which identifies itself on its web site as
</EM><BR>
<EM>&gt; the world leader in machine vision. &quot;Visualization&quot; is an important
</EM><BR>
<EM>&gt; aspect of the 19 factors (along with Verbalization, Memory and Reasoning
</EM><BR>
<EM>&gt; as 'common sense' dimensions). E.R. Davies writes in his 1997 Machine
</EM><BR>
<EM>&gt; Vision text &quot;...there is an important guiding principal: if the eye can do
</EM><BR>
<EM>&gt; it, so can the machine....&quot; (p.14). In what SPECIFIC ways can machine
</EM><BR>
<EM>&gt; vision meet the human equivalency criterion? The East London Burrough of
</EM><BR>
<EM>&gt; Newham uses surveillance cameras to automatically identify known criminals
</EM><BR>
<EM>&gt; on the street. See &lt;<A HREF="http://www.faceit.com">http://www.faceit.com</A>&gt; and Raymond Kurzweil writes in
</EM><BR>
<EM>&gt; his 1999 book, that face recognition technology is &quot;...evidently reliable
</EM><BR>
<EM>&gt; enough that the banks are willing to have users walk away with real
</EM><BR>
<EM>&gt; cash.&quot; (p. 77). If www.faceit software can identify a face in a crowd can
</EM><BR>
<EM>&gt; it not be modified to identify a book on a table? There may be some reason
</EM><BR>
<EM>&gt; it cannot do so and that is why I ask. If we go to
</EM><BR>
<EM>&gt; &lt;<A HREF="http://www.braintech.com">http://www.braintech.com</A>&gt; we find that the &quot;object recognition system&quot; as
</EM><BR>
<EM>&gt; Braintech calls it is sufficiently well developed to handle the &quot;binning
</EM><BR>
<EM>&gt; and sorting process with multiple objects&quot;. Can it not pick a cup out of a
</EM><BR>
<EM>&gt; bin of mixed objects? So the broader question of perception/visualization
</EM><BR>
<EM>&gt; makes me wonder what specific examples of tasks are beyond present machine
</EM><BR>
<EM>&gt; capabilities. Perhaps the examples above (book, cup etc.) entail some
</EM><BR>
<EM>&gt; unsolvable features but I don't know that for a fact yet and I am hoping
</EM><BR>
<EM>&gt; Mr. Lubofsky at Cognex can inform us of exactly where the
</EM><BR>
<EM>&gt; machine/software capabilities fall short of human equivalency. 
</EM><BR>
<EM>&gt;    Quite a lot of machine vision software is now coming onto the market.
</EM><BR>
<EM>&gt; The Davies quote above sums up the overall question and it is another way
</EM><BR>
<EM>&gt; of saying &quot;human equivalency&quot;. But it is a question, not a firm
</EM><BR>
<EM>&gt; declaration. The Omron Company at &lt;<A HREF="http://www.qub.ac.uk/ivs">http://www.qub.ac.uk/ivs</A>&gt; lists its
</EM><BR>
<EM>&gt; F400 system which has &quot;hue, saturation and intensity-based color
</EM><BR>
<EM>&gt; detection.&quot; I have to ask how well this system compares to human detection
</EM><BR>
<EM>&gt; of hue, saturation and intensity? Moreover, if it falls short, what could
</EM><BR>
<EM>&gt; be done with more money for a better system?  The F400 system has
</EM><BR>
<EM>&gt; &quot;position compensation (which) detects objects regardless of
</EM><BR>
<EM>&gt; orientation&quot;. How well can it detect those objects in a room above? 
</EM><BR>
<EM>&gt;     In testing human mental abilities, a number of visualization tasks
</EM><BR>
<EM>&gt; entail visualizing objects from different perspectives. Like other mental
</EM><BR>
<EM>&gt; abilities one can readily see &quot;real world applications&quot; though mental
</EM><BR>
<EM>&gt; measurements people are quick to point out that the initial idea of
</EM><BR>
<EM>&gt; finding particular profiles of primary mental abilities which would match
</EM><BR>
<EM>&gt; to specific vocations was long ago shown to have little validity. However,
</EM><BR>
<EM>&gt; I used to work with surveyors and make maps in a mine so I am quite aware
</EM><BR>
<EM>&gt; of the parallel between test items here and real world problems. If a
</EM><BR>
<EM>&gt; miner for example could look at a map from one perspective, then quickly
</EM><BR>
<EM>&gt; and accurately visualize the shafts and stopes and drifts (excavated
</EM><BR>
<EM>&gt; regions) from another perspective, we would recognize that as a sign of
</EM><BR>
<EM>&gt; intelligence. I have to expect that a computer program could do this much
</EM><BR>
<EM>&gt; better than a human. If there is any doubt we could ask Dr. Baiden from
</EM><BR>
<EM>&gt; Inco with whom we corresponded earlier. I think he will be an interviewee
</EM><BR>
<EM>&gt; (subject to final approval by Inco). 
</EM><BR>
<EM>&gt;    And what about depth perception? That policeman's radar tells me that a
</EM><BR>
<EM>&gt; machine has better depth perception than a human (as well as speed
</EM><BR>
<EM>&gt; estimation if one wants to call that a Visualization ability). What else
</EM><BR>
<EM>&gt; can we say about the comparisons here? In what ways can machines measure
</EM><BR>
<EM>&gt; depth better than humans and in what ways are they inferior? Again, is
</EM><BR>
<EM>&gt; there any shortcoming of machine depth perception which more money cannot
</EM><BR>
<EM>&gt; remedy?
</EM><BR>
<EM>&gt;    Machine Visualization is obviously better than human when it comes to
</EM><BR>
<EM>&gt; detecting light at very low intensities and very high
</EM><BR>
<EM>&gt; intensities. Machines can detect outside the human spectrum (eg infrared
</EM><BR>
<EM>&gt; and ultraviolet).
</EM><BR>
<EM>&gt;    Thus we can carefully put together a profile of Human vs. Humanoid with
</EM><BR>
<EM>&gt; respect to the primary factors of mental ability related to Visualization.
</EM><BR>
<EM>&gt; If we can work this out then I would like to go on to the other problem
</EM><BR>
<EM>&gt; situations presented in your posting, Professor Minsky. And we will look
</EM><BR>
<EM>&gt; at factors in the areas of Reasoning, Verbalization and
</EM><BR>
<EM>&gt; Memory. Immediately we know that machines surpass human equivalency in
</EM><BR>
<EM>&gt; a number of ways. So we need to also know: (1) For what reasons, exactly,
</EM><BR>
<EM>&gt; do they fall short at present? (2) Do we have the know-how, subject to
</EM><BR>
<EM>&gt; large infusions of money, to bring them up to human equivalency?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Thank you again for your help on this matter.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Sincerely-FWP  
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; <A HREF="http://users.uniserve.com/~culturex/Machine-Psychology.htm">http://users.uniserve.com/~culturex/Machine-Psychology.htm</A>
</EM><BR>
<P>&nbsp;&nbsp;&nbsp;Visualization factors among the 19 primary mental abilities are: P,
<BR>
Perceptual Speed; Vi, Spatial Visualization; S, Spatial Relations, SO,
<BR>
Spatial Orientation; Cs, Speed of Closure; Cf, Flexibility of Closure.
<BR>
If we can meet human equivalency for these 6 factors plus the 4 Reasoning
<BR>
factors we have 10 of the 19 taken care of. The mental abilities profile
<BR>
of human vs. humanoid is getting interesting.
<BR>
<P>&nbsp;&nbsp;&nbsp;A key to this is having the best interviewee possible on OBJECT
<BR>
RECOGNITION SOFTWARE.
<BR>
<P>Is it now possible to write software so that any object can be recognized
<BR>
with a cluttered background?
<BR>
<P>Can the cup and book above be recognized regardless of how cluttered the
<BR>
field is around them?  
<BR>
<P>Next question: Is there any way in which a machine cannot detect the
<BR>
distance of an object as well as a human or better? (artificial humanoid
<BR>
depth perception vs. real human depth perception).
<BR>
<P>Next question: Can machines detect as many pixels/unit of area as a
<BR>
human? (another measure of human equivalency).
<BR>
<P>FWP
<BR>
<P><P>To unsubscribe from this group, send an email to:
<BR>
<A HREF="mailto:EDTV-Robotics-State-Of-The-Art-unsubscribe@egroups.com?Subject=Re:%20AI-State-Of-The-Art&In-Reply-To=&lt;Pine.GSO.4.21.0009061604220.12489-100000@vcn.bc.ca&gt;">EDTV-Robotics-State-Of-The-Art-unsubscribe@egroups.com</A>
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4429.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4427.html">Alex Future Bokov: "Re: META: Why I'm boycotting Extropy(TM)."</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4428">[ date ]</A>
<A HREF="index.html#4428">[ thread ]</A>
<A HREF="subject.html#4428">[ subject ]</A>
<A HREF="author.html#4428">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:23 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
