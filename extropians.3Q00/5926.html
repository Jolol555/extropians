<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Robots, but philosophers (or, Hal-2001)</TITLE>
<META NAME="Author" CONTENT="Franklin Wayne Poley (culturex@vcn.bc.ca)">
<META NAME="Subject" CONTENT="Re: Robots, but philosophers (or, Hal-2001)">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Robots, but philosophers (or, Hal-2001)</H1>
<!-- received="Wed Sep 27 15:53:16 2000" -->
<!-- isoreceived="20000927215316" -->
<!-- sent="Wed, 27 Sep 2000 14:53:30 -0700 (PDT)" -->
<!-- isosent="20000927215330" -->
<!-- name="Franklin Wayne Poley" -->
<!-- email="culturex@vcn.bc.ca" -->
<!-- subject="Re: Robots, but philosophers (or, Hal-2001)" -->
<!-- id="Pine.GSO.4.21.0009271352380.20746-100000@vcn.bc.ca" -->
<!-- inreplyto="39D1B496.A6BEC7AD@objectent.com" -->
<STRONG>From:</STRONG> Franklin Wayne Poley (<A HREF="mailto:culturex@vcn.bc.ca?Subject=Re:%20Robots,%20but%20philosophers%20(or,%20Hal-2001)&In-Reply-To=&lt;Pine.GSO.4.21.0009271352380.20746-100000@vcn.bc.ca&gt;"><EM>culturex@vcn.bc.ca</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 27 2000 - 15:53:30 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5927.html">Edward Case: "Re: extropians-digest V5 #267"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5925.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5956.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5956.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5926">[ date ]</A>
<A HREF="index.html#5926">[ thread ]</A>
<A HREF="subject.html#5926">[ subject ]</A>
<A HREF="author.html#5926">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
On Wed, 27 Sep 2000, Samantha Atkins wrote:
<BR>
<P><EM>&gt; Franklin Wayne Poley wrote:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt; How about 2001, Hal? Could it be that by 2001, someone somewhere will
</EM><BR>
<EM>&gt; &gt; already have AI machinery to surpass human equivalency? 
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Not on this planet.  Maybe you want to call on Ashtar High Command or
</EM><BR>
<EM>&gt; some such. :-)  They've been feeding us all of this tech anyway, don't
</EM><BR>
<EM>&gt; ya know?  
</EM><BR>
<P>How about the &quot;Andromeda Strain&quot;, some little AI seed that will grow by
<BR>
genetic algorithms until it knows all?
<BR>
<P><EM>&gt; &gt;    In summary, here is the argument that AI now is at a stage comparable
</EM><BR>
<EM>&gt; &gt; to the man-on-the-moon program from a 1960 perspective. In other words, we
</EM><BR>
<EM>&gt; &gt; mostly need quantitative extensions of what we know now and the
</EM><BR>
<EM>&gt; &gt; qualititative aspect of this project is not overwhelming. That is, we can
</EM><BR>
<EM>&gt; &gt; now see the areas which require innovation or invention and we can
</EM><BR>
<EM>&gt; &gt; reasonably assume that the breakthroughs will be made. The sheer magnitude
</EM><BR>
<EM>&gt; &gt; of the project should not be a deterrent. If we know how to reach the
</EM><BR>
<EM>&gt; &gt; objective and it is worth while to do so, so what if it costs hundreds of
</EM><BR>
<EM>&gt; &gt; billions?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Qualitative is not overwhelming?
</EM><BR>
<P>I listed 4 particular areas. The fact that significant progress has been
<BR>
made in all 4 seems hopeful to me. For example, a computer programmer from
<BR>
Australia sent me 390 k. on a program for grade one reading (if anyone
<BR>
wants it just let me know off-list). I'm not even sure there is a
<BR>
qualitative problem to be overcome here. Can you give an example of a
<BR>
passage of grade one reading for which we can't program questions with
<BR>
correct answers? If not, the programmers go on to grade two and so on.
<BR>
What are the inventions required in the other 3 areas I mentioned? 
<BR>
<P>&nbsp;&nbsp;This has to be a joke.  We have no
<BR>
<EM>&gt; idea what qualia even are among other &quot;qualitative&quot; problems of reaching
</EM><BR>
<EM>&gt; human level intelligence.
</EM><BR>
<P>I think the specialists working in these areas will be able to give a very
<BR>
clear statement on what they need to progress. For example, if it is a
<BR>
problem which has to do with edge detection for object
<BR>
recognition/itemization they will be able to say so. That is what the
<BR>
proposed EDTV-Robotics-State-Of-The-Art program needs to know. I'm not
<BR>
interested in writing the script for another &quot;golly gosh&quot; ed tv program to
<BR>
&quot;wow&quot; the public and provide a little education at the same time. I need
<BR>
these precise statements of what if needed to progess, eg huge amounts of
<BR>
additional labor using known technology or inventions of something new.
<BR>
<P>&nbsp;&nbsp;We have relatively poor grasp of even higher
<BR>
<EM>&gt; level issues like concept formation and usage. 
</EM><BR>
<P>And I can list these esoteric and mentalist notions until the cows come
<BR>
home. How about consciousness, common sense, comphrehension,
<BR>
contemplation....? Watson's 1913 ms. in Psych Review exorcised mentalism
<BR>
from scientific psychology. My own personal philosophy is dualistic so I
<BR>
don't take the &quot;strong behaviourist&quot; position but I use it for practical
<BR>
purposes. For a generation before Binet's very practical approach to
<BR>
intelligence testing in 1905, psychologists spent enormous amounts of time
<BR>
with this mentalistic navel gazing. They got nowhere. 
<BR>
&nbsp;&nbsp;&nbsp;I don't mean to be harsh because I think a number of disciplines are
<BR>
required to solve the problems presented in AI, but I wonder how many AI
<BR>
workers have ever studied the history of trying to measure/observe/define
<BR>
real human intelligence, let alone ever given an IQ test? What I see is a
<BR>
lot of people treading the same ground with artificial humanoid
<BR>
intelligence that philosophers-psychologists-educators-physicians had trod
<BR>
with real human intelligence before practical, operational psychometrics
<BR>
came along. And it is expected they would do so. After all aren't they
<BR>
trying to simulate real human intelligence? 
<BR>
<P>&nbsp;Lots of theory, no
<BR>
<EM>&gt; satisfying fully general and full powered learning programs.  No model
</EM><BR>
<EM>&gt; we are even happy about for describing what humans do with
</EM><BR>
<EM>&gt; percept-concept-more abstract concept chains.
</EM><BR>
<P>Just give one example of such a chain which cannot be
<BR>
verbalized. Skinner's dictum was &quot;If it can be verbalized it can be
<BR>
programmed&quot;. Now I think he meant programming in a more general sense but
<BR>
it applies pretty well to computer programming. If we can verbalize the
<BR>
rules for human conversation I think it is likely someone can write the
<BR>
program for it. If we can verbalize a set of rules for
<BR>
reading-questions-answers we can likely write a program for those rules.
<BR>
&nbsp;&nbsp;&nbsp;With words like &quot;abstract&quot; and &quot;concept&quot; we're back to the old
<BR>
mentalism problem again. Peoples' eyes glaze over. They throw up their
<BR>
hands and say, &quot;We don't know what it is. How can we ever write a program
<BR>
for it?&quot;  Instead of waiting for the High Priests of Esoterics to tell
<BR>
them, psychologists a long time ago decided to turn this over to
<BR>
pragmatics. What they said was, &quot;If you can describe a situation which
<BR>
purports to express intelligence, tell us. Then we will refine that
<BR>
situation and turn it into a standardized test. If you don't have a
<BR>
describable, observable situation, then go away until you do.&quot; 
<BR>
&nbsp;&nbsp;&nbsp;As a result of that those involved in mental measurements are now
<BR>
standing on pretty solid ground. It is as unlikely that a testable
<BR>
situation of importance is going to be added to the pool as an element
<BR>
will be added to the periodic table of the chemists. I don't deny that
<BR>
there may well be a reality to something like &quot;consciousness&quot; and
<BR>
thousands of other esoteric/mentalist notions. But almost all of
<BR>
scientific psychology will agree with me that we don't want to be held
<BR>
ransom by the witch doctors of esoterics. 
<BR>
<P>&nbsp;&nbsp;Without this you will not
<BR>
<EM>&gt; get there.  Or is there something already done I am unaware of?  Any
</EM><BR>
<EM>&gt; pointers appreciated.
</EM><BR>
<P>The pointers are as above. Also I explained that those 19 primary mental
<BR>
abilities are based on the work of over a century of hard working and
<BR>
smart people (counting the time spent in introspection labs which went
<BR>
nowhere). What I've said is that if you want to simulate real human
<BR>
intelligence with artificial humanoid intelligence this has to be a good
<BR>
model to work with. Doesn't that make sense? If not, why not?
<BR>
<P><EM>&gt; Many are pretty darn sure you cannot reach human level congnition
</EM><BR>
<EM>&gt; without at least much closer to human level computational throughput. 
</EM><BR>
<EM>&gt; Please show why these people, many of them experts who very much are at
</EM><BR>
<EM>&gt; the vanguard of the quest, are wrong.
</EM><BR>
<P>One error is trying to simulate HOW human minds work. (For basic or pure
<BR>
research that's another matter...go ahead). I posted previously that it is
<BR>
the RESULT of mind I am concerned with and now the HOW of it. We may take
<BR>
another thousand years to find out all about how the human mind works and
<BR>
right now we don't know very much at all. 
<BR>
&nbsp;&nbsp;&nbsp;As long as Hal-2001 gives me the RESULT of all those problems in
<BR>
intelligence I don't care how it does so. So tell me which of the 19
<BR>
factors are going to be troublesome and why? Do we need massive amounts of
<BR>
additional labour or do we need a new invention? If the latter, what is
<BR>
the invention?
<BR>
<P>&nbsp;&nbsp;If they are right, please show a
<BR>
<EM>&gt; way that in 1 year (initial suggestion above) we will both get this
</EM><BR>
<EM>&gt; incredible leap in computational hardware density
</EM><BR>
<P>Well, let's look at the requirements for the programming first and see if
<BR>
we have the hardware already. For example, I think some estimates have
<BR>
been made of what it would take to run a conversational program (to
<BR>
converse as well as a typical human) and I think it is within present
<BR>
technology.
<BR>
<P>&nbsp;AND make use of it
<BR>
<EM>&gt; with appropriate software based on the brand new theoretical
</EM><BR>
<EM>&gt; breakthroughs we also get in this year.
</EM><BR>
<P>I've set out the framework for arriving at the results of measured human
<BR>
intelligence (eg examining what we arrive at with 19 primary mental
<BR>
abilities). I've pointed out the fact that human equivalency has already
<BR>
been met for a significant portion of this. I've listed the areas where I
<BR>
think invention/innovation MAY be be required (but I have to hear from the
<BR>
specialists to know more precisely what those innovations might be). There
<BR>
is nothing wrong with this framework or model if you want to call it that.
<BR>
So just tell me the answers to the questions raised. 
<BR>
<P>&nbsp;&nbsp;While you are at it please send
<BR>
<EM>&gt; me some of the same drugs you are taking so I can also enjoy this
</EM><BR>
<EM>&gt; fantasy as much as you are.
</EM><BR>
<P>There is no fantasy in machine procedures for arithmetic/logic/mathematics 
<BR>
to give us the results yielded when we test humans on the various 
<BR>
Reasoning Factors. Don't machines surpass humans? There is no fantasy in
<BR>
machine memory which surpasses humans as assessed by those Memory Factors.
<BR>
There is no fantasy in machines doing mapping and visualization to surpass
<BR>
humans on Visualization Factors. No fantasy in verbal abilities of
<BR>
machines like the ability to give definitions and spell checking. No
<BR>
fantasy in thinking that someone out there among millions of educators,
<BR>
linguists, etc. might very well be able to verbalize the rules for grade
<BR>
two readers as well as grade one readers and also the rules for
<BR>
conversation. etc. etc. 
<BR>
<P>FWP
<BR>
<P><P>-------------------------------------------------------------------------------
<BR>
Machine Psychology:
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;<A HREF="http://users.uniserve.com/~culturex/Machine-Psychology.htm">http://users.uniserve.com/~culturex/Machine-Psychology.htm</A>&gt;
<BR>
-------------------------------------------------------------------------------
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5927.html">Edward Case: "Re: extropians-digest V5 #267"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5925.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5881.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5956.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5956.html">Samantha Atkins: "Re: Robots, but philosophers (or, Hal-2001)"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5926">[ date ]</A>
<A HREF="index.html#5926">[ thread ]</A>
<A HREF="subject.html#5926">[ subject ]</A>
<A HREF="author.html#5926">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:16 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
