<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="hal@finney.org (hal@finney.org)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sun Sep 24 16:11:56 2000" -->
<!-- isoreceived="20000924221156" -->
<!-- sent="Sun, 24 Sep 2000 15:08:30 -0700" -->
<!-- isosent="20000924220830" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="200009242208.PAA31776@finney.org" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> <A HREF="mailto:hal@finney.org?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;200009242208.PAA31776@finney.org&gt;"><EM>hal@finney.org</EM></A><BR>
<STRONG>Date:</STRONG> Sun Sep 24 2000 - 16:08:30 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5605.html">Bill Douglass: "Re: extropians-digest V5 #264"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5603.html">Natasha Vita-More: "Re: 2-Sided Perceptions"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5604">[ date ]</A>
<A HREF="index.html#5604">[ thread ]</A>
<A HREF="subject.html#5604">[ subject ]</A>
<A HREF="author.html#5604">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Darin writes:
<BR>
<EM>&gt; Think one level farther up. If a gun is in the process of firing at you, you
</EM><BR>
<EM>&gt; have already completely failed to predict the behavior of the agent firing
</EM><BR>
<EM>&gt; the gun. Now, obviously none of US can treat a human being as a
</EM><BR>
<EM>&gt; deterministic process, but what if the gun is being fired by a simple robot?
</EM><BR>
<EM>&gt; All it does is run in circles, and fire the gun from the same spot, at the
</EM><BR>
<EM>&gt; same target, every 30 seconds or so. You can quite easily determine the
</EM><BR>
<EM>&gt; pattern in that robot's behaivior and never be at risk from the gun. The
</EM><BR>
<EM>&gt; difference between the behaivior of a human and that robot is nothing more
</EM><BR>
<EM>&gt; then complexity. Given that humans are not infinitely complex, it is not an
</EM><BR>
<EM>&gt; impossible task to discover the deterministic rules governing human
</EM><BR>
<EM>&gt; behaivior.
</EM><BR>
<P>Determinism is not enough, it also depends on what the deterministic
<BR>
system does.  You need a degree of malleability in order to twist its
<BR>
actions to suit yourself.  In your robot example, what if the robot runs
<BR>
in circles and then shoots at you every 30 seconds?  You can still easily
<BR>
detect a pattern in the robot's behavior but you are still at risk.
<BR>
Or what if you're in a room whose walls squish together every minute?
<BR>
Again, full determinism, but you are in danger.
<BR>
<P><EM>&gt; &gt;Believers in the omnipotence of AIs seem to think that for any given
</EM><BR>
<EM>&gt; &gt;person, in any given situation, there is some input they can be given
</EM><BR>
<EM>&gt; &gt;which will cause them to produce any desired output.  If I see a nun
</EM><BR>
<EM>&gt; &gt;in the middle of prayer in the chapel, there is something I can say to
</EM><BR>
<EM>&gt; &gt;her that will make her immediately start screeching like a chimp while
</EM><BR>
<EM>&gt; &gt;jumping around the room scratching herself.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; You know, given a trillion high fidelity simulations of that nun to test
</EM><BR>
<EM>&gt; possible responses, I bet I could construct a sentence that would do just
</EM><BR>
<EM>&gt; that. My first order approximation is that it would involve me claiming to
</EM><BR>
<EM>&gt; be sent from God, combined with a thourough demonstration of omniscience
</EM><BR>
<EM>&gt; with respect to her life up to that point, all of which is easily acheivable
</EM><BR>
<EM>&gt; given those simulations, and an arbitrary amount subjective time to think
</EM><BR>
<EM>&gt; about it.
</EM><BR>
<P>I don't think this would work, because even if you convinced her that
<BR>
you could read her mind, that would not prove you were sent by God.
<BR>
You could be an agent of the devil, or simply an individual with ESP.
<BR>
The fact that you are giving her instructions that are so bizarre and
<BR>
seemingly damaging to the sanctity and holy air of the chapel will make
<BR>
her that much less likely to believe you.
<BR>
<P><EM>&gt; Now, convincing her within 30 seconds could very well be impossible, just
</EM><BR>
<EM>&gt; like you cannot overwrite 64 megabytes of memory with all 0s in less then 64
</EM><BR>
<EM>&gt; million (or so) fetch-execute cycles. The n-dimensional Hamming distance
</EM><BR>
<EM>&gt; between those two mind-states may be too far to bridge using only 30 seconds
</EM><BR>
<EM>&gt; of vocal input. But if you eliminate the time constraint, and give me, say,
</EM><BR>
<EM>&gt; 6 months to get her to do a convincing chimp imitation, then again, given
</EM><BR>
<EM>&gt; that simulation ability, I don't think it's an impossible task at all.
</EM><BR>
<P>It sounds like you agree that there are limits to the persuasive ability
<BR>
of even an infinitely intelligent AI.  This means that, in fact, we can't
<BR>
be sure that an AI could talk us out of pulling the plug.  It could well
<BR>
take longer for it to change our decision than it would take us to flip
<BR>
the switch.
<BR>
<P>Hal
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5605.html">Bill Douglass: "Re: extropians-digest V5 #264"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5603.html">Natasha Vita-More: "Re: 2-Sided Perceptions"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5604">[ date ]</A>
<A HREF="index.html#5604">[ thread ]</A>
<A HREF="subject.html#5604">[ subject ]</A>
<A HREF="author.html#5604">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:49 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
