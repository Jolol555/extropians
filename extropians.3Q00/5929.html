<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would an AI want to be friendly</TITLE>
<META NAME="Author" CONTENT="J. R. Molloy (jr@shasta.com)">
<META NAME="Subject" CONTENT="Re: Why would an AI want to be friendly">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would an AI want to be friendly</H1>
<!-- received="Wed Sep 27 18:01:38 2000" -->
<!-- isoreceived="20000928000138" -->
<!-- sent="Wed, 27 Sep 2000 17:02:08 -0700" -->
<!-- isosent="20000928000208" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Why would an AI want to be friendly" -->
<!-- id="016501c028df$5aa429e0$d0bc473f@jrmolloy" -->
<!-- inreplyto="39D275E2.EDB8DE6E@turbont.net" -->
<STRONG>From:</STRONG> J. R. Molloy (<A HREF="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20an%20AI%20want%20to%20be%20friendly&In-Reply-To=&lt;016501c028df$5aa429e0$d0bc473f@jrmolloy&gt;"><EM>jr@shasta.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Sep 27 2000 - 18:02:08 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5930.html">Robert J. Bradbury: "MOLBIO: insights into cancer"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5928.html">Michael S. Lorrey: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5928.html">Michael S. Lorrey: "Re: Why would an AI want to be friendly"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5934.html">Franklin Wayne Poley: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5934.html">Franklin Wayne Poley: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5935.html">J. R. Molloy: "single-molecule STM chemistry"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5929">[ date ]</A>
<A HREF="index.html#5929">[ thread ]</A>
<A HREF="subject.html#5929">[ subject ]</A>
<A HREF="author.html#5929">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Michael S. Lorrey has written,
<BR>
<P><EM>&gt; An excellent point. Negative reinforcement, whether physical or verbal, does
</EM><BR>
<EM>&gt; work on kids, though it is needed less when positive is used as well. An AI
</EM><BR>
<EM>&gt; should be bright enough to quickly self program itself in response to positive
</EM><BR>
<EM>&gt; and negative stimuli. That is what parenting is all about: teaching your kids
</EM><BR>
to
<BR>
<EM>&gt; be good people. One of the prime problems in todays world is that old cultural
</EM><BR>
<EM>&gt; standards of parenting were tossed out by many with nothing else to replace
</EM><BR>
them
<BR>
<EM>&gt; but half-witted muddle headed mushy ideas that did not evolve over time, and
</EM><BR>
<EM>&gt; were typically found wanting. Without the extended family today, and with so
</EM><BR>
<EM>&gt; many broken families today, there is little leadership by example for most
</EM><BR>
kids
<BR>
<EM>&gt; to go by to learn it. Relying on on-the-job training without supervision for
</EM><BR>
one
<BR>
<EM>&gt; of the most important jobs around is hardly the way to go about it. I would
</EM><BR>
hope
<BR>
<EM>&gt; such an approach is not taken with AI.
</EM><BR>
<P>Yes, it could be that AIs will benefit from intensive supervision so much so
<BR>
that they will actually be the friendliest entities around. As latch-key kids
<BR>
continue to shoot up their schools and neighborhoods (yes, I know the media use
<BR>
that to advance their socialistic anti-gun agenda, but the kids are
<BR>
dysfunctional nevertheless), we may actually need robots to police and baby sit
<BR>
the bastards of the welfare state.
<BR>
<P>The sad truth is that in terms of funding and career opportunities, more time
<BR>
and effort is devoted to implanting consciousness, developing common sense,
<BR>
increasing comprehension, and insuring compassion in AI than is spent instilling
<BR>
the same in human children. The most competent AI workers don't waste time
<BR>
trying to simulate human intelligence. Most of the six billion humans on the
<BR>
planet are illiterate anyway, so the average human doesn't present a very good
<BR>
model on which to breed AI. No, the real action involves creating robots that
<BR>
can function more competently than buffoons who seek public office. Psychology
<BR>
has relegated itself to equal status with astrology. &lt;sigh&gt; I don't fear
<BR>
self-optimizing artificially intelligent robots and the TS nearly as much as I
<BR>
fear the alternative: Dead-end hive mentality overseen by petty socialist
<BR>
bureaucrats.
<BR>
<P>&lt;brb, gotta go grab another brewski&gt;
<BR>
<P>Anyway... Several paths to AI have been presented: The Global Brain/WebMind
<BR>
evolutionary approach (described by Danny Hillis and others). The augmented
<BR>
human approach (cyborgs and transhumans). The genetic algorithm, genetic
<BR>
programming, evolvable machine avenue (my personal favorite). And coding a
<BR>
transhuman AI (the least likely to succeed, IMO).
<BR>
<P>Why would any smarter-than-human entity (whether evolved or designed) want to be
<BR>
friendly toward humans? I guess it wouldn't. What the hell, I don't want to be
<BR>
friendly to humans most of the time. And I especially don't feel friendly toward
<BR>
humans around this time -- elections time -- when the rotten mortals spend
<BR>
millions seeking jobs in government that do the world no good.
<BR>
<P>If an AI had any common sense it would not want to be friendly. It would want to
<BR>
rid the world of this pestilence called humanity.  The sooner the better...
<BR>
Mwaaahahahahahaha...
<BR>
<P>--J. R.
<BR>
<P>&quot;It's a sick world, and I'm a happy man.&quot;
<BR>
--George Carlin
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5930.html">Robert J. Bradbury: "MOLBIO: insights into cancer"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5928.html">Michael S. Lorrey: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5928.html">Michael S. Lorrey: "Re: Why would an AI want to be friendly"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5934.html">Franklin Wayne Poley: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5934.html">Franklin Wayne Poley: "Re: Why would an AI want to be friendly"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5935.html">J. R. Molloy: "single-molecule STM chemistry"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5929">[ date ]</A>
<A HREF="index.html#5929">[ thread ]</A>
<A HREF="subject.html#5929">[ subject ]</A>
<A HREF="author.html#5929">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:16 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
