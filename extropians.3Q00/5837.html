<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Michael S. Lorrey (retroman@turbont.net)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Tue Sep 26 12:55:46 2000" -->
<!-- isoreceived="20000926185546" -->
<!-- sent="Tue, 26 Sep 2000 15:03:30 -0400" -->
<!-- isosent="20000926190330" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="retroman@turbont.net" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39D0F302.A62C3D90@turbont.net" -->
<!-- inreplyto="Pine.GSO.4.21.0009251853120.2702-100000@vcn.bc.ca" -->
<STRONG>From:</STRONG> Michael S. Lorrey (<A HREF="mailto:retroman@turbont.net?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39D0F302.A62C3D90@turbont.net&gt;"><EM>retroman@turbont.net</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 26 2000 - 13:03:30 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5838.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5836.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5768.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5837">[ date ]</A>
<A HREF="index.html#5837">[ thread ]</A>
<A HREF="subject.html#5837">[ subject ]</A>
<A HREF="author.html#5837">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Franklin Wayne Poley wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; On Mon, 25 Sep 2000, Michael S. Lorrey wrote:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; Franklin Wayne Poley wrote:
</EM><BR>
<EM>&gt; &gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; &gt; I have given hundreds of IQ tests over the course of my career and
</EM><BR>
<EM>&gt; &gt; &gt; &gt; participated in the development of one of them (Cattell's CAB). If I were
</EM><BR>
<EM>&gt; &gt; &gt; &gt; to measure transhuman-machine intelligence and human intelligence; and
</EM><BR>
<EM>&gt; &gt; &gt; &gt; compare the profiles, how would they differ?
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; The transhuman would max out every single IQ test.  It is just barely possible
</EM><BR>
<EM>&gt; &gt; &gt; that a mildly transhuman AI running on sufficiently limited hardware might
</EM><BR>
<EM>&gt; &gt; &gt; perform badly on a test of visual intelligence, or - if isolated from the
</EM><BR>
<EM>&gt; &gt; &gt; Internet - of cultural knowledge.  A true superintelligence would max those
</EM><BR>
<EM>&gt; &gt; &gt; out as well.
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; I don't know. Could you not utilize response times on each question to extend
</EM><BR>
<EM>&gt; &gt; the range of estimation? Perhaps limiting the response time would help as well.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Please elaborate. I don't know what you are getting at.
</EM><BR>
<P>Well, having taken many IQ tests, and having played chess against the computer
<BR>
often, where I found I won more often when I limited the amount of time the
<BR>
computer could think about its next move, that either counting the amount of
<BR>
time a subject takes to answer a question, or else limiting the amount of time
<BR>
the subject can take for each question, should allow us to measure the IQ of a
<BR>
person who can ace any IQ test if given indefinite amounts of time to finish it.
<BR>
Each progressively harder question takes more time for a subject of a given
<BR>
intelligence to answer.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5838.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5836.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5768.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5837">[ date ]</A>
<A HREF="index.html#5837">[ thread ]</A>
<A HREF="subject.html#5837">[ subject ]</A>
<A HREF="author.html#5837">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:12 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
