<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="J. R. Molloy (jr@shasta.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Tue Sep  5 21:52:55 2000" -->
<!-- isoreceived="20000906035255" -->
<!-- sent="Tue, 5 Sep 2000 20:51:34 -0700" -->
<!-- isosent="20000906035134" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="000001c017b6$3c5eb3e0$a0bc473f@jrmolloy" -->
<!-- inreplyto="Pine.GSO.4.21.0009051812140.3351-100000@vcn.bc.ca" -->
<STRONG>From:</STRONG> J. R. Molloy (<A HREF="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;000001c017b6$3c5eb3e0$a0bc473f@jrmolloy&gt;"><EM>jr@shasta.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Sep 05 2000 - 21:51:34 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4331.html">John Clark: "Re: Harry Potter"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4329.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4315.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="4338.html">Jason Joel Thompson: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4346.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4330">[ date ]</A>
<A HREF="index.html#4330">[ thread ]</A>
<A HREF="subject.html#4330">[ subject ]</A>
<A HREF="author.html#4330">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Why would AIs want to be friendly?
<BR>
Because if cognitive scientists can make one AI, they can make millions
<BR>
(billions) of them, simply by copying them. When developers have sufficient
<BR>
numbers of intelligent agents, they simply let the IAs compete for the right to
<BR>
reproduce. These evolvable agents then do their own genetic programming. The
<BR>
friendliest AIs get to reproduce, the rest get terminated. The socialization of
<BR>
AIs would be a snap compared to the socialization of human children.
<BR>
By the time the AIs evolve to above-human-intelligence, they would be far more
<BR>
trustworthy than any human, due to many generations of culling the herd of AIs.
<BR>
Think of AI as a huge population of intelligent agents rather than as a single
<BR>
entity, and the problem of making them friendly disappears. All you have to do
<BR>
is discard any artificially intelligent individuals which show symptoms of
<BR>
unfriendliness, and you end up with very friendly, docile, and helpful agents
<BR>
all very intent on breeding themselves into friendly, docile, and helpful SIs.
<BR>
<P>AFAIK, Asimov never considered the possibility of genetic programming and
<BR>
evolvable machines which could compete against each other to reach higher levels
<BR>
of IQ. With thousands (or millions and billions) of artificially intelligent
<BR>
agents battling each other to reproduce, all humans would need to do is to cull
<BR>
the herd, so to speak. Any unfriendly AI agents (unlike human children) could
<BR>
simply be terminated. This would result in a population of AIs with docility and
<BR>
compliance as part of their genetic code. Moravec's Mind Children could
<BR>
obviously number in the millions from the start, because as soon as one is
<BR>
developed, it could be duplicated ad infinitum. With an unlimited supply of
<BR>
genetically programmed AIs, their evolution could be guided and directed as
<BR>
experimenters see fit. The socialization of AI would consequently be far easier
<BR>
than the socialization of humans.
<BR>
<P>--J. R.
<BR>
<P>&quot;I like the dreams of the future better than the history of the
<BR>
past.&quot;  --Thomas Jefferson
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4331.html">John Clark: "Re: Harry Potter"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4329.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4315.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="4338.html">Jason Joel Thompson: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4346.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4330">[ date ]</A>
<A HREF="index.html#4330">[ thread ]</A>
<A HREF="subject.html#4330">[ subject ]</A>
<A HREF="author.html#4330">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:37:16 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
