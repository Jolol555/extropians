<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Thu Sep 28 00:59:20 2000" -->
<!-- isoreceived="20000928065920" -->
<!-- sent="Thu, 28 Sep 2000 02:40:40 -0400" -->
<!-- isosent="20000928064040" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39D2E7E8.C6DA6365@pobox.com" -->
<!-- inreplyto="3.0.6.32.20000928143316.0088d340@ariel.its.unimelb.edu.au" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39D2E7E8.C6DA6365@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Sep 28 2000 - 00:40:40 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5946.html">Eugene Leitl: "single-molecule STM chemistry"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5937.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6003.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6012.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5945">[ date ]</A>
<A HREF="index.html#5945">[ thread ]</A>
<A HREF="subject.html#5945">[ subject ]</A>
<A HREF="author.html#5945">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Damien Broderick wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; At 10:53 AM 27/09/00 -0400, Eliezer wrote:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt;Phylum radiation is
</EM><BR>
<EM>&gt; &gt;cognitively plausible only if the SI possesses an explicit drive for
</EM><BR>
<EM>&gt; &gt;reproduction and diversification at the expense of its own welfare.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; This seems a rather odd thing to read from a fan of mutation-with-selection
</EM><BR>
<EM>&gt; accounts of lebenforms.
</EM><BR>
<P>I'm a fan of *what*?  Either you have me confused with 'gene or this is
<BR>
Damienspeak for &quot;evolutionary psychology&quot;.
<BR>
<P><EM>&gt; Presumably there are a couple of suppressed
</EM><BR>
<EM>&gt; premises here: that SIs would never choose to copy themselves, or if they
</EM><BR>
<EM>&gt; did choose to do so they'd have absolutely perfect reliable error-checking,
</EM><BR>
<EM>&gt; forever.
</EM><BR>
<P>Both of these sound much more plausible to me than the alternatives.  Even if
<BR>
distinct nodes need to run separate decision-making mechanisms, the use of
<BR>
identical algorithms can ensure that there'll never be a major conflict. 
<BR>
Infinitesimal conflicts about the third decimal place can be resolved by
<BR>
compromise or flipping a coin, as opposed to general warfare between the nodes
<BR>
of a single mind.  That's the way I'd set things up.  Even if a
<BR>
superintelligence needs multiple components due to lightspeed limitations, the
<BR>
result isn't a society, it's a multicellular organism.  (But without the
<BR>
possibility of cancer.)
<BR>
<P>Perfectly reliable error-checking doesn't look difficult, if you're (a)
<BR>
superintelligent and (b) willing to expend the computing power.  And imperfect
<BR>
error-checking (or divergent world-models) aren't a disaster, or even a
<BR>
departure from the multicellular metaphor, as long as you anticipate the
<BR>
possibility of conflicts in advance and design a resolution mechanism for any
<BR>
conflicts in the third decimal place that do show up.
<BR>
<P>Just because we live in a world of reproduction and imperfect error-checking
<BR>
says nothing whatsoever about how things work in the realm of design.  I think
<BR>
the Foresight Guidelines would have a few words to say about the assumption
<BR>
that, say, nanomachines need to reproduce, or that they can't have absolutely
<BR>
perfect reliable error-detection.
<BR>
<P>Assuming that *unintentional* phylum radiation takes place requires assuming a
<BR>
stupid SI - what we can see, an SI can see and prevent.  Assuming intentional
<BR>
phylum radiation requires the intention.  I stand by my statement.
<BR>
<P>--              --              --              --              -- 
<BR>
Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A> 
<BR>
Research Fellow, Singularity Institute for Artificial Intelligence
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5946.html">Eugene Leitl: "single-molecule STM chemistry"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5944.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5937.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="6003.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="6012.html">Damien Broderick: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5945">[ date ]</A>
<A HREF="index.html#5945">[ thread ]</A>
<A HREF="subject.html#5945">[ subject ]</A>
<A HREF="author.html#5945">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:17 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
