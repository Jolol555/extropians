<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Fwd: Earthweb from transadmin</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: Fwd: Earthweb from transadmin">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Fwd: Earthweb from transadmin</H1>
<!-- received="Mon Sep 18 13:21:31 2000" -->
<!-- isoreceived="20000918192131" -->
<!-- sent="Mon, 18 Sep 2000 15:00:55 -0400" -->
<!-- isosent="20000918190055" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Fwd: Earthweb from transadmin" -->
<!-- id="39C66667.A543DD6E@pobox.com" -->
<!-- inreplyto="14789.48853.952912.480283@lrz.uni-muenchen.de" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Fwd:%20Earthweb%20from%20transadmin&In-Reply-To=&lt;39C66667.A543DD6E@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Sep 18 2000 - 13:00:55 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5216.html">David Lubkin: "Re: The Future of Work"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5214.html">Michael S. Lorrey: "Re: responsibility for children"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5175.html">Eugene Leitl: "Fwd: Earthweb from transadmin"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5237.html">Matt Gingell: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5237.html">Matt Gingell: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5251.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5215">[ date ]</A>
<A HREF="index.html#5215">[ thread ]</A>
<A HREF="subject.html#5215">[ subject ]</A>
<A HREF="author.html#5215">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eugene Leitl wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; So, please tell me how you can predict the growth of the core
</EM><BR>
<P>I do not propose to predict the growth of the core.
<BR>
<P>Commonsense arguments are enough.  If you like, you can think of the
<BR>
commonsense arguments as referring to fuzzily-bordered probability volumes in
<BR>
the Hamiltonian space of possibilities, but I don't see how that would
<BR>
contribute materially to intelligent thinking.
<BR>
<P>I can predict the behavior of the core in terms of ternary logic:  Either it's
<BR>
friendly, or it's not friendly, or I have failed to understand What's Going
<BR>
On.
<BR>
<P>All else being equal, it should be friendly.
<BR>
<P><EM>&gt; Tell me how a piece of &quot;code&quot; during the bootstrap process and
</EM><BR>
<EM>&gt; afterwards can formally predict what another piece of &quot;code&quot;
</EM><BR>
<P>I do not propose to make formal predictions of any type.  Intelligence
<BR>
exploits the regularities in reality; these regularities can be formalized as
<BR>
fuzzily-bordered volumes of phase space - say, the space of possible minds
<BR>
that can be described as &quot;friendly&quot; - but this formalization adds nothing. 
<BR>
Build an AI right smack in the middle of &quot;friendly space&quot; and it doesn't
<BR>
matter how what kind of sophistries you can raise around the edges.
<BR>
<P>I cannot formally predict the molecular behavior of a skyscraper; the
<BR>
definition of skyscraper is not formally definable around the edges; I can
<BR>
still tell the difference between a skyscraper and a hut.
<BR>
<P><EM>&gt; Tell me how a team of human programmers is supposed to break through
</EM><BR>
<EM>&gt; the complexity bareer while building the seed AI without resorting to
</EM><BR>
<EM>&gt; evolutionary algorithms
</EM><BR>
<P>We've been through this.
<BR>
<P>Evolution is the degenerate case of intelligent design in which intelligence
<BR>
equals zero.  If I happen to have a seed AI lying around, why should it be
<BR>
testing millions of unintelligent mutations when it could be testing millions
<BR>
of intelligent mutations?
<BR>
<P><EM>&gt; Tell me how a single distributed monode can arbitrate synchronous
</EM><BR>
<EM>&gt; events separated by light seconds, minutes, hours, years, megayears
</EM><BR>
<EM>&gt; distances without having to resort to relativistic signalling.
</EM><BR>
<P>You confuse computational architecture with cognitive coherence and
<BR>
motivational coherence.
<BR>
<P><EM>&gt; If it's not single, tell me what other nodes will do with a node's
</EM><BR>
<EM>&gt; decision they consider not kosher, and how they enforce it.
</EM><BR>
<P>I do not expect motivational conflicts to arise due to distributed processing,
<BR>
any more than I expect different nodes to come up with different laws of
<BR>
arithmetic.
<BR>
<P><EM>&gt; Tell me how the thing is guarded against spontaneous emergence of
</EM><BR>
<EM>&gt; autoreplicators in its very fabric, and from invasion of alien
</EM><BR>
<EM>&gt; autoreplicators from the outside.
</EM><BR>
<P>Solar Defense is the Sysop's problem; I fail to see why this problem is
<BR>
particularly more urgent for the Sysop Scenario then in any of the other
<BR>
possible futures.
<BR>
<P><EM>&gt; Tell me how many operations the thing will need to sample all possible
</EM><BR>
<EM>&gt; trajectories on the behaviour of the society as a whole (sounds
</EM><BR>
<EM>&gt; NP-complete to me), to pick the best of all possible worlds. (And will
</EM><BR>
<EM>&gt; it mean that all of us will have to till our virtual gardens?)
</EM><BR>
<P>I don't understand why you think I'm proposing such a thing.  I am not
<BR>
proposing to instruct the Sysop to create the best of all possible worlds; I
<BR>
am proposing that building a Sysop instructed to be friendly while preserving
<BR>
individual rights is the best possible world *I* can attempt to create.
<BR>
<P><EM>&gt; What is the proposed temporal scope of the prediction horizont?
</EM><BR>
<EM>&gt; Minutes? Hours? Years?
</EM><BR>
<P>Again, explain to me what the Sysop is predicting and why it needs to predict
<BR>
it.  I can predict that the Sun will not naturally explode; this prediction
<BR>
horizon has a million years and Godel be damned.
<BR>
<P><EM>&gt; How can you decide what the long-term impact of an event in the here
</EM><BR>
<EM>&gt; and now is?
</EM><BR>
<P>Crossing the street is pretty long-term from the Planck-time perspective, yet
<BR>
somehow you manage not to get hit by any cars.  Exercise some common sense.
<BR>
<P><EM>&gt; There's more, but I'm finished for now. If you can argue all of above
</EM><BR>
<EM>&gt; points convincingly (no handwaving please), I might start to consider
</EM><BR>
<EM>&gt; that there's something more to your proposal than just hot air. So
</EM><BR>
<EM>&gt; show us the money, instead of constantly pelting the list with many
</EM><BR>
<EM>&gt; redundant descriptions of how wonderful the sysop will be. Frankly,
</EM><BR>
<EM>&gt; I'm getting sick of it.
</EM><BR>
<P>Frankly, 'gene, I'm starting to get pretty sick of your attitude.  Who are you
<BR>
to decide whether my proposal is hot air?  I can't see that it makes the least
<BR>
bit of difference to the world what you think of my proposal, and frankly, you
<BR>
have now managed to tick me off.  I may consider my AI work to be superior to
<BR>
yours, but I don't propose that you have a responsibility to convince me of
<BR>
one damn thing.  I expect to be extended the same courtesy.
<BR>
<P>Sincerely,
<BR>
Eliezer.
<BR>
<P>--              --              --              --              -- 
<BR>
Eliezer S. Yudkowsky                          <A HREF="http://singinst.org/">http://singinst.org/</A> 
<BR>
Research Fellow, Singularity Institute for Artificial Intelligence
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5216.html">David Lubkin: "Re: The Future of Work"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5214.html">Michael S. Lorrey: "Re: responsibility for children"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5175.html">Eugene Leitl: "Fwd: Earthweb from transadmin"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5237.html">Matt Gingell: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5237.html">Matt Gingell: "Re: Fwd: Earthweb from transadmin"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5251.html">Samantha Atkins: "Re: Fwd: Earthweb from transadmin"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5215">[ date ]</A>
<A HREF="index.html#5215">[ thread ]</A>
<A HREF="subject.html#5215">[ subject ]</A>
<A HREF="author.html#5215">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:25 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
