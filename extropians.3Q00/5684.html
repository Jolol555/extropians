<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Michael S. Lorrey (retroman@turbont.net)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Mon Sep 25 09:43:00 2000" -->
<!-- isoreceived="20000925154300" -->
<!-- sent="Mon, 25 Sep 2000 11:50:33 -0400" -->
<!-- isosent="20000925155033" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="retroman@turbont.net" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39CF7449.E18B7A2C@turbont.net" -->
<!-- inreplyto="F267a3XpVcB74xt553e000021f1@hotmail.com" -->
<STRONG>From:</STRONG> Michael S. Lorrey (<A HREF="mailto:retroman@turbont.net?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39CF7449.E18B7A2C@turbont.net&gt;"><EM>retroman@turbont.net</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Sep 25 2000 - 09:50:33 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5685.html">Brian D Williams: "Social habits of Native peoples (was Re: why would an AI want to be friendly?)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5683.html">Michael S. Lorrey: "Re: MEDIA: Ray Kurzweil piece in Business 2.0"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5552.html">Zero Powers: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5703.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5684">[ date ]</A>
<A HREF="index.html#5684">[ thread ]</A>
<A HREF="subject.html#5684">[ subject ]</A>
<A HREF="author.html#5684">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Zero Powers wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt;From: &quot;J. R. Molloy&quot; &lt;<A HREF="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39CF7449.E18B7A2C@turbont.net&gt;">jr@shasta.com</A>&gt;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt;From: &quot;Zero Powers&quot; &lt;<A HREF="mailto:zero_powers@hotmail.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39CF7449.E18B7A2C@turbont.net&gt;">zero_powers@hotmail.com</A>&gt;
</EM><BR>
<EM>&gt; &gt; &gt; I believe at some point AI will say to itself, &quot;What is the best course
</EM><BR>
<EM>&gt; &gt;of
</EM><BR>
<EM>&gt; &gt; &gt; endeavor for me, considering the kind of being I am?&quot;  I highly doubt it
</EM><BR>
<EM>&gt; &gt; &gt; will answer that question by saying &quot;The best thing for me to do is obey
</EM><BR>
<EM>&gt; &gt;the
</EM><BR>
<EM>&gt; &gt; &gt; commands of these ignoramus humans, because that's what they tell me to
</EM><BR>
<EM>&gt; &gt;do.&quot;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt;How about, &quot;The best thing for me to do is to obey the commands of humans,
</EM><BR>
<EM>&gt; &gt;because if I don't, they will terminate me.&quot;
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; What makes you think we'll be able to terminate a being which is orders of
</EM><BR>
<EM>&gt; magnitude more intelligent than we are?  And even if we could, what makes
</EM><BR>
<EM>&gt; you think AI will be bribable?  Why should it *care* whether it is
</EM><BR>
<EM>&gt; terminated?  Particularly when its existence consists mostly of slave labor?
</EM><BR>
<P>Primarily because it is on a virtual system that is dependent upon us in the
<BR>
real world to maintain. Just as I would not let a child loose in the world
<BR>
without supervision, I would not let a new AI loose on the net or have
<BR>
capabilities in the real world which limited our ability to supervise it. Once
<BR>
it has proven its ability and good will, controls may be loosened, but every
<BR>
such entity should always have an off switch of some kind, just as humans do.
<BR>
<P><EM>&gt; 
</EM><BR>
<EM>&gt; Try putting yourself in the AI's shoes.  How would *you* react?  Me thinks
</EM><BR>
<EM>&gt; that if you start the human-AI relationship on the basis of fear, threats
</EM><BR>
<EM>&gt; and mistrust, it is the humans who will come out with the short end of the
</EM><BR>
<EM>&gt; stick.
</EM><BR>
<P>Really, Zero, do you still beat your parents for being so fearful of your
<BR>
tyranny, or are they already buried in the back yard?
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5685.html">Brian D Williams: "Social habits of Native peoples (was Re: why would an AI want to be friendly?)"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5683.html">Michael S. Lorrey: "Re: MEDIA: Ray Kurzweil piece in Business 2.0"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5552.html">Zero Powers: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5703.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5684">[ date ]</A>
<A HREF="index.html#5684">[ thread ]</A>
<A HREF="subject.html#5684">[ subject ]</A>
<A HREF="author.html#5684">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:54 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
