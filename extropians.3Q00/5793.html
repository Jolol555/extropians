<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="Samantha Atkins (samantha@objectent.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Mon Sep 25 23:31:13 2000" -->
<!-- isoreceived="20000926053113" -->
<!-- sent="Mon, 25 Sep 2000 22:32:49 -0700" -->
<!-- isosent="20000926053249" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="39D03501.5E10C9E1@objectent.com" -->
<!-- inreplyto="Pine.GSO.4.21.0009252038510.20702-100000@vcn.bc.ca" -->
<STRONG>From:</STRONG> Samantha Atkins (<A HREF="mailto:samantha@objectent.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;39D03501.5E10C9E1@objectent.com&gt;"><EM>samantha@objectent.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Sep 25 2000 - 23:32:49 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5794.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5792.html">T0Morrow@aol.com: "Re: GUNS: Why here?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5782.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5804.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5793">[ date ]</A>
<A HREF="index.html#5793">[ thread ]</A>
<A HREF="subject.html#5793">[ subject ]</A>
<A HREF="author.html#5793">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Franklin Wayne Poley wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; On Mon, 25 Sep 2000, J. R. Molloy wrote:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt; The general public need not back or fund AI projects because the US military is
</EM><BR>
<EM>&gt; &gt; spending millions trying to develop AI.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; This could be a nightmare. What do you think? If the militaries are in an
</EM><BR>
<EM>&gt; AI race what does it mean? What if we are only a decade or so away from AI
</EM><BR>
<EM>&gt; to surpass human equivalency on all major measured outcomes of
</EM><BR>
<EM>&gt; intelligence including learning ability?
</EM><BR>
<P>That is pretty unlikely despite some optimistic opinions here.
<BR>
<P><EM>&gt; What if the present
</EM><BR>
<EM>&gt; state-of-the-art is that it 'only' takes x billions of dollars (available
</EM><BR>
<EM>&gt; to the militaries) and machines will be on hand which are more
</EM><BR>
<EM>&gt; &quot;learned&quot; than humans and can add to that learning better and faster than
</EM><BR>
<EM>&gt; humans? 
</EM><BR>
<P>We are at least a jump in substrate away from machines as
<BR>
computationally complex as human brains.  That is just for the hardware
<BR>
to be feasible for the task.  The software is another matter that is not
<BR>
just going to magically come together.  
<BR>
&nbsp;&nbsp;
<BR>
<EM>&gt; They can then work on advancing military science 24 hours a
</EM><BR>
<EM>&gt; day. It makes Roswell conspiracy theories pale by comparison. But then
</EM><BR>
<EM>&gt; this is all just distant futuristic fantasy, right? And we the public can
</EM><BR>
<EM>&gt; sit back and know that private and military AI research is many decades
</EM><BR>
<EM>&gt; away from any such state of development.
</EM><BR>
<P>I would say more like 2 decades away minimum than 1.  But then I saw
<BR>
average consensus for when we would have at least basic nano-assembler
<BR>
systems drop from an average of 20+ years in March to about 12 in
<BR>
September.  So I probably should adjust AI guesstimates also.
<BR>
<P><P>- samantha
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5794.html">Samantha Atkins: "Re: Why would AI want to be friendly?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5792.html">T0Morrow@aol.com: "Re: GUNS: Why here?"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5782.html">Franklin Wayne Poley: "Re: Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<LI><STRONG>Reply:</STRONG> <A HREF="5804.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5793">[ date ]</A>
<A HREF="index.html#5793">[ thread ]</A>
<A HREF="subject.html#5793">[ subject ]</A>
<A HREF="author.html#5793">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:39:07 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
