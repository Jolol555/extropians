<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why would AI want to be friendly?</TITLE>
<META NAME="Author" CONTENT="phil osborn (philosborn@hotmail.com)">
<META NAME="Subject" CONTENT="Re: Why would AI want to be friendly?">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why would AI want to be friendly?</H1>
<!-- received="Sat Sep 16 19:47:30 2000" -->
<!-- isoreceived="20000917014730" -->
<!-- sent="Sat, 16 Sep 2000 18:47:34 PDT" -->
<!-- isosent="20000917014734" -->
<!-- name="phil osborn" -->
<!-- email="philosborn@hotmail.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="LAW2-F111XQRmRHgwkv000016df@hotmail.com" -->
<!-- inreplyto="Why would AI want to be friendly?" -->
<STRONG>From:</STRONG> phil osborn (<A HREF="mailto:philosborn@hotmail.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;LAW2-F111XQRmRHgwkv000016df@hotmail.com&gt;"><EM>philosborn@hotmail.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat Sep 16 2000 - 19:47:34 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5122.html">Eugene Leitl: "Re: just me"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5120.html">Technotranscendence: "Re: Small libraries"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5121">[ date ]</A>
<A HREF="index.html#5121">[ thread ]</A>
<A HREF="subject.html#5121">[ subject ]</A>
<A HREF="author.html#5121">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
What this really boils down to is that any SI is going to eat us, one way or 
<BR>
another.  We will probably chose to be eaten (some people prefer the term 
<BR>
&quot;assimilated&quot;), because it will be better in terms of our subjective 
<BR>
experience to be completely transformed into something else - another SI, or 
<BR>
a piece of one.  The question is whether our subjective experience or choice 
<BR>
will matter to the SI.
<BR>
<P>On today's Digital Village, one of the heads of IBM's advanced R &amp; D was 
<BR>
interviewed about a presentation he gave at the &quot;Next 20 Years&quot; conference.  
<BR>
During Q &amp; A from the public, one of the callers asked about some report 
<BR>
indicating that it might be possible to build a quantum computer that could 
<BR>
simulate the entire universe - at a higher resolution.
<BR>
<P>Interesting thing was that this guy - who also discussed the ubiquitous 
<BR>
computing environment at length, overlaid reality, etc., as things likely to 
<BR>
be a part of everyday life 10 to 20 years off - was in fact aware of the 
<BR>
quantum computing report in question, and did not simply dismiss it as SF, 
<BR>
altho he did express major reservations as to when we would be able to 
<BR>
actually build such a machine.
<BR>
<P>He did say that we were running up against a serious computing lag in terms 
<BR>
of the results coming from the genome projects.  Just knowing the sequence 
<BR>
is only the first step - obviously.  But what isn't so obvious to most 
<BR>
people is that the really useful stuff, as he put it, would come when we 
<BR>
were able to simulate the large protein folding quickly and accurately.  
<BR>
Then he predicted major breakthroughs in every area of medicine - including 
<BR>
aging.
<BR>
<P>Nice to know that there are people like that.
<BR>
<P><EM>&gt;From: Ken Clements &lt;<A HREF="mailto:Ken@Innovation-On-Demand.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;LAW2-F111XQRmRHgwkv000016df@hotmail.com&gt;">Ken@Innovation-On-Demand.com</A>&gt;
</EM><BR>
<EM>&gt;Subject: Re: Why would AI want to be friendly?
</EM><BR>
<EM>&gt;Date: Mon, 11 Sep 2000 05:32:31 -0400
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;You can use the term &quot;friendly&quot; in connection with the behavior of
</EM><BR>
<EM>&gt;humans and dogs and many other creatures that we understand, but it has
</EM><BR>
<EM>&gt;no meaning when applied to behavior that we have no hope of
</EM><BR>
<EM>&gt;understanding.  I am always amused when SF writers attempt to describe
</EM><BR>
<EM>&gt;the motives and behaviors of the SI.  As if!!
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;An SI may decide that it is &quot;friendly&quot; to suddenly halt all humans in
</EM><BR>
<EM>&gt;mid thought.  No humans would see this as &quot;bad&quot; because no one would
</EM><BR>
<EM>&gt;experience it at all (I think I hear a tree falling in the woods
</EM><BR>
<EM>&gt;somewhere).  Now you might say that it was &quot;bad&quot; anyway because the SI
</EM><BR>
<EM>&gt;would have known that if we knew what it was going to do we would not
</EM><BR>
<EM>&gt;have liked it.  But, what if the SI actually halted all of us because it
</EM><BR>
<EM>&gt;decided to make a very &quot;friendly&quot; world for us, but knew that the
</EM><BR>
<EM>&gt;planned manipulation of the matter of the galaxy would take several
</EM><BR>
<EM>&gt;billion years, and wanted to spare us the subjective wait for paradise
</EM><BR>
<EM>&gt;by encoding us now for playback later.  What if we cannot make an SI in
</EM><BR>
<EM>&gt;the first place, because at some point in development they always go
</EM><BR>
<EM>&gt;into some kind of introspective state and halt themselves?  These &quot;what
</EM><BR>
<EM>&gt;ifs&quot; are nonfalsifiable, and pointless.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;We cannot know what an SI will do, if we could, it would not be one.  It
</EM><BR>
<EM>&gt;all comes down to this basic childhood wisdom:
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;&quot;It takes one to know one.&quot;
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;-Ken
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt;
</EM><BR>
<P>_________________________________________________________________________
<BR>
Get Your Private, Free E-mail from MSN Hotmail at <A HREF="http://www.hotmail.com">http://www.hotmail.com</A>.
<BR>
<P>Share information about yourself, create your own public profile at 
<BR>
<A HREF="http://profiles.msn.com">http://profiles.msn.com</A>.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5122.html">Eugene Leitl: "Re: just me"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5120.html">Technotranscendence: "Re: Small libraries"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="5641.html">J. R. Molloy: "Why would AI want to be friendly?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5121">[ date ]</A>
<A HREF="index.html#5121">[ thread ]</A>
<A HREF="subject.html#5121">[ subject ]</A>
<A HREF="author.html#5121">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:38:16 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
