<!-- received="Mon Jan 27 20:56:45 1997 MDT" -->
<!-- sent="Mon, 27 Jan 1997 19:54:58 -0800 (PST)" -->
<!-- name="John K Clark" -->
<!-- email="johnkc@well.com" -->
<!-- subject="Free Will" -->
<!-- id="199701280354.TAA26912@well.com" -->
<!-- inreplyto="" -->
<title>extropians: Free Will</title>
<h1>Free Will</h1>
John K Clark (<i>johnkc@well.com</i>)<br>
<i>Mon, 27 Jan 1997 19:54:58 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1484">[ date ]</a><a href="index.html#1484">[ thread ]</a><a href="subject.html#1484">[ subject ]</a><a href="author.html#1484">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1485.html">Mitchell Porter: "NEURO/IA: "Brain Not Evolving Any Time Soon""</a>
<li> <b>Previous message:</b> <a href="1483.html">Hara Ra: "Re: Von Neumann's Blunder"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
-----BEGIN PGP SIGNED MESSAGE-----<br>
<p>
On  Mon, 27 Jan 1997  Omega &lt;omega@pacific.net&gt; Wrote:<br>
             <br>
<i>        &gt;I agree that your definition is clear and precise (at least in         </i><br>
<i>        &gt;meaning):</i><br>
<p>
<p>
Thanks, meaning is what counts. My definition is  "A being has free will if  <br>
and only if it can not predict what it will do next".<br>
<p>
<p>
<i>        &gt;The problem is that many things (as in a digital slot machine) can        </i><br>
<i>        &gt;be random (in the broad sense) because of Turing non-predictability,         </i><br>
<i>        &gt;while yet being totally deterministic.</i><br>
<p>
<p>
I agree and said as much in my post, but I don't see what the "problem" is, <br>
at least not for me. You say that a determinist universe has no room for what <br>
you call free will, not even with Turing non-predictability, so the only <br>
thing you have left is events without a cause, that is randomness. Sounds <br>
like a rather poor sort of free will to me, not much worth having.<br>
             <br>
<p>
<i>        &gt;The classic definition (in my own words) of free will in philosophy,         </i><br>
<i>        &gt;theology (ackh), and culture at large, is: The ability to select or         </i><br>
<i>        &gt;to not select an action </i><br>
        <br>
<p>
Then we most certainly have free will, I select things and make decisions a <br>
thousand times a day.<br>
<p>
<p>
<i>        &gt;free from constraints imposed by external circumstances,         </i><br>
<p>
<p>
Free? The term you're trying to define is FREE will, I fear we're getting a  <br>
little circular here. I gave you my definition and it is not circular.                       <br>
<p>
<p>
<i>        &gt;or by other agencies (such as divine will) that might impose         </i><br>
<i>        &gt;additional constraints not found in the external circumstances.          </i><br>
<p>
<p>
Vague. How do you distinguish between " additional constraints" and "external <br>
circumstances"? It all seems like exactly the same thing to me, even divine <br>
will is just part of the external circumstances, just part of the problem to <br>
be solved. I gave you my definition and it is not vague. <br>
             <br>
<p>
<i>        &gt;one has free will if they are an acausal agent within some realm </i><br>
<p>
<p>
Then we have free will, I certainly cause things to happen, but it's too  <br>
broad for my taste, my definition is just a subset of that.                         <br>
<p>
<p>
<i>        &gt;Where something is predictable, then free will does not exist.</i><br>
<p>
<p>
Not according to my definition. I may be able to predict your behavior <br>
perfectly (provided I don't tell you what it is) and you can do the same with <br>
me, but we both have free will because we can't predict our own behavior.<br>
<p>
<p>
<i>        &gt;Unfortunately your definition is the logical negative of the classic        </i><br>
<i>        &gt;definition because when stripped of the self-reference (which I will         </i><br>
<i>        &gt;get to shortly) it reduces to an operative principle which says:        </i><br>
<i>        &gt;? Where something is not predictable, then free will does exist.       </i><br>
<i>        &gt;It is a well established fact in formal logic that the negative of a         </i><br>
<i>        &gt;logical statement has a different meaning from the original, and         </i><br>
<i>        &gt;furthermore derives no support as to its validity from the original         </i><br>
<i>        &gt;statement.  </i><br>
             <br>
<p>
Please note, I said "if and only if",  A being has free will if and only if  <br>
it can not predict what it will do next. If A = B  then it is also true that <br>
not A = not B, thus because it means exactly the same thing, I am of course  <br>
perfectly happy with the following statement: A being does not have free will <br>
if and only if it can predict what it can do next.                         <br>
          <br>
<p>
<i>        &gt;This redefinition thus leads a couple of problems: The first is         </i><br>
<i>        &gt;that it changes the the established meaning of a term which goes         </i><br>
<i>        &gt;back millenia in human culture.      </i><br>
   <br>
<p>
I sure hope so, because the established meaning of the term is, well..., <br>
it has no meaning, its not even wrong, its gibberish.<br>
                        <br>
<p>
<i>        &gt;By this definition you could have the "free will" to use your keys         </i><br>
<i>        &gt;to enter a building, when in fact, you have no such free will         </i><br>
<i>        &gt;because your landlord just changed all the locks.  </i><br>
<p>
<p>
1) I predict that in 2 minutes or less I will be inside my house. <br>
2) I find that my key does not work. <br>
3) My "prediction" was not a prediction at all, it was wrong. <br>
4) I have free will.<br>
<p>
Of course, sometimes we can make correct prediction about out behavior, and <br>
sometimes we feel like we've fallen into a rut and are turning into robots.<br>
                         <br>
<p>
<i>        &gt;the "actuality" of free will that I'm talking about would (according         </i><br>
<i>        &gt;to your above commentary) change strictly as a result of changes in         </i><br>
<i>        &gt;one's knowledge regarding self and/or environment.          </i><br>
                         <br>
Correct. <br>
                         <br>
<p>
<i>        &gt;it leads to local definitions of truth         </i><br>
<p>
<p>
No. I can always predict what I am going to do or I can not, and that is true <br>
hear and there and everywhere.<br>
<p>
<p>
<i>        &gt;or worse yet solipsism         </i><br>
<p>
<p>
My definition does not demand solipsism, neither does it disprove it, and I  <br>
don't know of anything else that can do one bit better in that regard. <br>
                         <br>
<p>
<i>        &gt;Either free will does not exist at all, in which case this new         </i><br>
<i>        &gt;definition is wholly wrong because nothing that it called free will,         </i><br>
<i>        &gt;was in fact such.</i><br>
<p>
<p>
According to my definition, free will defiantly exists, absolutely no doubt <br>
about it, Turing proved it.                 <br>
     <br>
<p>
<i>        &gt;Or, through some form of trancendent acausality in keeping with the         </i><br>
<i>        &gt;first meaning, some limited form of free will does exist    </i><br>
<p>
<p>
Trancendent acausality? I have no idea what that means.<br>
                         <br>
<p>
<i>        &gt;To say that we might have some form of free will within what might         </i><br>
<i>        &gt;well be a totally deterministic reality is an insult to anyone's         </i><br>
<i>        &gt;intelligence         </i><br>
<p>
<p>
No not everyone, I say that sort of thing a lot and I don't feel insulted.<br>
                         <br>
<p>
<i>        &gt;yet this is what complexity based free-will theory tries to tell us         </i><br>
<i>        &gt;is possible.</i><br>
<p>
<p>
I don't think complexity theory has anything to do with it and never said it <br>
did.                     <br>
<p>
<p>
<i>        &gt;Consciousness and free will may or may not exist in actuality </i><br>
<p>
<p>
There is one consciousness that I know for sure exists, my own. I can't be as  <br>
certain about yours or anybody else.<br>
<p>
<p>
<i>        &gt;wondering how much we really know of ourselves.</i><br>
<p>
<p>
I don't wonder I know. We know very little about ourselves and will never <br>
know much more, that's why we'll always have free will. Someday we or our  <br>
offspring will be far smarter than we are now, but the thing they will try to <br>
understand, themselves, will be far more complex.<br>
          <br>
<p>
<i>        &gt;&gt;John:        </i><br>
<i>        &gt;&gt;Yes, I've found that nearly everybody I meet on the street has        </i><br>
<i>        &gt;&gt;exactly the same opinions I do.</i><br>
<p>
<i>        &gt;Omega:        </i><br>
<i>        &gt;This is not at all my experience.       </i><br>
  <br>
<p>
Holy cow, what a revaluation! Let me write this down before I forget it. <br>
The people who sit next to me on the buss may not have exactly the same <br>
opinions I do about Anarchy, Atheism, Nanotechnology, Uploading or Turing's <br>
solution of the Entscheidungproblem and its relationship to free will. <br>
Thank you for the insight you have given me about my fellow man.<br>
<p>
<p>
                                            John K Clark      johnkc@well.com <br>
<p>
-----BEGIN PGP SIGNATURE-----<br>
Version: 2.6.i<br>
<p>
iQCzAgUBMu12eX03wfSpid95AQHLIwTvdLuWei7652he2M7MImauHR0I/wPSY9BH<br>
lDDPxk5qtzXRSYKAiC9TnNpFFIZOxoEfMlU0OTUWVbJbbaUt1+Z6qYYD3WwCDA8y<br>
s+H8Xp2VKsuddPRVmsyffUkxmvO1+3CovmrLbCMiAgkWG6D5UQzHucU62ogJ+hcS<br>
kmpM5QImqmNR0C6Fmlbwrk6pxocAmgB9O6A00tddS6EAzyqL7R0=<br>
=ROew<br>
-----END PGP SIGNATURE-----<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1485.html">Mitchell Porter: "NEURO/IA: "Brain Not Evolving Any Time Soon""</a>
<li> <b>Previous message:</b> <a href="1483.html">Hara Ra: "Re: Von Neumann's Blunder"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
