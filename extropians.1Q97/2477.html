<!-- received="Mon Feb 10 18:41:25 1997 MDT" -->
<!-- sent="Mon, 10 Feb 1997 16:39:48 -0800" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="PHIL/AI: Humongous Lookup Table" -->
<!-- id="199702110039.QAA00641@crypt.hfinney.com" -->
<!-- inreplyto="" -->
<title>extropians: PHIL/AI: Humongous Lookup Table</title>
<h1>PHIL/AI: Humongous Lookup Table</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Mon, 10 Feb 1997 16:39:48 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2477">[ date ]</a><a href="index.html#2477">[ thread ]</a><a href="subject.html#2477">[ subject ]</a><a href="author.html#2477">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2478.html">mlbowli1@cord.iupui.edu: "localized drug delivery to brain"</a>
<li> <b>Previous message:</b> <a href="2476.html">Michael Lorrey: "Re: Universal Schelling points (was SPORT: Ready? . . . Break!)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2480.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2480.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2498.html">Max More: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2500.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2510.html">Gregory Houston: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2520.html">Max More: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2526.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2530.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2541.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2543.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2683.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2687.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2688.html">postmaster: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2720.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2729.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
From: Eliezer Yudkowsky &lt;sentience@pobox.com&gt;<br>
<i>&gt; [...]</i><br>
<i>&gt; I can PROVE that a giant</i><br>
<i>&gt; hashtable-thermostat can maximize anything a computational mind can. </i><br>
<i>&gt; I.e. REALLY BIIG (but less than 3^^^3) lookup table, duplicates inputs</i><br>
<i>&gt; and outputs, no mind, but works as well.</i><br>
<p>
I had a new (to me) idea about this old puzzle.<br>
<p>
For people who have not run into it, the humongous (slang for huge) lookup<br>
table is a device which should be able to pass the Turing test, while being<br>
simple enough in design that it is hard to understand how it could be<br>
conscious.  It is often presented as a challenge to the validity of the<br>
Turing test.<br>
<p>
As I understand the HLT concept, it would be a table which is indexed by<br>
"the conversation so far" and produces "the next response".  You could<br>
create an HLT by running all possible conversations through a conscious<br>
computer program and recording its output for each conversation.  (We will<br>
ignore the practical impossibility of running so many simulations.)<br>
The resulting table would be truly humongous, since the number of possible<br>
conversations is astronomically large.<br>
<p>
Once the table is created, though, it is easy to use, a simple matter of a<br>
single lookup per response.  You can sit down and converse with the table,<br>
and have an intelligent conversation with this seemingly mindless device.<br>
<p>
My idea is to suggest that you're not "really" conversing with the table.<br>
I have an electronic device on my desk, smaller than a shoebox, with which<br>
I can have an intelligent conversation.  It converses in natural English<br>
and easily passes the Turing test.  It is my telephone.<br>
<p>
The telephone isn't a challenge to the Turing test because we know that<br>
we're not really talking with the telephone.  We're talking with the<br>
person on the other end of the line.  The telephone is just a conduit,<br>
a channel, to the person we're really talking to.<br>
<p>
I think that the HLT can be thought of in the same way.  It is a conduit<br>
to the person or program which was used to create the HLT.  When we talk<br>
to the HLT, we're really talking to that program.<br>
<p>
This is a little different from the telephone because the HLT is in<br>
effect a channel into the past.  The reactions which the program had to<br>
our conversation, and which were recorded as its reactions in the HLT,<br>
have already occured when we talk.  Still, the mental picture I form of<br>
the person I am talking to is real.  It doesn't exist now, but it did<br>
exist in the past, just in the form I am imagining it.  So I think this<br>
justifies thinking of the HLT as being just a channel between that mind<br>
and my own.<br>
<p>
In this light, the HLT is not really a challenge to the Turing test because<br>
we're not really talking to the HLT at all.  The HLT attracts our attention<br>
so that we forget about the program which was used to create it.  That is<br>
where the mind actually is.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2478.html">mlbowli1@cord.iupui.edu: "localized drug delivery to brain"</a>
<li> <b>Previous message:</b> <a href="2476.html">Michael Lorrey: "Re: Universal Schelling points (was SPORT: Ready? . . . Break!)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2480.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2480.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2498.html">Max More: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2500.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2510.html">Gregory Houston: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2520.html">Max More: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2526.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2530.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2541.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2543.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2683.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2687.html">Hara Ra: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2688.html">postmaster: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2720.html">Michael Lorrey: "Re: PHIL/AI: Humongous Lookup Table"</a>
<li> <b>Maybe reply:</b> <a href="2729.html">CurtAdams@aol.com: "Re: PHIL/AI: Humongous Lookup Table"</a>
<!-- reply="end" -->
</ul>
