<!-- received="Fri Feb  7 07:35:40 1997 MDT" -->
<!-- sent="Sun, 02 Feb 97 02:09:54 GMT" -->
<!-- name="N.BOSTROM@lse.ac.uk" -->
<!-- email="N.BOSTROM@lse.ac.uk" -->
<!-- subject="Attractors and Values" -->
<!-- id="9701078553.AA855351172@ccgw9.lse.ac.uk" -->
<!-- inreplyto="" -->
<title>extropians: Attractors and Values</title>
<h1>Attractors and Values</h1>
<i>N.BOSTROM@lse.ac.uk</i><br>
<i>Sun, 02 Feb 97 02:09:54 GMT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2337">[ date ]</a><a href="index.html#2337">[ thread ]</a><a href="subject.html#2337">[ subject ]</a><a href="author.html#2337">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2338.html">N.BOSTROM@lse.ac.uk: "Moravecian platonism (was: Mental vs. Physical)"</a>
<li> <b>Previous message:</b> <a href="2336.html">Anders Sandberg: "Re: Mental vs. Physical"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
          Not all interesting statements about the future need to be <br>
          specific. Suppose, for example, that we want to claim that <br>
          all advanced civilisations tend to approach some common <br>
          ideal state, but that we don't want to commit ourselves to <br>
          exactly what this state is. Well, why not define a <br>
          convergence thesis, saying that the possible civilisations <br>
          trajectories through configuration space tend to converge in <br>
          the positive time direction. This expresses an interesting <br>
          form of sociological/technological determinism (one that <br>
          doesn't have anything to do with physical determinism on the <br>
          microlevel).<br>
                As it stand, the convergence hypothesis is quite <br>
          unsatisfactory, however. It is instructive to think about <br>
          how we could begin to refine and sharpen it.<br>
                We could begin by clarifying what we mean by <br>
          "possible" civilisation. We could mean every civilisation <br>
          that is consistent with physical laws, excluding boundary <br>
          conditions; but something that is more restrictive might be <br>
          more fruitful. So we could say that the "possible" <br>
          civilisations are all possible civilisations that are <br>
          compatible with what we know about our civilisation; the <br>
          idea being that we are interested in what might happen to <br>
          the human civilisation and that we say something about that <br>
          by saying that all possible civilisations, which have all <br>
          properties we know that the human civilisation has, will all <br>
          share the same long term fate. We might then want to soften <br>
          this a bit by modifying it to "almost all of the reasonably <br>
          probable specifications of human civilisations (modulo our <br>
          knowledge) will share a similar long term fate". -Still very <br>
          much too vague, but a step in the right direction. We might <br>
          go on to decide how long the "long term" is supposed to be, <br>
          and who "we" shall be taken to refer to (you and me? the <br>
          intellectual elite? all living humans?), and how similar the <br>
          shared fates are supposed to be, etc. Needless to say, we <br>
          are not aiming at mathematical precision here, that would be <br>
          to shoot far above the goal.<br>
                An interesting variant is to extend the denotation of <br>
          the "possible civilisations" to include not only possible <br>
          civilisations that could turn out to be our but also other <br>
          possible civilisations that are sufficiently advanced. We <br>
          might want to say something like "Almost all civilisations, <br>
          once they have become sufficiently advanced, will become <br>
          even more advanced, and as they advance they will become <br>
          more and more similar in most important aspects.". Add a <br>
          little precision, and you would have formulated an <br>
          interesting proposition.<br>
                There are other flavours of the convergence thesis. We <br>
          might be interested in a thesis that says that all possible <br>
          civilisations into which we could transform our civilisation <br>
          will share a similar fate. (If that were true, we would be <br>
          powerless to change the world in the long run.) Here it is <br>
          very important to specify what we mean by "we". For example, <br>
          if "we" were all living humans, then we could easily <br>
          transform our society into one in which no crimes were <br>
          committed -and that might be a good idea-, but if "we" <br>
          refers to you and me, then we can't do that. (I find that <br>
          discussions about politics often suffer from a lack of <br>
          relativisation of policy to agents: what should you do? what <br>
          should your interest group do? what should your country do? <br>
          what should civilised educated people do? - it is hopeless <br>
          to try to work out a good policy in general; one can only <br>
          make a good policy for such and such agents in such and such <br>
          situations, (given such and such aims).)<br>
                One rival hypothesis would be the divergent track <br>
          hypothesis, according to which the future trajectories will <br>
          divide up into a small number (3 2) of diverging clusters, <br>
          the trajectories within each cluster tending to converge. It <br>
          is slightly misleading here to speak of converging <br>
          trajectories; what is meant is rather "routes of development <br>
          of civilisations tending toward the same goal-state". As an <br>
          illustration, take the following somewhat ludicrous story. <br>
          Some deep investigation reveals that in each possible <br>
          civilisation similar to ours in certain specified ways, <br>
          there will emerge either one or the other of two religions, <br>
          A and B, with roughly equal probability. These religions <br>
          will be such as to inspirit their adherents with such zeal, <br>
          cohesion and adaptability that they will eventually come to <br>
          dominate the culture in which they arise. Having obtained <br>
          local power, they will employ new technologies (drugs, <br>
          electrodes etc. etc. ) to cement their old strongholds and <br>
          to win converts from other groups as well. The stronger <br>
          these religions become, the better they are able to optimise <br>
          their strategy. Thus a positive feedback loop sets in and <br>
          soon leads to total domination on earth. Then the religions <br>
          embark on the project of transforming as much of cosmos as <br>
          they can into the structures on which they place most <br>
          values; perhaps they generate the cosmic equivalent of the <br>
          Tibetean prayer wheels, giant ultra-centrifuges rotating <br>
          trillions of  inscriptions of "Gloria in excelsis Deo A" or <br>
          "Deo B" as the case might be. All civilisations in which one <br>
          of these religions emerges, will converge in some sense: <br>
          they will all lead to the rapid transformation of earth and <br>
          the gradual transformation of cosmos into the specific value <br>
          structures of the religion in question, although the timing <br>
          and precise execution may vary somewhat between different <br>
          possible civilisations.<br>
                In this case, one could say that the artefactual <br>
          configuration space of the universe (i.e. its configuration <br>
          with respect to its content of artefacts; two universes are <br>
          in the same artefactual state iff they contain identical <br>
          artefacts) will have two attractors: world dominion of <br>
          religion A or of religion B. Moreover, we could say that the <br>
          paths toward the attractor centre are quite uniform over all <br>
          realistic directions of approach. When this is the case, we <br>
          say that the artefactual configuration space contains <br>
          tracks, courses of development such that once a civilisation <br>
          has begun to travel along them, it is unlikely that it will <br>
          diverge from them barring major external event <br>
          interposition.<br>
                 We are now in a position to formulate and argue for <br>
          an interesting hypothesis about the future's topology: the <br>
          track hypothesis, saying that the artefactual configuration <br>
          space for all civilisations roughly comparable to present <br>
          human civilisation contains trenchant tracks in the future <br>
          direction, either one track or a small number of them.<br>
                The outlines of some fragments of the argument for <br>
          this claim (a full exposition would presumably require <br>
          book-length treatment) could begin to be drawn as follows. <br>
          As progress is made in science, technology, infrastructure, <br>
          economic structure etc., this will have the effect of making <br>
          us more effective. New technologies will increase our power; <br>
          augmented cognitive capacities (whether through &gt;AI or <br>
          through mere extension of present systems such as science, <br>
          education, information technology etc.), will increase our <br>
          understanding of the consequences of using this power in <br>
          various ways. The result of this is that we will have <br>
          increased ability to make reality conform to our desires. <br>
          There is no reason why we shouldn't also be able to mould <br>
          our desires according to our higher-order desires. Thus, if <br>
          are only a few highest-level desires that are genuinely held <br>
          by large number of influential agents, then, it might be <br>
          argued, there are only a few attractors into which our <br>
          civilisation could sink, and if it could be established that <br>
          the approach to any of these attractors would tend to be <br>
          rather uniform over all realistic directions of approach, <br>
          then we would have found that our future-topology contains <br>
          so many tracks, and we would have made a case for the track <br>
          hypothesis.<br>
                One could then go on to list some prima facie <br>
          plausible basic goals or values. (Basic ones, not values <br>
          such as playing golf, for those who value that activity <br>
          presumably does so because they think it is fun; but if, <br>
          e.g., they could have much more fun by having their reward <br>
          centres directly stimulated chemically or electronically, <br>
          without any ill side effects, then there is no reason to <br>
          suppose that they would insist on continuing the golf.) Here <br>
          are some out of the hat: (1) maximal total pleasure <br>
          (hedonism); (2) average of present human meta-desires <br>
          ("humanism"); (3) maximal consciousness, pure consciousness, <br>
          religious experiences, wonderful deep experiences <br>
          ("spiritualism"); (4) maximal reproduction ("Darwinism", <br>
          could this be argued for on Darwinistic grounds if several <br>
          competing value systems are present? -Hanson (1994)); (5) <br>
          maximal practical utility, such as safety, computational <br>
          power etc. ("pragmatism"); (6) annihilation, voluntary or <br>
          involuntary (nihilism). Involuntary annihilation is not a <br>
          value, but a very real possibility anyway; it's a plausible <br>
          candidate for being one of the tracks in our <br>
          future-topology.<br>
          <br>
          Nicholas Bostrom              n.bostrom@lse.ac.uk<br>
          <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2338.html">N.BOSTROM@lse.ac.uk: "Moravecian platonism (was: Mental vs. Physical)"</a>
<li> <b>Previous message:</b> <a href="2336.html">Anders Sandberg: "Re: Mental vs. Physical"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
