<!-- received="Sun Jan 19 19:25:56 1997 MDT" -->
<!-- sent="Sun, 19 Jan 1997 20:20:34 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Meme: A call for help" -->
<!-- id="199701200208.TAA24729@primenet.com" -->
<!-- inreplyto="Meme: A call for help" -->
<title>extropians: Re: Meme: A call for help</title>
<h1>Re: Meme: A call for help</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 19 Jan 1997 20:20:34 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#918">[ date ]</a><a href="index.html#918">[ thread ]</a><a href="subject.html#918">[ subject ]</a><a href="author.html#918">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0919.html">Eliezer Yudkowsky: "Re: AI: Relative difficulty (Was: SCI:BIO: raw genome length)"</a>
<li> <b>Previous message:</b> <a href="0917.html">Natasha V. Mor: "ART: Extropic Art Manifesto"</a>
<li> <b>Maybe in reply to:</b> <a href="0909.html">Dan Fabulich: "Meme: A call for help"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0962.html">Dan Fabulich: "Re: Meme: A call for help"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
[Saith Dan Fabulich:]<br>
<i>&gt; I don't like any of this.  But this has been a problem that I've been</i><br>
<i>&gt; fighting with for most of my life.  I'm not here to argue that religion</i><br>
<i>&gt; is better than healthy criticism and spontaneous order.  I don't think</i><br>
<i>&gt; that.  But in the face of what's out there, how can I, and others like</i><br>
<i>&gt; me, fight a meme of centralization which may be fundamentally more</i><br>
<i>&gt; powerful than the one I'm trying to spread, simply by virtue of the fact</i><br>
<i>&gt; that the meme I'm spreading can never be a dogma?  Can this meme ever</i><br>
<i>&gt; surpass authoritarianism?</i><br>
<p>
[Trans (?):  Authoritarian memes have better survive/rep chances than<br>
Extropianism, because Extropianism consciously rejects many memetic<br>
survival strategies.]<br>
<p>
It depends.  Suppose Extropian memes start receiving nationwide<br>
attention, without any attempt on our part to control the memetic<br>
evolution.  People will take the parts of Extropianism that appeal to<br>
them, such as immortality and material omnipotence, ignore the parts<br>
that they don't like, such as intelligence enhancement or<br>
Libertarianism, and *add* parts of their own, such as a belief that the<br>
Universe is divided into "Extropic" good-guys and "Entropic" bad-guys,<br>
and that the good guys (us) are being victimized by some group<br>
(lawyers?), and so on.<br>
<p>
What I'm trying to say is that memes *mutate* over time.  If<br>
unadulterated Extropianism isn't popular, it *will* mutate into<br>
something that is.  Not, perhaps, in stages as drastic as those depicted<br>
above.<br>
<p>
Can Extropianism win?  From my perspective, no, frankly, because like<br>
the Marxists, you offer nothing to replace the energies you have<br>
removed.  In Marxism, they took away the profit-motive and didn't<br>
replace it, so nothing got done.  If you remove all moralizing and<br>
self-righteousness and coercion and victimization and resentment and so<br>
on, nothing is left to propel the meme forward.  Extropianism isn't<br>
quite so morality-free, which is why it survives, but it still has<br>
nothing to replace the power-engines it has forsaken.<br>
<p>
I believe that the best strategy is first (step one) to elevate the<br>
truth, small "t", above everything else.  This step is equivalent to<br>
getting the member of a disliked religion to be willing, emotionally, to<br>
stake his beliefs on a a matter of fact.  Quote from an unpublished<br>
piece:<br>
<p>
<i>&gt; It's sort of like the attitude we take in science, when we aren't</i><br>
<i>&gt; afraid to test our theories, and we don't make up excuses in advance</i><br>
<i>&gt; for when they fail. Because our theories won't fail. They are right.</i><br>
<i>&gt; Why make excuses for them? A scientist who is afraid to perform an</i><br>
<i>&gt; experiment because he thinks the evidence will come out the other</i><br>
<i>&gt; way doesn't believe in his theory. Science requires a faith even</i><br>
<i>&gt; greater than that of religion. Science requires that we believe in our</i><br>
<i>&gt; theories so strongly that we can happily stake our beliefs on the</i><br>
<i>&gt; outcome of an experiment, because we know it will come out our</i><br>
<i>&gt; way, and if it doesn't come out our way, then we're wrong and that's</i><br>
<i>&gt; all there is to it.</i><br>
<i>&gt; </i><br>
<i>&gt; A lot of supposedly religious people don't believe at all. Suppose that</i><br>
<i>&gt; a time camera was invented, capable of looking into the past. If</i><br>
<i>&gt; you're a religious person, you would probably claim to believe that</i><br>
<i>&gt; certain events took place at 1 A.D. or 3200 B.C. or whatever. Suppose</i><br>
<i>&gt; that an atheist hands you a time camera and says, "Let's settle this</i><br>
<i>&gt; once and for all. We'll look back at Mt. Sinai and see if Moses really</i><br>
<i>&gt; received the Bible there. If Moses is there and he receives the Ten</i><br>
<i>&gt; Commandments from God, I convert to your religion, and if there's</i><br>
<i>&gt; just a mountain, you become an agnostic." I'm sure that most</i><br>
<i>&gt; atheists would be happy to make such a bargain, because they're</i><br>
<i>&gt; sure they won't have to pay up, and if they do have to pay up, they</i><br>
<i>&gt; were wrong anyway.</i><br>
<p>
[This argument is not itself morality-free.  It challenges the reader by<br>
saying:  "You don't really believe."  But, the argument is *true*:  Many<br>
people *don't* really believe, and they *wouldn't* stake their faith on<br>
a prediction of their religious theories.  I may object to morality as<br>
an integral part of *theories*, but I don't object to it as part of<br>
arguments used to wean others from morality-based theories.  As long as<br>
the arguments are true!  As long as some readers really will be guilty<br>
of what you accuse them of, or as long as a genuine wrong *is* being<br>
committed!]<br>
<p>
Step two:  Try to convince them that morality-based arguments are<br>
inferior to rational thought.  This may take some doing.  Point out that<br>
science is the denial of morality; that all morality-based soft<br>
"sciences" never work, that morality is the foundation of politics, and<br>
so on.  Above all, attack the foundations of morality through cognitive<br>
science; explain what the moral emotions are and why they're there and<br>
why we shouldn't trust them.<br>
<p>
Steps three through seventeen are left as an exercise to the reader.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0919.html">Eliezer Yudkowsky: "Re: AI: Relative difficulty (Was: SCI:BIO: raw genome length)"</a>
<li> <b>Previous message:</b> <a href="0917.html">Natasha V. Mor: "ART: Extropic Art Manifesto"</a>
<li> <b>Maybe in reply to:</b> <a href="0909.html">Dan Fabulich: "Meme: A call for help"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0962.html">Dan Fabulich: "Re: Meme: A call for help"</a>
<!-- reply="end" -->
</ul>
