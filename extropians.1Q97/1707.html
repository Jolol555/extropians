<!-- received="Thu Jan 30 13:13:13 1997 MDT" -->
<!-- sent="Thu, 30 Jan 1997 11:54:25 -0800 (PST)" -->
<!-- name="The Low Willow" -->
<!-- email="phoenix@ugcs.caltech.edu" -->
<!-- subject="Re: Humanrintelligences' motivation (Was: Superintelligences' motivation)" -->
<!-- id="199701301954.LAA08019@off.ugcs.caltech.edu" -->
<!-- inreplyto="nv91-asa@nada.kth.se" -->
<title>extropians: Re: Humanrintelligences' motivation (Was: Superintelligences' motivation)</title>
<h1>Re: Humanrintelligences' motivation (Was: Superintelligences' motivation)</h1>
The Low Willow (<i>phoenix@ugcs.caltech.edu</i>)<br>
<i>Thu, 30 Jan 1997 11:54:25 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1707">[ date ]</a><a href="index.html#1707">[ thread ]</a><a href="subject.html#1707">[ subject ]</a><a href="author.html#1707">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1708.html">Eliezer Yudkowsky: "Re: Linguist's Of The Apocalypse, unite!"</a>
<li> <b>Previous message:</b> <a href="1706.html">Ray Peck: "Re: Software virtues into AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Jan 30,  2:40pm, Anders Sandberg wrote:<br>
<p>
} and you will end up with "Who watches the watchmen?". Another possibility <br>
} would be an automated "immune system" against nanotech, but even if it <br>
} would work well, there are always other dangers. <br>
 <br>
} Most likely the only stable way of preventing widespread disaster is <br>
} dispersion.<br>
 <br>
For defense against bio and nano immune systems probably are the best<br>
way to go.  Best would be mutable systems that could be changed to small<br>
or large degrees.  It would be unlikely that anyone could be certain<br>
they were protected against everything, but you wouldn't worry about<br>
plagues, because there woouldn't be a common system to infect.  The<br>
ultimate case for diversity: if all your neighbors are alien freaks then<br>
you're unlikely to ever get ill, because nothing that infects them will<br>
infect you.  Security in the High Beyond is largely cryptology and<br>
immunology, especially combined.<br>
<p>
I don't have any bright ideas for defense against Really Big Explosions.<br>
(Nukes, asteroids, solar flares, etc.)<br>
<p>
Merry part,<br>
 -xx- Damien R. Sullivan X-) &lt;*&gt; <a href="http://www.ugcs.caltech.edu/~phoenix">http://www.ugcs.caltech.edu/~phoenix</a><br>
<p>
Be not a beauty proud or vain,<br>
For mortal maid it will be your bane.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1708.html">Eliezer Yudkowsky: "Re: Linguist's Of The Apocalypse, unite!"</a>
<li> <b>Previous message:</b> <a href="1706.html">Ray Peck: "Re: Software virtues into AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
