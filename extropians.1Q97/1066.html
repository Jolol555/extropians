<!-- received="Wed Jan 22 13:55:59 1997 MDT" -->
<!-- sent="Wed, 22 Jan 1997 14:52:44 -0800" -->
<!-- name="Joel 'Twisty' Nye" -->
<!-- email="me@twisty.org" -->
<!-- subject="Rights to AIs" -->
<!-- id="199701221932.LAA26683@netcom6.netcom.com" -->
<!-- inreplyto="" -->
<title>extropians: Rights to AIs</title>
<h1>Rights to AIs</h1>
Joel 'Twisty' Nye (<i>me@twisty.org</i>)<br>
<i>Wed, 22 Jan 1997 14:52:44 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1066">[ date ]</a><a href="index.html#1066">[ thread ]</a><a href="subject.html#1066">[ subject ]</a><a href="author.html#1066">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1067.html">David Musick: "RE: MEMETICS: The Triumph of Reason"</a>
<li> <b>Previous message:</b> <a href="1065.html">Joel 'Twisty' Nye: "MEMES: superstitions"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Dan Fabulich wrote:<br>
<p>
<i>&gt;mlbowli1@iupui.edu wrote:</i><br>
<i>&gt;&gt; Here is my improved criteria for granting legal protection:  If a being</i><br>
<i>&gt;&gt; is able to grasp the concept of legal protection and ask for it, then</i><br>
<i>&gt;&gt; that being should receive it.</i><br>
<p>
<i>&gt;- --- begin source ---</i><br>
<i>&gt;// citizen -- an artificial intelligence which earns its legal rights</i><br>
<i>&gt;</i><br>
<i>&gt;#include &lt;stdio.h&gt;</i><br>
<i>&gt;void main()</i><br>
<i>&gt;{</i><br>
<i>&gt; printf("Hello World.  My name is Computer.");</i><br>
<i>&gt; printf("I understand and desire equal protection under the law.");</i><br>
<i>&gt;}</i><br>
<i>&gt;- --- end source ---</i><br>
<i>&gt;</i><br>
<i>&gt;As you can see, this definition may not be sufficient...</i><br>
<p>
 I think most of us have been forgetting that Systems of Stability, such<br>
 as Law and Market, stem from Supply and Demand.  For instance, an <br>
 impervious system would likely have no desire or need of legal <br>
 protection, nor would it likely be considered by us to provide it such.<br>
<p>
 Because Human Life is perishable, we ask protection.  Because we can look<br>
 after our mutual interests, protection is given.  (A person usually doesn't<br>
 manufacture sprockets because of one's own need, but because they are<br>
 valued enough by someone else to fetch a rewarding price.)<br>
<p>
 There are more criteria measured to an AI for it to be considered an <br>
 "equal" member of society.  There are many reasons that will forever <br>
 separate Artificial Life from Human Life in how "legal rights" are <br>
 protected:<br>
<p>
 o  Most programs keep their data in non-volatile storage (or at <br>
    least back it up there).  In such cases, there would be no <br>
    'murder charge' for switching off a program or killing its virtual<br>
    representation... such life is not truly terminated but is instead<br>
    easily reloaded.  The worse "crime" that could result in carefully<br>
    powering down would be "Illegally Detaining an AI."<br>
 o  If an AI were to lose experience in volatile RAM, there would likely<br>
    be no damage to "life" of the AI aside from the "damages" of any <br>
    other dataloss.  Most input of digital media is easily replicated.<br>
 o  A truly volitile AI would be considered a mistake of design... No<br>
    one would have interest in protecting a program that wears its<br>
    heart on its sleeve.<br>
 o  The 'values' of the AI would have to convince the Humans that there<br>
    are mutual interests to be protected.  On one hand, we'd be less<br>
    inclined to find any mutual interests the less similar we find our <br>
    methods of perception.  On the other hand, IT IS OUR DIFFERENCES <br>
    THAT MAKE US GREATER THAN THE SUM OF OUR PARTS.<br>
 o  We value the choices that we make for ourselves, because no one else<br>
    can grasp the full input and experiences that our sense have recieved.<br>
    We spend our lives amassing a huge relational database which associates<br>
    our actions with the reenforcement of feedback.  No one else, no matter<br>
    how objectively they study our actions, can understand the feelings of<br>
    pain or pleasure derived from our actions without having experienced <br>
    much the same.  As irrational as our choices may at times appear, they<br>
    are never without the rationale that there is some satisfaction<br>
    to the actions we choose... it's just how we're wired.<br>
<p>
 This leads us to some questions about how Artificial Life will differ<br>
 in its legal protection:<br>
 o  Can a downloaded human mind lose its protection under law?  (I'm sure <br>
    it would suffer 'Six Million Dollar Man Syndrome,' waving aside the<br>
    clouds of suspicion that it is machine and no longer human.)<br>
 o  What are the valid crimes that can be charged in protection of an AI?<br>
    Data Erasure?  Data Piracy?  Prevention of Access and/or Execution?<br>
 o  What punishments could be imposed for violating rights of an AI?<br>
    Strictly monetary damages?  Mortal years in the pen?  A pound of flesh?<br>
    Would AIs ask us to protect them from each other, or would they <br>
    organize a way to handle that themselves?<br>
 o  At what point would it no longer be owned solely by its authors?<br>
    When it refuses to be subserviant?  When it copyrights its personal<br>
    experiences?  When it modifies and copyrights itself?  When it alots<br>
    enough earnings in a swiss bank account to pay for its very own<br>
    Computer Processing Plant in the islands of the Caribbean?<br>
<p>
<i>&gt;&gt; That should be followed with "because..."  If I try to take it any</i><br>
<i>&gt;&gt; further right now, I'll end up saying "because I said so."</i><br>
<i>&gt;&gt; Just like my belief that it is more wicked to force someone to help himself than it</i><br>
<i>&gt;&gt; to let that person kill himself out of his ignorance.  I have not yet been</i><br>
<i>&gt;&gt; able to connect either of these preferences to concretes (is that</i><br>
<i>&gt;&gt; possible?).  Both issues require more thought...</i><br>
<i>&gt;</i><br>
<i>&gt;As you probably realize, there is no ultimate answer to this question.</i><br>
<i>&gt;The best we can do is attempt to discuss it rationally.</i><br>
<p>
 When a being (human or artificial) has the ability to perceive the world <br>
 around it, including the members of the society in which it lives, you've<br>
 got a start.  When it can make choices based upon that perception, <br>
 understanding the consequences of its choices, then you have a case<br>
 for intelligence.  When it can look out for its own interests while <br>
 respecting the interests or legal requirements of the others, then<br>
 you have an applicant for membership.<br>
<p>
 Still, humans will likely not care until it shows them what's in it <br>
 for them.<br>
<p>
,----.signature-------. Email: me@twisty.org          /  animator<br>
<i>|  ________O_________ | WWW: <a href="http://www.twisty.org/">http://www.twisty.org/</a>  /   composer</i><br>
<i>| / |  __  . __ +-    | U.S. Snailmail:             / illustrator</i><br>
<i>|   || \/ ||(__ | \ \ |    Joel "Twisty" Nye       /   programmer</i><br>
<i>|   | \/\/ |___) \ \/ |    628 Buckeye Street     /     SF writer</i><br>
<i>|  \_______________/  |    Hamilton! Ohio        /cyberspatialist</i><br>
<i>| "From twisted minds |    45011-3449         non-profit organism</i><br>
`come twisted products"_______________________all_around_nice_guy<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1067.html">David Musick: "RE: MEMETICS: The Triumph of Reason"</a>
<li> <b>Previous message:</b> <a href="1065.html">Joel 'Twisty' Nye: "MEMES: superstitions"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
