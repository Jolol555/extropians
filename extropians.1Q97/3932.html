<!-- received="Mon Mar 24 18:09:17 1997 MDT" -->
<!-- sent="Mon, 24 Mar 1997 15:54:22 -0800 (PST)" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@hss.caltech.edu" -->
<!-- subject="What is to be done?" -->
<!-- id="199703242354.PAA26463@hss.caltech.edu" -->
<!-- inreplyto="" -->
<title>extropians: What is to be done?</title>
<h1>What is to be done?</h1>
Robin Hanson (<i>hanson@hss.caltech.edu</i>)<br>
<i>Mon, 24 Mar 1997 15:54:22 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3932">[ date ]</a><a href="index.html#3932">[ thread ]</a><a href="subject.html#3932">[ subject ]</a><a href="author.html#3932">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3933.html">Robert Schrader: "Re: Intellectual property"</a>
<li> <b>Previous message:</b> <a href="3931.html">Lee Daniel Crocker: "Re: Intellectual property"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
An anonymous poster says:<br>
<i>&gt;The overwhelming majority of intelligent and well-educated people to whom I</i><br>
<i>&gt;attempt to explain transhumanism react negatively.  ...</i><br>
<i>&gt;The fact is that we are a tiny minority among a tiny minority.  ...</i><br>
<p>
I think it is very important to develop good models of why this happens.<br>
("They laughed at Galileo too" is *not* an especially good model.)<br>
I strongly disagree with those who have said we should ignore <br>
critics because they'll just distract us or depress us or whatever.<br>
The rest of this long post is devoted to this question.<br>
<p>
Consider these 3 reasons why someone might take an extreme view:<br>
1.  They like to be extreme so they can shock people and feel special.<br>
2.  They have to reason through everything for themselves from basics,<br>
    and refuse to rely in any way on the opinions of others.  A small <br>
    fraction of these people will inevitably take an extreme view.<br>
3.  They take the opinions of others seriously as an important source<br>
    of information, and only take an extreme position when they think<br>
    they have a particularly unique source of info on the subject, or <br>
    when they think an especially strong but apparently overlooked<br>
    case can be made from publicly available information.<br>
 <br>
It is very easy to and reasonable to discount and ignore the extreme<br>
views of type 1 extremists.  It is also easy to do the same for type 2<br>
extremists if the fraction of them observed is small enough relative<br>
to all type 2 folks.  And segmenting type 2 folks by smarts, it is<br>
also easy to ignore larger fractions of extremists among those people<br>
who don't seem very smart (as evidenced for example by some gross<br>
cognitive blunder).  Type 3 extremists, however, aught to be taken<br>
seriously.<br>
 <br>
So if you want your extreme views to be taken seriously by other<br>
people, you aught to try to look like a type 3 extremist.  And if you<br>
want to make good decisions over all, you aught to try and be a type<br>
3 person.  This means making a good effort to find reasons why smart<br>
thoughtful people might disagree with you.<br>
<p>
<i>&gt;"Extropian libertarianism is naive and simplistic in a juvenile way.  Its</i><br>
<i>&gt;association with Ayn Rand and 'objectivism' will consign it permanently to</i><br>
<i>&gt;the fringe.  A lot of teen agers go through an `Atlas Shrugged phase': How</i><br>
<i>&gt;old did you say most of these people are?"</i><br>
<p>
Here I have to agree with the critics, thought I would say "sophmoric"<br>
rather than "juvenile".  While the policies advocated are reasonable,<br>
the moral axiomatic types of arguments offered *are* sophmoric, i.e.<br>
the sort of thing mostly done by college sophmores (and a few moral<br>
philosophers).  Not that the conclusions don't follow from the axioms,<br>
but that most people don't feel very compelled to accept the axioms.<br>
Thinking that these axioms will persuade very many people also seems a<br>
sophmoric cognitive blunder, and does not encourage people to take the<br>
other extreme views of these folks seriously.<br>
<p>
<i>&gt;"Transhumanism is an immature rejection of reality, a selfish and</i><br>
<i>&gt;self-centered desire to escape from the simple and basic facts of</i><br>
<i>&gt;life. Quit dreaming."</i><br>
<p>
Here I also have to agree with the critics, at least when they refer<br>
to people who expect remarkably rapid progress toward transhuman<br>
technologies in the next few decades.  This stuff will take a while to<br>
appear, and those of us interested in thinking about it anyway are<br>
indulging ourselves to some extent.  <br>
<p>
I have heard a related criticism that anyone who would especially want<br>
to become transhuman is excessively selfish.  And I think such people<br>
*are* more selfish than average, but "excessive" is harder to judge. <br>
<p>
<i>&gt;"Extropians are a bunch of mad scientists who simply haven't studied history.</i><br>
<i>&gt; Rushing into the things they want to do is likely to cause an economic or</i><br>
<i>&gt;ecological disaster.  If there were even the slightest chance any of this</i><br>
<i>&gt;stuff would come into being, I'd be the first to vote to regulate all of it.</i><br>
<i>&gt; Maybe some of this stuff could do some good, but not if you rush into it,</i><br>
<i>&gt;and not if you do it all at once.  Just because you can do something doesn't</i><br>
<i>&gt;mean you should."</i><br>
<p>
I think most of us do *not* propose doing it all at once everywhere.<br>
Those who do so propose are rightly criticized.<br>
<p>
I think the core issue here is the "fragility" and "interdependence"<br>
of our social order.  Those of us who lean toward more decentralized<br>
libertarian policies tend to think of social systems as robust and<br>
relatively independent.  Thus experimenting with a variation on one<br>
social institution in one locale does not greatly threaten everything<br>
else, and the information to be gained outweighs the possible local<br>
harm.  So we favor decentralization to allow variation and selection.<br>
<p>
However, others tend to think of our social systems as fragile and<br>
interdependent, and so think more global oversight and control is<br>
needed to prevent contagion from local experiments from threatening<br>
everything else.  It bothers me that I don't have good arguments<br>
against this view.<br>
<p>
<i>&gt;"Transhumanists want to create a master race, just like the Nazis.  And don't</i><br>
<i>&gt;they think Nietzsche is some sort of intellectual godfather?  What does that</i><br>
<i>&gt;tell you?"</i><br>
<p>
Bottom line is: transhumanists *are* close to Nazis in the sense of<br>
wanting to create better people.  They differ from Nazis in not trying<br>
to achieve this goal by killing off "inferior" people.  But Nazis are<br>
such a reviled prototype that simple heuristic case-based inference<br>
(anything too much reminiscint of Nazis must be bad) *does* make many<br>
people reject the whole enterprize.<br>
<p>
<i>&gt;"Extropians are elitists.  What about the billions of people suffering on the</i><br>
<i>&gt;edge of starvation?  Sounds like they want a bunch of high-tech toys for a</i><br>
<i>&gt;few rich white male Americans that will just make things worse for everybody</i><br>
<i>&gt;else."</i><br>
<p>
Extropians are elitist and selfish in many ways - but most of them<br>
don't think that will hurt others.<br>
<p>
This highlights another core issue: to what degree does social pressure<br>
function to stabilize our social order?  Economists like me, who tend<br>
to ignore social pressure in our models, tend to think that the effect<br>
is minor.  But others see social pressure which keeps people acting<br>
"nice" and punishes very "selfish" behavior as central.  And so they<br>
fear the consequences if this pressure is relaxed.  It bothers me<br>
that I don't have better arguments to say why they are mistaken.<br>
<p>
<p>
Putting this all together here's my image of a reasonable person who<br>
dislikes extropian views:<br>
<p>
"Our social world is complex, fragile, interdependent on large scales,<br>
and relies on social pressure to constrain selfish behavior.  Big<br>
changes threaten to break this system, and so prudence requires<br>
non-local oversight.  You extropians are outliers regarding your<br>
preferences for self over community, change over continuity, and<br>
resistance to social pressure.  Left unconstrained, you would endanger<br>
us all by radically changing our bodies, politics, economies, personal<br>
relations, and everything else.  So we must constrain you."<br>
<p>
My personal response is:  <br>
<p>
Considering how much humanity has changed over the last 50,000 years,<br>
it is hard to think we're terribly fragile.  But yes, changes can be<br>
dangerous.  However, some big changes are coming that humanity seems<br>
both unwilling and unable to stop.  So we need some mature reasonable<br>
people to be thinking about these upcoming changes in some detail.<br>
It turns out that there are a bunch of such people talking about<br>
these details, and many of them hang out under the banner<br>
"extropians".  Yes, since fear tends to freeze thought, people willing<br>
to talk details are biased toward the optimists.  And you should<br>
expect an extreme banner like this to especially attract sloppy<br>
thinkers, people who like to be extreme, and those who think<br>
everything through for themselves.  But relative to these<br>
expectations, I think you'll find a surprisingly large fraction of<br>
very reasonable people under that banner.  <br>
<p>
Robin D. Hanson  hanson@hss.caltech.edu  <a href="http://hss.caltech.edu/~hanson/">http://hss.caltech.edu/~hanson/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3933.html">Robert Schrader: "Re: Intellectual property"</a>
<li> <b>Previous message:</b> <a href="3931.html">Lee Daniel Crocker: "Re: Intellectual property"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
