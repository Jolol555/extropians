<!-- received="Sun Feb  2 12:14:36 1997 MDT" -->
<!-- sent="Sun, 2 Feb 1997 19:45:46 +0100 (MET)" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="Paul M. Churchland end (IV)" -->
<!-- id="Pine.SOL.3.91.970202194248.12167B-100000@sun6" -->
<!-- inreplyto="" -->
<title>extropians: Paul M. Churchland end (IV)</title>
<h1>Paul M. Churchland end (IV)</h1>
Eugene Leitl (<i>Eugene.Leitl@lrz.uni-muenchen.de</i>)<br>
<i>Sun, 2 Feb 1997 19:45:46 +0100 (MET)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2107">[ date ]</a><a href="index.html#2107">[ thread ]</a><a href="subject.html#2107">[ subject ]</a><a href="author.html#2107">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2108.html">J. Daugherty: "RE: Free Will"</a>
<li> <b>Previous message:</b> <a href="2106.html">J. Daugherty: "FW: Memes and Conspiracy"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
subject: Paul M. Churchland end (IV)<br>
<p>
7 The representational power of state spaces<br>
<p>
Discussion so far has been concentrated on the impressive<br>
computational power of coordinate transformations of state spaces,<br>
and on the possible neural implementation of such activity. But it<br>
is important to appreciate fully the equally powerful representational<br>
capacity of neural state spaces. A global circumstance comprised of n<br>
distinct varables can be economically represented by a single point in<br>
an abstract n-dimensional state space. And such a state-space point<br>
can be neurally implemented, in the simplest case, by a specific<br>
distribution of n spiking frequencies in a system of only n distinct<br>
fibres. Moreover, a state-space representation embodies the metrical<br>
relations between distinct possible positions within it, and thus<br>
embodies the representation of _similiarity_ relations between<br>
distinct items thus represented. These claims can be illustrated by<br>
the outputs of several of our sensory organs.<br>
<p>
Consider first a simple case: the human gustatory system has a four-<br>
channel output, with each of the four pathways representing the level<br>
of stimulation at one of the four sets of taste sensors in the mouth,<br>
the so-called sweet, sour, salty, and bitter receptors. Any humanly<br>
possible taste sensation, it is therefore conjectured, is a point<br>
somewhere within a four-dimensional gustatory state space. Or more<br>
literally, it is a quadruple of spiking frequencies in the four<br>
proprietary pathways carrying information from the gustatory<br>
receptors for distribution to the rest of the brain. [ wish I had<br>
a GC/MS combo for input instead, also takes care of the olfaction<br>
-- 'gene]<br>
<p>
A sweet taste, for example, is coded as a specific set of activity<br>
levels across the four pathways (a high value on one, and a low<br>
value on each on the other three). Other combinations of activity<br>
levels yield all of the taste sensations possible for humans. The<br>
qualitative or subjective similiarity of sensations emerges, both<br>
theoretically and experimentally, as the proximity of the relevant<br>
codings within gustatory state-space.<br>
<p>
Such a coding system also gives us an enormous range of<br>
discrimination at a very low price. Just to illustrate the point,<br>
suppose our discrimination of distinct positions (activity levels)<br>
along each of the four axes of gustatory state space is limited<br>
to just ten positions. This gives us an overall four-dimensional<br>
space with fully 10^4 discriminable points. This state-space<br>
approach to gustatory sensations appears in the neuroscience<br>
literature as the _across-fibre pattern_ theory [...].<br>
<p>
An account of this same general kind may old four our olfactory<br>
system, which has six or more distinct types of receptor. A six-<br>
dimensional space, at 10-unit axial discrimination, will permit<br>
the discrimination of 10^6 odors. And if we imagine only a seven-<br>
dimensional olfactory space, with only three times the human<br>
axial discrimination, which space a dog almost certainly possesses,<br>
then we are contemplating a state space with 30^7, or 22 billion,<br>
discriminable positions! Given this, the canines' ability to<br>
distinguish, by smell, any one of the 3.5 billion people on the<br>
planet no longer presents itself as a mystery.<br>
<p>
Consider the human 'module' for facial recognition. We apparently<br>
have one, since the specific ability to recognize faces can be<br>
destroyed by specific right parietal lesions. Here it is plausible<br>
to suggest an internal state-space representation of perhaps<br>
twenty dimensions, each coding some salient facial feature such<br>
as nose length, facial width, and so on. (Police 'Identikits'<br>
attempt to exploit such a system, with some success.) Even if<br>
discrimination along each axis were limited to only five distinct<br>
positions such a high-dimensional space would still have an enormous<br>
volume (=5^20 positions), and it would permit the discrimination<br>
and recognition of billions of distinct faces. It would also<br>
embody similiarity relations, so that close relatives could be<br>
successfully grouped, and so that the same person could be<br>
reidentified in photos taken at different ages. Consider two photos<br>
of the young and the old Einstein. What makes them similiar?<br>
They occupy approximate positions in one's facial state space.<br>
<p>
Finally, let us turn to a motor example, and let us consider<br>
one's "body image": one's continuously updated sense of one's<br>
overall bodily configuration in space. That configuration is<br>
constituted by the simultaneous position and tension of several<br>
hundreds of muscles, and one monitors it all quite successfully,<br>
to judge from the smooth coordination of most of one's movements.<br>
How does one do it? With a high-dimensional state space,<br>
according to the theories of Pellionicz and Llinas, who ascribe<br>
to the cerebellum the job of computing appropriate transformations<br>
among high-dimensional codings of actual and intended motor<br>
circumstances, codings lodged in the input parallel fibers and<br>
the output Purkinje axons.<br>
<p>
[Figure 11: a) Step cycle: feline hind leg. b) Skeletal state<br>
space [Roughly, you see an eadweard muybridge of a stylized<br>
cat's hind limb during one full stride cycle, and an according<br>
scimitar-shaped closed trajectory loop in the joint-angle<br>
space spanned by the hip, knee, ankle angles]]<br>
<p>
Some of the possibilities here can be evoked by a very simple<br>
example. Consider a highly complex and critically orchestrated<br>
periodic motion, such as occurs in feline locomotor activity<br>
(Figure 11a). Consider now a three-dimensional joint-angle<br>
motor space for the cat's hind limb, a space in which every<br>
possible configuration of that limb is represented by a point,<br>
and every possible movement is represented by a continuous<br>
path. The graceful step cycle of the galloping cat will be<br>
very economically represented by a closed loop in that joint-<br>
angle state space (figure 11b). If the relevant loop is<br>
specified or "marked" in some way, then the awesome task of<br>
coordinated locomotion reduces to a clear-cut tracking problem:<br>
make your motor state-space position follow the path of that<br>
loop. [ now why must I constantly think of robotics when I<br>
read this passage? Inaudible gliding of position feedback<br>
sensors, hum of motors, digitally homeostased by the dedicated<br>
circuitry containing and executing the binary pattern, the<br>
control automaton network -- 'gene]<br>
<p>
Once we have taken the step beyond the coginitiv significance<br>
of points in two-dimensional state space to the cognitive<br>
significance of lines and closed loops in n-dimensional state<br>
spaces, it seems possible that we will also find cognitive<br>
significance in surfaces, and hypersurfaces, and intersection<br>
of hypersurfaces, and so forth. What we have opening before us<br>
is a "geometrical," as opposed to a narrowly syntactic, conception<br>
of cognitive activity.<br>
<p>
8 Concluding remarks<br>
<p>
We have seen how a representation scheme of this kind can account,<br>
in a biologically realistic fashion, for a number of important<br>
features of motor control, sensory discrimination, and sensorimotor<br>
coordination. But has it the resources to account for the so-called<br>
higher cognitive activities, as represented by language use, for<br>
example, and by our propositional knowledge of the world in general?<br>
<p>
Conceivably, yes. One might try to find, for example, a way of<br>
representing "anglophone linguistic hyperspace" so that all<br>
grammatical sentences turn out to reside on a proprietary<br>
hypersurface within that hyperspace, with the logical relations<br>
between them reflected as spatial relations of some kind. I do<br>
not know how to do this, of course, but it holds out the<br>
possibility of a alternative to, or potential reduction of,<br>
the familiar Chomskyan picture.<br>
<p>
As for the "set of beliefs" that is commonly supposed to constitute<br>
a person's knowledge, it may be that a geometrical representation<br>
of sentences will allow us to solve the severe problem of "tacit<br>
belief" [...]. Just as a hologram does not "contain" a large<br>
number of distinct three-dimensional images, curiously arranged<br>
so as to present a smoothly changing picture of a real object<br>
as the hologram is viewed from different positions, so may humans<br>
not "contain" a large number of distinct beliefs, curiously arranged<br>
so as collectively to present a coherent account of the world.<br>
<p>
Perhaps the truth is rather that, in both cases, a specific image<br>
or belief is just an arbitrary projection or "slice" of a deeper set<br>
of data structures, and the collective coherence of such sample<br>
slices is a simple consequence of the manner in which the global<br>
information is stored at the deeper level. It is not a consequence<br>
of, for example, the busywork of some fussy inductive machine<br>
applying inductive rules for the acceptance or rejection of discrete<br>
slices taken singly. Which means that, to understand learning, we<br>
may have to understand the forces that dictate directly the evolution<br>
of the global data structures at the deeper level. The learning<br>
algorithm of Rumelhart, Hinton, and Williams comes to mind again<br>
here, for in a network of that sort no symbols of any kind are being<br>
manipulated. Rather, in the course of a training session a function<br>
is progressively approximated, and the information the network<br>
acquires is stored in nothing more contentful than a distributed<br>
set of synapse-like weights.<br>
<p>
These highly speculative remarks illustrate one direction of<br>
research suggested by the theory outlined in this paper: just what<br>
are the abstract representational and computational capacities<br>
of a system of state spaces interacting of coordinate transformations?<br>
Can we use a system of state spaces to articulate models for the<br>
"higher" forms of cognitive activity? The theory also begs research<br>
in the opposite direction, towards the neurophysiology of the brain.<br>
Given that the brain is definitely not a "general purpose" machine<br>
in the way that a digital computer is, it may often turn out that,<br>
once we are primed to see them, the brain's localized computational<br>
tactics can simply be read off its microstructure. There is point,<br>
therefore, to studying that microstructure [...].<br>
<p>
Taken jointly, the prodigious representational and computational<br>
capacities of a system of state spaces interacting by coordinate<br>
transformations suggest a powerful and highly general means of<br>
understanding the cognitive activities of the nervous system,<br>
especially since the physical mechanisms appropriate to implement<br>
such a system are widespread throughout the brain.<br>
<p>
[ The "[...]"'s mostly denote copious references to the literature.<br>
  Should I get several persons' demand for the bibliography, I shall<br>
  supplement -- 'gene ]<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2108.html">J. Daugherty: "RE: Free Will"</a>
<li> <b>Previous message:</b> <a href="2106.html">J. Daugherty: "FW: Memes and Conspiracy"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
