<!-- received="Mon Mar 31 13:07:24 1997 MDT" -->
<!-- sent="Mon, 31 Mar 1997 11:59:02 -0800 (PST)" -->
<!-- name="Lee Daniel Crocker" -->
<!-- email="lcrocker@calweb.com" -->
<!-- subject="Re: Protean Self-Transformation" -->
<!-- id="199703311959.LAA13368@web2.calweb.com" -->
<!-- inreplyto="333F5DA3.2FBA@triberian.com" -->
<title>extropians: Re: Protean Self-Transformation</title>
<h1>Re: Protean Self-Transformation</h1>
Lee Daniel Crocker (<i>lcrocker@calweb.com</i>)<br>
<i>Mon, 31 Mar 1997 11:59:02 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4202">[ date ]</a><a href="index.html#4202">[ thread ]</a><a href="subject.html#4202">[ subject ]</a><a href="author.html#4202">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4203.html">John K Clark: "Uploading"</a>
<li> <b>Previous message:</b> <a href="4201.html">GeoffCobb@aol.com: "Re: The Emotional Computer"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; &gt; The fact that</i><br>
<i>&gt; &gt; you experience physical sensations at the same time as your cognitive</i><br>
<i>&gt; &gt; state of emotion provides no evidence of which is cause and which is</i><br>
<i>&gt; &gt; effect, nor does it prove that there is anything necessary about those</i><br>
<i>&gt; &gt; physical sensations to achieve the cognitive state.</i><br>
<i>&gt; </i><br>
<i>&gt; I believe your difficulty here lies in your assumption that emotions are</i><br>
<i>&gt; cognitive states. They are not. That is why we call them emotive rather</i><br>
<i>&gt; than cognitive. Cognitive --&gt; cogito --&gt; think, e.g., cogito ergo sum, I</i><br>
<i>&gt; *think* therefor I am. Emotions may influence thinking (abstract</i><br>
<i>&gt; thought), and thinking may influence emotions, but they are not one in</i><br>
<i>&gt; the same. They are qualitatively different.</i><br>
<p>
It is not an error, and you still have yet to provide any evidence of<br>
your preposterous claim that computers cannot experience emotion.  A<br>
simple thought experiment should suffice to show your mistake: Other<br>
mammals clearly have emotional states.  Fear, lust, hunger, and other<br>
experiences are not unique to Homo Sapiens.  But our machinery is<br>
different.  What emotions does a dolphin feel in its "melon" sonar<br>
sensory organ?  What erogenous sensations does a cat feel in its 2nd<br>
and third sets of teats?  What olfactory images are invoked in a dog's<br>
brain when he feels fear?  What emotional associations does a whale<br>
make with depth and pressure?<br>
<p>
Even if we postulate that one must evolve a more complex brain than<br>
those other creatures to have emotional states similar to ours, it is<br>
clear that the emotional states are felt in /whatever hardware/ is<br>
available to feel them.  It is palpable nonsense to say that because<br>
my mouth is dry when I feel fear, that fear therefore requires a mouth<br>
and salivary glands.  Fear /is/ the cognitive state associated with<br>
those bodily reactions, or whatever the reactions to it are in another<br>
kind of body with different inputs and outputs.  To claim that a<br>
computer can't achieve that same state with whatever inputs it happens<br>
<p>
They won't feel fear in exactly the way I do, but then neither do<br>
you or anyone else.  That doesn't mean you don't feel fear at all.<br>
<p>
<i>&gt; Recognize perhaps, express [emulate in an artificial way] perhaps, but</i><br>
<i>&gt; theres no way in the world it could experience an emotion without the</i><br>
<i>&gt; proper hardware. </i><br>
<p>
Who decides what hardware is "proper" for experiencing fear?  It obviously<br>
doesn't require arms or legs; a paraplegic can feel it.  It doesn't<br>
require sight or hearing or smell or touch; those whithout those inputs<br>
can still fear.  Don't patients with artificial hearts feel fear?  Those<br>
breathing with a respirator?  Those on dialysis?  As should be obvious<br>
by this reduction, the only organ needed to experience fear is a brain,<br>
and whatever inputs to it one happens to have available.  <br>
<p>
<i>&gt; &gt;  If a computer</i><br>
<i>&gt; &gt; tells me that the bit-pattern I just entered into its front panel is</i><br>
<i>&gt; &gt; beautiful, who am I to tell him otherwise?</i><br>
<i>&gt; </i><br>
<i>&gt; Him? The computer can only determine beauty based on the criteria the</i><br>
<i>&gt; programmer programmed into it. The computer cannot determine beauty</i><br>
<i>&gt; based on its own experiences of emotive affect. It may *know* what</i><br>
<i>&gt; beauty is supposed to be, but it has never experienced the emotive</i><br>
<i>&gt; sensations of beauty.</i><br>
<p>
Please give me evidence of this.  Why is my assumption that a computer's<br>
cognition  /does/ include states analagous to our emotions have any<br>
less weight than your assumption that they don't?  I refuse to be so<br>
anthropocentric without reason.  We are not unique.<br>
<p>
<pre>
-- 
Lee Daniel Crocker &lt;lee@piclab.com&gt;  &lt;<a href="http://www.piclab.com/lcrocker.html">http://www.piclab.com/lcrocker.html</a>&gt;
"All inventions or works of authorship original to me, herein and past,
are placed irrevocably in the public domain, and may be used or modified
for any purpose, without permission, attribution, or notification."--LDC
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4203.html">John K Clark: "Uploading"</a>
<li> <b>Previous message:</b> <a href="4201.html">GeoffCobb@aol.com: "Re: The Emotional Computer"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
