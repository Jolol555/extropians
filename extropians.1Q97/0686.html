<!-- received="Tue Jan 14 23:09:18 1997 MDT" -->
<!-- sent="Tue, 14 Jan 1997 21:13:26 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Plea (was ExI: Cognitive Extropians)" -->
<!-- id="199701150551.VAA22240@pure.PureAtria.COM" -->
<!-- inreplyto="Plea (was ExI: Cognitive Extropians)" -->
<title>extropians: Re: Plea (was ExI: Cognitive Extropians)</title>
<h1>Re: Plea (was ExI: Cognitive Extropians)</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Tue, 14 Jan 1997 21:13:26 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#686">[ date ]</a><a href="index.html#686">[ thread ]</a><a href="subject.html#686">[ subject ]</a><a href="author.html#686">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0687.html">Michael Wiik: "Re: Extropians web site?"</a>
<li> <b>Previous message:</b> <a href="0685.html">Eliezer Yudkowsky: "Re: PHIL: Church vs Turing"</a>
<li> <b>Maybe in reply to:</b> <a href="0669.html">E. Shaun Russell: "Plea (was ExI: Cognitive Extropians)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0721.html">Sunah.Caroline.Cherwin@pobox.com: "Re: Plea (was ExI: Cognitive Extropians)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; I don't think that it is the fact that Eli is young so much as the</i><br>
<i>&gt; fact that he makes too many generalizations and assumptions.</i><br>
<p>
I'll drink to that, or I would if alcohol wasn't Evil.<br>
<p>
The way I figure it, overgeneralizing is simply one of the inevitable<br>
side effects of being in a major hurry.  Which I am.  I figure that it's<br>
better to be wrong than to keep quiet... at least if your goal isn't<br>
impressing anyone, but is instead to solve all the secrets of the<br>
Universe within five years.  If I'm wrong, I can be corrected, and then<br>
I know something.  If I'm right, I'm right.  Silence is ignorance.  To<br>
err is to learn.<br>
<p>
This is somewhat in conflict with the conventional view that silence is<br>
golden.  Fortunately I'm sure that the silence types won't object, since<br>
they realize that "silence is golden" is a generalization and that they<br>
don't really know whether silence is golden for all conceivable people.<br>
<p>
I optimize my conversations, and my thoughts, for speed.  It's not so<br>
important to be right as to get X amount of thinking done about the<br>
subject so it can coalesce into an understanding.  Wrong and right don't<br>
matter for that threshold; it's the quality and quantity and complexity<br>
that count.  Then, once the understanding coalesces, you can remove all<br>
the wrong stuff.  The important thing is to have a large amount of<br>
thought to get that crucial click-click-click.<br>
<p>
And then there's the simple stylistic issue; I'm minded of the time that<br>
I rephrased:<br>
<p>
"Smartness is the ability to solve some problem"<br>
<p>
as:<br>
<p>
<i>&gt; Smartness is an abstraction,</i><br>
<i>&gt; existing solely in the human mind, from the observation - also existing</i><br>
<i>&gt; in the human mind - that System X - also in the mind - can solve problem</i><br>
<i>&gt; Y - also in the mind.  To give this term, "smartness", a useful</i><br>
<i>&gt; definition, we say that if System X can solve more problems than System</i><br>
<i>&gt; Y, or solve them more elegantly - where elegance is in the mind - then</i><br>
<i>&gt; System X is smarter than System Y.  The terms used may not precisely</i><br>
<i>&gt; reflect the truth, not having definitions down to the level of such</i><br>
<i>&gt; definitively real items as quarks or whatever the fundamental particles</i><br>
<i>&gt; may be, but if we attempted so foolish an endeavor as to make all mental</i><br>
<i>&gt; assertions correspond precisely to reality, we wouldn't be able to think</i><br>
<i>&gt; or walk across the room.  The most we can hope for is terms which are</i><br>
<i>&gt; useful, experimentally testable, and precise.  I believe that</i><br>
<i>&gt; "smartness", or - so I don't get another lecture on there being multiple</i><br>
<i>&gt; types of smartness - that type of smartness which has to do with the</i><br>
<i>&gt; rotation of mental pictures - is experimentally testable, precise, and</i><br>
<i>&gt; useful.  Other types of smartness are more vaguely defined due to our</i><br>
<i>&gt; primitive grasp of cognitive science, but are still useful.</i><br>
<p>
Qualification and evasion of responsibility, for me, has always been<br>
very much something that is done *after* your theory is in place.  I<br>
build it up, you smash it down, you build it up, I smash it down, but I<br>
*never* deliberately *slow* it down, and I try not to do anything which<br>
would slow me down.  I've always viewed thinking from an engineering<br>
standpoint; a sweeping generalization is okay, as long as it works.  The<br>
object is not to spew out thirty pages of blither to whom nobody could<br>
possibly object, but to be able to solve problems.<br>
<p>
If I say:  "Schools don't work because of a short-circuit between<br>
learning and verification," it may not be true of every school or every<br>
student.  But it does tell you how to fix the problem; you set up<br>
Institutes of Verification.  And that's all I wanted from the<br>
generalization.<br>
<p>
Time will tell whether this method works better, at least for me, than<br>
slow and careful critical thought.  I figure that I'm good at making<br>
sweeping and possibly incorrect statements on subjects that nobody else<br>
has even been able to touch.  I lay the foundations and get out.  This<br>
is the Meaning of Life, this is how to redo schools, this is how to<br>
amplify intelligence, do you have any other questions?<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0687.html">Michael Wiik: "Re: Extropians web site?"</a>
<li> <b>Previous message:</b> <a href="0685.html">Eliezer Yudkowsky: "Re: PHIL: Church vs Turing"</a>
<li> <b>Maybe in reply to:</b> <a href="0669.html">E. Shaun Russell: "Plea (was ExI: Cognitive Extropians)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0721.html">Sunah.Caroline.Cherwin@pobox.com: "Re: Plea (was ExI: Cognitive Extropians)"</a>
<!-- reply="end" -->
</ul>
