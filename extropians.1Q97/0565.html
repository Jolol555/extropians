<!-- received="Sun Jan 12 19:05:03 1997 MDT" -->
<!-- sent="Sun, 12 Jan 1997 20:40:29 -0500 (EST)" -->
<!-- name="mlbowli1@iupui.edu" -->
<!-- email="mlbowli1@iupui.edu" -->
<!-- subject="Re: PHILOSOPHY: Make violent computergames illegal." -->
<!-- id="199701130111.LAA29804@smople.thehub.com.au" -->
<!-- inreplyto="PHILOSOPHY: Make violent computergames illegal." -->
<title>extropians: Re: PHILOSOPHY: Make violent computergames illegal.</title>
<h1>Re: PHILOSOPHY: Make violent computergames illegal.</h1>
<i>mlbowli1@iupui.edu</i><br>
<i>Sun, 12 Jan 1997 20:40:29 -0500 (EST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#565">[ date ]</a><a href="index.html#565">[ thread ]</a><a href="subject.html#565">[ subject ]</a><a href="author.html#565">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0566.html">Eliezer Yudkowsky: "Re: Stephen Jay Gould and progress"</a>
<li> <b>Previous message:</b> <a href="0564.html">Mitchell Porter: "Re: Stephen Jay Gould and progress"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
It seems that my first try did not post-- here it is again.<br>
<p>
On Fri, 10 Jan 1997, Max M wrote:<br>
<p>
<i>&gt; Artifical life might be created by running a simulation based on DNA (Like</i><br>
<i>&gt; the recent WIRED article). Maybe some kind of life will evolve by itself.</i><br>
<i>&gt; All common stuff.</i><br>
<i>&gt; If we upload shurely we want to be regarded as legal entities in that form</i><br>
<i>&gt; with the right to make money, buy stuff, take someone to court etc. It will</i><br>
<i>&gt; then be natural that all artificial lifeforms be regarded as such. I mean</i><br>
<i>&gt; if life can exist in a computersystem it can take any kind of shape.</i><br>
<i>&gt; </i><br>
<i>&gt; In a game like Quake from ID-Software you can play against "bot's".</i><br>
<i>&gt; Computer based adviseries made with Neural nets, fuzzy logic etc. At some</i><br>
<i>&gt; time computergame characters will be as intelligent as other artificial</i><br>
<i>&gt; lifeforms.</i><br>
<i>&gt; </i><br>
<i>&gt; won't that make computergames against Bots/AI's illegal?</i><br>
<i>&gt; &gt; </i><br>
How about instead of killing them, they just lay down, cover their eyes <br>
and count to 50.  I don't think its necessary to kill game bots to have a <br>
violent game.  For instance, Hollywood has become very adept at making <br>
violent movies without actually killing anyone.<br>
<p>
Playing "life or death" games with humans would probably be a pretty cool <br>
job for a Bot or AI, as long as both parties could walk away from the <br>
carnage carnival (great name for a game, eh!).<br>
<p>
To address the meat of your question, I say self awareness in any being <br>
presupposes and necessitates legal rights and protection.  But how can <br>
self awareness be measured in an AI?  (Maybe they can be equiped with <br>
genitals: If such a being plays with its virtual self when looking in a <br>
mirror, then we'll know! :) )<br>
<p>
I expect that when the time comes protect artificial beings, the issue <br>
will be quite controversial.  Many people will be unwilling/inable to <br>
accept that something without a face is alive.  I predict members of the <br>
pro-life camp will be especially inclined to this troubling opionion.<br>
<p>
Exovivo!<br>
<p>
Michael Bowling<br>
mlbowli1@cord.iupui.edu<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0566.html">Eliezer Yudkowsky: "Re: Stephen Jay Gould and progress"</a>
<li> <b>Previous message:</b> <a href="0564.html">Mitchell Porter: "Re: Stephen Jay Gould and progress"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
