<!-- received="Tue Jan 28 22:13:38 1997 MDT" -->
<!-- sent="Wed, 29 Jan 1997 00:16:57 -0500" -->
<!-- name="Steve Witham" -->
<!-- email="sw@tiac.net" -->
<!-- subject="Software virtues into AI" -->
<!-- id="v01540b00af134da2f6d2@[199.3.130.133]" -->
<!-- inreplyto="" -->
<title>extropians: Software virtues into AI</title>
<h1>Software virtues into AI</h1>
Steve Witham (<i>sw@tiac.net</i>)<br>
<i>Wed, 29 Jan 1997 00:16:57 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1558">[ date ]</a><a href="index.html#1558">[ thread ]</a><a href="subject.html#1558">[ subject ]</a><a href="author.html#1558">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1559.html">Kennita Watson: "Be the first on your block...."</a>
<li> <b>Previous message:</b> <a href="1557.html">David Musick: "PHILOSOPHY: It's All Shifting Patterns"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1571.html">Chris Hind: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1571.html">Chris Hind: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1574.html">max m: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1580.html">James Rogers: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="2372.html">James Rogers: "Re: Software virtues into AI"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Hi.  I'm about 90 days backlogged in reading the list but I had a thought<br>
you might like.  (I feel like that character who only communicated by<br>
(virtual) teletype in the dungeons-and-dragons world of Vinge's _True<br>
Names_.  The UPS guys would deliver this teletype to the Castle...<br>
was it THE POSTMAN?)<br>
<p>
I like to wonder how AI might arise from software development efforts<br>
going on right now.  Also, I wonder how we might give AIs the qualities<br>
we want them to have.<br>
<p>
Maybe AIs will come about as assemblies of pieces of software that all<br>
do sensible jobs that we understand: indexing, modeling, taking statistics<br>
and making predictions, parsing and composing sentences, keeping schedules,<br>
etc.<br>
<p>
Maybe the personalities of these AIs will have a lot to do with the<br>
personalities of the components.  You know what I mean.  Every piece of<br>
software has some sort of personality.  We notice whether<br>
software is easy or hard, fun or boring, straightforward or devious,<br>
dependable or flakey or downright infuriating...<br>
<p>
If the personality of AI is going to flow from the personalities of its<br>
components, that's scary, because a lot of software these days is nasty<br>
and badly behaved.  I spend a lot of time trying to deal with software that<br>
seems to be written by people who have no respect for me, my time, my<br>
sanity, my need to understand, or my peace of mind.  People who seem not<br>
to take responsibility for the context in which their software is going<br>
to be used.  These attitudes seem implicit in the behavior of software.<br>
For instance, I install a new version of my OS and the TCP settings are<br>
toast, and the new control panel doesn't make sense.  Or it fails with a<br>
completely uninformative and patently absurd message, with no clue where<br>
to go from there. I call up the help wizzard and it says, "Put your<br>
DNS server address here," indicating a section of a form that has no<br>
blanks to fill in.  (This is Mac System 7.5.5's Guide on the TCP/IP<br>
control panel.  A really beautiful animation of drawing a red crayon<br>
circle in an empty white space, including showing through the translucent<br>
help box.)<br>
<p>
I'm not so much complaining about the present as fearing for the future:<br>
imagine an AI with all the worst personality flaws of the latest<br>
releases from your favorite software companies.  Larry Ellison and<br>
Bill Gates on chips, or downloading intently into your WebTV.  You get home<br>
and you your house has been upgraded with a butler that's like Word 6.<br>
<p>
But on the other hand, maybe the path to nice AIs is to realize that it's<br>
already gotten to the point where software needs virtues built into it.<br>
People have already sensed (although not always catered to) needs for<br>
clarity and useability.  Sometimes even adaptability.  How about respon-<br>
sibility?  How do you write software that knows when it's letting you down<br>
and has some idea how to figure out what it's doing wrong, or what recourse<br>
you can seek?  I mean haven't you ever wanted to whack a piece of software<br>
on the side, but realized that software doesn't generally have a way of<br>
dealing with whacks?  I once saw a proposal for error messages with<br>
explorable levels of detail--like stack traces with English subtitles--<br>
the idea hasn't caught on.  What if software could show you its assumptions<br>
and let you tell it which ones were wrong?  But these things are hard.<br>
<p>
I guess what I'm saying is that maybe virtues--good qualities--aren't<br>
just separate parts, but need to be built in throughout a system (or<br>
personality), and only get there if someone takes responsibility for<br>
putting them there.  But if people do take that care, then you end up<br>
with systems that are naturally more likely to turn out virtuous.<br>
<p>
Which is really just saying that virtues are more like skills than<br>
compulsions, which I believe.<br>
<p>
 --Steve<br>
<p>
<pre>
--
sw@tiac.net           Steve Witham            <a href="http://www.tiac.net/users/sw">http://www.tiac.net/users/sw</a>
"...the Vild, where the manifold was as dangerous and deranged as a
 Scutari shahzadix in heat." --David Zindell
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1559.html">Kennita Watson: "Be the first on your block...."</a>
<li> <b>Previous message:</b> <a href="1557.html">David Musick: "PHILOSOPHY: It's All Shifting Patterns"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1571.html">Chris Hind: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1571.html">Chris Hind: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1574.html">max m: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="1580.html">James Rogers: "Re: Software virtues into AI"</a>
<li> <b>Maybe reply:</b> <a href="2372.html">James Rogers: "Re: Software virtues into AI"</a>
<!-- reply="end" -->
</ul>
