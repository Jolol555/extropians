<!-- received="Sun Mar 30 04:48:18 1997 MDT" -->
<!-- sent="Sun, 30 Mar 1997 12:24:23 GMT" -->
<!-- name="Guru George" -->
<!-- email="gurugeorge@sugarland.idiscover.co.uk" -->
<!-- subject="Re[2]: Protean Self-Transformation" -->
<!-- id="199703301224.MAA10159@hal.9000series.idiscover.net" -->
<!-- inreplyto="Pine.SOL.3.91N2x.970330124135.1520D-100000@hemul.nada.kth.se" -->
<title>extropians: Re[2]: Protean Self-Transformation</title>
<h1>Re[2]: Protean Self-Transformation</h1>
Guru George (<i>gurugeorge@sugarland.idiscover.co.uk</i>)<br>
<i>Sun, 30 Mar 1997 12:24:23 GMT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4146">[ date ]</a><a href="index.html#4146">[ thread ]</a><a href="subject.html#4146">[ subject ]</a><a href="author.html#4146">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4147.html">Mitchell Porter: "URL: Is Engines of Creation off the web?"</a>
<li> <b>Previous message:</b> <a href="4145.html">Anders Sandberg: "Re: Protean Self-Transformation"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4155.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<li> <b>Reply:</b> <a href="4155.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Sun, 30 Mar 1997 12:46:36 +0200 (MET DST)<br>
Anders Sandberg &lt;nv91-asa@nada.kth.se&gt; wrote:<br>
<p>
<i>&gt;On Sat, 29 Mar 1997, Gregory Houston wrote:</i><br>
<i>&gt;&gt; Emotions are felt in a physical manner. I *feel* sexual pleasure via my</i><br>
<i>&gt;&gt; organs. I *feel* hunger via my organs. I *feel* excitement via my</i><br>
<i>&gt;&gt; organs. Without this specialized hardware I would *feel* nothing. As a</i><br>
<i>&gt;&gt; computer I might be "aware" of conditions, but I would not *feel* those</i><br>
<i>&gt;&gt; conditions unless someone created specialized hardware that would allow</i><br>
<i>&gt;&gt; me to *feel*.</i><br>
<i>&gt;</i><br>
<i>&gt;OK, what you seems to say is that if I put damage sensors in a robot, it </i><br>
<i>&gt;would be able to feel pain. But this relates to the awfully tricky </i><br>
<i>&gt;problem of qualia: does the robot *experience* pain, or doe it just think </i><br>
<i>&gt;"pain"? How can we tell? </i><br>
<i>&gt;</i><br>
<i>&gt;(My personal view is that the hardware doesn't matter; after all, </i><br>
<i>&gt;stimulating a sensor or nerve produces the same sensation, so the qualia </i><br>
<i>&gt;are likely happining in the brain, which I also think could be run on a </i><br>
<i>&gt;different hardware)</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; If a computer is to feel pleasure from the outside world it will require</i><br>
<i>&gt;&gt; peripheal nodes which can register sensation (pleasure and pain). If a</i><br>
<i>&gt;&gt; computer is to feel pleasure from its own internal processes it will</i><br>
<i>&gt;&gt; require internal nodes which can register sensation (pleasure and pain). </i><br>
<i>&gt;&gt; We can program computers to think because that is what the hardware was</i><br>
<i>&gt;&gt; designed for. The hardware has not yet been designed to feel emotion.   </i><br>
<i>&gt;</i><br>
<i>&gt;It would be quite possible to create programs that can watch their </i><br>
<i>&gt;internal states and hence feel internal pleasure, no hardware needed. In </i><br>
<i>&gt;fact, programs that watch or affect their own states have been written </i><br>
<i>&gt;(but as far as I know nobody has done anything truly serious with it).</i><br>
<i>&gt;</i><br>
I have to say that I agree with Gregory here.  And it's not just sensors<br>
that are the problem.  As I understand it, emotions are mediated by the<br>
'R-complex' and limbic system in the brain. These electro-chemical<br>
processes create the kinds of events we call 'pleasure' and 'pain' in<br>
response to stimuli. They comprise primitive forms of cognition, highly<br>
peculiar, particular, and specialised (i.e. they have to to with the<br>
typical concerns of reptiles and lower mammals), that are 'gerrymandered'<br>
by the neocortex. AI people could perhaps duplicate the functions of<br>
these systems electro-mechanically right now, with enough work, but as<br>
Dennett has said, what's the point? <br>
<p>
But unless you uploaded into a system that did duplicate them, you<br>
wouldn't experience them, I think. (Then again, maybe that does provide<br>
a 'point' to the exercise of trying to duplicate them?)<br>
<p>
Speculation:- Without systems that duplicate emotional functions, the<br>
nearest I can imagine to what it would be like uploading would be the<br>
experience of doing pure mathematics: all experience would occur as a<br>
kind of mathematical trance, except with sensory images as mathematical<br>
symbols.<br>
<p>
This wouldn't be transhuman so much as totally non-human, perhaps no<br>
different from the experience of a built or evolved AI.<br>
<p>
<p>
<p>
Guru George<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4147.html">Mitchell Porter: "URL: Is Engines of Creation off the web?"</a>
<li> <b>Previous message:</b> <a href="4145.html">Anders Sandberg: "Re: Protean Self-Transformation"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4155.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<li> <b>Reply:</b> <a href="4155.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<!-- reply="end" -->
</ul>
