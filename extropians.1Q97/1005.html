<!-- received="Tue Jan 21 14:29:21 1997 MDT" -->
<!-- sent="Wed, 22 Jan 1997 21:03:00 GMT" -->
<!-- name="Guru George" -->
<!-- email="gurugeorge@sugarland.idiscover.co.uk" -->
<!-- subject="Re[2]: EVOLUTION: Mental Adaptation" -->
<!-- id="199701222103.VAA06143@hal.9000series.idiscover.net" -->
<!-- inreplyto="Pine.SOL.3.91N2x.970121152104.12406F-100000@badminton.nada.kth.se" -->
<title>extropians: Re[2]: EVOLUTION: Mental Adaptation</title>
<h1>Re[2]: EVOLUTION: Mental Adaptation</h1>
Guru George (<i>gurugeorge@sugarland.idiscover.co.uk</i>)<br>
<i>Wed, 22 Jan 1997 21:03:00 GMT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1005">[ date ]</a><a href="index.html#1005">[ thread ]</a><a href="subject.html#1005">[ subject ]</a><a href="author.html#1005">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1006.html">Robert Schrader: "Re: Throwing ape's hip structure"</a>
<li> <b>Previous message:</b> <a href="1004.html">Lee Daniel Crocker: "Re: Plea (was ExI: Cognitive Extropians)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Tue, 21 Jan 1997 15:29:54 +0100 (MET)<br>
Anders Sandberg &lt;nv91-asa@nada.kth.se&gt; wrote:<br>
<p>
<i>&gt;On Tue, 21 Jan 1997, James Rogers wrote:</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; Vast improvements in intelligence will be THE</i><br>
<i>&gt;&gt; defining feature in the progress of the human species.</i><br>
<i>&gt;</i><br>
<i>&gt;I wonder if intelligence or brain power is the important point here. </i><br>
<i>&gt;</i><br>
<i>&gt;Together with my computer, I can communicate with experts across the</i><br>
<i>&gt;world, solve mathematical problems quickly and reliably, gather and</i><br>
<i>&gt;process information much faster than in a library and remember my results </i><br>
<i>&gt;for years perfectly. Obviously, my productivity (my effective </i><br>
<i>&gt;intelligence) has been increased. </i><br>
<i>&gt;</i><br>
<i>&gt;But what am I really doing? I'm letting various more or less autonomous </i><br>
<i>&gt;subsystems do work for me, sometimes quite complex work, while I don't </i><br>
<i>&gt;even need to understand how it is done. This is very similar to how we </i><br>
<i>&gt;acquire skill: at first we need to understand and concentrate on what we </i><br>
<i>&gt;are doing, but later it becomes natural and unconscious. Typing on a </i><br>
<i>&gt;keyboard is a very complex process, but since I know it well it appears </i><br>
<i>&gt;to me as an unitary process with no internal complexity, I just do it.</i><br>
<i>&gt;</i><br>
<i>&gt;The modern environment is filled with this proceduralization: we have </i><br>
<i>&gt;simplified it to a large extent by hiding away the complexity inside </i><br>
<i>&gt;black boxes, which greatly improves our efficiency without relying on </i><br>
<i>&gt;increased intelligence (in fact, many technologies seem to decrease it!). </i><br>
<i>&gt;So greater *personal* intelligence might not be the crucial thing in the </i><br>
<i>&gt;future, but greater *effective* intelligence. </i><br>
<i>&gt;</i><br>
This is all true.  But I would point out that a good deal of native<br>
intelligence is still  required to *learn* these intelligence amplification<br>
systems, not to mention *use* them intelligently.  We still need our smart<br>
drugs (or neurosurgery or whatever)!<br>
<p>
<p>
Guru George<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1006.html">Robert Schrader: "Re: Throwing ape's hip structure"</a>
<li> <b>Previous message:</b> <a href="1004.html">Lee Daniel Crocker: "Re: Plea (was ExI: Cognitive Extropians)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
