<!-- received="Thu Jan  9 07:19:46 1997 MDT" -->
<!-- sent="Thu, 9 Jan 1997 15:07:55 +0100 (MET)" -->
<!-- name="Anders Sandberg" -->
<!-- email="nv91-asa@nada.kth.se" -->
<!-- subject="Re: &gt;H UPLOAD:advocatus diaboli" -->
<!-- id="199701090834.AAA22906@igc3.igc.apc.org" -->
<!-- inreplyto="199701080546.VAA06420@well.com" -->
<title>extropians: Re: &gt;H UPLOAD:advocatus diaboli</title>
<h1>Re: &gt;H UPLOAD:advocatus diaboli</h1>
Anders Sandberg (<i>nv91-asa@nada.kth.se</i>)<br>
<i>Thu, 9 Jan 1997 15:07:55 +0100 (MET)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#444">[ date ]</a><a href="index.html#444">[ thread ]</a><a href="subject.html#444">[ subject ]</a><a href="author.html#444">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0445.html">Eugene Leitl: "TECH:"Naturally Intelligent Systems", MITP, a quote, pp. 234-235"</a>
<li> <b>Previous message:</b> <a href="0443.html">Anders Sandberg: "A Transhuman Fairy Tale"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
It seems to me that Eugene and John are talking about different things. <br>
<p>
Eugene gave an estimate of the computing requirements of a somewhat<br>
realistic uploading scenario that was essentially a bound on what we need<br>
to simulate neurons well enough to have identical activities. John argues<br>
that memory information is distributed between synapses (a fairly common<br>
view among neuroscientists). But that doesn't change the bound on<br>
uploading requirements! <br>
<p>
It might be possible to compress the brain into a more efficient<br>
simulation (replacing 100 synapses with one meta-synapse etc), but my<br>
intuition tells me that is practically impossible or at least NP complete;<br>
it is just a restatement of how information is stored distributed in the<br>
weights of a large neural net. It might also mean that the inevitable<br>
errors in uploading are manageable, since there is a large redundancy, but<br>
we should not rely on this (it just requires a few erroneous neural<br>
circuits to create an epileptic locus, and some neural circuits seem to <br>
be very finely tuned). <br>
<p>
Far too often people think the brain works as a computer; it don`t. A <br>
synapse isn't a bit, but a cluster of synapses isn't a bit either!<br>
<p>
On Tue, 7 Jan 1997, John K Clark wrote:<br>
<p>
<i>&gt;                 &gt;Ask Joe Strout, he burns any number of MFlops for hours to </i><br>
<i>&gt;                 &gt;simulate just _one_ biologically realistic neuron, and far </i><br>
<i>&gt;                 &gt;from running in realtime.</i><br>
<i>&gt; </i><br>
<i>&gt; The complexity of an individual neuron is irrelevant, the Madison and Schuman</i><br>
<i>&gt; findings are about redundancy. The point is, it may not take any more computer</i><br>
<i>&gt; power to simulate many neurons than to simulate one.</i><br>
<p>
This is the cruicial question. My guess is that it is possible to capture <br>
much of the dynamics in easier models, but it is the complex behaviors <br>
that escape the basic model that are relevant! There is a lot of <br>
subtelity in how neurons fire, and how this subtelity is used varies from <br>
locus to locus...<br>
<p>
-----------------------------------------------------------------------<br>
Anders Sandberg                                      Towards Ascension!<br>
nv91-asa@nada.kth.se         <a href="http://www.nada.kth.se/~nv91-asa/main.html">http://www.nada.kth.se/~nv91-asa/main.html</a><br>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0445.html">Eugene Leitl: "TECH:"Naturally Intelligent Systems", MITP, a quote, pp. 234-235"</a>
<li> <b>Previous message:</b> <a href="0443.html">Anders Sandberg: "A Transhuman Fairy Tale"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
