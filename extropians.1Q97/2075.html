<!-- received="Sat Feb  1 18:28:16 1997 MDT" -->
<!-- sent="Sat, 01 Feb 1997 19:04:47 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Free will, still more" -->
<!-- id="Pine.SOL.3.91.970201235717.16810B-100000@sun2" -->
<!-- inreplyto="Free will, still more" -->
<title>extropians: Re: Free will, still more</title>
<h1>Re: Free will, still more</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sat, 01 Feb 1997 19:04:47 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2075">[ date ]</a><a href="index.html#2075">[ thread ]</a><a href="subject.html#2075">[ subject ]</a><a href="author.html#2075">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2076.html">Eliezer Yudkowsky: "Re: Linguist's Of The Apocalypse, unite!"</a>
<li> <b>Previous message:</b> <a href="2074.html">Eliezer Yudkowsky: "Re: Free will, still more"</a>
<li> <b>Maybe in reply to:</b> <a href="2047.html">John K Clark: "Free will, still more"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2167.html">Eric Watt Forste: "Re: Free will, still more"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
[Saith John K. Clark:]<br>
<i>&gt; OK, if you want to play that game, please give me a non circular definition  </i><br>
<i>&gt; of the word "definition".</i><br>
<p>
No problem whatsoever from *my* philosophical standpoint.<br>
<p>
Definition (n):  An explanation intended to convey all information<br>
necessary for the formation of a symbol.<br>
<p>
	Our mind contains cognitive objects called 'symbols'.  Nobody knows<br>
where or how they are stored, except that we think the hippocampus<br>
creates them and the cerebellum retrieves them.  'Symbols' generally<br>
have words attached to them, be they auditory or ASL or whatever. <br>
Symbols are widely thought to be handles to semantic structures,<br>
composed of other semantic primitives such as symbols, and connected by<br>
various semantic links the nature of which is not well understood.<br>
	The network does ground out, because semantic primitives other than<br>
symbols exist.  As a general rule the non-symbolic primitives consist of<br>
either some experiences, or a transformation performed on the current<br>
working memory or visualization, often by attempting to alter the<br>
visualization so that it is analogous to abstracted extracts from<br>
previous experience.<br>
	Classical AIs have no visualizational facilities and their symbols are<br>
all defined in terms of other symbols, which is why classical AI is such<br>
a horrible model of the mind.<br>
<p>
Definition (n):  An explanation intended to convey all information<br>
necessary for the formation of a symbol.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2076.html">Eliezer Yudkowsky: "Re: Linguist's Of The Apocalypse, unite!"</a>
<li> <b>Previous message:</b> <a href="2074.html">Eliezer Yudkowsky: "Re: Free will, still more"</a>
<li> <b>Maybe in reply to:</b> <a href="2047.html">John K Clark: "Free will, still more"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2167.html">Eric Watt Forste: "Re: Free will, still more"</a>
<!-- reply="end" -->
</ul>
