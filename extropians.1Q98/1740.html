<!-- received="Wed Feb 11 22:39:05 1998 MDT" -->
<!-- sent="Wed, 11 Feb 1998 21:38:52 -0800 (PST)" -->
<!-- name="John K Clark" -->
<!-- email="johnkc@well.com" -->
<!-- subject="Searle" -->
<!-- id="199802120538.VAA05796@well.com" -->
<!-- inreplyto="" -->
<title>extropians: Searle</title>
<h1>Searle</h1>
John K Clark (<i>johnkc@well.com</i>)<br>
<i>Wed, 11 Feb 1998 21:38:52 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1740">[ date ]</a><a href="index.html#1740">[ thread ]</a><a href="subject.html#1740">[ subject ]</a><a href="author.html#1740">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Previous message:</b> <a href="1739.html">David A Musick: "Self Improvement"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Reply:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Reply:</b> <a href="1751.html">jamesr@best.com: "Re: Searle"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
-----BEGIN PGP SIGNED MESSAGE-----<br>
<p>
On Tue, 10 Feb 1998 Brent Allsop &lt;allsop@swttools.fc.hp.com&gt; Wrote:<br>
           <br>
<i>        &gt;Something physically real and objectively (or abstractly) observable         </i><br>
<i>        &gt;is going on in our brain that is producing conscious sensations or         </i><br>
<i>        &gt;qualia.  </i><br>
<p>
<p>
I agree that something physical must be causing qualia, but we can never know <br>
what it is with any certainty unless we assume there is a direct connection <br>
between qualia and behavior.<br>
              <br>
<p>
<i>        &gt;We simply must figure out how and why this is.</i><br>
<p>
<p>
I'm not saying we can't come up with theories of conscienceless, we can come <br>
up with lots of them, I'm saying that without behavior there is no reason to <br>
pick one over the other because there are no facts they must explain, all are<br>
equally good, or bad.<br>
              <br>
<p>
<i>        &gt;Someone will say, I'm going to manipulate/stimulate a part of your         </i><br>
<i>        &gt;brain in such a way that it will produce precisely the sensation        </i><br>
<i>        &gt;I experience or use to represent salt in your mind.  </i><br>
<p>
<p>
And when you do I will make a sound with my mouth like this:<br>
<p>
 "I hear the sounds you just made with your mouth and it is causing me to  <br>
  make the following sounds with my own mouth:"<br>
<p>
    I do feel a sensation, I've felt it before and called it "salty". You have    <br>
    shown me detailed measurements of your brain when you claim you are also   <br>
    experiencing a salty sensation, and I have compared them to  measurements <br>
    of my own brain. I see a vast number, an astronomical number,  of <br>
    differences in the measurements of our two brains, however because we're   <br>
    both making the same noise with our mouth (this is salty) there must be   <br>
    something similar in the two measurements. You have found them and proven    <br>
    conclusively that these small brain similarities in a huge sea of <br>
    differences are the reasons we made the same sounds with our mouths. I <br>
    have no problem with any of this, HOWEVER you then make a huge unwarranted <br>
    leap of logic that this has something to do with consciousness. Just <br>
    because you and I make similar sounds is no reason to think that your <br>
    subjective experience is anything like mine, or even that you have any <br>
    subjective experience at all, UNLESS I assume that qualia and behavior <br>
    are inextricably linked. I have made that assumption, you have not. <br>
    If as you think, one part of the brain produces intelligent behavior and <br>
    a completely different part produces qualia, then all you've explained is <br>
    the intelligent part, the qualia might be made somewhere else in all <br>
    those enormous differences between  you and me.<br>
<p>
   <br>
<p>
<i>        &gt;The experiencer might respond with, that's not what salt tastes like         </i><br>
<i>        &gt;to me. You would be able to verify that this person isn't lying, and         </i><br>
<i>        &gt;that he uses a different sensation to represent salt because you        </i><br>
<i>        &gt;will be able to objectively observe the physical phenomenon that is  </i><br>
<i>        &gt;producing his sensation and see that it is different.  </i><br>
<p>
<p>
You're saying that if you already have a theory of consciousness that you <br>
know for sure is correct (!) then you could know for sure what somebody else <br>
is feeling. There are two problems.<br>
<p>
1) The theory you came up with can never be better than the evidence, and the    <br>
   evidence can only come from behavior.<br>
<p>
2) Even if I knew that at the present moment you at 88.4762 on the happiness   <br>
   scale, 23.2211 on the fear scale, and 11.0216 on the pain scale, I still    <br>
   wouldn't know what it's like to be you, even reading a poem by a great    <br>
   poet can't do that. At best all I could know is how I would feel if I were   <br>
   in your situation, not how you feel in your situation. <br>
              <br>
<p>
<i>        &gt;Are you saying that abstractly representing 700 nm light with an </i><br>
<i>        &gt;array of transistors in a particular state could reproduce the same </i><br>
<i>        &gt;phenomenally glorious "red" qualia your consciousness use to </i><br>
<i>        &gt;represent 700 nm light?  </i><br>
<p>
<p>
Yes, that's exactly what I'm saying. It's not obvious to me that an array of <br>
transistors in inherently less glorious than a glob of gray goo.<br>
                            <br>
<p>
<i>       &gt;In order to represent any abstract information, there must be some        </i><br>
<i>       &gt;physically real phenomenon that can reliably assume various different        </i><br>
<i>       &gt;distinguishable states.  </i><br>
<p>
<p>
Correct. Shakespeare can be represented as ink on paper or magnetic spots on <br>
a disk or charged capacitors in a RAM chip or neuron connections in a brain,  <br>
it doesn't matter, the meaning is the same, it's still Shakespeare.<br>
<p>
<p>
<i>        &gt;Though certain physical phenomenon can model different physical        </i><br>
<i>        &gt;phenomenon, they will never be precisely, fundamentally, like each         </i><br>
<i>        &gt;other.  </i><br>
<p>
<p>
If so then how could I ever know for sure what it's like to be you?<br>
                            <br>
<p>
<i>        &gt;You are as smart as I am.  But if you use a drastically different         </i><br>
<i>        &gt;sensation to represent a salty taste than I do, this  matters.  </i><br>
        <br>
<p>
I can say with complete confidence that the way your brain represents a salty <br>
sensation is different than the way my brain does, because we're different <br>
people with different brains. However, if neither of us likes a lot  of salt <br>
in our drinking water and both of us like a little salt on our popcorn then<br>
that is evidence (I admit not proof) that the two subjective sensations may <br>
be similar<br>
                            <br>
<p>
<i>        &gt;A purely abstract machine can achieve the same ability to be aware         </i><br>
<i>        &gt;of salt.  But again, the fact that there is no real subjective salty         </i><br>
<i>        &gt;that is representing salt </i><br>
<p>
<p>
I have 4 questions:<br>
<p>
1) Why is a person less abstract than a machine? <br>
2) How do you know the machine is not experiencing a salty taste? <br>
3) How do you know that I am? <br>
4) Most important of all, why oh why did random mutation ever come up with   <br>
   things that have subjective experience if it is not linked to behavior?<br>
                            <br>
<p>
<i>        &gt;People think that red is something out beyond our eyes, some quality        </i><br>
<i>        &gt;of light or something.  </i><br>
<p>
<p>
I think you're attacking a straw man, nobody in the AI field, or anybody who <br>
has spent any time thinking about philosophy would believe such a foolish <br>
thing.<br>
<p>
                                              John K Clark    johnkc@well.com<br>
<p>
-----BEGIN PGP SIGNATURE-----<br>
Version: 2.6.i<br>
<p>
iQCzAgUBNOKMrX03wfSpid95AQGVMATvd6QQ5C+rFcdoYRsy5I0pmkAHvpnoG9oP<br>
c83JLPjtEQdJSkGxXCui02ahYKX1kfv3CVWxhF6l8AR/zWPkZ319g7f3ZEfi5UsT<br>
bqQFomxvm/KY9R5gAZ4wxghWJwf3fjZ20PqagAs+aGea9oe810bjOuVQR3RyOifv<br>
vlSpdPiSa3EjmN7GRTqTlbGs1sdqINE/VIbeYymhOM0NMIxTUtE=<br>
=LiFi<br>
-----END PGP SIGNATURE-----<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Previous message:</b> <a href="1739.html">David A Musick: "Self Improvement"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Reply:</b> <a href="1741.html">Lee Daniel Crocker: "Re: Searle"</a>
<li> <b>Reply:</b> <a href="1751.html">jamesr@best.com: "Re: Searle"</a>
<!-- reply="end" -->
</ul>
