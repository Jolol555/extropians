<!-- received="Fri Feb 27 04:27:04 1998 MDT" -->
<!-- sent="Fri, 27 Feb 1998 14:33:42 +0300 (MSK)" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene@liposome.genebee.msu.su" -->
<!-- subject="Re: Singularity or Holocaust" -->
<!-- id="199802271049.DAA27061@maxwell.kumo.com" -->
<!-- inreplyto="0014500018399800000002L002*@MHS" -->
<title>extropians: Re: Singularity or Holocaust</title>
<h1>Re: Singularity or Holocaust</h1>
Eugene Leitl (<i>eugene@liposome.genebee.msu.su</i>)<br>
<i>Fri, 27 Feb 1998 14:33:42 +0300 (MSK)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2175">[ date ]</a><a href="index.html#2175">[ thread ]</a><a href="subject.html#2175">[ subject ]</a><a href="author.html#2175">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<li> <b>Previous message:</b> <a href="2174.html">den Otter: "Re: PHIL: Extropy, Boundaries and Suicide"</a>
<li> <b>In reply to:</b> <a href="2136.html">DOUG.BAILEY@EY.COM: "Re: Singularity or Holocaust"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<li> <b>Reply:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Thu, 26 Feb 1998 DOUG.BAILEY@EY.COM wrote:<br>
<p>
<i>&gt; I do not believe anyone, regardless of their power base, will be able to</i><br>
<i>&gt; effectively prepare in such a manner as to increase their survival chances at</i><br>
<i>&gt; and after a technological singularity event.</i><br>
<p>
This would seem to depend on the flavour of the Singularity, wouldn't it? <br>
<p>
If it was a full-blown DIY Blight, we won't have any chances at all. A<br>
typical scenario of the Blight would seem the sudden emergence of one or<br>
several malignant/indifferent Powers as a result of Web transcending, or<br>
of a supercritical ALife experiment. I'm just rehashing the FAQ here, of<br>
course.<br>
<p>
Otoh, the Singularity may be benign/slow, so there are traversable<br>
continuous persona space trajectories. Of course anybody not following is<br>
endangered even on the short run. And of course many will choose not to<br>
follow. <br>
<p>
On the third nanomanipulator, there might be no Singularity at all.<br>
Bummer :(<br>
 <br>
<i>&gt; If a singularity event were to occur, life would be extremely different.  I am</i><br>
<p>
By definition.<br>
<p>
<i>&gt; not saying it would be necessarily incomprehensible to those who were around</i><br>
<i>&gt; after the event.  But my guess is we can not imagine the changes a singularity</i><br>
<p>
If their reality representations was faulty, they would't remain around<br>
for long. Darwin would seem one of the very few constant factors<br>
throughout the Singularity. Then maybe I'm using an invalid extrapolation. <br>
<p>
<i>&gt; would cause before it occurs and thus we would have a hard time effectively</i><br>
<i>&gt; planning for such an event.</i><br>
<p>
As we are on the outskirts of the Singularity already, trying to keep<br>
himself _very_ informed while accreting personal wealth (=a richer set of<br>
possible future ego trajectories) would seem a pretty good strategy. Of<br>
course being part of the team about to transcend would be even better ;) <br>
<p>
<i>&gt; Vinge's idea of a technological singularity looming in the future is based on</i><br>
<i>&gt; the exponential tendecies of technological progress over time.  In mathematics,</i><br>
<i>&gt; a singularity is a point where mathematic modelling no longer works.  I think</i><br>
<i>&gt; the best way to view a technological singularity is as a mathematical</i><br>
<i>&gt; singularity.  In this sense, I view a technological singularity not as a point</i><br>
<p>
As I seem to recall, Vinge himself spoke against such an interpretation in<br>
his recent interview with N. More. <br>
<p>
<i>&gt; where technological progress becomes infinite but as a paradigm shift.  Our</i><br>
<i>&gt; conception of technological progress can not comprehend the environment at or</i><br>
<i>&gt; after a singularity event.  Thus when we attempt to graph it or manifest it in</i><br>
<i>&gt; some way we come up with "infinity".  The singularity event where a black hole</i><br>
<p>
But physics itself does not know infinities. With the possible exception<br>
of infinite spacetime curvature (where God divided by zero ;) -- which<br>
probably tells us more about shortcomings in current theories then<br>
infinities in the 'real' 'world'. <br>
<p>
<i>&gt; is formed is equally incomprehensible to our current conception of the laws</i><br>
<i>&gt; that govern the universe.  Many theorists believe that to fully understand what</i><br>
<i>&gt; takes place at the black hole singularity (and at the possible singularity that</i><br>
<i>&gt; existed near or before the point where the universe was the Planck time in age)</i><br>
<i>&gt; requires a dramatic shift (paradigm shift) in our understanding of the universe.</i><br>
<p>
Aren't superstrings, and M-theories not weird enough for ya? There are<br>
paradigm shifts occuring every second Monday. <br>
 <br>
<i>&gt; Would I survive a technological singularity event?  Maybe, but not without</i><br>
<i>&gt; being changed by it.  Perhaps the lithmus test will be whether people can adapt</i><br>
<p>
Sounds very plausible ;)<br>
<p>
<i>&gt; to the post-singularity environment after the singularity occurs.  Perhaps</i><br>
<i>&gt; we'll need drastically enhanced intelligence, mental resources, or other</i><br>
<i>&gt; characteristics completely strange to us now.</i><br>
<p>
There is no way how flesh would be able to persist even halfway through a<br>
Darwinian Singularity (does anybody disagree?). I even do not see how<br>
uploads are hoping to survive virtually unchanged (as there are<br>
conservative cryonists, there are conservative upload researchers) in a<br>
world rushing towards the new equilibrium (which might well be a Red Queen<br>
equilibrium). <br>
<p>
Several mails upstream, Randal Koene of MURG cited several buckytube<br>
theorists who recently estimated (before you ask, I have no idea who it<br>
was, which reference values for the human equivalent they used, and<br>
intuitively, their estimations would seem totally off) that about three<br>
bottlefulls of buckytube nanocircuitry would eclipse the combined wetware<br>
crunch of the whole planet. Even assuming one person/waterglass-grade<br>
circuitry (certainly achievable with autoassembly-constructable molecular<br>
circuits), one cubic mile of it would seem to be able to do a bit more<br>
than just to walk the dog. <br>
<p>
<i>&gt; About concerns of a holocaust, I made a post a month or so ago about what</i><br>
<i>&gt; meaning transhumanism had in a future where the Strong AI hypothesis ended up</i><br>
<i>&gt; being true.  I think a technological singularity could produce similar</i><br>
<i>&gt; concerns.  Every method Vinge proposed to get us to such an event involved</i><br>
<p>
Singularity is impossible without the strong AI hypothesis not being true.<br>
Brains the size of a planet are a bit difficult to do with plain wetware.<br>
<p>
<i>&gt; drastic changes in the way we are now.  I am not saying this would necessarily</i><br>
<i>&gt; be a "bad" thing.  But it would serve as a virtual holocaust of the way we are</i><br>
<i>&gt; now.  Terms such as transhuman imply some residue of humanity surviving.  Its</i><br>
<i>&gt; possible the future will result in a posthuman era where whatever you define as</i><br>
<i>&gt; "human" is no longer discernable in the resulting lifeforms.  But all of this</i><br>
<p>
Can there be an isomorphy between an embryo in blastula stage and an adult<br>
individuum?<br>
<p>
<i>&gt; hinges on factors we have no real control over.  If a holocaust of humanity</i><br>
<i>&gt; resides in the future then there is little we can do to avoid it.  Such a</i><br>
<i>&gt; holocaust, if it is to happen, will ride in on the apparently inexorable tide</i><br>
<i>&gt; of technological progress.</i><br>
<p>
Er, what was that thing, what was it called.. Dynamical Optimism, like?<br>
<p>
ciao,<br>
'gene<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<li> <b>Previous message:</b> <a href="2174.html">den Otter: "Re: PHIL: Extropy, Boundaries and Suicide"</a>
<li> <b>In reply to:</b> <a href="2136.html">DOUG.BAILEY@EY.COM: "Re: Singularity or Holocaust"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<li> <b>Reply:</b> <a href="2176.html">Anders Sandberg: "Re: Singularity or Holocaust"</a>
<!-- reply="end" -->
</ul>
