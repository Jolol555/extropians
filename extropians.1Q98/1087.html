<!-- received="Fri Jan 23 16:04:15 1998 MDT" -->
<!-- sent="Fri, 23 Jan 1998 18:01:15 -0500" -->
<!-- name="DOUG.BAILEY@ey.com" -->
<!-- email="DOUG.BAILEY@ey.com" -->
<!-- subject="(Ir)Relevance of Transhumanity in a Strong AI Future" -->
<!-- id="0014500017693120000002L002*@MHS" -->
<!-- inreplyto="" -->
<title>extropians: (Ir)Relevance of Transhumanity in a Strong AI Future</title>
<h1>(Ir)Relevance of Transhumanity in a Strong AI Future</h1>
<i>DOUG.BAILEY@ey.com</i><br>
<i>Fri, 23 Jan 1998 18:01:15 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1087">[ date ]</a><a href="index.html#1087">[ thread ]</a><a href="subject.html#1087">[ subject ]</a><a href="author.html#1087">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1088.html">James Rogers: "Re: Gov't Loves Gov't"</a>
<li> <b>Previous message:</b> <a href="1086.html">Prof. Gomes: "Clinton's sexual adventures..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1090.html">Anders Sandberg: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Reply:</b> <a href="1090.html">Anders Sandberg: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Maybe reply:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Reply:</b> <a href="1160.html">Charlie Stross: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Maybe reply:</b> <a href="1162.html">mark@unicorn.com: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
What relevance does transhumanity have in a future where the strong AI<br>
hypothesis turns out to be true?  The intuitive answers appears to be "very<br>
little".  To the extent that we can create artificial minds that are more<br>
intelligent that the human mind, transhumanity would appear to have the same<br>
significance in such a world as trans-raccoonism has today.<br>
<p>
We do not discuss trans-raccoonism that much since even a transraccoon would<br>
still be less intelligent than a human.  Put another way, in terms of future<br>
boundaries of possibilities it makes sense only to concentrate attention on the<br>
group that would possess the highest level of intelligence.  In a weak AI<br>
future, that group very well could be transhumans.  However, in a strong AI<br>
world it appears highly probably that some nonhuman nonbiological group would<br>
be at the top of the intelligence "heap".<br>
<p>
A fair amount of discourse exists concerning what such ultra-intelligent<br>
artificial minds would "do" with humans (or transhumans for that matter).  Some<br>
scenarios have humans being discarded but allowed to exist.  The scenario I<br>
consider more probable would be the eventual eclipse of humanity.  This<br>
scenario is based on several assumptions about the nature of superintellgient<br>
nonhuman entities which I will not go into here.<br>
<p>
I submit that such discourse is irrelevant.  Does it matter what happens to<br>
humanity in a strong AI future?  The raccoon example serves as a useful<br>
parallel.  Is there significant (or any) discourse on the fate of raccoons (or<br>
any nonhuman biological lifeform) in a transhuman future (regardless of the<br>
variation)?  Not that I am aware of.  Why?  Its irrelevant.  What does it<br>
matter what happens to raccoons in the future?<br>
<p>
Following the consequences of a strong AI future leads me to believe that<br>
transhumanity and the very fate of humanity (and transhumanity) will become<br>
irrelevant.  After a cursory review of this conclusion I do not see any way to<br>
avoid this conclusion.   We have moved from a geocentric to heliocentric to<br>
baryonic to anthropic view of the universe.  Our own universe may not even be<br>
that big of a deal, one of a virtual infinity of universes.  Now it seems, that<br>
in a future where the strong AI hypothesis holds true, that humanity is<br>
irrelevant.  Though I would rather not sound melodramatic (maybe its too late<br>
for that) it appears rueful that we would have the ability to fathom our own<br>
irrelevance.<br>
<p>
I invite others views on such a future and ways in which humanity<br>
(transhumanity) can maintain relevance.  Then again, is "relevance" such a<br>
noble goal in the first place?<br>
<p>
Doug Bailey<br>
doug.bailey@ey.com<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1088.html">James Rogers: "Re: Gov't Loves Gov't"</a>
<li> <b>Previous message:</b> <a href="1086.html">Prof. Gomes: "Clinton's sexual adventures..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1090.html">Anders Sandberg: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Reply:</b> <a href="1090.html">Anders Sandberg: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Maybe reply:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Reply:</b> <a href="1160.html">Charlie Stross: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Maybe reply:</b> <a href="1162.html">mark@unicorn.com: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- reply="end" -->
</ul>
