<!-- received="Thu Feb 26 11:50:20 1998 MDT" -->
<!-- sent="Thu, 26 Feb 1998 13:47:38 -0500" -->
<!-- name="DOUG.BAILEY@EY.COM" -->
<!-- email="DOUG.BAILEY@EY.COM" -->
<!-- subject="Re: Singularity or Holocaust" -->
<!-- id="0014500018399800000002L002*@MHS" -->
<!-- inreplyto="Singularity or Holocaust" -->
<title>extropians: Re: Singularity or Holocaust</title>
<h1>Re: Singularity or Holocaust</h1>
<i>DOUG.BAILEY@EY.COM</i><br>
<i>Thu, 26 Feb 1998 13:47:38 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2136">[ date ]</a><a href="index.html#2136">[ thread ]</a><a href="subject.html#2136">[ subject ]</a><a href="author.html#2136">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2137.html">Lee Daniel Crocker: "Re: human capital market"</a>
<li> <b>Previous message:</b> <a href="2135.html">Alexander 'Sasha' Chislenko: "Re: Credibility of SciAm?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2175.html">Eugene Leitl: "Re: Singularity or Holocaust"</a>
<li> <b>Reply:</b> <a href="2175.html">Eugene Leitl: "Re: Singularity or Holocaust"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
I do not believe anyone, regardless of their power base, will be able to<br>
effectively prepare in such a manner as to increase their survival chances at<br>
and after a technological singularity event.<br>
<p>
If a singularity event were to occur, life would be extremely different.  I am<br>
not saying it would be necessarily incomprehensible to those who were around<br>
after the event.  But my guess is we can not imagine the changes a singularity<br>
would cause before it occurs and thus we would have a hard time effectively<br>
planning for such an event.<br>
<p>
Vinge's idea of a technological singularity looming in the future is based on<br>
the exponential tendecies of technological progress over time.  In mathematics,<br>
a singularity is a point where mathematic modelling no longer works.  I think<br>
the best way to view a technological singularity is as a mathematical<br>
singularity.  In this sense, I view a technological singularity not as a point<br>
where technological progress becomes infinite but as a paradigm shift.  Our<br>
conception of technological progress can not comprehend the environment at or<br>
after a singularity event.  Thus when we attempt to graph it or manifest it in<br>
some way we come up with "infinity".  The singularity event where a black hole<br>
is formed is equally incomprehensible to our current conception of the laws<br>
that govern the universe.  Many theorists believe that to fully understand what<br>
takes place at the black hole singularity (and at the possible singularity that<br>
existed near or before the point where the universe was the Planck time in age)<br>
requires a dramatic shift (paradigm shift) in our understanding of the universe.<br>
<p>
Would I survive a technological singularity event?  Maybe, but not without<br>
being changed by it.  Perhaps the lithmus test will be whether people can adapt<br>
to the post-singularity environment after the singularity occurs.  Perhaps<br>
we'll need drastically enhanced intelligence, mental resources, or other<br>
characteristics completely strange to us now.<br>
<p>
About concerns of a holocaust, I made a post a month or so ago about what<br>
meaning transhumanism had in a future where the Strong AI hypothesis ended up<br>
being true.  I think a technological singularity could produce similar<br>
concerns.  Every method Vinge proposed to get us to such an event involved<br>
drastic changes in the way we are now.  I am not saying this would necessarily<br>
be a "bad" thing.  But it would serve as a virtual holocaust of the way we are<br>
now.  Terms such as transhuman imply some residue of humanity surviving.  Its<br>
possible the future will result in a posthuman era where whatever you define as<br>
"human" is no longer discernable in the resulting lifeforms.  But all of this<br>
hinges on factors we have no real control over.  If a holocaust of humanity<br>
resides in the future then there is little we can do to avoid it.  Such a<br>
holocaust, if it is to happen, will ride in on the apparently inexorable tide<br>
of technological progress.<br>
<p>
Doug Bailey<br>
doug.bailey@ey.com<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2137.html">Lee Daniel Crocker: "Re: human capital market"</a>
<li> <b>Previous message:</b> <a href="2135.html">Alexander 'Sasha' Chislenko: "Re: Credibility of SciAm?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2175.html">Eugene Leitl: "Re: Singularity or Holocaust"</a>
<li> <b>Reply:</b> <a href="2175.html">Eugene Leitl: "Re: Singularity or Holocaust"</a>
<!-- reply="end" -->
</ul>
