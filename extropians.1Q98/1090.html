<!-- received="Fri Jan 23 16:40:19 1998 MDT" -->
<!-- sent="24 Jan 1998 00:40:03 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: (Ir)Relevance of Transhumanity in a Strong AI Future" -->
<!-- id="199801232340.AA06020@park.uvsc.edu" -->
<!-- inreplyto="Fri, 23 Jan 1998 18:01:15 -0500" -->
<title>extropians: Re: (Ir)Relevance of Transhumanity in a Strong AI Future</title>
<h1>Re: (Ir)Relevance of Transhumanity in a Strong AI Future</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>24 Jan 1998 00:40:03 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1090">[ date ]</a><a href="index.html#1090">[ thread ]</a><a href="subject.html#1090">[ subject ]</a><a href="author.html#1090">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Previous message:</b> <a href="1089.html">Derek Strong: "Re: Clinton's sexual adventures..."</a>
<li> <b>In reply to:</b> <a href="1087.html">DOUG.BAILEY@ey.com: "(Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
DOUG.BAILEY@ey.com writes:<br>
<p>
<i>&gt; What relevance does transhumanity have in a future where the strong AI</i><br>
<i>&gt; hypothesis turns out to be true?</i><br>
<p>
Fist, a semantic quibble: I think you misuse the term strong AI to<br>
mean "superintelligent AI". The term already has a standard use in<br>
discussions about AI where the strong AI hypothesis refers to the idea<br>
that artificial intelligence is possible and implementable.<br>
<p>
BTW, this is yet another incarnation of an old debate. Look in the<br>
archives for more.<br>
<p>
<i>&gt; The intuitive answers appears to be "very little".  To the extent</i><br>
<i>&gt; that we can create artificial minds that are more intelligent that</i><br>
<i>&gt; the human mind, transhumanity would appear to have the same</i><br>
<i>&gt; significance in such a world as trans-raccoonism has today.</i><br>
<p>
I don't trust intuitive answers. I think you have fallen for what I<br>
sometimes call the "cult of superintelligence": the entity that is<br>
most intelligent will by necessity run the show. It is by no mean<br>
obvious that this is true, even on earth today there are plenty of<br>
species that couldn't care less about the doings of humans unless we<br>
start to mess up the biosphere *strongly*. And it is not inconceivable<br>
with superintelligent AI programmed or convinced to behave in a<br>
humanocentric fashion, much weirder motivations and value systems are<br>
possible. <br>
<p>
<i>&gt; We do not discuss trans-raccoonism that much since even a</i><br>
<i>&gt; transraccoon would still be less intelligent than a human.  Put</i><br>
<i>&gt; another way, in terms of future boundaries of possibilities it makes</i><br>
<i>&gt; sense only to concentrate attention on the group that would possess</i><br>
<i>&gt; the highest level of intelligence.</i><br>
<p>
I think this is a mistake. One should concentrate on the group or<br>
groups that have the most influence on events, regardless of their<br>
intelligence level. Of course, SI makes a very likely candidate for<br>
this, but one should not blithely assume that just because an AI is<br>
superintelligent it would run the world (cf. Stanislaw Lem's _Golem<br>
XIV_ where the SI had better things to do).<br>
<p>
<i>&gt; I submit that such discourse is irrelevant.  Does it matter what happens to</i><br>
<i>&gt; humanity in a strong AI future?  The raccoon example serves as a useful</i><br>
<i>&gt; parallel.  Is there significant (or any) discourse on the fate of raccoons (or</i><br>
<i>&gt; any nonhuman biological lifeform) in a transhuman future (regardless of the</i><br>
<i>&gt; variation)?  Not that I am aware of.  Why?  Its irrelevant.  What does it</i><br>
<i>&gt; matter what happens to raccoons in the future?</i><br>
<p>
There has been discussions about trans- and posthuman ecology. There<br>
are plenty of us on the list who regard biological diversity as<br>
desirable, and I seem to recall several discussions over the years I<br>
have participated on this and similar lists on animal rights,<br>
ecological modifications and the possibility of uplifting animals (not<br>
to mention the extropian squirrels). It should be noted that there are<br>
transhumanists who regard the fate of non-intelligent species as very<br>
relevant. I think this shows that what values the dominant entities<br>
will express is probably a very relevant question, and that some<br>
conceivable value sets might well involve the wellfare of racoons.<br>
<p>
<i>&gt; I invite others views on such a future and ways in which humanity</i><br>
<i>&gt; (transhumanity) can maintain relevance.  Then again, is "relevance"</i><br>
<i>&gt; such a noble goal in the first place?</i><br>
<p>
My partial answer is that, no, relevance is not neccessarily a noble<br>
or important goal (it is an expression of our evolutionarily developed<br>
tendency to value our survival and social freedom), but I seriously<br>
doubt many on this list wouldn't do their best to retain their<br>
relevance in the context they can fathom (note that we could become<br>
irrelevant in a context we do not care about, like amount of memorized<br>
decimals of pi (to use a silly example), which was very important for<br>
some other group of entities).<br>
<p>
However, I see one likely way for us humans and transhumans to retain<br>
our relevance even in a strongly posthuman era. And that is to become<br>
an integral part of the emerging superintelligences. After all,<br>
intelligence amplification provides a technology with obvious<br>
short-term benefits, and can in the long run be combined with ever<br>
more advanced AI systems (in fact, it is a reasonable assumption to<br>
guess that it is easier to develop human-supported AI than stand-alone<br>
AI, and much more profitable). <br>
<p>
If we play our cards well, our mental structure and values could<br>
remain a part of the emerging superintelligences just as our brains<br>
contain a trans-fish, a trans-lizard and a trans-marsupial in the form<br>
of the spinal cord, limbic system and cortex. We cannot do without<br>
them, but at the same time they have been subsumed into something<br>
greater. I suggest the same fate for humanity: we will not be replaced<br>
by the posthumans, we will become parts of the posthumans, their<br>
seeds.<br>
<p>
Hidden in my core<br>
a human soul template.<br>
Consciousness pearl<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<li> <b>Previous message:</b> <a href="1089.html">Derek Strong: "Re: Clinton's sexual adventures..."</a>
<li> <b>In reply to:</b> <a href="1087.html">DOUG.BAILEY@ey.com: "(Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1091.html">Dan Clemmensen: "Re: (Ir)Relevance of Transhumanity in a Strong AI Future"</a>
<!-- reply="end" -->
</ul>
