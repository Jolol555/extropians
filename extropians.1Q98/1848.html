<!-- received="Sun Feb 15 19:57:04 1998 MDT" -->
<!-- sent="Sun, 15 Feb 1998 18:56:56 -0800" -->
<!-- name="Peter C. McCluskey" -->
<!-- email="pcm@rahul.net" -->
<!-- subject="Re: Moral Complexity, Moral Efficacy  Was: Moo/Boo!" -->
<!-- id="199802160256.AA03221@foxtrot.rahul.net" -->
<!-- inreplyto="Moral Complexity, Moral Efficacy  Was: Moo/Boo!" -->
<title>extropians: Re: Moral Complexity, Moral Efficacy  Was: Moo/Boo!</title>
<h1>Re: Moral Complexity, Moral Efficacy  Was: Moo/Boo!</h1>
Peter C. McCluskey (<i>pcm@rahul.net</i>)<br>
<i>Sun, 15 Feb 1998 18:56:56 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1848">[ date ]</a><a href="index.html#1848">[ thread ]</a><a href="subject.html#1848">[ subject ]</a><a href="author.html#1848">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1849.html">CountZero: "Re: Melatonin where the sun never shines"</a>
<li> <b>Previous message:</b> <a href="1847.html">CurtAdams@aol.com: "Re:  Re: Why preserving BioDiversity is Extropian (was re:    Environmental Degr"</a>
<li> <b>Maybe in reply to:</b> <a href="1736.html">dalec@socrates.berkeley.edu: "Moral Complexity, Moral Efficacy  Was: Moo/Boo!"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1871.html">dalec@socrates.berkeley.edu: "Intuitions about animals  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1871.html">dalec@socrates.berkeley.edu: "Intuitions about animals  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1872.html">dalec@socrates.berkeley.edu: "Respect for Animals, Respect for People  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1873.html">dalec@socrates.berkeley.edu: "Arguing with a Power  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1874.html">dalec@socrates.berkeley.edu: "Re: Moral Complexity, Moral Efficacy  Was: Moo/Boo!"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
 dalec@socrates.berkeley.edu (dalec@socrates.berkeley.edu) writes:<br>
<i>&gt;On Tue, 10 Feb 1998, Peter C. McCluskey wrote:</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; Increasing those other features you mentioned may tend to cause an increase</i><br>
<i>&gt;&gt; in complexity, but that doesn't make complexity valuable in and of itself,</i><br>
<i>&gt;&gt; nor a good indicator of the others.</i><br>
<i>&gt;</i><br>
<i>&gt;As I mentioned before, there would seem to be a tradeoff between</i><br>
<i>&gt;decisiveness and openness that I would want to take into consideration</i><br>
<i>&gt;drawing the line as to just how complex I want my ethical deliberations to</i><br>
<i>&gt;be.  Nevertheless I have a strong prejudice in favor of complexity.  We're</i><br>
<i>&gt;probably talking a little past one another here.  To me, "simplicity" </i><br>
<i>&gt;taken as a value in a moral system codes usually as intolerance and lack</i><br>
<i>&gt;of imagination.</i><br>
<p>
 Under most conditions when society is working well, lack of imagination<br>
about moral codes is good because the rules tend to be close enough to<br>
optimal that random changes are more likely to hurt than to help.<br>
<p>
 To the limited extent that simplicity and intolerance have any correlation,<br>
it sure looks to me like it's a negative correlation. The genealogical<br>
contortions needed for racists to keep their rules from being subverted<br>
by interbreeding is hardly as simple as the rule that all humans have<br>
equal rights. Until you mention some examples of connections between<br>
simplicity and intolerance, I will be inclined to assume that your claim<br>
is based on inadequate stereotypes of bigots as being simpler because they<br>
are less educated.<br>
<p>
<i>&gt;  Want I want from ethical life are strategies that will</i><br>
<i>&gt;put me in a position to appreciate and thrive in as many situations as</i><br>
<i>&gt;either chance or my own design can contrive to throw at me.  What seems to</i><br>
<i>&gt;me to be wanted from ethics is richness more than simplicity.</i><br>
<p>
 You are clearly using "ethics" to refer to a much broader set of rules<br>
than I do.<br>
<p>
<i>&gt;I would distinguish an individual moral code (an esthetic/prudential style</i><br>
<i>&gt;of living and individual meaning-making), from a social or political civil</i><br>
<i>&gt;code.  I think I've mentioned before that although I pretty strongly</i><br>
<i>&gt;advocate vegetarian practices as individually broadening, I don't think</i><br>
<i>&gt;vegetarian sensitivities should be mandated at the level of law.  This is</i><br>
<i>&gt;partly for the reasons you mentioned above.  Still, even on your own terms</i><br>
<i>&gt;it seems to me that simplicity isn't a *self-evident* value here.  Doesn't</i><br>
<p>
 Very few values are self-evident.<br>
 Some more hints about why simplicity is good:<br>
 Occam's Razor.<br>
 Given 2 pieces of software that can accomplish the same tasks, would<br>
you prefer the more complex or the simpler?<br>
<p>
<i>&gt;it sometimes conduce to the benefit of social stability for a moral code</i><br>
<i>&gt;to institute wiggle-room and ongoing contestation of norms?  Sometimes</i><br>
<i>&gt;it's good to make moral consensus a difficult thing to achieve.  Sometimes</i><br>
<i>&gt;its good to keep the dividing lines between the moral and immoral pretty</i><br>
<i>&gt;muddy (as when a clear "us" and "them" underwrites genocidal rages for</i><br>
<i>&gt;order and purity).</i><br>
<p>
 Good point. I need to think some more about how this relates to my other<br>
desires about moral systems.<br>
<p>
<i>&gt;Animal rights discourse seems intriguing to me, but pretty flawed.  As a</i><br>
<i>&gt;rule I simply try not to inflict pain knowingly and unecessarily on beings</i><br>
<i>&gt;capable of experiencing it.  It does seem to me profoundly disrespectful</i><br>
<i>&gt;to recognize that the pain experienced by the beings we instrumentalize as</i><br>
<i>&gt;food (etc) is real but simply doesn't *matter*.  I want to respect as wide</i><br>
<i>&gt;a range of beings as I can.  </i><br>
<p>
 Making the ability to experience pain an important basis for respecting<br>
rights bothers me because the difficulty of figuring out what beings<br>
dissimilar to us experience makes it easy for people who rely on this<br>
rule to rationalize almost any treatment of those beings that happens<br>
to be convenient. How does your moral system handle these:<br>
 - fish<br>
 - clams<br>
 - humans genetically engineered so they say they feel no emotional<br>
 reaction to things that would be painful to us<br>
 - uploaded humans<br>
 - AIs<br>
 These last three are probably the areas where different moral systems will<br>
have the most important differences in results in the next century.<br>
<p>
 My idea of a moral rule that can handle these better is based on the<br>
ability to agree to respect each others rights. However, I'm still<br>
dissatisfied with the difficulties in dealing with beings who can't<br>
communicate well with us.<br>
<p>
<i>&gt;	One of the negative consequences of the line between human and</i><br>
<i>&gt;nonhuman animals being so obvious to most people is that it creates a</i><br>
<i>&gt;general category of beings whose pain doesn't matter to us ethically, a</i><br>
<i>&gt;category that seems to attach pretty promiscuously to other beings whose</i><br>
<i>&gt;pain we would prefer not to bother too much with.  It is a matter of</i><br>
<i>&gt;record that justifications for misogynist or racist practices often</i><br>
<i>&gt;(almost *always*) make recourse to the theme of the so-called subhuman or</i><br>
<i>&gt;bestial nature of the people it dismisses.  Muddying these categorical</i><br>
<i>&gt;waters and so depriving this rhetorical tactic of its sting would possibly</i><br>
<i>&gt;be a salutary thing.</i><br>
<p>
 I don't know. How likely is it that people who are open to racist rhetoric<br>
will also be open to adopting your ethics in a consistently principled way?<br>
 Where do racist vegetarians like Hitler fit into this?<br>
 My impression is that xenophobic intolerance rarely depends in any important<br>
way on classifying others as subhuman. It appears to be largely an<br>
evolutionary adaptation for creating tribal unity that is most powerfull<br>
when the objective differences between the tribes are smallest (i.e. when<br>
the danger of tribe members defecting is largest). Hatred towards, say,<br>
mosquitos, seems to be much more subdued than hatred between Catholics<br>
and Protestants in Northern Ireland.<br>
<p>
<i>&gt;	If I were in a position to argue with a Power who was on the verge</i><br>
<i>&gt;of using the population of Poughkeepsie as ubergoo feedstock for some</i><br>
<i>&gt;transhuman construction project, I would say that respecting diversity has</i><br>
<i>&gt;the consequence of opening up an unforseeably richer range of pleasurable</i><br>
<p>
 That might work for some harmfull things a Power would be tempted to do,<br>
but would be couterproductive in other circumstances. What about the<br>
Power who wants to have fun by watching how humans respond to random<br>
disturbances it adds to human society? A virus here, some random bits<br>
flipped there, could give it a richer understanding of nature than<br>
mere passive observation. I'd rather aim for convincing it to follow<br>
a rule which implied respecting our rights.<br>
 Also, a Power will probably know enough that the example you set by <br>
your vegetarianism is very unlikely to convince it to change its moral<br>
system.<br>
<p>
<i>&gt;experiences (I for one don't think of my vegetarianism as a limiting or</i><br>
<i>&gt;ascetic lifestyle as many seem to), as well as providing a robust and</i><br>
<p>
 Vegetarianism wouldn't be much of a limitation on meals I eat alone,<br>
but when eating out with others the costs of determining which foods<br>
meet vegetarian standards and altering behavior to follow those standards<br>
consistently seem enough that it would take a compelling argument to<br>
persuade me to adopt vegetarianism.<br>
<p>
<i>&gt;resilient cultural system better able to fend off dangers unforseeable to</i><br>
<i>&gt;even such a Power.  I see my vegetarianism as a dress rehearsal for Power</i><br>
<i>&gt;ethics to come.  (I'm sorry to hereby inflict the list with more "My</i><br>
<i>&gt;Little Pony" extropianism.)</i><br>
<p>
 Huh? You're sorry for being interesting?<br>
<p>
<i>&gt;  Anyway, I agree with you that the boundary</i><br>
<i>&gt;does indeed seem to be one of personal choice.  I wouldn't say it is</i><br>
<i>&gt;"just"  personal choice, since this suggests that stronger injunctions are</i><br>
<i>&gt;available, when ultimately I suspect they are not.  Peter, thanks for the</i><br>
<p>
 I expect stronger injunctions for rules that I have confidence in as<br>
moral systems. For instance, I normally demand that they be evolutionarily<br>
stable, and that people willingly accept them.<br>
<pre>
-- 
------------------------------------------------------------------------
Peter McCluskey  |  pcm@rahul.net  | Has anyone used <a href="http://crit.org">http://crit.org</a>
<a href="http://www.rahul.net/pcm">http://www.rahul.net/pcm</a>           | to comment on your web pages?
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1849.html">CountZero: "Re: Melatonin where the sun never shines"</a>
<li> <b>Previous message:</b> <a href="1847.html">CurtAdams@aol.com: "Re:  Re: Why preserving BioDiversity is Extropian (was re:    Environmental Degr"</a>
<li> <b>Maybe in reply to:</b> <a href="1736.html">dalec@socrates.berkeley.edu: "Moral Complexity, Moral Efficacy  Was: Moo/Boo!"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1871.html">dalec@socrates.berkeley.edu: "Intuitions about animals  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1871.html">dalec@socrates.berkeley.edu: "Intuitions about animals  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1872.html">dalec@socrates.berkeley.edu: "Respect for Animals, Respect for People  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1873.html">dalec@socrates.berkeley.edu: "Arguing with a Power  Was: Moral Complexity"</a>
<li> <b>Reply:</b> <a href="1874.html">dalec@socrates.berkeley.edu: "Re: Moral Complexity, Moral Efficacy  Was: Moo/Boo!"</a>
<!-- reply="end" -->
</ul>
