<!-- received="Tue Feb 24 23:24:58 1998 MDT" -->
<!-- sent="Wed, 25 Feb 1998 17:16:17 +0000" -->
<!-- name="Damien Broderick" -->
<!-- email="damien@ariel.ucs.unimelb.edu.au" -->
<!-- subject="Re: &gt;H Free Will" -->
<!-- id="E0y7aML-0002pZ-00@mail.unixg.ubc.ca" -->
<!-- inreplyto="&gt;H Free Will" -->
<title>extropians: Re: &gt;H Free Will</title>
<h1>Re: &gt;H Free Will</h1>
Damien Broderick (<i>damien@ariel.ucs.unimelb.edu.au</i>)<br>
<i>Wed, 25 Feb 1998 17:16:17 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2082">[ date ]</a><a href="index.html#2082">[ thread ]</a><a href="subject.html#2082">[ subject ]</a><a href="author.html#2082">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2083.html">Michael M. Butler: "Re: the loss of privacy"</a>
<li> <b>Previous message:</b> <a href="2081.html">Geoff Smith: "Re: PHIL: Extropy, Boundaries and Suicide"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 09:23 PM 2/24/98 -0800, John Clark wrote at random, that is, freely (by<br>
his own account):<br>
<p>
<i>&gt; A man, animal or machine has free will if it can not always predict  </i><br>
<i>&gt;what it will do in the future even if the external environment is constant. </i><br>
&lt;snips&gt;<br>
<i>&gt;If I had total self knowledge then I'd always know what I was going to do </i><br>
<i>&gt;next and so I'd feel like a robot</i><br>
<p>
John, I think this is a terrible confusion, although one that many people<br>
hold to.  Freedom of choice for humans does not mean acting at random like<br>
the Dice Man; that would be psychosis, not freedom.  I think your model<br>
doesn't imply that anyway, but rather that our consciousness or ego is a<br>
module (either executive or interpretative) with very restricted<br>
information about the full state of the self.  This means that when we opt,<br>
we do so from many more `unconscious' motives and after many more<br>
`unconscious' or `non-conscious' combinatory and analytical moves made in<br>
parallel than can be registered by the conscious self, except via some kind<br>
of sampled/gestalted `feeling tone' of satisfaction, flow, frustration,<br>
confusion, guilt, etc.  But most free choices, and the satisfactory feeling<br>
that goes with acting in ways that are not plainly constrained to our<br>
disadvantage, *do* have the characteristic of being consistent with our<br>
acquired values.  True, some of those values function as meta-values, so<br>
that we can try to rewire others lower down the hierarchy, or debug values<br>
and templates that were ported into us before we had enough nous to<br>
evaluate and reject or modify them.  But I think that the more we make our<br>
values `our own', the more free we feel - that is, against your claim that<br>
we would feel like robots.<br>
<p>
I guess.<br>
<p>
Damien Broderick<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2083.html">Michael M. Butler: "Re: the loss of privacy"</a>
<li> <b>Previous message:</b> <a href="2081.html">Geoff Smith: "Re: PHIL: Extropy, Boundaries and Suicide"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
