<!-- received="Tue Feb  3 15:20:07 1998 MDT" -->
<!-- sent="Tue, 3 Feb 1998 13:33:04 -0800 (PST)" -->
<!-- name="Yak Wax" -->
<!-- email="yakwax@yahoo.com" -->
<!-- subject="[CRYONICS][BOOK] "The First Immortal"" -->
<!-- id="0014500017959332000002L022*@MHS" -->
<!-- inreplyto="" -->
<title>extropians: [CRYONICS][BOOK] "The First Immortal"</title>
<h1>[CRYONICS][BOOK] "The First Immortal"</h1>
Yak Wax (<i>yakwax@yahoo.com</i>)<br>
<i>Tue, 3 Feb 1998 13:33:04 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1444">[ date ]</a><a href="index.html#1444">[ thread ]</a><a href="subject.html#1444">[ subject ]</a><a href="author.html#1444">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1445.html">Anders Sandberg: "Re: Guru wanted!"</a>
<li> <b>Previous message:</b> <a href="1443.html">DOUG.BAILEY@ey.com: "Re: Heroism"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1388.html">Hal Finney: "Re: [CRYONICS][BOOK] "The First Immortal""</a>
<li> <b>Maybe reply:</b> <a href="1388.html">Hal Finney: "Re: [CRYONICS][BOOK] "The First Immortal""</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Hal Finney &lt;hal@rain.org&gt; wrote:<br>
<p>
<i>&gt; Halperin has a couple of tricks to slow the rate of technology</i><br>
advance.<br>
<i>&gt; One is to put restrictions on AI research.  Some early AI machines</i><br>
become<br>
<i>&gt; aggressive and kill people, and after that they are not supposed to be</i><br>
<i>&gt; programmed with emotions or survival instincts.  They're just a</i><br>
bunch of<br>
<i>&gt; Vulcan types.  They do become much smarter than humans over the course</i><br>
<i>&gt; of the 21st century, but presumably these restrictions do limit their</i><br>
<i>&gt; rate of advance.</i><br>
<p>
The ironic thing is we do the same thing in real life - appoint<br>
authority so we can quitely 'ignore' the real complexity of a<br>
situation.  I've said it before and I'll say it again - authority is<br>
ignorance.<br>
<p>
<i>&gt; The other magic which Halperin has up his sleeve is his Truth Machine.</i><br>
<i>&gt; This was the subject of his first novel, which I haven't read.  The</i><br>
device<br>
<i>&gt; is a foolproof lie detector, and it allows laws to be enforced with a</i><br>
<i>&gt; certainty far beyond anything which would be reasonable today.</i><br>
<p>
The problem with (most) Sci-fi is the way it's written - first you<br>
find a problem (crime), the you find a solution (the truth machine). <br>
However, real life works differently - breakthrough technology is<br>
created before any 'real-world' application has been thought of.<br>
<p>
I wrote a paper on how the web could evolve into a "truth machine" of<br>
sorts, but it would not be abusable in the same way.  One of the<br>
factors people are most worried about on the internet is the lack of<br>
privacy, but it could turn out to be its greatest advantage.  When<br>
everything you do is recorded and stored in a distributed/open<br>
environment and then linked to everything everyone else does, it's<br>
impossible to lie or cheat.  This doesn't require a revolutionary new<br>
technology but the continuation of a trend (so it's more likely to<br>
happen.)<br>
<p>
<i>&gt; In effect this kind of technology is a power amplifier.  Whoever has</i><br>
the<br>
<i>&gt; bulk of power in society can use this to enforce their will.  If the</i><br>
mass<br>
<i>&gt; of people ultimately has the power, then in many ways the truth</i><br>
machine<br>
<i>&gt; will be beneficial, as they can prevent evil people from seizing power</i><br>
<i>&gt; away from them.  On the other hand, where the masses misuse their</i><br>
power,<br>
<i>&gt; there won't be the limitations on their abilities that we have today.</i><br>
<i>&gt; The majority of people in the United States believes in conventional</i><br>
<i>&gt; religious morality, but if it wants to legislate on that basis, in</i><br>
<i>&gt; practice it can't control people's private lives very well.  A truth</i><br>
<i>&gt; machine would change that.</i><br>
<p>
Of course, if there was absolute truth (and I mean "absolute" not just<br>
the detection of crime) then it would create a truly 'open' society. <br>
We would  not only see the crime, but the reasons for the crime and<br>
may well decide it is not a crime after all.  We would also see that<br>
*everyone* is breaking the law.  The idea of this kind of<br>
"open-society" appeals to me (not because it brings peace and love,<br>
but because it's one of those things that changes *everything*.)  Hey,<br>
and finally others may see the world in the same way I do<br>
(--&gt;shocking&lt;--)<br>
<p>
<i>&gt; I thought Halperin's novel was most effective in depicting a 21st</i><br>
century<br>
<i>&gt; where we'd like to live, and where technology really does advance to</i><br>
<i>&gt; the point where it solves many of our most difficult problems.  I was</i><br>
<i>&gt; uncomfortable when it took on a scolding tone, shaking its head over</i><br>
how<br>
<i>&gt; blind people were in the late 20th century not to sign up for</i><br>
cryonics.<br>
<i>&gt; This reminds me too much of a temperance tract regaling us with the</i><br>
<i>&gt; evils of Demon Alcohol.</i><br>
<p>
I wouldn't like to live there - government!<br>
<p>
<i>&gt; Science fiction authors often succumb to the temptation to have their</i><br>
<i>&gt; future characters talk about the mistakes of the 20th century - if</i><br>
<i>&gt; only they'd taken care of the environment, or if only they'd been more</i><br>
<i>&gt; socialist, no, if only they'd been more capitalist, etc.  I never find</i><br>
<i>&gt; this realistic (how much time do we spend talking about the mistakes</i><br>
of<br>
<i>&gt; the 1890's?), and even when it does fit, I don't necessarily think the</i><br>
<i>&gt; future characters are right (people today disagree over the morality</i><br>
<i>&gt; of the "robber barons" of the 19th century, even with 100 years of</i><br>
<i>&gt; hindsight).</i><br>
<p>
This is something I don't get - people (writers especially) seem to<br>
think that in their future (unlike their parents, or grandparent<br>
before them) they'll look back and think, "I'm so ashamed by all that<br>
pain and suffering we caused, things are so much better now."  The<br>
problem is, things aren't going to better from our perspective, but<br>
they will be better.  'Good' is subjective and future 'good' is<br>
subject to future citizens (i.e. kids)  The only way<br>
potential-immortals could 'survive' tommorow is by doing away with<br>
that kind of subjectivity (hence the reason I don't believe in<br>
'morals', 'ethics', etc).  Here's a clue: if you think there's<br>
something wrong with the world today, you're not going to fit-in<br>
tommorow.<br>
<p>
<i>&gt; Halperin doesn't overdo this, fortunately.  If his novel is a success</i><br>
<i>&gt; then it probably will help to make cryonics more acceptable.  But I</i><br>
<i>&gt; suspect that it will be many years before it becomes truly mainstream.</i><br>
<p>
The only obvious advantage of mainstream acceptance is having cheaper,<br>
more ubiquitous cryonics centers.  Which would be nice (I want a<br>
portable.)<br>
<p>
--Wax<br>
<p>
Rise - Future proof your thinking.<br>
On-Line Q4 1998<br>
Preview Q2 1998<br>
<p>
<p>
<p>
<p>
_________________________________________________________<br>
DO YOU YAHOO!?<br>
Get your free @yahoo.com address at <a href="http://mail.yahoo.com">http://mail.yahoo.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1445.html">Anders Sandberg: "Re: Guru wanted!"</a>
<li> <b>Previous message:</b> <a href="1443.html">DOUG.BAILEY@ey.com: "Re: Heroism"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1388.html">Hal Finney: "Re: [CRYONICS][BOOK] "The First Immortal""</a>
<li> <b>Maybe reply:</b> <a href="1388.html">Hal Finney: "Re: [CRYONICS][BOOK] "The First Immortal""</a>
<!-- reply="end" -->
</ul>
