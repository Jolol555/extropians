<!-- received="Thu Feb 26 12:06:46 1998 MDT" -->
<!-- sent="26 Feb 1998 20:06:42 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Singularity or Holocaust?" -->
<!-- id="199802261927.LAA13537@mercury.colossus.net" -->
<!-- inreplyto="Wed, 25 Feb 1998 22:52:49 -0800" -->
<title>extropians: Re: Singularity or Holocaust?</title>
<h1>Re: Singularity or Holocaust?</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>26 Feb 1998 20:06:42 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2138">[ date ]</a><a href="index.html#2138">[ thread ]</a><a href="subject.html#2138">[ subject ]</a><a href="author.html#2138">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2139.html">Max More: "Virtual Obsession/Host tonight on ABC"</a>
<li> <b>Previous message:</b> <a href="2137.html">Lee Daniel Crocker: "Re: human capital market"</a>
<li> <b>In reply to:</b> <a href="2121.html">Paul Hughes: "Singularity or Holocaust?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2150.html">Paul Hughes: "Re: Singularity or Holocaust?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Paul Hughes &lt;planetp@aci.net&gt; writes:<br>
<p>
<i>&gt;I have pondered with great interest some of the recent postings on the</i><br>
<i>&gt;singularity and post-humanism.  One of the passages that caught my eye</i><br>
<i>&gt;was by den Otter posted to the list on Feb 21.  It reads as follows:</i><br>
<i>&gt;</i><br>
<i>&gt;&gt;'Unless trasnhumanists get somehow organized the chances that any of</i><br>
<i>&gt;&gt;us will make it past the singularity are close to zero; the powers</i><br>
<i>&gt;&gt;that be will crush us like worms.  Only (some of) the rich and</i><br>
<i>&gt;&gt;powerful are going yo make it.'</i><br>
<i>&gt;</i><br>
<i>&gt;I have to say I can't argue with this - this seems liek a *very* real</i><br>
<i>&gt;scenario.  Does anybody see it differnetly?  And if so, how and why</i><br>
<i>&gt;have you come to a different set of conclusions?</i><br>
<p>
There are two questions here that needs to be answered: what do we<br>
mean with the singularity, and what social dynamics will we see around<br>
it. Unless we answer the first the rest of the discussion will be just<br>
a loud waste of bits. All too often the singularity becomes just<br>
another name for the rapture, some kind of techno-escaton that is left<br>
conveniently undescribed and magical.<br>
<p>
What we know is that a lot of growth curves are nearly exponential<br>
(interestingly no longer the population curve, if the new figures are<br>
to be believed) and that it seems possible that they can get even<br>
steeper (vide Hans Moravecs discussion of Moore's "law"). Will they<br>
all become asymptotically vertical in a finite time (the Vinge<br>
singularity), have an inflexion point and then settle towards a very<br>
high but finite level (the sigmoid singularity) or does the<br>
singularity mean no predictions about the future are possible (the<br>
horizon singularity?).<br>
<p>
If we speak about the horizon singularity this discussion is fairly<br>
pointless; den Otter's exhortation is still a good idea for a number<br>
of reasons, but we cannot discuss what we need to do to survive the<br>
singularity since it is by definition unknowable. Boring.<br>
<p>
If we speak about the other two singularities it becomes clear that<br>
change is the keyword here. Can we and what we enjoy survive<br>
steepening change? That is a very good question.<br>
<p>
One of my favorite devices is "exponential change makes differences<br>
grow exponentially". If I have good intelligence amplification, then I<br>
can use it to earn enough to buy or develop better IA equipment, and<br>
so on. My neighbor, who isn't quite as bright will still improve, but<br>
will lag after more and more while I soar towards transcension. The<br>
same can be said about various economies: many poor nations are<br>
actually doing reasonably well, but compared to us they appear almost<br>
static. And guess who will afford the scientists, engineers,<br>
businessmen and other people who will make growth even faster?<br>
<p>
There are equalizing forces too. Many of the results from expensive<br>
and time-consuming research appear openly in journals and on the net,<br>
making it possible for others to leapfrog. Technology spreads, and<br>
rich groups can and do give some of their surplus to others<br>
(voluntarily or not). The problem is of course: are these forces<br>
enough to keep the differences finite? I doubt it. <br>
<p>
I will try to model this like N coupled differential equations,<br>
where the solutions Y_n(t) are growing exponentially but linked by<br>
diffusion terms. Something like<br>
<p>
Y'_n = k*Y_n + l*(sum Y_i - N*m*Y_n) = (k-lmN)Y_n + l*sum Y(i)<br>
<p>
If l is large enough, then every Y_n will tend to<br>
approach each other, and we smaller differences over time. This<br>
corresponds to strong diffusion where sharing costs you m (this is<br>
essentially growth with redistribution). If the cost m is zero (like<br>
in broadcasting it on the net), then the solutions do not approach or<br>
diverge, their internal differences remains but do not grow. In fact,<br>
if you look at the derivatives of the differences you get <br>
<p>
(Y_i-Y_j)' = (k-lmN)(Y_i - Y_j)<br>
<p>
which shows that if m is low or zero, then the differences will grow<br>
regardless of how much help the advantaged give the disadvantaged;<br>
just helping others wont bridge the gap, you need to slow down<br>
yourself to do that (and that might put you at an<br>
disadvantage). Sharing is also more likely when m is small than when m<br>
is big. The N term is however a bit hopeful, the more players there<br>
are, the more differences will be averaged out and the overall support<br>
from others will become dominant.<br>
<p>
m seems to be decreasing rather than increasing in an information<br>
society like ours, k is already fairly high and l has obviously not<br>
been high enough in the past to lessen differences. N might be<br>
increasing, though, as new players enters the global arena.<br>
<p>
(I actually wrote a small MatLab script to play with this while<br>
writing this article, I have appended it at the end. Nothing special,<br>
but useful for thinking graphically)<br>
<p>
So it seems likely that differences will grow rather than shrink as<br>
the singularity or any other period of fast, self-supporting change is<br>
approached. Now, given the human tendency for envy and fear of anybody<br>
who get's too powerful, this suggests that tensions will increase long<br>
before the truly transhuman stage (no need to invoke the Powers). Even<br>
if most of the have-nots profit from the haves, there will likely be<br>
some who resent them for various reasons.<br>
<p>
How these tensions are released is a tricky question which depends on<br>
the relative power of the haves and have-nots. If the have-nots<br>
cannot seriously hurt the haves, then nothing will likely happen<br>
except that the haves will grow ever stronger (faster than the<br>
have-nots, who will still grow) with plenty of mutual ill<br>
feelings. It is not given that the haves would want to stomp out the<br>
have-nots if m is low or zero - as long sum(Y_i) is larger than m*Y_n<br>
they will profit from the occasional useful idea from the other<br>
side. It is once m*Y_n becomes larger than the sum the situation<br>
becomes improfitable, but then it is just easier to break contact<br>
(aha, the economic reason for transcending?) (cost: 0) than remove the<br>
have-nots (cost: finite).<br>
<p>
So this scenario contains one part of humanity transcending, leaving<br>
the rest (by now fairly advanced) in the dust. This part can still<br>
transcend, and we might even get a multipart singularity. The long<br>
range fate of everybody depends a lot on tricky questions about<br>
resources: are the have-nots economical as feedstock? do the Powers<br>
need to struggle for resources in the solar system? It should be noted<br>
that if the sigmoid theory of technological growth holds, then the<br>
Powers will reach a point of diminishing returns where k and l will<br>
begin to decrease (say like k0/(1+Y_n)) and the differences will<br>
eventually start to decrease again as everybody eventually reaches the<br>
same technological ceiling. At this point ordinary economics likely<br>
takes over again, there is no real point in struggling with each other<br>
since it is more profitable to wotk together at solving the remaining<br>
problems.<br>
<p>
The other scenario involves that the have-nots can hurt the haves, say<br>
through terrorism. In this case it will be in the interest of the<br>
haves to either grow so fast that they become invulnerable (this<br>
assumes they can beforehand figure out that "at tech level X nothing<br>
the others can do could hurt us", a doubtful assumption, especially<br>
since the others are learning from the haves), decrease the<br>
likeliehood of terrorism or neurtralize the have-nots. The problem<br>
here is that the more powerful technologies appear in the world, the<br>
easier it seems to create a terror weapon (the shields are not keeping<br>
pace with the spears - it might be interesting to ask under what<br>
circumstances this could change). Since there is a finite chance that<br>
somebody somewhere might use a terror weapon, the situation becomes<br>
less and less stable as technology advances (unless a Cold War<br>
standoff can emerge, which requires *strict* control of the relevant<br>
technologies by *few* groups). So even if the haves are spending<br>
resources on goodwill, there is always a chance that somewhere in a<br>
remote corner a lunatic could be building a weapon of mass destruction<br>
using fairly old tech (fertilizer, anybody?). Goodwill just lowers the<br>
risk, it does not remove it (this is true regardless of the<br>
differences between haves and have-nots, it seems to be a general<br>
problem for sufficiently advanced and violent civilizations). So the<br>
obvious solution would be to neutralize the have-nots. Traditionally<br>
this has been done using extinction, but that might not be ideal (the<br>
have-but-not-so-muchs just below the haves might get paranoid, and<br>
since both sides understand this they might not want to start a trend<br>
that could spell the doom for both of them) and other possibilities<br>
could be used: deliberate steering away from dangerous technologies<br>
and ideas, gnatbot police or even subtle brainwashing. This comes at a<br>
noticeable cost, including loss of useful help from the have-nots<br>
(remember that they are still useful up to very high differences) and<br>
the risk of being discovered and attacked (once you have become<br>
paranoid, you cannot stop - it is a memetic cancer). <br>
<p>
So a lot will hinge on the exact distribution of<br>
power/knowhow/extropy/whatever between the players. At present the<br>
distribution has a noticeable tail in the positive direction (my guess<br>
is that it is some form of x exp(-x) curve). As this distribution<br>
evolved, it will become broader, carried along the dynamics discussed<br>
above. If we make the oversimplifaction of seeing it as roughly<br>
exponential, then the distribution f(x) at time 0 will become<br>
f(exp(tx)) at time t. Even a fairly narrow distribution will become<br>
broader and develop a tail. <br>
<p>
If there exists a continuum of players between the foremost haves and<br>
the last have-nots, then the strains will be more distributed and<br>
every player would have to deal with both greater, lesser and equal<br>
players. This might be stabilising, since no single player would<br>
easily be able to control the whole system - there are players at<br>
least of equal power and a significant number of less powerful players<br>
that could ally against it. Even the most powerful player would have<br>
to deal with the total mass below. Only if one group could separate<br>
itself significantly from the others would it be possible for it to<br>
neutralize the others, and any such separation moves would naturally<br>
be keenly watched by others. This suggests that the possibility of<br>
secretly planned jumps ahead as a powerful destabilizing force - if<br>
they are possible, then it might be possible for a player to become<br>
dominant before anybody can react. If these jumps really are possible<br>
is both determined by technology/physical law (e.g. could a dominant<br>
technology such as (say) workable brainwashing nanites be developed?<br>
Could espionage become soo good that it forces openness?)  and policy<br>
(do the leading players demand openness from each other?). It seems<br>
that the "weapon of openness" is quite cruicial here. Since nobody<br>
wants to become neutralized and have everything to win by cooperating<br>
with the others, a mutual openness policy would be desirable for all<br>
players, unless they have reason to believe such an openness could be<br>
subverted.<br>
<p>
Will the haves remain cohesive? Their internal differences would have<br>
exactly the same dynamics as for the others, and since they would be<br>
growing the fastest, the strains would be largest. It is rather likely<br>
this model does not work identically on the smaller scale of such a<br>
group (e.g. the constants k,l and m are different in groups than<br>
between groups). This could lead to cohesive groups diverging from<br>
each other (potential for inter-group conflicts) or that groups loose<br>
cohesion. If the growth dynamics is dependent on the size of the<br>
groups (for example, due to the need of specialization in a complex<br>
field), then this loss of cohesion would also act as a limiting factor<br>
on the growth of the have's, enabling the have-nots to catch up<br>
slightly. On the other hand, as I have discussed above, there is no<br>
reason much more advanced individuals could not work together with<br>
less advanced individuals if both profit from it due to their<br>
different specialisations. This requires further consideration (a<br>
first rough model might be to decrease k and l inversely<br>
proportionally to Y_1, which would make the model identical to the<br>
sigmoid model mentioned above. However, the response is likely more<br>
nonlinear).<br>
<p>
Conclusions: <br>
<p>
It seems very likely that the differences between different groups of<br>
humans at least on some scales will grow exponentially in the near<br>
future. Traditional solutions to lessening differences<br>
(redistribution) fail when sharing becomes cheaper (as in an<br>
information society). The appearance of a large number of interacting<br>
players might make the growth period easier. The growing differences<br>
are likely to cause strains forcing the leading edge to either speed<br>
ahead to a safe region, attempt to control the situation or neutralize<br>
the threat of the have-nots. Only the first alternative appears to be<br>
completely stable, the others have noticeable risks. The leading edge<br>
will suffer from the most intense differences, and might be hampered<br>
in its growth for these reasons. Openness seems to be one of the best<br>
ways of handling the risks of "jumping ahead" and gap formation, as<br>
well as allowing the have-nots to assure the haves that they have no<br>
evil plans in store.<br>
<p>
<p>
<p>
Well, this got a bit out of hand (I had only planned to write a simple<br>
response), but I hope this response shows why I remain optimistic<br>
about the future but at the same time think it will become much too<br>
interesting for us to like :-)<br>
<p>
<p>
----------------<br>
<p>
% Number of players<br>
n=10;<br>
% Timestep<br>
h=0.1;<br>
<p>
% Rate of advance<br>
k=1;<br>
% Technology diffusion<br>
l=0.06;<br>
% Cost of sharing<br>
m=0;<br>
<p>
y=abs(randn(1,n));<br>
mm=[];<br>
<p>
for i=1:10,<br>
ys=sum(y);<br>
yp=k*y+l*(ys-m*n*y);<br>
y=y+yp*h;<br>
mm=[mm; y];<br>
end,<br>
plot(log(mm)),<br>
<p>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2139.html">Max More: "Virtual Obsession/Host tonight on ABC"</a>
<li> <b>Previous message:</b> <a href="2137.html">Lee Daniel Crocker: "Re: human capital market"</a>
<li> <b>In reply to:</b> <a href="2121.html">Paul Hughes: "Singularity or Holocaust?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2150.html">Paul Hughes: "Re: Singularity or Holocaust?"</a>
<!-- reply="end" -->
</ul>
