<!-- received="Tue Feb  3 14:25:46 1998 MDT" -->
<!-- sent="Tue, 3 Feb 1998 13:08:24 -0800" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: POLL: Strong AI Hypothesis: for or against" -->
<!-- id="199802032108.NAA00626@s20.term1.sb.rain.org" -->
<!-- inreplyto="POLL: Strong AI Hypothesis: for or against" -->
<title>extropians: Re: POLL: Strong AI Hypothesis: for or against</title>
<h1>Re: POLL: Strong AI Hypothesis: for or against</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Tue, 3 Feb 1998 13:08:24 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1440">[ date ]</a><a href="index.html#1440">[ thread ]</a><a href="subject.html#1440">[ subject ]</a><a href="author.html#1440">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1441.html">DOUG.BAILEY@ey.com: "Prelude to a Singularity? Science and Science Fiction"</a>
<li> <b>Previous message:</b> <a href="1439.html">Brent Allsop: "Re: POLL: Strong AI Hypothesis: for or against"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
The original author indicated that his posting was accidental.  He did<br>
not include a definition of the strong AI hypothesis.<br>
<p>
In philosophical circles, "strong AI" has a specific meaning.<br>
It means that executing a certain type of computer program *produces*<br>
consciousness.  This happens irrespective of the nature of the computer<br>
which executes the program.  Any kind of computer which executes an AI<br>
program (of which no examples are yet known to exist) becomes conscious<br>
(or perhaps we might more carefully say that it causes consciousness<br>
to exist).<br>
<p>
Weaker forms of AI might propose that computer programs have some<br>
properties like consciousness, or that we can learn more about human<br>
consciousness by studying programs which model it, etc.  Strong AI says<br>
that all you need to be conscious is to execute the right kind of program,<br>
an AI program.<br>
<p>
Many thought experiments have been proposed on each side.  Searle's<br>
chinese room is designed to show that strong AI can not be true, while<br>
the gradual-neuron-replacement scenarios are intended to show that it<br>
must be true.  It is probably one of the most contentious issues in the<br>
philosophy of consciousness.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1441.html">DOUG.BAILEY@ey.com: "Prelude to a Singularity? Science and Science Fiction"</a>
<li> <b>Previous message:</b> <a href="1439.html">Brent Allsop: "Re: POLL: Strong AI Hypothesis: for or against"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
