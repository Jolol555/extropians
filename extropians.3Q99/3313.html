<!-- received="Wed Sep  1 20:43:40 1999 MDT" -->
<!-- sent="Wed, 01 Sep 1999 20:43:06 MDT" -->
<!-- name="Clint O'Dell" -->
<!-- email="clintodell@hotmail.com" -->
<!-- subject="Re: -H RE: Present dangers to transhumanism" -->
<!-- id="19990902024307.97857.qmail@hotmail.com" -->
<!-- inreplyto="-H RE: Present dangers to transhumanism" -->
<!-- version=1.10, linesinbody=115 -->
<html><head><title>extropians: Re: -H RE: Present dangers to transhumanism</title>
<meta name=author content="Clint O'Dell">
<link rel=author rev=made href="mailto:clintodell@hotmail.com" title ="Clint O'Dell">
</head><body>
<h1>Re: -H RE: Present dangers to transhumanism</h1>
Clint O'Dell (<i>clintodell@hotmail.com</i>)<br>
<i>Wed, 01 Sep 1999 20:43:06 MDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3313">[ date ]</a><a href="index.html#3313">[ thread ]</a><a href="subject.html#3313">[ subject ]</a><a href="author.html#3313">[ author ]</a>
<!-- next="start" -->
<li><a href="3314.html">[ Next ]</a><a href="3312.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3273.html">Stan Kretler</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
I know where you are comming from and I agree that there should be a 
philosophy of "being".  But it is more important for me at this present time 
to make sure that I'll survive.  After I've achieved immortality (putting 
aside getting hit by a super nova, etc.) than I can work on those ideas.  Of 
course if you want to come up with some a reason for being I'm all ears.  I 
just love life!



<p>
From: "Robert J. Bradbury" &lt;bradbury@www.aeiveos.com&gt;
<a name="5179qlink1"><a name="4204qlink1"><a name="4157qlink1"><a name="3419qlink1">Reply-To: extropians@extropy.com
<br>
To: extropians@extropy.</a>com
<br>
Subject: Re: &gt;H RE: Present dangers to transhumanism
</a></a>Date: Wed, 1 Sep 1999 18:35:40 -0700 (PDT)
</a>

<p>
<a name="3385qlink1">On Wed, 1 Sep 1999, Stan Kretler wrote:

<p>
<a href="3304.html#3313qlink1"> &gt; From: "Eliezer S. Yudkowsky" &lt;sentience@pobox.com&gt;</a><br>
<i> &gt;</i><br>
<i> &gt; : Frankly, I think a fairly large percentage of you *are* naive</i><br>
<i> &gt; : technophiles.  You think you can take controlled sips from a tidal</i><br>
<i> &gt; : wave.</i><br>
<i> &gt;</i><br>
<i> &gt;</i><br>
<i> &gt; I just joined this list recently, but I do not see a lot of what I would</i><br>
</a>
<i> &gt; I call "naive technophiles". I do see a lot of technophiles, and a lot</i><br>
<i> &gt; of naivete, but the naivete seems to be about the philosophical</i><br>
<i> &gt; undergirding of transhumanism, not about the technology. Taking</i><br>
<i> &gt; "controlled sips from a tidal wave" seems easy enough. Technology can do</i><br>
<i> &gt; anything. But thought about *why*  taking a controlled sip from a tidal</i><br>
<i> &gt; wave is a worthwhile goal seems to be absent from this list.</i><br>

<p>
<a name="3434qlink1">I know why -- because I don't want to drown. :-)
But, the point about the "philosophical undergirding of transhumansim"
strikes home.  We are faced with a fundamental problem of constructing
a philosophy for a system which we are woefully ill-equipped</a> to
comprehend.

<p>
Humans have been selected to be about two things: survival &amp; reproduction.
<a name="3385qlink6">Now, all of the technophile discussions, AI discussions, political
discussions, etc. seem to some degree to revolve around --
"how can *I* survive?", and as a subtheme --
"and how can *I* live in an environment that is just the way</a> *I* like it?".
<a name="3385qlink7">Sometimes this gets extended to inviting/dragging other people along
into your perfect environment or encouraging them to create their own.

<p>
Now, leaving aside the technical details of whether it is really
feasible, let us *assume* that survival is guaranteed.  It does seem
like that is a distinct possibility (ignoring the probabilities).
So lets say we are surviving in whatever enhanced form and perfect
environment we have choosen.

<p>
How does a species that to a large degree based on a fight for
survival, develop a philosophy, or a rasion-d'etre, for this
environment.  Yes, we have all seen the posts -- I want to travel,
I want to create music/art/explore interesting scientific problems,
etc.  I raised a point a week or so back, that perhaps the purpose
of it all was to turn all of the available matter &amp; energy in
the universe into a "perfect" structure or the "ultimate" thought
machine, or maybe the single most aesthetic work of art.  I don't
recall anyone commenting on that, but I think it begins to chip
at the problem.

<p>
When it is *not* about survival (or reproduction) -- What is it about?
</a>
<a name="3317qlink1">Is it possible for non-transhumans to discuss transhumanist philosophy?</a>

<p>
<a name="3434qlink2">A related background information piece would be for someone who
has a significant understanding of philosopy to outline all of
the known philosophies (and religions?) and divide them into some
categories -- not/concerned with survival, not/concerned with
purpose for existance, not/concerned with happiness, etc.</a>

<p>
We could use this to see how existing philosophies [religions?]
stack up and determine which have to be thrown out entirely
in a transhumanist[technology at the limits of physics] environment.

<p>
<i> &gt;</i><br>
<a href="3273.html#3313qlink2"> &gt; Seems important to think about these things. Is anyone here worried</a><br>
<i> &gt; about slipping into a psychosis of nihilism once their IQs are high</i><br>
<i> &gt; enough that they realize that their goals have no philosophical</i><br>
<i> &gt; foundation (or *might* have no foundation)?</i><br>
<i> &gt;</i><br>

<p>
I would argue that the condition of nihilism [rejection of traditional
perspectives (esp. morality &amp; religion)] must exist in an advanced
SI(perhaps even AI) because the traditional perspectives are fundamentally
based on surivival &amp; reproduction requirements (which are largely irrelevant
to them).  But I think psychosis (as a detachment from reality)
would not exist, unless intentionally created, because they are
capable of observing reality much more clearly than we are.

<p>
But so far the discussion about what SIs/AIs *do* has only seemed
to generate the result of (a) compute a safe path of existence;
(b) put yourself on that path; (c) suspend all thought until something
that represents an unanticipated threat or is simply novel occur.

<p>
<a name="3434qlink3"><a name="3385qlink8"><a name="3317qlink2">Now, if the other possibility that seems to fit the available data
is -- become an SI/AI, think about a philosopy for existence,
realize that there is no philosopy (because survival *was*
the purpose for existence and once survival is guaranteed,
existence is pointless); dismantle yourself back into atoms.</a></a>
<a name="3434qlink4"><a name="3317qlink3">This seems to fit the paradox of "Why do we still see stars?".</a></a></a>

<p>
<a href="3273.html#3313qlink3"> &gt; If this is an old topic, perhaps someone could point me to a place where</a><br>
<i> &gt; it has already been discussed.</i><br>

<p>
I haven't seen it yet, but there are minds with deeper
memory banks than mine lurking in the shadows.

<p>
Robert

<hr>
<br>
Get Your Private, Free Email at <a href="http://www.hotmail.com">http://www.hotmail.com</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3314.html">[ Next ]</a><a href="3312.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3273.html">Stan Kretler</a>
<!-- nextthread="start" -->
</ul>
</body></html>
