<!-- received="Thu Jul 29 14:55:43 1999 MDT" -->
<!-- sent="29 Jul 1999 13:51:33 -0700" -->
<!-- name="paul@i2.to" -->
<!-- email="paul@i2.to" -->
<!-- subject="Re: IA vs. AI was: Longevity vs. Singlularity" -->
<!-- id="19990729205133.28801.cpmta@c004.sfo.cp.net" -->
<!-- inreplyto="IA vs. AI was: Longevity vs. Singlularity" -->
<!-- version=1.10, linesinbody=34 -->
<html><head><title>extropians: Re: IA vs. AI was: Longevity vs. Singlularity</title>
<meta name=author content="paul@i2.to">
<link rel=author rev=made href="mailto:paul@i2.to" title ="paul@i2.to">
</head><body>
<h1>Re: IA vs. AI was: Longevity vs. Singlularity</h1>
<i>paul@i2.to</i><br>
<i>29 Jul 1999 13:51:33 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1323">[ date ]</a><a href="index.html#1323">[ thread ]</a><a href="subject.html#1323">[ subject ]</a><a href="author.html#1323">[ author ]</a>
<!-- next="start" -->
<li><a href="1324.html">[ Next ]</a><b>In reply to:</b> <a href="1271.html">Max More</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1324.html">Eugene Leitl</a>
</ul>
<!-- body="start" -->

<p>
Max More wrote:

<p>
<a href="1271.html#1323qlink1">&gt;Why should SI's see turning humans into uploads as competition in any sense</a><br>
<i>&gt;that harms them? It would just mean more persons with whom to have</i><br>
<i>&gt;productive exchanges.</i><br>

<p>
<a name="1324qlink1">I agree. Why waste the benefits of diversity and *unique* informational
structures (us) in the sole pursuit of more raw materials for computronium?</a>
However one must consider that it might be more efficient for them
to deconstruct us using a destructive upload, and use our
informational strucutures for their convenience rather than ours? The benifts
could be equal as far as they are concerned - yet for us it is either our
extinction as individuals or at the very least our utter mental enslavement.
I'm not willing to risk my life on the hope that SI are benevolent in exactly
the way I want them to be.  Regardless of anything else, thats a completely
reckless attitue towards our future.

<p>
<a href="1271.html#1323qlink2">&gt; While uploads and SI's may not have any inevitable desire</a><br>
<i>&gt;to wipe us out, some might well want to, and I agree that it</i><br>
<i>&gt;makes sense to deal with that from a position of strength.</i><br>

<p>
I agree with this sentiment completely, but what could this
position of strength possibly be? That *is* the $1 million
dollar question. IMHO the answer is our own Intelligence Augmentation.
But as Eli and others are claiming AI will always be ahead
of IA unless they *are* benevolent.

<p>
I would really like to hear your thoughts on this Max.

<p>
Paul Hughes
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1324.html">[ Next ]</a><b>In reply to:</b> <a href="1271.html">Max More</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1324.html">Eugene Leitl</a>
</ul>
</body></html>
