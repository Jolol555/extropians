<!-- received="Tue Aug  3 14:56:05 1999 MDT" -->
<!-- sent="3 Aug 1999 13:56:01 -0700" -->
<!-- name="paul@i2.to" -->
<!-- email="paul@i2.to" -->
<!-- subject="Re: IA vs. AI (vs. humanity)" -->
<!-- id="19990803205601.17158.cpmta@c004.sfo.cp.net" -->
<!-- inreplyto="IA vs. AI (vs. humanity)" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Re: IA vs. AI (vs. humanity)</title>
<meta name=author content="paul@i2.to">
<link rel=author rev=made href="mailto:paul@i2.to" title ="paul@i2.to">
</head><body>
<h1>Re: IA vs. AI (vs. humanity)</h1>
<i>paul@i2.to</i><br>
<i>3 Aug 1999 13:56:01 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1493">[ date ]</a><a href="index.html#1493">[ thread ]</a><a href="subject.html#1493">[ subject ]</a><a href="author.html#1493">[ author ]</a>
<!-- next="start" -->
<li><a href="1494.html">[ Next ]</a><a href="1492.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1477.html">J. R. Molloy</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
On Tue, 03 August 1999, "J. R. Molloy" wrote:

<p>
<i>&gt; Jeff Davis wrote,</i><br>
<i>&gt; </i><br>
<a href="1477.html#1493qlink1">&gt; &gt;Despite the dramatic talk of an SI destroying humanity, I picture a</a><br>
<i>&gt; &gt;well-thought-out, cautious, gradual approach to "waking up" and training an</i><br>
<i>&gt; &gt;artificial mind.  The runaway self-evolution which Eliezer and others have</i><br>
<i>&gt; &gt;predicted seems unlikely in this setting, all the moreso because the</i><br>
<i>&gt; &gt;principles will be anticipating just such a situation.</i><br>

<p>
I also like what I'm hearing from both you and Jeff.

<p>
<a href="1477.html#1493qlink2">&gt; Precisely so. No pragmatic economic or organizational reason exists to</a><br>
<i>&gt; incorporate a machine based consciousness outside a 100% secure containment</i><br>
<i>&gt; environment. Hence, it won't happen.</i><br>

<p>
This is where I disagree.  Please see previous post on a
'Clemmenson' distributed computing, Internet based SI.

<p>
<a href="1477.html#1493qlink3">&gt; The fact that the AI doesn't feel pain (no reason to build it in) may allow</a><br>
<i>&gt; the AI to function perfectly with no concern for its virtual slavery.</i><br>

<p>
Very good point.

<p>
<a href="1477.html#1493qlink4">&gt; There again, since it has experienced no pain, it need not indulge in</a><br>
<i>&gt; forgiveness or tolerance exercises.</i><br>

<p>
Another good point.
 
<p>
<a href="1477.html#1493qlink5">&gt; I think government aims at our best, not its best. Governments</a><br>
<i>&gt; (corporatations, religions, families, and other entities) function as</i><br>
<i>&gt; superorganisms, with their own continuity and longevity as their primary</i><br>
<i>&gt; objectives.</i><br>

<p>
I completely disagree.  Superorganisms aim at their best not 
their component parts best.  I could care less about a few
blood cells, as long as my body keeps functioning.  Same
goes for governments and corporations.  They exist to
perpetuate their own existence. Since when did a corporation care if it laid-off 20,000 workers, as long as it stock price keeps rising?  I can't believe you were being serious.

<p>
Paul Hughes
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1494.html">[ Next ]</a><a href="1492.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1477.html">J. R. Molloy</a>
<!-- nextthread="start" -->
</ul>
</body></html>
