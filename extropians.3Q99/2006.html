<!-- received="Thu Aug 12 13:40:10 1999 MDT" -->
<!-- sent="Thu, 12 Aug 1999 15:39:35 -0400" -->
<!-- name="dan" -->
<!-- email="dan@Clemmensen.ShireNet.com" -->
<!-- subject="Re: singularity and exi-GIMPS team" -->
<!-- id="37B322F7.791A19E7@clemmensen.shirenet.com" -->
<!-- inreplyto="singularity and exi-GIMPS team" -->
<!-- version=1.10, linesinbody=41 -->
<html><head><title>extropians: Re: singularity and exi-GIMPS team</title>
<meta name=author content="dan">
<link rel=author rev=made href="mailto:dan@Clemmensen.ShireNet.com" title ="dan">
</head><body>
<h1>Re: singularity and exi-GIMPS team</h1>
dan (<i>dan@Clemmensen.ShireNet.com</i>)<br>
<i>Thu, 12 Aug 1999 15:39:35 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2006">[ date ]</a><a href="index.html#2006">[ thread ]</a><a href="subject.html#2006">[ subject ]</a><a href="author.html#2006">[ author ]</a>
<!-- next="start" -->
<li><a href="2007.html">[ Next ]</a><a href="2005.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1925.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Eliezer S. Yudkowsky" wrote:
<br>
<i>&gt; </i><br>
<a href="1925.html#2006qlink1">&gt; Spike, you're not in my kill file.</a><br>
<i>&gt; </i><br>
<i>&gt; Yes, distributed computing advances the Singularity.  I think the people</i><br>
<i>&gt; at singularity.org have a bunch of old Pentiums networked together.  I'm</i><br>
<i>&gt; not sure an ExI network would help, unless there was new software coming</i><br>
<i>&gt; out as a result.  I don't know of anyone here who's working on</i><br>
<i>&gt; AI/neural-net stuff that runs distributed, someone who could benefit directly.</i><br>
<i>&gt; --</i><br>
Actually, there are some interesting algorithms that can use a very
loosely coupled system. Many parallel algorithms need high bandwidth and
low latency, but others don't. The current Key finders and SETI search
are at the extreme end of a spectrum, and can make effective use of a 
large number of intermittently-connected processors with extremely low
bandwidth. At the other end are algorithms that are bandwidth-constrained
even when the processors are using processor busses or shared memory for
interprocessor communication.

<p>
The trick is to find a useful algorithm that uses the environment that is
now emerging. Many of us will soon have full-time connections (cable or ADSL)
with bandwidth in the 100Kbps range or better. Just as the advent of lots
of intermittently-connected Pentium-class computers gave rise to the Key
searchers, etc. cable modems and ADSL will enable a new class of distributed
algorithms.

<p>
It looks to me like genetic algorithms may be very effective in such an
environment. It appears that you can send a small "population" of solutions
off to a computer and have that computer "breed" an improved population, and then
"cross-breed" the resulting population back into the larger "gene pool."
With a simple fitness function, the intergeneration time is low and the bandwidth
high, but a more complex fitness function can be employed to gain better
results if you have enough computers. This lowers the bandwidth per computer,
and I think we can find some neat singularity-advancing genetic algorithms.

<p>
I don't know if this can be used an the first step of the "singularity bootstrap"
we discussed three years ago ( <a href="http://www.shirenet.com/~dgc/singularity">http://www.shirenet.com/~dgc/singularity</a> ) But
maybe it could be. If we can create a fitness function for optimizing
fitness functions, and a fitness function for evaluating how well a program
works, we will be on our way to optimizing the web.
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2007.html">[ Next ]</a><a href="2005.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1925.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
