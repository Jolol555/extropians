<!-- received="Sun Aug  1 16:04:58 1999 MDT" -->
<!-- sent="Sun, 1 Aug 1999 15:11:10 -0700" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: longevity vs singularity/Question" -->
<!-- id="008101bedc6a$c698cf60$71bc473f@jr" -->
<!-- inreplyto="longevity vs singularity/Question" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Re: longevity vs singularity/Question</title>
<meta name=author content="J. R. Molloy">
<link rel=author rev=made href="mailto:jr@shasta.com" title ="J. R. Molloy">
</head><body>
<h1>Re: longevity vs singularity/Question</h1>
J. R. Molloy (<i>jr@shasta.com</i>)<br>
<i>Sun, 1 Aug 1999 15:11:10 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1372">[ date ]</a><a href="index.html#1372">[ thread ]</a><a href="subject.html#1372">[ subject ]</a><a href="author.html#1372">[ author ]</a>
<!-- next="start" -->
<li><a href="1373.html">[ Next ]</a><a href="1371.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1370.html">Gina Miller</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
From: Gina Miller &lt;nanogirl@halcyon.com&gt;
<br>
<a href="1370.html#1372qlink1">&gt;I told him that the real question is "what is the definition of</a><br>
<i>&gt;consciousness", until that is clear this kind of question is limited in</i><br>
<i>&gt;answer. Any idea's?</i><br>

<p>
"Those who say, don't know.
<br>
Those who know, don't say," because definitions cannot contain the principle
used to create definitions. Hence, consciousness does not try to define
itself, knowing that it understands definitions cannot convey its own
self-evident existence. A sufficiently complex machine may experience the
side-effect of consciousness (as humans do), but I can't think of any
economically pragmatic reason to make it do so. Total self-awareness
interferes with one's ability to concentrate on a given task. Owners will
simply abort machines which come too close to spontaneously attaining
consciousness. (First symptom: behavior similar to human's "terrible twos")
As superhuman (but nevertheless incompletely conscious) intelligence
emerges, it may roboticize and infantilize human thinking ever more
completely. This robotic disgenesis opposes extropy by devolving the
epiphenomenon of consciousness. To the extent humans invest in autonomous
machine intelligence, they forfeit the fulfillment of their own liberated
pure consciousness.

<p>
Etymologically, consciousness means "with knowledge" (or "with science") and
so, I'd say the way to find out about the implications of the Singularity
and its significance for human longevity has to adhere rather strictly to
scientific methodology. NB: Scientists also shy away from the word
|consciousness|, and wisely so.<a name="1397qlink1"> We all know what consciousness means. We
only haggle about the details, such as how did it originate, and can we
build a machine to do it, and how far can you expand it, and how does it
relate to sanity, etc.</a>

<p>
I suspect conscious entities have preceded humans, because it seems
incredibly unlikely that we -- in all the universe -- became conscious
first. So, a technological Singularity could have happened before. But we
don't really know for sure that we alone have not become the first conscious
entities... or perhaps just the last in a long line of life forms to
experience total oblivion as a result of a Singularity.
<hr>
<br>
I learned from Dyson's _Infinite In All Directions_ that no matter how small
a thing you think about, something can exist infinitely smaller.

<p>
Inward!
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1373.html">[ Next ]</a><a href="1371.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1370.html">Gina Miller</a>
<!-- nextthread="start" -->
</ul>
</body></html>
