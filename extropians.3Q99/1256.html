<!-- received="Tue Jul 27 23:04:43 1999 MDT" -->
<!-- sent="Tue, 27 Jul 1999 22:01:11 -0700" -->
<!-- name="Paul Hughes" -->
<!-- email="paul@i2.to" -->
<!-- subject="Re: Neurons vs. Transistors (IA vs. AI)" -->
<!-- id="379E8E97.4BB97E5D@i2.to" -->
<!-- inreplyto="Neurons vs. Transistors (IA vs. AI)" -->
<!-- version=1.10, linesinbody=78 -->
<html><head><title>extropians: Re: Neurons vs. Transistors (IA vs. AI)</title>
<meta name=author content="Paul Hughes">
<link rel=author rev=made href="mailto:paul@i2.to" title ="Paul Hughes">
</head><body>
<h1>Re: Neurons vs. Transistors (IA vs. AI)</h1>
Paul Hughes (<i>paul@i2.to</i>)<br>
<i>Tue, 27 Jul 1999 22:01:11 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1256">[ date ]</a><a href="index.html#1256">[ thread ]</a><a href="subject.html#1256">[ subject ]</a><a href="author.html#1256">[ author ]</a>
<!-- next="start" -->
<li><a href="1257.html">[ Next ]</a><a href="1255.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1247.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eugene Leitl wrote:

<p>
<a href="1247.html#1256qlink1">&gt; paul@i2.to writes:</a><br>
<i>&gt;</i><br>
<i>&gt;  &gt; How many thousands is the real question.  I suspect you're looking at 100's of</i><br>
<i>&gt;  &gt; thousands.  Sure, once you achieve the proper transistor density, the next</i><br>
<i>&gt;  &gt; challenge is actually hooking them up in such a way as to accurately</i><br>
<i>&gt;  &gt; emulate the entire spectrum of neurochemical activity! :-)</i><br>
<i>&gt;</i><br>
<i>&gt; Talk is cheap. Can you gives us numbers?</i><br>

<p>
Well, I'm no neurophsyiologist, but lets give it a shot.  First of all, how many
'and/or' gates would it take to model a seratonin molecule interacting with a
phosphate molecule?  This is outside of my expertise, but I suspect this would
require several dozen 'and/or' gates to model even the simplest of interactions.
<a name="1328qlink3">The next challenge is coming up with a complex enough circuit design to model
*all* of the possible interactions of seratonin along a single neuron connection.
And of course this only describes seratonin!  So the next challenge is moving up
the scale of complexity to design a software/hardware system general enough to
accommodate *all* neurotransmitter activity.  You would think</a> with today's
<a name="1328qlink4">supercomputers, somebody somewhere has designed a program that can emulate
every conceivable molecular state of a single neuron.  If not, then my point is well
taken in how complex each neuron in fact</a> is.

<p>
<a name="1328qlink5">Assuming someone has designed a program that's capable of this; conceptually then,
one must then have this program run simultaneously and in parallel with thousands
of others to match the average neuronal connectivity.  The program would</a> have
<a name="1328qlink6">to do a complete run through an average of 10 times/sec. Since it would be a waste
for a simultaneous program running for every neuron (10 billion?) it would</a> be
<a name="1328qlink7">easier to have each neuron be stored as rapidly-accessed data until used.  How much
data would be required to store accurately the state of each neuron? I don't know,
but I suspect it's easily on the order of a megabyte at least - as it
would have to store the entire array of unique molecular states the neuron</a> is in.

<p>
At this point it's all guess work, but my point is that even if when we achieve
atomic
<br>
scale transistor densities, the real challenge will be organizing those transistors
to
<br>
emulate the entire brain, which is itself a molecular switching computer.

<p>
**The challenge is not the speed or density, which will eventually give us the
_potential_
<br>
to run a human brain 1000's of times faster than our own.  No, the real challenge
<a name="1328qlink10">is creating something complex and coherent enough to emulate the brain itself.  I
suspect
<br>
the hardware and software bottlenecks in actually doing so will be difficult enough
to close the gap between brain augmentation (IA) and human-level AI considerably.</a>


<p>
<a href="1247.html#1256qlink2">&gt;  &gt; Therefore, my primary position is that the gap between uploading</a><br>
<i>&gt;  &gt; and human-level AI is much narrower than is often argued.</i><br>
<i>&gt;</i><br>
<i>&gt; Gap in which context? Brute-force uploading (aka neuroemulation)</i><br>
<i>&gt; requires many orders of magnitude more power than straight bred</i><br>
<i>&gt; AI. And the translation procedure to the more compact target encoding</i><br>
<i>&gt; is nonobvious (i.e. I do have hints, but can't be sure it's going to</i><br>
<i>&gt; work).</i><br>

<p>
That is also completely non-obvious.  I have yet to hear a single convincing argument

<p>
that sufficient *speed* and density automatically yields human-level AI. You will
need
<br>
complexity, and where by chance will you be getting it?  Until this can be
convincingly
<br>
answered, all human-level AI claims should be kept in every Skeptics top 5.

<p>
<a name="1328qlink12"><a name="1297qlink1">**Since no one has actually built or designed a theoretical human-level AI, how can
anyone possibly claim what it takes to build one?  This seems completely</a> absurd
<a name="1328qlink13">to the point of self-contradiction!  As so many are fond of saying around here -
extraordinary claims require extraordinary proof.</a>  To re-iterate the obvious, until
<a name="1297qlink2">someone can prove otherwise, a human-level AI will have to equal the complexity of
</a>the
<br>
human brain.
</a>

<p>
Paul Hughes
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1257.html">[ Next ]</a><a href="1255.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1247.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
</body></html>
