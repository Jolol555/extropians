<!-- received="Tue Aug 31 19:50:25 1999 MDT" -->
<!-- sent="Tue, 31 Aug 1999 18:50:35 -0700" -->
<!-- name="Doug Jones" -->
<!-- email="random@qnet.com" -->
<!-- subject="Re: &gt;H RE: Present dangers to transhumanism" -->
<!-- id="37CC866B.A22B217B@qnet.com" -->
<!-- inreplyto="&gt;H RE: Present dangers to transhumanism" -->
<!-- version=1.10, linesinbody=32 -->
<html><head><title>extropians: Re: &gt;H RE: Present dangers to transhumanism</title>
<meta name=author content="Doug Jones">
<link rel=author rev=made href="mailto:random@qnet.com" title ="Doug Jones">
</head><body>
<h1>Re: &gt;H RE: Present dangers to transhumanism</h1>
Doug Jones (<i>random@qnet.com</i>)<br>
<i>Tue, 31 Aug 1999 18:50:35 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3216">[ date ]</a><a href="index.html#3216">[ thread ]</a><a href="subject.html#3216">[ subject ]</a><a href="author.html#3216">[ author ]</a>
<!-- next="start" -->
<li><a href="3217.html">[ Next ]</a><a href="3215.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3209.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky wrote:
<br>
<a href="3209.html#3216qlink1">&gt; I don't see any grounds for believing in a "difficulty" that will</a><br>
<i>&gt; prevent a nanocomputer with a million times the raw computing power</i><br>
<i>&gt; of a human from being at least as much smarter than humans as humans</i><br>
<i>&gt; are from chimpanzees,</i><br>

<p>
I agree completely... if the AI has that nanocomputer to run on.

<p>
<i>&gt; or in a difficulty that prevents an AI running over the Internet</i><br>
<a href="3209.html#3216qlink2">&gt; from being intelligent enough to use rapid infrastructure to</a><br>
<i>&gt; recompile the planet's mass and upload the population.</i><br>

<p>
So where's that rapid infrastructure?  I can see a very frustrated AI
wasting years teaching these dim gaussian humans how to make the tools to
make the tools to make the processors the AI *really* wants.  Even with
robotic tools, a lot of human interaction would be needed, unless the
nascent AI can earn enough (or steal enough) to buy a *lot* of robots.  If
Elisson can't turn itself into a crack nanotech and robotics designer
within limited resources, the rampup will be limited.

<p>
<a href="3209.html#3216qlink3">&gt; Whether difficulties occur after that is something of a moot point,</a><br>
<i>&gt; don't you think?</i><br>

<p>
...and I agree with that too.  Too many visions of nanotech are childish
wish fulfillment things.  Sure, you could make 3D video wallpaper- but why
bother when the (properly processed) video signal could simply be injected
directly into the viewer's optic nerve?  Assuming the viewer still has
anything as outdated as jelly eyeballs and optic nerves, of course.

<pre>
--
Doug Jones, Freelance Rocket Plumber
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3217.html">[ Next ]</a><a href="3215.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3209.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
