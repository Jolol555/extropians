<!-- received="Thu Sep  9 11:34:59 1999 MDT" -->
<!-- sent="Thu, 9 Sep 1999 13:32:01 -0400" -->
<!-- name="John Clark" -->
<!-- email="jonkc@worldnet.att.net" -->
<!-- subject="Re: &gt;H RE: Present dangers to transhumanism" -->
<!-- id="001401befae9$5d6cfbe0$3e9d4d0c@flrjs" -->
<!-- inreplyto="&gt;H RE: Present dangers to transhumanism" -->
<!-- version=1.10, linesinbody=74 -->
<html><head><title>extropians: Re: &gt;H RE: Present dangers to transhumanism</title>
<meta name=author content="John Clark">
<link rel=author rev=made href="mailto:jonkc@worldnet.att.net" title ="John Clark">
</head><body>
<h1>Re: &gt;H RE: Present dangers to transhumanism</h1>
John Clark (<i>jonkc@worldnet.att.net</i>)<br>
<i>Thu, 9 Sep 1999 13:32:01 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3819">[ date ]</a><a href="index.html#3819">[ thread ]</a><a href="subject.html#3819">[ subject ]</a><a href="author.html#3819">[ author ]</a>
<!-- next="start" -->
<li><a href="3820.html">[ Next ]</a><a href="3818.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3768.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky &lt;sentience@pobox.com&gt;


<pre>
   &gt;&gt;Me:
   &gt;&gt;Rightly or wrongly many people, myself included,
</pre>
<br>
<a href="3768.html#3819qlink1">    &gt;&gt; are certain that the universe can not supply us with meaning,</a><br>
<i>    &gt;&gt;and yet  that idea does not drive us insane</i><br>

<p>
  &gt;You aren't a self-modifying AI, buckaroo.

<p>
It's true that I haven't changed my hardware but sometimes I try to
overclock it a little and I have been known to modify and upgrade
my software from time to time. I'm still sane. Mostly.

<p>
<a href="3768.html#3819qlink2">    &gt;It doesn't strike me as being tremendously stable to have no reference</a><br>
<i>    &gt; for what the contents of your mind should be except the current</i><br>
<i>    &gt; contents of your mind.</i><br>

<p>
Apparently it's stable enough. Godel showed that nothing has a perfect
foundation, anything you build on will be incomplete or inconsistent
or both, and yet we manage. The English language is a far greater
muddle than the formal logic Godel dealt with and it has almost no
foundation at all yet it works pretty well most of the time.

<p>
Any mind, artificial or not, is going to need pleasure and pain
subsystems, the probability that an AI would deliberately modify
such a subsystem so it would freeze up into an orgasm of existential
melancholy is almost zero. The reason why you'd want to hard wire
the poor machine to do such a thing is utterly beyond me.

<p>
If you want something to worry about it's the machine modifying
itself in the other direction so it's always happy, very happy, like a
junkie with a unlimited supply of Heroin. I guess you'd have to hard
wire the machine to be a little bit squeamish about modifying its
own brain, not too squeamish obviously but a little. Finding this
happy medium might not be easy, I worry that it might not be possible.


<p>
<a href="3768.html#3819qlink3">    &gt; I am *not* going to construct an AI that thinks the contents</a><br>
<i>    &gt;of its mind are facts.</i><br>

<p>
It's a fact, I don't like sweet potatoes. You can trust me on this
because I am the world's greatest expert of what John K Clark
likes and does not.

<p>
<i>    &gt;&gt;Me:</i><br>
<a href="3768.html#3819qlink4">    &gt;&gt; You might argue that even though I can't be proven wrong I still</a><br>
<i>    &gt;&gt; might be wrong, well maybe.</i><br>

<p>
   &gt;Nonsense.  I think you can be proven wrong.

<p>
How?  I am certain that meaning can not exist without mind but you're
going to prove that I'm wrong and I really think that meaning is
independent of mind. Good luck. Are you going to prove that I really like
sweet potatoes too?

<p>
<a href="3768.html#3819qlink5">    &gt;I'd say a brain that correctly predicts and successfully manipulates</a><br>
<i>    &gt;reality is constructed well</i><br>

<p>
I agree.

<p>
    &gt;but only a brain that incarnates the logic of the Universe is real.<br>

<p>
I'm not sure I understand you but if the logic of the universe produces
a brain in a coma and I can use my own logic to produce a brain that
manipulates reality then I prefer a brain that is not real, and that's a fact.

<p>
   John K Clark      jonkc@att.net
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3820.html">[ Next ]</a><a href="3818.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3768.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
