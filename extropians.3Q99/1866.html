<!-- received="Wed Aug 11 10:20:19 1999 MDT" -->
<!-- sent="Wed, 11 Aug 1999 12:19:07 -0400" -->
<!-- name="John Clark" -->
<!-- email="jonkc@worldnet.att.net" -->
<!-- subject="Re: Personal goal system was: IA vs. AI" -->
<!-- id="000801bee415$60fea5a0$739f4d0c@flrjs" -->
<!-- inreplyto="Personal goal system was: IA vs. AI" -->
<!-- version=1.10, linesinbody=50 -->
<html><head><title>extropians: Re: Personal goal system was: IA vs. AI</title>
<meta name=author content="John Clark">
<link rel=author rev=made href="mailto:jonkc@worldnet.att.net" title ="John Clark">
</head><body>
<h1>Re: Personal goal system was: IA vs. AI</h1>
John Clark (<i>jonkc@worldnet.att.net</i>)<br>
<i>Wed, 11 Aug 1999 12:19:07 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1866">[ date ]</a><a href="index.html#1866">[ thread ]</a><a href="subject.html#1866">[ subject ]</a><a href="author.html#1866">[ author ]</a>
<!-- next="start" -->
<li><a href="1867.html">[ Next ]</a><a href="1865.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1826.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1

<p>
Eliezer S. Yudkowsky &lt;sentience@pobox.com&gt; On  August 10, 1999 Wrote:


<p>
<a href="1826.html#1866qlink1">    &gt;If you define "free will" as actions that are not caused by any external</a><br>
<i>    &gt;force or lower level of physical reduction, then there's obviously no</i><br>
<i>    &gt;such thing.</i><br>

<p>
Sure there is, it's called randomness

<pre>
     &gt;If you use the same definition of "reduce" as in "The Adapted Mind"
     &gt;(thank you, Paul Hughes!) and say that a higher level does not
     &gt;reduce to a lower one unless there's an identity of pattern, not
     &gt;just causation of pattern, then there might be free will.

</pre>
<p>
If you increase the speed that gas molecules move at inside a toy balloon
the temperature will increase, if the temperature increases the pressure
will become greater, if the pressure is greater the balloon will get larger.
Size does not seem to reduce to pressure, pressure does not seem to be of the
same pattern as temperature, and certainly temperature seems very different
from speed, almost as different as a firing neuron is from a conscious thought.
Question: Did the toy balloon decide to get larger, does a toy balloon have
free will?  Yes I would maintain that it does, and for that reason I would also
maintain that free will is not a useful concept.

<p>
<a href="1826.html#1866qlink2">    &gt;free will is a cognitive abstraction used to define the basic unit of</a><br>
<i>    &gt;attributed moral responsibility.</i><br>

<p>
The idea of Free will is not needed for morality, or for anything else.
A person or animal is responsible for an action if and only if punishing
that person or animal will reduce the occurrence of the action in the future.
If I see my dog tearing up my couch I will discipline him, if he's sick and I
see him vomit on the floor I will not.

<p>
    John K Clark      jonkc@att.net


<p>
-----BEGIN PGP SIGNATURE-----
<br>
Version: PGP for Personal Privacy 5.5.5

<p>
iQA/AwUBN7Giet+WG5eri0QzEQJtKwCgxHW7fux3HaL09BvKxkNsrZybSdYAoIqy
+VeqOOMfgJEzd7iuq1pXRpfV
<br>
=lKMQ
<br>
-----END PGP SIGNATURE-----
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1867.html">[ Next ]</a><a href="1865.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1826.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
