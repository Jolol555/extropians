<!-- received="Mon Jul 26 17:00:42 1999 MDT" -->
<!-- sent="26 Jul 1999 16:04:02 -0700" -->
<!-- name="paul@i2.to" -->
<!-- email="paul@i2.to" -->
<!-- subject="Re: IA vs. AI." -->
<!-- id="19990726230402.25744.cpmta@c004.sfo.cp.net" -->
<!-- inreplyto="IA vs. AI." -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropians: Re: IA vs. AI.</title>
<meta name=author content="paul@i2.to">
<link rel=author rev=made href="mailto:paul@i2.to" title ="paul@i2.to">
</head><body>
<h1>Re: IA vs. AI.</h1>
<i>paul@i2.to</i><br>
<i>26 Jul 1999 16:04:02 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1172">[ date ]</a><a href="index.html#1172">[ thread ]</a><a href="subject.html#1172">[ subject ]</a><a href="author.html#1172">[ author ]</a>
<!-- next="start" -->
<li><a href="1173.html">[ Next ]</a><a href="1171.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1121.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1178.html">Eugene Leitl</a>
</ul>
<!-- body="start" -->

<p>
On Sun, 25 July 1999, "Eliezer S. Yudkowsky" wrote: 
<pre>
              
<br>
<a href="1121.html#1172qlink1">             &gt; See, what *you* want is unrealistic </a><br>
<i>             &gt; because you want yourself to be the first one to upload,<a name="1245qlink9"> which excludes </i><br>
<i>             &gt; you from cooperation with more than a small</a> group and limits your </i><br>
<i>             &gt; ability to rely on things like open-source projects and charitable </i><br>
<i>             &gt; foundations. </i><br>
              
<a name="1178qlink1">             Since you seem to be advocating open-source for AI, why 
             not an open-source movement for nanotech development as well?</a> 
<a name="1178qlink2">             The advantages seem to heavily outweight the alternative of leaving 
             it soley to competive yet highly secretive governements or 
             corporations.  This would seem to level the playing field and minimize 
             said risks of nanotech preceding SI.  What do you think?</a> 
              
<br>
<a href="1121.html#1172qlink2">             &gt; A-priori chance that you, personally, can be in the first 6 people to </a><br>
<i>             &gt; upload:  1e-9. </i><br>
              
             Agree. 
<br>
<a href="1121.html#1172qlink3">             &gt; Extremely optimistic chance:  1% </a><br>
              
             Agree. 
              
<br>
<a href="1121.html#1172qlink4">             &gt; Extremely pessimistic chance that AIs are benevolent: 10% </a><br>
              
             What do you consider a likely probability?  And more importantly, 
             could you elaborate on why you think Super-AI's are likely to 
             be benevolent? 
              
<br>
<a href="1121.html#1172qlink5">             &gt; Therefore it's 10 times better to concentrate on AI. </a><br>
              
             I suppose until you answer the above, I remain unconvinced. 
              
             Paul Hughes 
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1173.html">[ Next ]</a><a href="1171.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1121.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1178.html">Eugene Leitl</a>
</ul>
</body></html>
