<!-- received="Thu Aug  5 16:01:29 1999 MDT" -->
<!-- sent="Thu, 05 Aug 1999 17:01:40 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="IA projects (was IA vs. AI)" -->
<!-- id="37AA09BF.E2342E22@pobox.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=77 -->
<html><head><title>extropians: IA projects (was IA vs. AI)</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>IA projects (was IA vs. AI)</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Thu, 05 Aug 1999 17:01:40 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1659">[ date ]</a><a href="index.html#1659">[ thread ]</a><a href="subject.html#1659">[ subject ]</a><a href="author.html#1659">[ author ]</a>
<!-- next="start" -->
<li><a href="1660.html">[ Next ]</a><a href="1658.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1639.html">den Otter</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1740.html">Gabriele Betti</a>
</ul>
<!-- body="start" -->

<p>
(WAS: Re: IA vs. AI was: longevity vs singularity)

<p>
den Otter wrote:
<br>
<i>&gt; </i><br>
<a href="1639.html#1659qlink1">&gt; &gt; Yes, I do have my "own" agenda, which involves using IA as a means to</a><br>
<i>&gt; &gt; AI.  And if you'd like to start your own IA project, I'll be more than</i><br>
<i>&gt; &gt; happy to contribute advice, brain scans, genetic material, or anything</i><br>
<i>&gt; &gt; else you need.</i><br>

<p>
Let me rephrase that:  "Anything else you need that I have."  In this
case, what I have is a knowledge of the theory and the only known
working sample.  I'll spend as much time under an fMRI as required, I'll
donate genes and (legal or moral) permission to grow a clone, and I'll
be happy to share my knowledge of cognitive engineering.  Furthermore,
I'll keep the fact quiet.  This is an open offer to anyone planning to
run a neurohacking IA project, even people whose ethics I strongly
disagree with - i.e. China, Saddam Hussein, den Otter - because the
development of this technology is more important than who has it.  The
offer does not extend to non-neurohacking IA or non-enhancive neurohacking.

<p>
I'm not offering funding, of course, being 19.

<p>
<a href="1639.html#1659qlink2">&gt; Are you serious about this? Well, ideally we'd have a project that</a><br>
<i>&gt; aims to develop practical nanotech designs for things like escape</i><br>
<i>&gt; craft, space habitats, food replicators, neurological enhancements,</i><br>
<i>&gt; weapons and, last but not least, mind uploading. If you test it</i><br>
<i>&gt; now in VR, that could save a lot of valuable time when the shit</i><br>
<i>&gt; hits the fan.</i><br>

<p>
I've actually given some thought to what could be accomplished by
nanotechnology predevelopment.  Ideally, what you want is a complete
lunar colony design given one assembler, so that Zyvex can take off and
have somewhere safe to hide and develop the rest of nanotechnology in
peace.  My impression, though, is that you need nanocomputers to do
real, large-scale nanodesigns; preplanning at this point just isn't
practical, and it wouldn't shorten the development time significantly. 
(And now I'm getting off the subject line.  Oops.)  Anyway, at this
point I'm thinking of IA as being synonymous with neurohacking - that's
the only project I've got a duty to volunteer for, anyway.

<p>
<i>&gt; Apart from this, we need to focus on non-nanotech</i><br>
<a href="1639.html#1659qlink3">&gt; (contemporary) means to achieve IA, and ways to get some</a><br>
<i>&gt; serious funding. If you have any suggestions, I'd love to hear</i><br>
<i>&gt; them.</i><br>

<p>
I really don't think it's practically possible to run any of the
do-it-yourself projects from _Algernon_.  It would only take a few
million dollars if you were willing to run it off the seat of one's
pants and take casualties, and you could do it by modifying
off-the-shelf technology.  In fact, IA is probably the single easiest
Singularity project to run, in strictly technological terms - the brain
is resilient, the parts already exist and all you have to is shuffle
them around, and there's that working sample.  Unfortunately, it's so
illegal that the Supreme Court would burst into flames, and running it
in a Third-World country or as a secret would add considerably to costs.
 A pity.

<p>
<a name="1685qlink1"><a href="1639.html#1659qlink4">&gt; As a matter of fact, you've mentioned on several occasions that</a><br>
<i>&gt; you have "thousands" of potentially lucrative ideas. I'm certainly</i><br>
<i>&gt; interested in a relatively easy, low budget way to make lots of</i><br>
<i>&gt; money. So, how about this: if you can give me something that</i><br>
<i>&gt; works, I'll give you 50% of all profits.</i><br>

<p>
Well, I certainly wouldn't give an idea like that away to someone
inexperienced enough to think 50% is a fair share!  5% would be damned
generous to someone who only came up with the idea, no matter how
brilliant it was!  Do you have any idea how much work it is to start a
corporation, even a "relatively easy", "low budget" one?

<p>
If you're interested in entrepreneuring, I suggest checking out "Inc.
Online" and "Red Herring".  That's inc.com and redherring.com.</a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1660.html">[ Next ]</a><a href="1658.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1639.html">den Otter</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1740.html">Gabriele Betti</a>
</ul>
</body></html>
