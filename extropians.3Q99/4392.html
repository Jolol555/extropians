<!-- received="Fri Sep 17 19:50:19 1999 MDT" -->
<!-- sent="Fri, 17 Sep 1999 18:50:14 -0700 (PDT)" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@www.aeiveos.com" -->
<!-- subject="Re: What Do Advanced Aliens Want? (was: Dyson shells are possible)" -->
<!-- id="Pine.SV4.3.91.990917183304.25735B-100000@www.aeiveos.com" -->
<!-- inreplyto="37E2E1E5.A49A045A@gmu.edu" -->
<!-- version=1.10, linesinbody=60 -->
<html><head><title>extropians: Re: What Do Advanced Aliens Want? (was: Dyson shells are possible)</title>
<meta name=author content="Robert J. Bradbury">
<link rel=author rev=made href="mailto:bradbury@www.aeiveos.com" title ="Robert J. Bradbury">
</head><body>
<h1>Re: What Do Advanced Aliens Want? (was: Dyson shells are possible)</h1>
Robert J. Bradbury (<i>bradbury@www.aeiveos.com</i>)<br>
<i>Fri, 17 Sep 1999 18:50:14 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4392">[ date ]</a><a href="index.html#4392">[ thread ]</a><a href="subject.html#4392">[ subject ]</a><a href="author.html#4392">[ author ]</a>
<!-- next="start" -->
<li><a href="4393.html">[ Next ]</a><a href="4391.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4384.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="4516.html">Robin Hanson</a>
</ul>
<!-- body="start" -->



<p>
On Fri, 17 Sep 1999, Robin Hanson wrote:

<p>
<a href="4384.html#4392qlink1">&gt; That is valuing computation as an intermediate good, not as an end good.</a><br>
<i>&gt; It is very different from claiming that aliens value only computation.</i><br>
<i>&gt; One can easily value other things and yet choose to let technology grow.</i><br>
<i>&gt; That's what we all do now.  I could more easily argue that natural</i><br>
<i>&gt; selection will favor civilizations that try to expand spatially.</i><br>

<p>
I will agree that spatial expansion will trump intelligence
if the intelligence isn't being used effectively.  We are now
just borderline between using our "intelligence/capacities"
to predict/eliminate hazards vs. expand spatially so our failur
to predict/eliminate is a hazard.

<p>
However spatial expansion tends to be defined by "limited"
intelligences.  A "maximal" intelligence would presumably
occupy all of the available computronium and eliminaite
any subintelligences within its sphere.

<p>
Here, I think is the fundamental point of our discussion --
<a name="4516qlink1">  What is maximally survivable -- the largest distributed
  intelligence -- or the densest local intelligence.

<p>
I would argue that (b) the densest local intelligence has
the greatest surivival potential provided it can predict
and track events based on physical laws in its local universe.</a>

<p>
<i>&gt; </i><br>
<a href="4384.html#4392qlink2">&gt; &gt; &gt; And I'm sure we could ifeden.computational problems that are so</a><br>
<i>&gt; &gt; &gt; hard that one could compute them more quickly by sending out probes</i><br>
<i>&gt; &gt; &gt; to turn the universe into computers, rather than just using one system</i><br>
<i>&gt; &gt; &gt; to compute with.  How can you know that advanced creatures aren't</i><br>
<i>&gt; &gt; &gt; interested in such problems?</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt; Yes, but there is probably only a small set of computational</i><br>
<i>&gt; &gt; problems where the data can be separated into logical subdivisions</i><br>
<i>&gt; &gt; that do not require significant communication of inputs and outputs.</i><br>
<i>&gt; &gt; ... You win much more by figuring out the optimal computer architecture</i><br>
<i>&gt; &gt; and building it locally, than you do by colonizing the nearest stars.</i><br>
<i>&gt; </i><br>
<i>&gt; I'm not going to take your word on this.  I want to see some analysis</i><br>
<i>&gt; before I'll be persuaded.</i><br>
<i>&gt; </i><br>
Agreed, this is just my gut feeling.  I don't know of how large
the space of computational problems that can be subdivided into
"survival-related" and "theoretical-interest" really is.  But
the propagation delays to nearby (other-stellar) supercomputers
is so large that there is huge pressure to solve them for oneself.

<p>
It comes down to a fundamental question -- at what point does
anticipational computation trump chaos (of the known universe).

<p>
If your survival is guaranteed, as seems to be likely, then your
problems become what are the "difficult" computational problems
and what are the optimal architectures to solve them.

<p>
Robert
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="4393.html">[ Next ]</a><a href="4391.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4384.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="4516.html">Robin Hanson</a>
</ul>
</body></html>
