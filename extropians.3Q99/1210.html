<!-- received="Tue Jul 27 10:39:28 1999 MDT" -->
<!-- sent="26 Jul 1999 12:36:09 -0700" -->
<!-- name="paul@i2.to" -->
<!-- email="paul@i2.to" -->
<!-- subject="Re: IA vs. AI was: longevity vs singularity" -->
<!-- id="19990726193609.17249.cpmta@c004.sfo.cp.net" -->
<!-- inreplyto="IA vs. AI was: longevity vs singularity" -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropians: Re: IA vs. AI was: longevity vs singularity</title>
<meta name=author content="paul@i2.to">
<link rel=author rev=made href="mailto:paul@i2.to" title ="paul@i2.to">
</head><body>
<h1>Re: IA vs. AI was: longevity vs singularity</h1>
<i>paul@i2.to</i><br>
<i>26 Jul 1999 12:36:09 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1210">[ date ]</a><a href="index.html#1210">[ thread ]</a><a href="subject.html#1210">[ subject ]</a><a href="author.html#1210">[ author ]</a>
<!-- next="start" -->
<li><a href="1211.html">[ Next ]</a><a href="1209.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1121.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
On Sun, 25 July 1999, "Eliezer S. Yudkowsky" wrote:

<p>
<i>&gt; See, what *you* want is unrealistic</i><br>
<a href="1121.html#1210qlink1">&gt; because you want yourself to be the first one to upload, which excludes</a><br>
<i>&gt; you from cooperation with more than a small group and limits your</i><br>
<i>&gt; ability to rely on things like open-source projects and charitable</i><br>
<i>&gt; foundations.</i><br>

<p>
Since you seem to be advocating open-source for AI, why
not an open-source movement for nanotech development as well?
The advantages seem to heavily outweight the alternative of leaving
it soley to competive yet highly secretive governements or
corporations.  This would seem to level the playing field and minimize
said risks of nanotech preceding SI.  What do you think?

<p>
<a href="1121.html#1210qlink2">&gt; A-priori chance that you, personally, can be in the first 6 people to</a><br>
<i>&gt; upload:  1e-9.</i><br>

<p>
Agree.
<br>
<a href="1121.html#1210qlink3">&gt; Extremely optimistic chance:  1%</a><br>

<p>
Agree.

<p>
<a href="1121.html#1210qlink4">&gt; Extremely pessimistic chance that AIs are benevolent: 10%</a><br>

<p>
What do you consider a likely probability?  And more importantly,
could you elaborate on why you think Super-AI's are likely to
be benevolent?

<p>
<a href="1121.html#1210qlink5">&gt; Therefore it's 10 times better to concentrate on AI.</a><br>

<p>
I suppose until you answer the above, I remain unconvinced.

<p>
Paul Hughes
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1211.html">[ Next ]</a><a href="1209.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1121.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
