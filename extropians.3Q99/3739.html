<!-- received="Tue Sep  7 22:06:52 1999 MDT" -->
<!-- sent="Tue, 7 Sep 1999 22:06:47 -0600" -->
<!-- name="Joseph Sterlynne" -->
<!-- email="vxs@mailandnews.com" -->
<!-- subject="Re: Mike Perry's work on self-improving AI" -->
<!-- id="l03130304b3fb52574743@[209.150.226.165]" -->
<!-- inreplyto="37D5481B.BFC2483E@pobox.com" -->
<!-- version=1.10, linesinbody=26 -->
<html><head><title>extropians: Re: Mike Perry's work on self-improving AI</title>
<meta name=author content="Joseph Sterlynne">
<link rel=author rev=made href="mailto:vxs@mailandnews.com" title ="Joseph Sterlynne">
</head><body>
<h1>Re: Mike Perry's work on self-improving AI</h1>
Joseph Sterlynne (<i>vxs@mailandnews.com</i>)<br>
<i>Tue, 7 Sep 1999 22:06:47 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3739">[ date ]</a><a href="index.html#3739">[ thread ]</a><a href="subject.html#3739">[ subject ]</a><a href="author.html#3739">[ author ]</a>
<!-- next="start" -->
<li><a href="3740.html">[ Next ]</a><a href="3738.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3719.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3742.html">Robert J. Bradbury</a>
</ul>
<!-- body="start" -->


<p>
<a href="3441.html#3739qlink1">&gt;  "Eliezer S. Yudkowsky" &lt;sentience@pobox.com&gt;</a><br>
<i>&gt;&gt; Joseph Sterlynne</i><br>

<p>
<a href="3719.html#3739qlink2">&gt;&gt; What guarantee do we have that there is no inherent</a><br>
<i>&gt;&gt; problem in a human-class mind perceiving all of itself?  There is of course</i><br>
<i>&gt;&gt; the question of self-observation; it would certainly help to know how much</i><br>
<i>&gt;&gt; control our consciousness really has over the rest of the mind.</i><br>
<i>&gt;</i><br>
<i>&gt;You don't modify your entire mind at once.  You look at a subsection,</i><br>
<i>&gt;then modify that.</i><br>

<p>
And presumably we could chart lines of influence which would affect even
those areas which might be difficult to reach more directly.  But would
not, for example, total recall of long-term memories or total access to
<a name="3742qlink1">nonconscious processes be a useful ability?  Is our (and apparently other
organisms') lack of such due to the basic architecture of mind or to the
vicissitudes of evolution?</a>  In such a case we might be able to access a
small section of this<a name="3742qlink2"> unconscious data (instead of everything at
</a>
once)---but we can't.  We'd like to think that there is no inherent
restriction; but then we might not end up with anything like the sort of
consciousness that we are used to.  An old idea in SF but one whose basic
formal characteristics we must work out in today's AI.
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3740.html">[ Next ]</a><a href="3738.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3719.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3742.html">Robert J. Bradbury</a>
</ul>
</body></html>
