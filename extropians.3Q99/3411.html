<!-- received="Thu Sep  2 18:55:39 1999 MDT" -->
<!-- sent="Thu, 02 Sep 1999 19:56:55 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity?" -->
<!-- id="37CF1CD4.20875A21@pobox.com" -->
<!-- inreplyto="Singularity?" -->
<!-- version=1.10, linesinbody=32 -->
<html><head><title>extropians: Re: Singularity?</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Singularity?</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Thu, 02 Sep 1999 19:56:55 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3411">[ date ]</a><a href="index.html#3411">[ thread ]</a><a href="subject.html#3411">[ subject ]</a><a href="author.html#3411">[ author ]</a>
<!-- next="start" -->
<li><a href="3412.html">[ Next ]</a><b>In reply to:</b> <a href="3410.html">hal@finney.org</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
hal@finney.org wrote:
<br>
<i>&gt; </i><br>
<a href="3410.html#3411qlink1">&gt; It sounds like you're saying that the "box" of conventional AI is simply</a><br>
<i>&gt; that they are working on tractable problems where progress is possible,</i><br>
<i>&gt; while you would rather build up complex theoretical designs.  But designs</i><br>
<i>&gt; without grounding in practical testing are very risky.  The farther you</i><br>
<i>&gt; go, the more likely you are to have made some fundamental mistake which</i><br>
<i>&gt; shakes the whole beautiful edifice to the ground.</i><br>

<p>
I have no problem with either toy domains or practical testing, but to
make any progress at all, sooner or later you have to attack that toy
domain with a toy - but complete - cognitive architecture, not a search
tree or a propositional-logic manipulator or whatever.  Modern AI is
sort of like six different chess-playing programs, one of which
simulates pawns, one rooks, one bishops...  Actually, bad analogy;
that'd be a more workable approach than what they're doing now.  Maybe
the analogy is to a chess-playing program that only moves pieces around,
without playing against an opponent?

<p>
Actually, the best analogy is the truth; modern AI is like a modern
chess-playing program.  No complexity.  No self-awareness.  No
consideration of the different facets of the problem.  No symbols.  No
memory.  No reasoning.  Just a search tree.

<p>
Again, I don't object to toy problems, but at some point you have to
attack them with a complete toy human.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3412.html">[ Next ]</a>
<b>In reply to:</b> <a href="3410.html">hal@finney.org</a>
<!-- nextthread="start" -->
</ul>
</body></html>
