<!-- received="Sat Jul 10 23:51:43 1999 MDT" -->
<!-- sent="Sun, 11 Jul 1999 00:53:30 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: SIs *MUST* exist (was Converting scientists.../was Re:" -->
<!-- id="37883151.A3356BF6@pobox.com" -->
<!-- inreplyto="SIs *MUST* exist (was Converting scientists.../was Re:" -->
<!-- version=1.10, linesinbody=38 -->
<html><head><title>extropians: Re: SIs *MUST* exist (was Converting scientists.../was Re:</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: SIs *MUST* exist (was Converting scientists.../was Re:</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 11 Jul 1999 00:53:30 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#513">[ date ]</a><a href="index.html#513">[ thread ]</a><a href="subject.html#513">[ subject ]</a><a href="author.html#513">[ author ]</a>
<!-- next="start" -->
<li><a href="0514.html">[ Next ]</a><a href="0512.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0509.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eugene Leitl wrote:
<br>
<i>&gt; </i><br>
<a href="0509.html#0513qlink1">&gt; Eliezer S. Yudkowsky writes:</a><br>
<i>&gt; </i><br>
<i>&gt;  &gt; Easy:  There is no meaning of life, no goal system can sustain itself</i><br>
<i>&gt;  &gt; without one, and they all commit suicide.  Of course, those three items</i><br>
<i>&gt; </i><br>
<i>&gt; Maybe this explains why you always tread the brittle AI path.</i><br>

<p>
What is this, the law of the excluded middle?  Just because an AI isn't
connectionist doesn't mean that it's classical.  Webmind is a
crystalline AI.  Elisson isn't.

<p>
<i>&gt; Real</i><br>
<a href="0509.html#0513qlink2">&gt; life is the ultimate Energizer Bunny: it just keeps going, and going,</a><br>
<i>&gt; and going without needing any formalized built-in goal.</i><br>

<p>
"Formalized" and "built-in" are mutually exclusive, don't you think? 
And name me one known brain that has goals but no built-in goals.

<p>
I'm always amused by the way that people who insist that all goals are
equally "correct" get so disturbed by my goal of saying it isn't so...

<p>
<a href="0509.html#0513qlink3">&gt;  &gt; in sequence form a rather tenuous logic (life could have meaning, our</a><br>
<i>&gt;  &gt; cheapjack human systems function without one, and why is suicide more</i><br>
<i>&gt;  &gt; rational than anything else?), but it's a possibility.</i><br>
<i>&gt; </i><br>
<i>&gt; Yes indeed. Commiting suicide is always about choice and values, the</i><br>
<i>&gt; same thing with going on living.</i><br>

<p>
And the same thing with walking across the room, or any mental action...
I don't see what prediction I can make based on your statement.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0514.html">[ Next ]</a><a href="0512.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0509.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
</body></html>
