<!-- received="Tue Aug  3 17:42:17 1999 MDT" -->
<!-- sent="Wed, 4 Aug 1999 00:32:10 +0100" -->
<!-- name="Bryan Moss" -->
<!-- email="bryan.moss@dial.pipex.com" -->
<!-- subject="Re: AI vs. uploading" -->
<!-- id="001c01bede08$9fe5e160$3384bc3e@jed" -->
<!-- inreplyto="AI vs. uploading" -->
<!-- version=1.10, linesinbody=54 -->
<html><head><title>extropians: Re: AI vs. uploading</title>
<meta name=author content="Bryan Moss">
<link rel=author rev=made href="mailto:bryan.moss@dial.pipex.com" title ="Bryan Moss">
</head><body>
<h1>Re: AI vs. uploading</h1>
Bryan Moss (<i>bryan.moss@dial.pipex.com</i>)<br>
<i>Wed, 4 Aug 1999 00:32:10 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1501">[ date ]</a><a href="index.html#1501">[ thread ]</a><a href="subject.html#1501">[ subject ]</a><a href="author.html#1501">[ author ]</a>
<!-- next="start" -->
<li><a href="1502.html">[ Next ]</a><a href="1500.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1489.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky wrote:

<p>
<a href="1489.html#1501qlink1">&gt; &gt; I would imagine from reading Hofstadter that he is fully capable of</a><br>
<i>&gt; &gt; being just as arrogant as Marvin Minsky.</i><br>
<i>&gt;</i><br>
<i>&gt; I can't for the life of me remember anything in _GEB_, _Metamagical</i><br>
<i>&gt; Themas_, or _Fluid Concepts_ that could be taken as arrogant.  Even when</i><br>
<i>&gt; he was ripping apart the "Structure Mapping Engine" in _Fluid_, he was a</i><br>
<i>&gt; lot nicer about it than I would have been.</i><br>

<p>
Hofstadter doesn't make such bold claims as others in the field, but he is
still in no position to claim that his models have any relation to human
intelligence than any other arbitrary model.  It is impossible to rigorously
test if a model thought-process is the same as a real one.  AI researchers
have ignored this problem by moving the goal posts; they're not simulating
the brain, they're simulating 'intelligence'.  The problem with this becomes
apparent when you consider that they are both defining and simulating
intelligence simulaneously.  Thus the simulation creates the definition and
the definition creates the simulation, eventually we arrive with both a
defintion of intelligence and a simulation, neither of which mean anything
to anyone.  To complicate this cycle even further the MIT AI lab has even
stated one of it's goals as understanding the brain to help us think better.
So these researchers are basing their models on observations of their
thought processes at the same time as trying to think in terms of those
models!  I personally find the entire premise of AI research to be based on
ill logic.  As I have said before, the very idea that you can understand the
brain while paying little or no attention to its structure is ridiculous.
Based on this I think it's possible to say all AI researchers (and
self-proclaimed cogintive scientists), Hofstadter included, are somewhat
arrogant.  Obviously I find other causes for thinking Hofstadter in
particular could be arrogant, but a large part of that is due to what I
state above.  I'm open to disagreement.

<p>
<a href="1489.html#1501qlink2">&gt; &gt; As for Lenat, he couldn't be insulted enough.  Cyc indeed.</a><br>
<i>&gt;</i><br>
<i>&gt; Yeah, Cyc is silly, they're pouring water into the bucket but they</i><br>
<i>&gt; forgot to build the bucket first.  I was talking about EURISKO.  Cyc is</i><br>
<i>&gt; just another failure.</i><br>

<p>
I consider EURISKO to be one of AIs brighter moments but it was missing a
foundamental element in that it could not function without constant
'tweaking' by its creator.  And that which it lacked was probably worth more
than its constituent parts.  After starting the Cyc project it became
obvious that Lenat's own thinking is obviously misguided.  The flaws in the
Cyc project are so obvious that either Lenat is a very stupid man or he had
an insight with his previous projects that is beyond my own understanding.
I find the latter to be unlikely (although if the ability to learn from
scratch is intractable then a common sense database would seem to be the
only option - perhaps Cyc is intended to be analogous to our own genetic
inheritance).

<p>
BM
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1502.html">[ Next ]</a><a href="1500.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1489.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
