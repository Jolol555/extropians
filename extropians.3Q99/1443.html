<!-- received="Tue Aug  3 02:13:36 1999 MDT" -->
<!-- sent="Tue, 03 Aug 1999 03:13:44 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="AI vs. uploading" -->
<!-- id="37A6A4B1.ECD9B3C9@pobox.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=70 -->
<html><head><title>extropians: AI vs. uploading</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>AI vs. uploading</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Tue, 03 Aug 1999 03:13:44 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1443">[ date ]</a><a href="index.html#1443">[ thread ]</a><a href="subject.html#1443">[ subject ]</a><a href="author.html#1443">[ author ]</a>
<!-- next="start" -->
<li><a href="1444.html">[ Next ]</a><a href="1442.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1441.html">paul@i2.to</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
paul@i2.to wrote:
<br>
<i>&gt; </i><br>
<a href="1441.html#1443qlink1">&gt; "Eliezer S. Yudkowsky" wrote:</a><br>
<i>&gt; </i><br>
<i>&gt; &lt;&lt;But seriously, when you make a segue of that magnitude, please change the subject line.  Or else try to maintain relevance to the topic; i.e. "And I think this demonstrates a disdain for all human beings that is the direct result of being an AI researcher, which is why I don't trust an AI Transcend.&gt;&gt;</i><br>
<i>&gt; </i><br>
<i>&gt; Yes! :-)  And that is my point!  I have yet to meet a</i><br>
<i>&gt; serious 'hard' AI researcher who is not lacking in either</i><br>
<i>&gt; ethics or social skills.  So how can you possibly ask me to</i><br>
<i>&gt; trust the 'sons-a-bitches' to create a benevolent AI?</i><br>

<p>
<a name="1488qlink1">Let me get this straight.  You're using the lousy behavior of humans as
an argument *against* AI?</a>

<p>
<a name="1488qlink2"><i>&gt; The</i><br>
<a href="1441.html#1443qlink2">&gt; assholes can barely behave themselves in the most controlled</a><br>
<i>&gt; social settings, and you want me to hedge my bets and my</i><br>
<i>&gt; life in the hands of this lot?  Gimme a break!</i><br>

<p>
<a name="1461qlink1">I think you are perhaps overgeneralizing just a tad.  In fact, you've
<a name="1577qlink1">just insulted... let's see, Douglas Hofstadter, Douglas Lenat, and...
</a>
well, actually that exhausts my store of people I'd challenge you to a
duel over, but I'm still a touch offended.</a>
</a>

<p>
<a name="1488qlink3"><a href="1441.html#1443qlink3">&gt; Eli, you want to create an SI before nanotech destroys</a><br>
<i>&gt; everything.  People like Den Otter, Max More and myself want</i><br>
<i>&gt; to IA ourselves to singularity before the SI's destroy us!</i><br>

<p>
Why are you including Max More on the list?  I have him down as an
benovelent-Powers neutral in the IA-vs-AI debate, unless he's changed
his mind lately.</a>

<p>
<a name="1488qlink4">As for you and den Otter... won't you feel like *such* idiots if the
Powers would have been benevolent but you manage to kill yourself with
grey goo instead?</a>  Well, no, but if that was the case, wouldn't you have
felt like idiots if you'd been around to... this language doesn't handle
nested subjunctives very well.

<p>
<a name="1488qlink5">Anyway, a touch of IA and you guys will be following me into Externalist-land.</a>

<p>
<a href="1441.html#1443qlink4">&gt; What makes  you think you can close the gap between</a><br>
<i>&gt; assembler and SI any sooner than we can close the gap</i><br>
<i>&gt; between SI and uploading?  You said it yourself - we are</i><br>
<i>&gt; fools to try to attempt to beat a 2020 CRNS technology with</i><br>
<i>&gt; 2040 CRNS technology.  But how are you any less the fool to</i><br>
<i>&gt; try to beat a 2010 CRNS tech with a 2020 CRNS tech?  And I'm</i><br>
<i>&gt; using your CRNS estimates!  :-)</i><br>

<p>
<a name="1488qlink6">Actually, it's 2015 vs. 2020, although Drexler's been talking about
2012, so I'd figured on 2010 for an attempted target date and 2005 for
the earliest possible target date.

<p>
Am I less of a fool?  Yes, I'm ten years less of a fool.  I'm the
absolute minimum of fool that I can possibly manage.</a>

<p>
The whole uploading business is almost impossible to navigate because
you aren't just trying to beat faster-developing technologies, you're
trying to beat *prerequisite* technologies.  Nanotechnology as a
prerequisite for uploading, for example.  And then with the
<a name="1526qlink2">nanotechnology for computing and finer neuroimaging for cognitive
science, building an AI becomes much easier.</a>  (Assuming war goo doesn't
kill you first, of course.)  Anyway, the thing about AI is that between
distributed.net and opensource.org, it's possible to accelerate it quite
a bit.<a name="1526qlink3">  Accelerating uploading is a lot harder.</a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1444.html">[ Next ]</a><a href="1442.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1441.html">paul@i2.to</a>
<!-- nextthread="start" -->
</ul>
</body></html>
