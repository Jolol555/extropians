<!-- received="Tue Aug 31 15:04:09 1999 MDT" -->
<!-- sent="Tue, 31 Aug 1999 22:03:38 +0000" -->
<!-- name="Nick Bostrom" -->
<!-- email="bostrom@ndirect.co.uk" -->
<!-- subject="Re: &gt;H RE: Present dangers to transhumanism" -->
<!-- id="199908312103.WAA25188@sioux.hosts.netdirect.net.uk" -->
<!-- inreplyto="b49emgkxex7.fsf@mdj.nada.kth.se" -->
<!-- version=1.10, linesinbody=42 -->
<html><head><title>extropians: Re: &gt;H RE: Present dangers to transhumanism</title>
<meta name=author content="Nick Bostrom">
<link rel=author rev=made href="mailto:bostrom@ndirect.co.uk" title ="Nick Bostrom">
</head><body>
<h1>Re: &gt;H RE: Present dangers to transhumanism</h1>
Nick Bostrom (<i>bostrom@ndirect.co.uk</i>)<br>
<i>Tue, 31 Aug 1999 22:03:38 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3207">[ date ]</a><a href="index.html#3207">[ thread ]</a><a href="subject.html#3207">[ subject ]</a><a href="author.html#3207">[ author ]</a>
<!-- next="start" -->
<li><a href="3208.html">[ Next ]</a><a href="3206.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3171.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="3273qlink1">Anders Sandberg wrote:

<p>
<a href="3171.html#3207qlink1">&gt; Actually, we probably need more good studies of pros and cons of</a><br>
<i>&gt; transhumanists ideas put on the web, to show that we are actually</i><br>
<i>&gt; looking seriously at these issues. Otherwise people will get</a> the wrong</i><br>
<i>&gt; impression and think we are just naive technophiles.</i><br>

<p>
And yet, wasn't den Otter's point that the real reason why we should 
do this is not because of the danger that otherwise people might 
think that we are naive, but because of the actual technological 
risks? As long as we are just thinking about what it takes to spread 
the meme, we aren't really serious about what ought to be one half of 
transhumanism: anticipating and averting threats.

<p>
Here is my view: Rather than thinking of transhumanism as 
pro-technology, let's think of it as pro certain options that 
advanced technology will offer (life extension etc.). This is fully 
compatible with focusing a lot of attention on potential risks.

<p>
So rather than saying that the problem of malicious nanomachines is 
an argument against transhumanism, let transhumanist thinking grow to 
encompass this danger. We can be the ones who talk about the risks 
and the need to do something about them. We can take the lead in 
thinking about the downsides and dangers as well as in envisioning 
the opportunities inherent in technological development. The 
Foresight Institute has managed to do this in the domain of 
nanotechnology, but I think we have some way to go to do the same for 
our field which includes science and technology in general.

<p>
A first step might be to separate the true threats (e.g. destructive 
uses of nanotech or malicious AI), that one should be worrying about, 
from the much smaller threats or pseudo-threats (e.g. GM food, 
cloning) that the public at large is worried about.

<p>
Step 2 will then be to discuss what strategies would minimize these 
threats.

<p>
Nick Bostrom
<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a>      n.bostrom@lse.ac.uk
Department of Philosophy, Logic and Scientific Method
London School of Economics
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3208.html">[ Next ]</a><a href="3206.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3171.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
</body></html>
