<!-- received="Sun Aug  8 21:07:25 1999 MDT" -->
<!-- sent="Sun, 08 Aug 1999 22:07:37 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Personal goal system was: IA vs. AI" -->
<!-- id="37AE45F8.ACC6BA34@pobox.com" -->
<!-- inreplyto="Personal goal system was: IA vs. AI" -->
<!-- version=1.10, linesinbody=76 -->
<html><head><title>extropians: Re: Personal goal system was: IA vs. AI</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Personal goal system was: IA vs. AI</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 08 Aug 1999 22:07:37 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1768">[ date ]</a><a href="index.html#1768">[ thread ]</a><a href="subject.html#1768">[ subject ]</a><a href="author.html#1768">[ author ]</a>
<!-- next="start" -->
<li><a href="1769.html">[ Next ]</a><b>In reply to:</b> <a href="1767.html">Edwin Evans</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Edwin Evans wrote:
<br>
<i>&gt; </i><br>
<a href="1767.html#1768qlink1">&gt; Eliezer, what do you mean by:</a><br>
<i>&gt; </i><br>
<i>&gt; &gt; Even in a</i><br>
<i>&gt; &gt; deterministic Universe, there are still causal dependencies between past</i><br>
<i>&gt; &gt; and present</i><br>
<i>&gt; </i><br>
<i>&gt; That's what I thought a deterministic universe is. One where the present</i><br>
<i>&gt; instant depends on the instant before.</i><br>

<p>
In a quantum-random Universe too, of course.  The point is that the
common visualization of "determinism" involves a Universe that converges
to a given future regardless of the past - tell anyone that the future
is "specified" and that's what they'll hear.  In such a case, of course,
free will wouldn't exist.  The idea that the future can be both
predetermined and causally reliant on the present requires some thought,
or training in deterministic formalisms like Turing computability.

<p>
<a href="1767.html#1768qlink2">&gt; I don't think its the paradox (between thinking I have control and being</a><br>
<i>&gt; controlled by low level processes) that is an illusion. The paradox has an</i><br>
<i>&gt; answer. The feeling of control is an illusion.</i><br>

<p>
While I'm still trying to find a good mathematical definition, I don't
think it's at all inappropriate to speak of high-level processes
controlling low-level processes.  But roughly, if the higher-level
process is simpler - if you can simulate it using a smaller Turing
machine - than it may make sense to view that process as being
self-directed.  All abstractions are unreal in a sense, but the
non-abstract level is always far too detailed for a human mind to
understand - and if the only way to predict and manipulate reality is to
deal with the abstraction, which it is, then I guess we're stuck with
the abstraction.  Besides, nobody is claiming that the abstractions are
real - just that they're useful.  Not in the make-a-better-person sense,
perhaps, but certainly in the deal-with-reality sense.

<p>
What it comes down to is causal patterns.  My image of these words may
only be events in the visual cortex, but the pattern of that image
mirrors the photons hitting my eyeballs, which mirrors the screen, which
mirrors the VRAM, which mirrors the letters I'm typing.  I think it's a
valid mode of thought to skip the reductionist perspective and the
chains of transmission and just say that it's the same pattern, since
that pattern-identity is both perfect, predictive, and manipulative.

<p>
In the same way, it makes sense for Paul to speak of choosing actions,
or for me to speak of reasoning to the truth.  In one sense we're only
neurons, but in an another sense we're the higher-level patterns of
thought, of rationality, or of truth incarnated in the neural substrate.

<p>
The issue ultimately boils down to the basic question of semantics: 
When does A mean B?  I would argue that to make any choices at all, you
have 

<p>
<a href="1767.html#1768qlink3">&gt; Paul, if you feel you need to believe in free will, then I would ask you if</a><br>
<i>&gt; it was enough to believe in the possibility of it. I also wonder what</i><br>
<i>&gt; "assortment of things" I shouldn't do because I don't think I have free</i><br>
<i>&gt; will. I think I should do what is right. (It seems like its mostly just a</i><br>
<i>&gt; theoretical or blaming issue. The only practical thing I can think of right</i><br>
<i>&gt; now is whether I argue that I have free will or that I don't have free</i><br>
<i>&gt; will.)</i><br>

<p>
<a href="1767.html#1768qlink4">&gt; Also, Eliezer wrote:</a><br>
<i>&gt; &gt; So</i><br>
<i>&gt; &gt; purposes, if not energy and short-term motivations, definitely fall into</i><br>
<i>&gt; &gt; the "software" category.</i><br>
<i>&gt; Huh? Purposes are definitely software but short-term motivations are not?</i><br>

<p>
They're a lot harder to manipulate.  Consider the relative difficulty of
deciding to saw off your hand with a rusty butter knife and actually
doing it.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1769.html">[ Next ]</a>
<b>In reply to:</b> <a href="1767.html">Edwin Evans</a>
<!-- nextthread="start" -->
</ul>
</body></html>
