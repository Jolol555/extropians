<!-- received="Mon Jul 12 15:36:30 1999 MDT" -->
<!-- sent="Mon, 12 Jul 1999 16:37:17 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: SSIs" -->
<!-- id="378A600B.81E7FC0F@pobox.com" -->
<!-- inreplyto="SSIs" -->
<!-- version=1.10, linesinbody=40 -->
<html><head><title>extropians: Re: SSIs</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: SSIs</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 12 Jul 1999 16:37:17 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#596">[ date ]</a><a href="index.html#596">[ thread ]</a><a href="subject.html#596">[ subject ]</a><a href="author.html#596">[ author ]</a>
<!-- next="start" -->
<li><a href="0597.html">[ Next ]</a><a href="0595.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0558.html">Weaver, Evan A.</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Weaver, Evan A." wrote:
<br>
<i>&gt; </i><br>
<a href="0558.html#0596qlink1">&gt; Since we are looking for SIs, what if all the SIs are busy looking for super</a><br>
<i>&gt; super intelligences, and those are looking for really super super</i><br>
<i>&gt; intelligences, and those are... Does anyone see any reason why this would</i><br>
<i>&gt; have to stop somewhere?</i><br>

<p>
Yes.  We're mortals.  We don't have the vaguest idea of what's really
going on.  We live our lives in fog.  Mortals do not engage in actual
"reasoning", but a process which may occasionally look like reasoning or
duplicate some outputs.  This is the defining aspect of being mortal. 
The whole thesis and hope of the Singularitarians is that with enough
intelligence you can stop being mortal and everything falls into place. 
If there are SSIs and SSSIs, we can hope that either the SIs know it
perfectly well, or that the transition is simple, easy, and obvious.

<p>
There's no a priori way of saying that either our theory or yours is
impossible, but we tend to assume that there's a qualitative difference
between limited thought and thought backed by a planetary supercomputer;
that the situation from an SI's perspective is *not* analogous to ours
unless proved to be so.

<p>
That, in turn, is what defines the "Singularity"; some people, like
Robin Hanson, assume - in accordance with the Law of Mediocrity and
Occam's Razor - that everything posthuman is analogous to the human
situation unless proved otherwise.  Some people, like Vernor Vinge,
assume - in accordance with non-anthropocentrism and Occam's Razor -
that everything posthuman bears no resemblance to the human situation
unless proved otherwise.

<p>
I go by the later theory because I think I understand the forces that
generate "the human situation", and these forces are not present in
posthumans.  Remove the elements and the holis (the holistic result of
element interactions) can't survive.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0597.html">[ Next ]</a><a href="0595.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0558.html">Weaver, Evan A.</a>
<!-- nextthread="start" -->
</ul>
</body></html>
