<!-- received="Fri Aug 13 22:32:04 1999 MDT" -->
<!-- sent="Sat, 14 Aug 1999 00:30:59 -0400" -->
<!-- name="John Clark" -->
<!-- email="jonkc@worldnet.att.net" -->
<!-- subject="Re: IA vs. AI (vs. humanity)" -->
<!-- id="001301bee60d$f7711820$c99f4d0c@flrjs" -->
<!-- inreplyto="IA vs. AI (vs. humanity)" -->
<!-- version=1.10, linesinbody=60 -->
<html><head><title>extropians: Re: IA vs. AI (vs. humanity)</title>
<meta name=author content="John Clark">
<link rel=author rev=made href="mailto:jonkc@worldnet.att.net" title ="John Clark">
</head><body>
<h1>Re: IA vs. AI (vs. humanity)</h1>
John Clark (<i>jonkc@worldnet.att.net</i>)<br>
<i>Sat, 14 Aug 1999 00:30:59 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2093">[ date ]</a><a href="index.html#2093">[ thread ]</a><a href="subject.html#2093">[ subject ]</a><a href="author.html#2093">[ author ]</a>
<!-- next="start" -->
<li><a href="2094.html">[ Next ]</a><a href="2092.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1465.html">Jeff Davis</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1

<p>
Jeff Davis &lt;jdavis@socketscience.com&gt; On Tuesday, August 03, 1999 Wrote:


<p>
<a href="1465.html#2093qlink1">    &gt;It seems to me that the military potential of both AI and IA will guarantee</a><br>
<i>    &gt;government monitoring and oversight of any development of these</i><br>
<i>    &gt;technologies. [...] It's a shame really, I'd much rather see it developed in an</i><br>
<i>    &gt;academic/civilian setting.</i><br>

<p>
I don't think the military will get there first for two reasons.


<OL>
  <li>  Experience has shown that when any project is put into deep black
    secrecy the costs increase and the rate of progress decreases
    by about 30%.


</OL>
<p>
2)The implications of the technology would be just as great in the civilian
<p>
    sector as in the military, thus the personal financial rewards could be
    astronomical. For this reason I would expect the brightest people,
    especially the very brightest, to gravitate toward corporate research not military.

<p>
<a href="1465.html#2093qlink2">    &gt;Despite the dramatic talk of an SI destroying humanity, I picture a</a><br>
<i>    &gt;well-thought-out, cautious, gradual approach to "waking up" and training an</i><br>
<i>    &gt;artificial mind.  The runaway self-evolution which Eliezer and others have</i><br>
<i>    &gt;predicted seems unlikely in this setting, all the moreso because the</i><br>
<i>    &gt;principles will be anticipating just such a situation.</i><br>

<p>
You've spent your entire professional life on this project, you're making good
progress and you know there will be a huge advantage for the team that
makes the first AI, you know others are also working on AI also but
you're not sure if they're ahead of you or not. Question: Would you
deliberately slow the pace of your work?

<p>
<a href="1465.html#2093qlink3">    &gt;Of the various external "safeguards", one would expect a complete suite of</a><br>
<i>    &gt;on/off switches and controlled access (from outside to in, and from inside</i><br>
<i>    &gt;to anywhere.</i><br>

<p>
Like everybody else there have been times in my life when people have convinced
me to do stupid things, and those people were not even geniuses, not by any stretch
of the imagination. I don't think a hyper intelligent AI would have much trouble in tricking
or convincing me to turn all the safety switches off and letting it go free.

<p>
John K Clark     jonkc@att.net





<p>
-----BEGIN PGP SIGNATURE-----
<br>
Version: PGP for Personal Privacy 5.5.5

<p>
iQA/AwUBN7TxA9+WG5eri0QzEQL0owCg2Q8H7Hp1Ok0UQhiw1NxJyfxvBR8An2tS
aAlRcXjw4BU0vruScoXkjDMO
<br>
=gOng
<br>
-----END PGP SIGNATURE-----
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2094.html">[ Next ]</a><a href="2092.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1465.html">Jeff Davis</a>
<!-- nextthread="start" -->
</ul>
</body></html>
