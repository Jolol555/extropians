<!-- received="Mon Jul 12 12:33:46 1999 MDT" -->
<!-- sent="Mon, 12 Jul 1999 11:31:00 -0700" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Human minds on Windows(?) (was Re: Web site up! (GUI vs. CLI))" -->
<!-- id="199907121831.LAA10244@finney.org" -->
<!-- inreplyto="Human minds on Windows(?) (was Re: Web site up! (GUI vs. CLI))" -->
<!-- version=1.10, linesinbody=32 -->
<html><head><title>extropians: Re: Human minds on Windows(?) (was Re: Web site up! (GUI vs. CLI))</title>
<meta name=author content="hal@finney.org">
<link rel=author rev=made href="mailto:hal@finney.org" title ="hal@finney.org">
</head><body>
<h1>Re: Human minds on Windows(?) (was Re: Web site up! (GUI vs. CLI))</h1>
<i>hal@finney.org</i><br>
<i>Mon, 12 Jul 1999 11:31:00 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#592">[ date ]</a><a href="index.html#592">[ thread ]</a><a href="subject.html#592">[ subject ]</a><a href="author.html#592">[ author ]</a>
<!-- next="start" -->
<li><a href="0593.html">[ Next ]</a><a href="0591.html">[ Previous ]</a>
<b>Maybe in reply to:</b> <a href="0312.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky, &lt;sentience@pobox.com&gt;, writes:
&gt; Which is more important:  The next level up in programming languages, or
&gt; a EURISKO-like reusable AI core?

<p>
This sounds like Cyc (www.cyc.com), but that is looking more and more like
a failed project.

<p>
Here is an interesting excerpt from the author:

<p>
<i>: In the late 1970s I built a computer program (Eurisko) that discovered</i><br>
<i>: things on its own in many fields. To get it to work, I had to give it the</i><br>
<i>: power to tinker with its own learning heuristics and its own goals. I</i><br>
<i>: would leave it running overnight and hurry in the next morning to see</i><br>
<i>: what it had come up with. Often I'd find it in a mode best described as</i><br>
<i>: "dead." Sometime during the night, Eurisko would decide that the best</i><br>
<i>: thing to do was to commit suicide and shut itself off. More precisely,</i><br>
<i>: it modified its own judgmental rules in a way that valued "making no</i><br>
<i>: errors at all" as highly as "making productive new discoveries." As soon</i><br>
<i>: as Eurisko did this, it found it could successfully meet its new goal</i><br>
<i>: by doing nothing at all for the rest of the night. This reminds me of</i><br>
<i>: HAL's boast: "No 9000 computer has ever made a mistake." I eventually</i><br>
: had to add a new heuristic to Eurisko-one it couldn't modify in any<br>
: way-to explicitly forbid this sort of suicide.<br>

<p>
It's too bad that Lenat's brilliance has been sucked into the abyss of
Cyc.  If he had continued to work on Eurisko, perhaps with the goal of
creating a system which could learn from experience the way babies do,
he might have built a system which could develop common sense for itself
rather than having to have it spoon-fed.

<p>
Hal
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0593.html">[ Next ]</a><a href="0591.html">[ Previous ]</a>
<b>Maybe in reply to:</b> <a href="0312.html">Eugene Leitl</a>
<!-- nextthread="start" -->
</ul>
</body></html>
