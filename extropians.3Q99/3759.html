<!-- received="Wed Sep  8 11:02:43 1999 MDT" -->
<!-- sent="Wed, 8 Sep 1999 10:02:59 -0700" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Mike Perry's work on self-improving AI" -->
<!-- id="199909081702.KAA09038@finney.org" -->
<!-- inreplyto="Mike Perry's work on self-improving AI" -->
<!-- version=1.10, linesinbody=30 -->
<html><head><title>extropians: Re: Mike Perry's work on self-improving AI</title>
<meta name=author content="hal@finney.org">
<link rel=author rev=made href="mailto:hal@finney.org" title ="hal@finney.org">
</head><body>
<h1>Re: Mike Perry's work on self-improving AI</h1>
<i>hal@finney.org</i><br>
<i>Wed, 8 Sep 1999 10:02:59 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3759">[ date ]</a><a href="index.html#3759">[ thread ]</a><a href="subject.html#3759">[ subject ]</a><a href="author.html#3759">[ author ]</a>
<!-- next="start" -->
<li><a href="3760.html">[ Next ]</a><a href="3758.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3744.html">Matt Gingell</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Matt Gingell, &lt;mjg223@nyu.edu&gt;, writes:
<br>
<a href="3744.html#3759qlink1">&gt; I believe this approach is provable optimal in the absence of any knowledge</a><br>
<i>&gt; about the shape of the search space, but I'm having trouble tracking down the</i><br>
<i>&gt; reference.</i><br>
<i>&gt;</i><br>
<i>&gt; A while back, I wrote an artificial life system which simulates a population of</i><br>
<i>&gt; organisms driven by neural networks. Unfortunately, I have to report that a herd</i><br>
<i>&gt; of parallel searches most certainly can get stuck! (In my case, I was dealing</i><br>
<i>&gt; with populations of around one or two thousand nodes.)</i><br>

<p>
A provably optimal search is not enough, because it may be infinitely
slow.  What you need is a method to get past local optima in a reasonable
amount of time.  There is no substitute in that case for hard work and
perhaps some luck.

<p>
I still think that it is very possible that there may be many barriers
in the self-improvement path to AI.  It seems likely to me that such
barriers exist below human intelligence: someone with an IQ of 50 could
not make progress on improving their own program.  it is questionable
whether someone of merely human intelligence will be smart enough to know
how to change a human AI into a super-human one, even (or especially,
for this constrains their options!) working one module at a time as
Eliezer suggests.  And there is no way whatsoever of knowing whether a
twice-human AI can see how to convert its program into a thrice-human one.

<p>
That self improvement can lead to a transcendentally powerful super-AI
seems to be an article of faith unsupported by facts.

<p>
Hal
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3760.html">[ Next ]</a><a href="3758.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3744.html">Matt Gingell</a>
<!-- nextthread="start" -->
</ul>
</body></html>
