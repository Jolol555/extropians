<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Calculating a personal long term good</TITLE>
<META NAME="Author" CONTENT="Adrian Tymes (wingcat@pacbell.net)">
<META NAME="Subject" CONTENT="Calculating a personal long term good">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Calculating a personal long term good</H1>
<!-- received="Sun Apr  9 17:04:22 2000" -->
<!-- isoreceived="20000409230422" -->
<!-- sent="Sun, 09 Apr 2000 16:00:32 -0700" -->
<!-- isosent="20000409230032" -->
<!-- name="Adrian Tymes" -->
<!-- email="wingcat@pacbell.net" -->
<!-- subject="Calculating a personal long term good" -->
<!-- id="38F10B90.6C3A7117@pacbell.net" -->
<!-- inreplyto="Pine.UW2.4.20.0004091202080.16669-100000@ilr" -->
<STRONG>From:</STRONG> Adrian Tymes (<A HREF="mailto:wingcat@pacbell.net?Subject=Re:%20Calculating%20a%20personal%20long%20term%20good&In-Reply-To=&lt;38F10B90.6C3A7117@pacbell.net&gt;"><EM>wingcat@pacbell.net</EM></A>)<BR>
<STRONG>Date:</STRONG> Sun Apr 09 2000 - 17:00:32 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="0487.html">Adrian Tymes: "Re: Technology: Rigid Airship"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0485.html">Zero Powers: "Re: Professional witness (was Re: Transparency Debate: test case!)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0453.html">Robert Bradbury: "Re: Nanotech Restrictions"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0502.html">Robert Bradbury: "Nanodevelopment [was Re: Calculating a personal long term good]"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0502.html">Robert Bradbury: "Nanodevelopment [was Re: Calculating a personal long term good]"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#486">[ date ]</A>
<A HREF="index.html#486">[ thread ]</A>
<A HREF="subject.html#486">[ subject ]</A>
<A HREF="author.html#486">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Robert Bradbury wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; AAHEMMM... Please note the subject line &quot;Nanotech Restrictions&quot; *NOT*
</EM><BR>
<EM>&gt; &quot;Cuban-American&quot; Poltics and *NOT* &quot;WACO (yet again)&quot;.
</EM><BR>
<P>Ne...technically, both sides of the thread were/are off-topic, then.
<BR>
<P><EM>&gt; Somedays I wonder if we will ever get to soar like the eagles when
</EM><BR>
<EM>&gt; members of the tribe display repeated patterns of attempting takeoffs
</EM><BR>
<EM>&gt; with bricks attached to their feet.
</EM><BR>
<P>That's actually one of the reasons I began tinkering with enlightened
<BR>
greed.  If I can soar under my own power, but I would never get off the
<BR>
ground if I tried to take said members with me...maybe seeing me flying
<BR>
would encourage them to take the bricks off?
<BR>
<P><EM>&gt; On Sat, 8 Apr 2000, Harvey Newstrom wrote:
</EM><BR>
<EM>&gt; &gt; &quot;Adrian Tymes&quot; &lt;<A HREF="mailto:wingcat@pacbell.net?Subject=Re:%20Calculating%20a%20personal%20long%20term%20good&In-Reply-To=&lt;38F10B90.6C3A7117@pacbell.net&gt;">wingcat@pacbell.net</A>&gt; wrote on Saturday, April 08, 2000 3:38
</EM><BR>
<EM>&gt; &gt; PM,
</EM><BR>
<EM>&gt; &gt; &gt; I call it &quot;enlightened greed&quot;, and it is driven by the principle that
</EM><BR>
<EM>&gt; &gt; &gt; the correct action is that which will benefit me most in the long term.
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; The important thing is that nowhere in the decision is there
</EM><BR>
<EM>&gt; &gt; &gt; consideration of what would be good or bad for anybody else,
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Wouldn't this system lead to mass criminal behavior?  If I am a skilled
</EM><BR>
<EM>&gt; &gt; hacker, then I can make money easier by stealing it than by working as a
</EM><BR>
<EM>&gt; &gt; consultant.  According to your system, that would be best for me.  Does your
</EM><BR>
<EM>&gt; &gt; system lead to this conclusion?
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Well, if as a result of criminal behavior, you get imprisoned, presumably
</EM><BR>
<EM>&gt; there is a real hit to your long term benefit.  So, unless you come up
</EM><BR>
<EM>&gt; with the foolproof perfect crime, enlightened self-interest dictates
</EM><BR>
<EM>&gt; a fair amount of other-interest.
</EM><BR>
<P>That's about the only explanation I can think of for why I'm seeing the
<BR>
results that I do.  Of course, it does require one to be intellectually
<BR>
honest - stealing an extra couple hundred bucks to spend on a dose of
<BR>
cocaine, or getting an orgasm and hearing a rape victim's cries, are not
<BR>
worth the consequent jail terms.
<BR>
<P><EM>&gt; If you are going to live 2000 years, sooner or later you are going to
</EM><BR>
<EM>&gt; have to deal with the cleaning up the mess of your miss-spent youth
</EM><BR>
<EM>&gt; (e.g. pollution).  So a *real* &quot;long-term&quot; perspective includes an
</EM><BR>
<EM>&gt; accounting for the commons, a desire to utilize and allocate resources
</EM><BR>
<EM>&gt; most efficiently, and a desire to uplift others to your level (because
</EM><BR>
<EM>&gt; its going to get damn boring talking to 10^10 copies of yourself), etc.
</EM><BR>
<P>Uplifting others goes beyond the boredom.  If you can uplift someone so
<BR>
they can do a task more efficiently, and their doing that task is of aid
<BR>
to you, and they wish to do that task anyway, then uplifting that person
<BR>
has a much more direct payback.
<BR>
<P>An example from my work: I was hired to create, among other things,
<BR>
software tools for use by other employees.  However, some of these
<BR>
employees ask for or can benefit from so many tools, and typically have
<BR>
a better internal model of the tools than they can communicate, that it
<BR>
is more efficient to teach them the basics of programming, to the point
<BR>
that they can create the tools - which are simple automation of manual
<BR>
tasks, not any advanced computer science.  They can create tools
<BR>
whenever they want, faster than it would take for them to think that it
<BR>
might be worth asking me, then ask me (the development time for some of
<BR>
these being practically nil), then adjust their minds to any differences
<BR>
between how I perceive the data they work with and how they perceive it.
<BR>
Their products also tend to be more useful to them, having been crafted
<BR>
with a better sense of how they would use it, and they also get a better
<BR>
sense of what can be automated, which has directly lead to more of their
<BR>
work being automated - which leads to better productivity, which means
<BR>
more clients served, which leads to the value of my stock in the company
<BR>
going up (even after accounting for any pay raises they may request for
<BR>
obtaining this skill).  It also leaves me time to do other things; the
<BR>
payoff on that usually takes less than a month.
<BR>
<P><EM>&gt; The whole nano-terrorist perspective has problems because its applying
</EM><BR>
<EM>&gt; current &quot;scarcity&quot; economics to a post-scarcity environment (unless
</EM><BR>
<EM>&gt; one invokes the making 10^10 copies of oneself caveat).  The only
</EM><BR>
<EM>&gt; terrorist situation I see that makes any sense is an &quot;irrational&quot;
</EM><BR>
<EM>&gt; scenario where individuals are motiviated by beliefs and not by needs.
</EM><BR>
<P>Though there are plenty of those around.  But is it easy to learn GNR
<BR>
when your mindset puts your beliefs ahead of rationality?  Genetics
<BR>
alone insists that there is not an absolute difference between humans
<BR>
and other primates.  Those who insist that Diety created humans from mud
<BR>
would reject that, and be unable to proceed.
<BR>
<P><EM>&gt; For example, Stephanson's &quot;The Diamond Age&quot;, provides no explanation
</EM><BR>
<EM>&gt; as to why the benefits of the technologies should not be available
</EM><BR>
<EM>&gt; to everyone.  It implicitly assumes there are some limits on energy
</EM><BR>
<EM>&gt; or mass (for an approx. current Earth level population) and that simply
</EM><BR>
<EM>&gt; *is not* true.
</EM><BR>
<P>For those who know enough to take advantage of future tech, there is
<BR>
potential for boundless resources, given time.  But at any specific date
<BR>
in the future, there will always be a finite number of people aware of
<BR>
the realities of nano, and a finite amount of time between now and then.
<BR>
If, starting tomorrow and for the next year, I operate a mobile food
<BR>
production factory that can produce enough food to feed up to ~1 billion
<BR>
people for a year per day, and give away as much output as people care
<BR>
to haul away, *and* take it on a tour that visits every population
<BR>
center in North America with at least ten human beings, there would
<BR>
still likely be people starving in North America unaware of my service
<BR>
at the end of that year.  And that's on what's probably the most media-
<BR>
saturated continent on Earth, with the highest amount of resources that
<BR>
would act independently of me to get the word out to everyone about such
<BR>
a thing.
<BR>
<P>Unlimited production does not mean immediately infinite supply, no
<BR>
matter how much we wish it were otherwise.
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0487.html">Adrian Tymes: "Re: Technology: Rigid Airship"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0485.html">Zero Powers: "Re: Professional witness (was Re: Transparency Debate: test case!)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0453.html">Robert Bradbury: "Re: Nanotech Restrictions"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0502.html">Robert Bradbury: "Nanodevelopment [was Re: Calculating a personal long term good]"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0502.html">Robert Bradbury: "Nanodevelopment [was Re: Calculating a personal long term good]"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#486">[ date ]</A>
<A HREF="index.html#486">[ thread ]</A>
<A HREF="subject.html#486">[ subject ]</A>
<A HREF="author.html#486">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:09:11 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
