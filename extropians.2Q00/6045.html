<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Hugo de Garis</TITLE>
<META NAME="Author" CONTENT="Brian Atkins (brian@posthuman.com)">
<META NAME="Subject" CONTENT="Re: Hugo de Garis">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Hugo de Garis</H1>
<!-- received="Sat Jun 24 14:27:04 2000" -->
<!-- isoreceived="20000624202704" -->
<!-- sent="Sat, 24 Jun 2000 16:28:10 -0400" -->
<!-- isosent="20000624202810" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Hugo de Garis" -->
<!-- id="395519DA.8FAF09D3@posthuman.com" -->
<!-- inreplyto="b498zvvx6xx.fsf@sans04.nada.kth.se" -->
<STRONG>From:</STRONG> Brian Atkins (<A HREF="mailto:brian@posthuman.com?Subject=Re:%20Hugo%20de%20Garis&In-Reply-To=&lt;395519DA.8FAF09D3@posthuman.com&gt;"><EM>brian@posthuman.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat Jun 24 2000 - 14:28:10 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="6046.html">GBurch1@aol.com: "Re: What is the best place in the world to live?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6044.html">Natasha Vita-More: "Re: PR disasters"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6024.html">Anders Sandberg: "Re: Hugo de Garis"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="6060.html">Bryan Moss: "Re: Hugo de Garis"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6045">[ date ]</A>
<A HREF="index.html#6045">[ thread ]</A>
<A HREF="subject.html#6045">[ subject ]</A>
<A HREF="author.html#6045">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
How can you debate something (AI) where it is impossible to know what
<BR>
the outcome will be? No one can say for sure whether or not the first
<BR>
AI will kill everyone or upload everyone or ? I suppose that leaves you
<BR>
with two possible discussions: how much of the risk can be managed (and
<BR>
what chances roughly are you left with that the AI kills everyone), and
<BR>
how does that compare with the risks of _not_ developing such an AI.
<BR>
Also you can discuss who would you prefer to develop the first AI if
<BR>
you had to choose?
<BR>
<P>Anders Sandberg wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &quot;Bryan Moss&quot; &lt;<A HREF="mailto:bryan.moss@btinternet.com?Subject=Re:%20Hugo%20de%20Garis&In-Reply-To=&lt;395519DA.8FAF09D3@posthuman.com&gt;">bryan.moss@btinternet.com</A>&gt; writes:
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; &gt; Cue sensationalism.  We see the Bomb, we see human skulls,
</EM><BR>
<EM>&gt; &gt; we see a post apocalyptic world, we see de Garis looking
</EM><BR>
<EM>&gt; &gt; serious next to his Brain Machine.  All the while de Garis
</EM><BR>
<EM>&gt; &gt; explains how he thinks AI has more destructive potential
</EM><BR>
<EM>&gt; &gt; than nuclear weapons.  (Personally I find the idea of
</EM><BR>
<EM>&gt; &gt; comparing intelligence to explosives rather disturbing.)
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; I think de Garis is indeed exaggerating and possibly worsening the
</EM><BR>
<EM>&gt; same problem he says he wants to avoid by setting up a conflict
</EM><BR>
<EM>&gt; beforehand in a very cartoonish manner, but one should give it to him
</EM><BR>
<EM>&gt; that he at least tries to think ahead on the drastic philosophical and
</EM><BR>
<EM>&gt; idological implications AI would have. Now if we could produce some
</EM><BR>
<EM>&gt; reasoned debate, things would get better.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; --
</EM><BR>
<EM>&gt; -----------------------------------------------------------------------
</EM><BR>
<EM>&gt; Anders Sandberg                                      Towards Ascension!
</EM><BR>
<EM>&gt; <A HREF="mailto:asa@nada.kth.se?Subject=Re:%20Hugo%20de%20Garis&In-Reply-To=&lt;395519DA.8FAF09D3@posthuman.com&gt;">asa@nada.kth.se</A>                            <A HREF="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</A>
</EM><BR>
<EM>&gt; GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</EM><BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="6046.html">GBurch1@aol.com: "Re: What is the best place in the world to live?"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="6044.html">Natasha Vita-More: "Re: PR disasters"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="6024.html">Anders Sandberg: "Re: Hugo de Garis"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="6060.html">Bryan Moss: "Re: Hugo de Garis"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#6045">[ date ]</A>
<A HREF="index.html#6045">[ thread ]</A>
<A HREF="subject.html#6045">[ subject ]</A>
<A HREF="author.html#6045">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:14:15 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
