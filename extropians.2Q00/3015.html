<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial</TITLE>
<META NAME="Author" CONTENT="Robert J. Bradbury (bradbury@aeiveos.com)">
<META NAME="Subject" CONTENT="Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain  building">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain  building</H1>
<!-- received="Sun May 14 00:53:46 2000" -->
<!-- isoreceived="20000514065346" -->
<!-- sent="Sat, 13 May 2000 23:54:51 -0700 (PDT)" -->
<!-- isosent="20000514065451" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain  building" -->
<!-- id="Pine.UW2.4.20.0005132341580.8775-100000@www.aeiveos.com" -->
<!-- inreplyto="3.0.6.16.20000513230353.53a789ce@pop.uniserve.com" -->
<STRONG>From:</STRONG> Robert J. Bradbury (<A HREF="mailto:bradbury@aeiveos.com?Subject=Re:%20AI:%20FWD%20(IUFO/mind-l)%20Robokitty%20and%20Artificial%20brain%20%20building&In-Reply-To=&lt;Pine.UW2.4.20.0005132341580.8775-100000@www.aeiveos.com&gt;"><EM>bradbury@aeiveos.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Sun May 14 2000 - 00:54:51 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3016.html">Damien Broderick: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3014.html">hal@finney.org: "Freitas on Gray Goo"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3012.html">E. Shaun Russell: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3016.html">Damien Broderick: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3015">[ date ]</A>
<A HREF="index.html#3015">[ thread ]</A>
<A HREF="subject.html#3015">[ subject ]</A>
<A HREF="author.html#3015">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
On Sat, 13 May 2000, E. Shaun Russell wrote:
<BR>
<P><EM>&gt; I had the chance to talk a bit with Hugo at one of Forrest Bishop's parties
</EM><BR>
<EM>&gt; a few years back.  Even then he was shooting for a cybernetic cat by 2001,
</EM><BR>
<EM>&gt; so it seems he is right on track.
</EM><BR>
<P>Ooooh, first hand knowledge, I'm jealous... (really!).
<BR>
<P>&nbsp;
<BR>
<EM>&gt; To answer the question: if Hugo de Garis truly feared for the extermination
</EM><BR>
<EM>&gt; of the human race, do you really think that he would be plotting the
</EM><BR>
<EM>&gt; creation of superior AI?  I doubt it.
</EM><BR>
<P>Not clear, I suspect there is hardly a microbiologist or genetic engineer who
<BR>
does not know the ills that the technologies they develop may be turned to.
<BR>
The Russians are still trying to destroy a huge store of bioweapons with no AI.
<BR>
<P><EM>&gt; On its own, superior AI could mean the extermination of the human race; however,
</EM><BR>
<EM>&gt; in truth, there are many advances being made in nanotech, genetic engineering,
</EM><BR>
<EM>&gt; space travel and a plethora of other &quot;perpetual human longevity&quot; pursuits.
</EM><BR>
<P>Not true, you have to require that (a) AIs must develop a control over
<BR>
the physical reality sufficient to exterminate humans; or (b) Humans in
<BR>
the face of overwhelming AI decide to go like lemmings down to the sea
<BR>
and drown themselves.  The fact that *most* of humanity is frequently faced
<BR>
with a need to interact with  individuals more intelligent than themselves
<BR>
(usually the individuals higher in the power structures) and lives to
<BR>
talk about it, seems to suggest that we will not suddenly become lemmings.
<BR>
<P><EM>&gt; The question will be whether or not we can keep up to AI; I, for one, don't
</EM><BR>
<EM>&gt; think so.  
</EM><BR>
If our children end up using sub-AIs on a regular basis, they may not be
<BR>
so reluctant to incorporating them into their being. 
<BR>
<P><EM>&gt; If Hugo and others succeed in creating superior AI, some humans will
</EM><BR>
<EM>&gt; probably try to co-exist, but it would be most convenient for the majority
</EM><BR>
<EM>&gt; of the human race to eventually leave the planet.
</EM><BR>
<P>It is a profound sociological &amp; psychological issue as to whether a
<BR>
conscious species that clearly understands that it has the technology
<BR>
to evolve to higher levels, but chooses to occupy a non-pinacle niche
<BR>
in the life forms of the galaxy would continue to survive in the long term.
<BR>
The waves of genetic drives are going to fall hard upon the shores of
<BR>
the reality of chosen inferiority.
<BR>
<P>Robert
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3016.html">Damien Broderick: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3014.html">hal@finney.org: "Freitas on Gray Goo"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3012.html">E. Shaun Russell: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3016.html">Damien Broderick: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3015">[ date ]</A>
<A HREF="index.html#3015">[ thread ]</A>
<A HREF="subject.html#3015">[ subject ]</A>
<A HREF="author.html#3015">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:11:12 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
