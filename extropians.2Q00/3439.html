<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: SITE: Coding a Transhuman AI 2.0a</TITLE>
<META NAME="Author" CONTENT="Matt Gingell (mjg223@is7.nyu.edu)">
<META NAME="Subject" CONTENT="Re: SITE: Coding a Transhuman AI 2.0a">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: SITE: Coding a Transhuman AI 2.0a</H1>
<!-- received="Sat May 20 15:28:05 2000" -->
<!-- isoreceived="20000520212805" -->
<!-- sent="Sat, 20 May 2000 17:25:48 -0400" -->
<!-- isosent="20000520212548" -->
<!-- name="Matt Gingell" -->
<!-- email="mjg223@is7.nyu.edu" -->
<!-- subject="Re: SITE: Coding a Transhuman AI 2.0a" -->
<!-- id="00052017274503.00501@localhost.localdomain" -->
<!-- inreplyto="Pine.GSO.4.10.10005200410080.15307-100000@morpheus.cis.yale.edu" -->
<STRONG>From:</STRONG> Matt Gingell (<A HREF="mailto:mjg223@is7.nyu.edu?Subject=Re:%20SITE:%20Coding%20a%20Transhuman%20AI%202.0a&In-Reply-To=&lt;00052017274503.00501@localhost.localdomain&gt;"><EM>mjg223@is7.nyu.edu</EM></A>)<BR>
<STRONG>Date:</STRONG> Sat May 20 2000 - 15:25:48 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3440.html">Natasha Vita-More: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3438.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3455.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3455.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3439">[ date ]</A>
<A HREF="index.html#3439">[ thread ]</A>
<A HREF="subject.html#3439">[ subject ]</A>
<A HREF="author.html#3439">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Dan Fabulich wrote:
<BR>
<P><EM>&gt; Matt Gingell wondered:
</EM><BR>
<EM>&gt; ...
</EM><BR>
<P><EM>&gt; BTW, the fact that no such Holy Grail exists also provides a plausible
</EM><BR>
<EM>&gt; explanation as to why AI has failed so often in the past.  In an
</EM><BR>
<EM>&gt; important sense, were you right about what intelligence is like, AI
</EM><BR>
<EM>&gt; would be easier than it is harder.
</EM><BR>
<P>How many attempts at heavier than air flight failed before we figured
<BR>
that out? Just because we haven't found an answer yet or we haven't
<BR>
got a fast enough machine to try it (a light enough engine) doesn't
<BR>
mean it isn't out there. We've only had computers for 50 years and
<BR>
already we've done things that even a hundred years ago would have
<BR>
been generally thought impossible. Give AI a break. Obviously there
<BR>
are huge holes left to be filled and principles yet to be discovered,
<BR>
but it's a very young science.
<BR>
<P><EM>&gt; ...
</EM><BR>
<P><EM>&gt; I can see that it would disappoint you if the answer turned out to be
</EM><BR>
<EM>&gt; that this feature emerged in our brains only due to some contingent
</EM><BR>
<EM>&gt; evolutionary process.
</EM><BR>
<P>Yes, it'd disappoint me. I don't want to think of the minds as nothing
<BR>
but an ad hoc, idiosyncratic  pile of junk spaghetti code. Of course,
<BR>
I recognize the facility of believing things because you'd like them
<BR>
to be true, and acknowledge that you may well turn out to be right. I
<BR>
don't think though there's anything wrong with a scientific enquiry
<BR>
being guided a personal sense of elegance and esthetics.
<BR>
<P><EM>&gt; ...
</EM><BR>
<P><EM>&gt; Look, suppose you WERE somehow able to map out a somewhat
</EM><BR>
<EM>&gt; comprehensive list of possible conceptual schemes which you would use
</EM><BR>
<EM>&gt; to categorize the &quot;raw sense data.&quot;  How could you algorithmically
</EM><BR>
<EM>&gt; determine which of these conceptual schemes worked better than some
</EM><BR>
<EM>&gt; others?  Any others?  Our ancestors had a way: use it as a rule for
</EM><BR>
<EM>&gt; action, see if it helps you breed.  You and your machines, even at
</EM><BR>
<EM>&gt; 10^21 ops/sec, would have nothing to test your values against.
</EM><BR>
<P>When Newton developed with theory of gravitation, did he iterate
<BR>
through the space of as possible physical laws till he found one that
<BR>
matched his data? You seem to still be convinced that learning,
<BR>
discovering patterns in facts, is a blind search.
<BR>
<P>A concept scheme is a theory about the world, a model of the way
<BR>
things in the world work and the sort of laws they obey. Some ways of
<BR>
looking at the world are objectively better than others, regardless of
<BR>
their utility as a tool for perpetuating your own genes. Intelligence
<BR>
is that which extracts those models from raw data - Feedback with the
<BR>
world is a useful tool for finding those them, but it isn't the
<BR>
only one.
<BR>
<P>This is a vision of learning as scientific discovery. There are an
<BR>
infinite number of theories which could account for, say, astronomical
<BR>
observations of the visible planets in the solar system, and yet we
<BR>
somehow distinguish good ones from bad ones. Epicycles predict the
<BR>
apparent motion of the planets with as much precision as Kepler's
<BR>
laws, yet we all agree that the second theory is, in some difficult to
<BR>
make rigorous way, more elegant and more 'correct' than assuming the
<BR>
Earth stands still.
<BR>
<P>Heres a simple example of the sort of thing I'm talking about: 
<BR>
<P>Suppose there exists some Vast set of character strings, and I've
<BR>
posed you the challenge of characterizing that set from some finite
<BR>
number of examples. The sample you've got contains instances like: (ab),
<BR>
(aab), (abb), (aaabbb), (abbb), etc. 
<BR>
<P>The answer is obvious, or at least it would be with enough samples:
<BR>
this is the set of strings beginning with one or more instances of 'a'
<BR>
followed by one or more instances of 'b.' Of course, any other answer
<BR>
is defensible: you could say we're looking at the set of all strings
<BR>
built of characters in the alphabet and we just got a misleading
<BR>
sample. Or you could say this set only contains the examples you've
<BR>
seen. Both those answers are wrong though, in the same way epicycles
<BR>
are wrong. It's my contention that there exists some general algorithm
<BR>
for determining those 'right' answers.
<BR>
<P><EM>&gt; Consider a search space in which you're trying to find local maximums.
</EM><BR>
<EM>&gt; Now imagine trying to do it without any idea of the height of any
</EM><BR>
<EM>&gt; point in the space.  Now try throwing 10^100 ops at the project.
</EM><BR>
<EM>&gt; Doesn't help, does it?
</EM><BR>
<P>You do have a criterion: The representation of a theory should be as
<BR>
small as possible, and it should generalize as little as possible while
<BR>
describing as many examples as possible. It's Occam's Razor. I'll read
<BR>
up on seed AI if you agree to read up on unsupervised learning
<BR>
(learning without feedback or tagged examples.)
<BR>
<P><EM>&gt; I see no reason to think that there is a &quot;raw mind.&quot;  There are some
</EM><BR>
<EM>&gt; minds, such as they are, but there is nothing out there to purify.
</EM><BR>
<EM>&gt; (Eliezer and others call this mythical purificant &quot;mindstuff.&quot;)
</EM><BR>
<P>A heart is a pump, an eye is a camera, why can't a brain be a baroque
<BR>
biological instance of something simpler and more abstract?
<BR>
<P><EM>&gt; To the extent that I can make this analogy in a totally non-moral way
</EM><BR>
<EM>&gt; (I'll try), this is the difference between fascist eugenics and
</EM><BR>
<EM>&gt; transhuman eugenics.  Fascist eugenics tries to breed out impurities,
</EM><BR>
<EM>&gt; to bring us back to the one pure thing at our center; transhuman
</EM><BR>
<EM>&gt; eugenics works to create something completely different, in nobody's
</EM><BR>
<EM>&gt; image in particular.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; [Again, I don't use this to imply anything morally about you or anyone
</EM><BR>
<EM>&gt; who agrees with you, but merely to draw the distinction.]
</EM><BR>
<P>Thanks for qualifying that, but it's still a hell of a loaded
<BR>
analogy. I prefer to think of blank-slate intelligence as a
<BR>
egalitarian notion: we are all the same, differing only in our
<BR>
experience and hardware resources, be we human, alien, or 
<BR>
machine. The politics is irrelevant to the question, of course, but 
<BR>
I'd still rather not be called a Nazi.
<BR>
<P>-matt
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3440.html">Natasha Vita-More: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3438.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3455.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3455.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3439">[ date ]</A>
<A HREF="index.html#3439">[ thread ]</A>
<A HREF="subject.html#3439">[ subject ]</A>
<A HREF="author.html#3439">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:11:27 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
