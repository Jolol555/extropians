<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: SITE: Coding a Transhuman AI 2.0a</TITLE>
<META NAME="Author" CONTENT="Matt Gingell (mjg223@is7.nyu.edu)">
<META NAME="Subject" CONTENT="Re: SITE: Coding a Transhuman AI 2.0a">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: SITE: Coding a Transhuman AI 2.0a</H1>
<!-- received="Fri May 19 23:00:08 2000" -->
<!-- isoreceived="20000520050008" -->
<!-- sent="Sat, 20 May 2000 00:57:15 -0400" -->
<!-- isosent="20000520045715" -->
<!-- name="Matt Gingell" -->
<!-- email="mjg223@is7.nyu.edu" -->
<!-- subject="Re: SITE: Coding a Transhuman AI 2.0a" -->
<!-- id="00052001001900.00501@localhost.localdomain" -->
<!-- inreplyto="00051911484702.00660@localhost.localdomain" -->
<STRONG>From:</STRONG> Matt Gingell (<A HREF="mailto:mjg223@is7.nyu.edu?Subject=Re:%20SITE:%20Coding%20a%20Transhuman%20AI%202.0a&In-Reply-To=&lt;00052001001900.00501@localhost.localdomain&gt;"><EM>mjg223@is7.nyu.edu</EM></A>)<BR>
<STRONG>Date:</STRONG> Fri May 19 2000 - 22:57:15 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3408.html">Lee Daniel Crocker: "Re: Congress votes on access charges:"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3406.html">J. Goard: "Smash the Transporters"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3372.html">Matt Gingell: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3407">[ date ]</A>
<A HREF="index.html#3407">[ thread ]</A>
<A HREF="subject.html#3407">[ subject ]</A>
<A HREF="author.html#3407">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
A gene collective with the tag 'Dan Fabulich' expressed themselves
<BR>
thusly:
<BR>
<P><EM>&gt; You're right, they don't spend years figuring out stoves.  That's
</EM><BR>
<EM>&gt; because they already have lots and lots and LOTS of information
</EM><BR>
<EM>&gt; about the world around them before they ever get out of the womb.
</EM><BR>
<EM>&gt; This information is stored in the genes and is visible as what we
</EM><BR>
<EM>&gt; call &quot;instinctual&quot; behavior.  THIS information took millions and
</EM><BR>
<EM>&gt; millions of years to develop, and without it, our children WOULD be
</EM><BR>
<EM>&gt; spending years (actually, years is an optimistic estimate, IMO)
</EM><BR>
<EM>&gt; figuring out a hot stove.
</EM><BR>
<P>Sure - I'm completely sympathetic to this point of view. Would you
<BR>
agree though that we shouldn't aim to hand code a machine that does
<BR>
anything a baby can't?
<BR>
<P>There is a wider, more important, question here though: What is a baby
<BR>
born with? What have millions of years of evolution invented? Do we
<BR>
have, as I would like to think, a superbly elegant, distributed
<BR>
learning and representation forming machine, a general purpose pattern
<BR>
extraction engine; or do we have a bunch of rules and hardwired
<BR>
concepts with an afterthought of theorem prover on top? Has our
<BR>
Darwinian history provided us with a database of rules and
<BR>
combinatorics, or has it stumbled across a universal blank slate
<BR>
automaton - itself more fit than any single, static apparatus?
<BR>
<P>Surely it's a bit of both - one can render the nature vs. nurture
<BR>
dialectic, or any other, bland by saying it's a mix. The question I'm
<BR>
posing though is as follows: Is intelligence something special, is it
<BR>
something beyond a vast store of facts and rules? Is instinctive
<BR>
knowledge necessary, or does instinct simply optimize something deeper
<BR>
and more interesting? Can we construct a general definition of what
<BR>
intelligence is, independent of it's utility in some specific
<BR>
environment - and if we can is it possible to develop an instance of
<BR>
that definition which would function 'intelligently' no matter what
<BR>
universe we drop it into? My answer is, obviously, yes, and finding
<BR>
that abstraction is the proper goal of AI and cognitive science
<BR>
research. Think, for instance, about the concept 'natural number.' What does it
<BR>
take to extract that from the world? Surely it's universal to anything we'd
<BR>
recognize as intelligent - but where does it come from, and by what process?
<BR>
<P><EM>&gt; Experiments with babies show that babies as early as a few months
</EM><BR>
<EM>&gt; are surprised to see objects vanish into thin air, come to a full
</EM><BR>
<EM>&gt; stop without being in contact with another object, and begin moving
</EM><BR>
<EM>&gt; without a force to propel them.  Babies have a very compicated idea
</EM><BR>
<EM>&gt; of what elements in their visual field constitute objects and how
</EM><BR>
<EM>&gt; those objects will generally behave.
</EM><BR>
<P>Moravec, if I'm remembering correctly, estimates the raw computing
<BR>
resources of the human brain at something like 10 teraflops. Give me
<BR>
'a few months' of time on a machine that big, and I'm confident I
<BR>
could extract a reasonable working theory of objects as permanent, law
<BR>
obeying things from raw sense data. You would argue, presumably, that
<BR>
these months are spent on physical/neurological maturation and the
<BR>
expression of world-describing genes - where as I would like to
<BR>
believe they are spent on what I will call, for lack of a more
<BR>
descriptive word, 'learning.'
<BR>
<P>Baby's are a useful thing to ask questions about - they're are only
<BR>
example of what a raw mind looks like - but we should keep in mind
<BR>
that the human mind is not the only possible solution to the problem
<BR>
of general intelligence. A brain is a useful thing to think about, but
<BR>
an artificial mind might bare no resemblance to any natural
<BR>
neurology. The design process and the engineering constraints differ
<BR>
profoundly: Take the example of flight: The Concord, and artificial
<BR>
bird, has no feathers, nor does it flap its wings for lift.
<BR>
<P><EM>&gt; This information is not learned from a blank slate at birth.  (There
</EM><BR>
<EM>&gt; was no time.)  We are born with it.  Unless we program it into our
</EM><BR>
<EM>&gt; AI, we should expect the AI to require evolutionary time in order to
</EM><BR>
<EM>&gt; figure these things out.  That's time we don't have.
</EM><BR>
<P>We'll do both: If you want to go work from the top down, more power to
<BR>
you. I happen to think the bottom is the important bit, but I wish you
<BR>
nothing but luck. Only time will tell who gets there first.
<BR>
<P>-matt
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3408.html">Lee Daniel Crocker: "Re: Congress votes on access charges:"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3406.html">J. Goard: "Smash the Transporters"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3372.html">Matt Gingell: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3412.html">Dan Fabulich: "Re: SITE: Coding a Transhuman AI 2.0a"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3407">[ date ]</A>
<A HREF="index.html#3407">[ thread ]</A>
<A HREF="subject.html#3407">[ subject ]</A>
<A HREF="author.html#3407">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:11:26 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
