<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial</TITLE>
<META NAME="Author" CONTENT="Spudboy100@aol.com (Spudboy100@aol.com)">
<META NAME="Subject" CONTENT="Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building</H1>
<!-- received="Sun May 14 06:56:19 2000" -->
<!-- isoreceived="20000514125619" -->
<!-- sent="Sun, 14 May 2000 08:56:51 EDT" -->
<!-- isosent="20000514125651" -->
<!-- name="Spudboy100@aol.com" -->
<!-- email="Spudboy100@aol.com" -->
<!-- subject="Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building" -->
<!-- id="6.5ef1c38.264ffc93@aol.com" -->
<!-- inreplyto="AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building" -->
<STRONG>From:</STRONG> <A HREF="mailto:Spudboy100@aol.com?Subject=Re:%20AI:%20FWD%20(IUFO/mind-l)%20Robokitty%20and%20Artificial%20brain%20building&In-Reply-To=&lt;6.5ef1c38.264ffc93@aol.com&gt;"><EM>Spudboy100@aol.com</EM></A><BR>
<STRONG>Date:</STRONG> Sun May 14 2000 - 06:56:51 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3023.html">Michael S. Lorrey: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3021.html">Spudboy100@aol.com: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="3000.html">Eugene Leitl: "AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3037.html">xllb: "RE: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3022">[ date ]</A>
<A HREF="index.html#3022">[ thread ]</A>
<A HREF="subject.html#3022">[ subject ]</A>
<A HREF="author.html#3022">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
In a message dated 5/13/00 11:06:05 PM Pacific Daylight Time, 
<BR>
<A HREF="mailto:e_shaun@uniserve.com?Subject=Re:%20AI:%20FWD%20(IUFO/mind-l)%20Robokitty%20and%20Artificial%20brain%20building&In-Reply-To=&lt;6.5ef1c38.264ffc93@aol.com&gt;">e_shaun@uniserve.com</A> writes:
<BR>
<P>&lt;&lt; I had the chance to talk a bit with Hugo at one of Forrest Bishop's parties
<BR>
&nbsp;a few years back.  Even then he was shooting for a cybernetic cat by 2001,
<BR>
&nbsp;so it seems he is right on track.
<BR>
&nbsp;
<BR>
&nbsp;To answer the question: if Hugo de Garis truly feared for the extermination
<BR>
&nbsp;of the human race, do you really think that he would be plotting the
<BR>
&nbsp;creation of superior AI?  I doubt it.  The problem with the writers of some
<BR>
&nbsp;of these articles is that they are too myopic: they cannot see that
<BR>
&nbsp;scientific progress occurs in a number of areas at once.  On its own,
<BR>
&nbsp;superior AI could mean the extermination of the human race; however, in
<BR>
&nbsp;truth, there are many advances being made in nanotech, genetic engineering,
<BR>
&nbsp;space travel and a plethora of other &quot;perpetual human longevity&quot; pursuits.
<BR>
&nbsp;The question will be whether or not we can keep up to AI; I, for one, don't
<BR>
&nbsp;think so.  
<BR>
&nbsp;
<BR>
&nbsp;If Hugo and others succeed in creating superior AI, some humans will
<BR>
&nbsp;probably try to co-exist, but it would be most convenient for the majority
<BR>
&nbsp;of the human race to eventually leave the planet.  My target date for this
<BR>
&nbsp;is for about 2070, though that will probably need to be modified if Hugo
<BR>
&nbsp;actually does succeed at Robokitty.
<BR>
&nbsp;
<BR>
&nbsp;As an aside, I personally think superior AI is the key to solving most
<BR>
&nbsp;other extropic problems such as space travel etc. &gt;&gt;
<BR>
Your analysis of the article and the true potentiality of Strong AI, as well 
<BR>
as De Garis's intention's seems more 'real-world' to me.  Hans Moravec 
<BR>
expects that A.i. is the ones to leave the planet, primarily, and not H. 
<BR>
Sapiens; due possibly to economic/darwinian reasons. However, you may be 
<BR>
right. Developing a marauding, antagonistic, A.I. though is somewhat 
<BR>
questionable, especially in about 70 years. Double that suggested time span 
<BR>
(old stick in the mud, me) and I feel that''s a more convincing target for 
<BR>
joy or Big Trouble. Survival and thriving in the solar system for the human 
<BR>
species, would be very cool, if this is really doable. Kind of a decades old 
<BR>
childhood dream for me. But how fast space tech can be developed for us 
<BR>
monkeys, has proved to be a grindingly, slow, process.
<BR>
Mitch
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3023.html">Michael S. Lorrey: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3021.html">Spudboy100@aol.com: "Re: AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<LI><STRONG>Maybe in reply to:</STRONG> <A HREF="3000.html">Eugene Leitl: "AI: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3037.html">xllb: "RE: FWD (IUFO/mind-l) Robokitty and Artificial brain building"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3022">[ date ]</A>
<A HREF="index.html#3022">[ thread ]</A>
<A HREF="subject.html#3022">[ subject ]</A>
<A HREF="author.html#3022">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:11:12 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
