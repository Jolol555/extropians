<!-- received="Wed Oct 29 17:55:55 1997 MDT" -->
<!-- sent="Thu, 30 Oct 1997 01:39:03 +0100" -->
<!-- name="Holger Wagner" -->
<!-- email="Holger.Wagner@lrz.uni-muenchen.de" -->
<!-- subject="How can we deal with risks?" -->
<!-- id="3.0.1.32.19971029154942.008c2ab0@econ.berkeley.edu" -->
<!-- inreplyto="" -->
<title>extropians: How can we deal with risks?</title>
<h1>How can we deal with risks?</h1>
Holger Wagner (<i>Holger.Wagner@lrz.uni-muenchen.de</i>)<br>
<i>Thu, 30 Oct 1997 01:39:03 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#947">[ date ]</a><a href="index.html#947">[ thread ]</a><a href="subject.html#947">[ subject ]</a><a href="author.html#947">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0948.html">Anton Sherwood: "Scientologists in Germany"</a>
<li> <b>Previous message:</b> <a href="0946.html">Damien Broderick: "egan site"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0962.html">Kennita Watson: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="0962.html">Kennita Watson: "Re: How can we deal with risks?"</a>
<li> <b>Reply:</b> <a href="0966.html">Anders Sandberg: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="0979.html">Dan Clemmensen: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="1024.html">Holger Wagner: "Re: How can we deal with risks?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
I actually don't want to sound pessimistic in my first posting to this<br>
list (just today, I've read the article about dynamic optimism which I<br>
found pretty good), but there's something I have been thinking about<br>
since I first found out about Extropy - but so far, I couldn't find an<br>
answer.<br>
<p>
In history, very often genius ideas and inventions turned out to be<br>
rather "dangerous", one example are nuclear weapons, a better one are<br>
CFCs. From what I know, when CFCs were discovered, everybody thought<br>
they were completely harmless (non-toxic etc.) It took some years before<br>
the actual problems they may cause (destroying the ozone-layer) was<br>
discovered. I don't know if this is as bad as the media keep on telling<br>
us, but there are a lot of other examples (like simply cars that pollute<br>
the air).<br>
<p>
Now, I'm not at all a conservative person, but I do see a problem here<br>
that should be solved somehow - actually, it's a couple of different<br>
problems. If solutions to these problems are already available, please<br>
tell me where to find them.<br>
<p>
1) Today, humans are by no means perfect. They have a certain idea of<br>
what they do and what the consequences are, but it happens quite often<br>
that something "impredictable" happens. If you apply changes to the<br>
ecologic system, can you really predict what consequences this will have<br>
in the long run - and would you take the responsibility?<br>
<p>
Possible solution: I assume that most scientists are very intelligent,<br>
so they should understand stuff like pancritical rationalism and should<br>
be able to apply this to their work. By doing that, they at least<br>
improve the chance of not doing anything that has extremely bad results<br>
in the long run. Usually, it's the innovator who decides whether<br>
something should be invented or not, right?<br>
<p>
2) Today, humans are by no means perfect. While I trust scientists to<br>
have at least a vague idea of what they're doing, I do not trust people<br>
in general. For example, people that work for governments (so-called),<br>
or people that are only interested in profit. Actually, you just have to<br>
walk on the street and talk to people, and you'll discover a lot of<br>
people that simply don't understand a lot of things (they don't actually<br>
need to - for what they want to do). I believe that this poses a great<br>
risk of misuse of any technological advancement.<br>
<p>
Solution: Educate people accordingly. (easy to say - but I don't believe<br>
it's possible until I see world-wide results).<br>
<p>
<p>
If you want to overcome the fear most people have of technology, you<br>
need to solve these problems and make people understand the solutions.<br>
This is obviously quite an old problem, but I think the risks are ever<br>
increasing - until humans themselves are majorly improved (anybody who<br>
has access to advanced technology that has a potential danger needs to<br>
be capable of understanding what he's dealing with - something that is<br>
definitely not trivial).<br>
<p>
The major problem with this is that I can improve myself, but I can't<br>
improve the rest of the world - and only one insane person can do great<br>
harm if he has access to the "right" weapons. Imagine a person like<br>
Adolf Hitler with access to future-genetics and nanotechnology. I assume<br>
it will be possible to create both - lethal viruses that spread quickly,<br>
and nanotech-robots that wipe-out life (maybe filtered with certain<br>
genes???). I've recently seen a documentary about Hitler's personality,<br>
and he actually was a poor fool. He was lonely and psychotic. If he<br>
didn't have the power he had, history would have been quite different.<br>
But what if there comes a day where we have to face an insane fool who<br>
has the technology to wipe out all life on this planet? Someone who just<br>
doesn't understand or just doesn't care about the responsibility?<br>
<p>
I've obviously put up the "worst scenario one could think of" - but I<br>
think it's quite possible if there is no major change to how most people<br>
think. If all people were Extropians, there would probably be no problem<br>
but I'm afraid that will take somewhat longer than development of<br>
Nanotechnology (and many other things that can be grrrrreat - if used in<br>
a responsible manner).<br>
<p>
Tell me what you think about this - I'm definitely not questioning<br>
technology but humans.<br>
<p>
later,<br>
Holger<br>
<pre>
-- 
o---------------------------------------------------------------o
| "That's the funny thing about memories, isn't it? We are not  |
| what we remember of ourselves, we are what people say we are. |
| They project upon us their convictions  -  we are nothing but |
| blank screens." ______________________________________________o
o________________/        Trevor Goodchild in "Aeon Flux"       |
                 \__ <a href="mailto:Holger.Wagner@lrz.uni-muenchen.de">mailto:Holger.Wagner@lrz.uni-muenchen.de</a> __|
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0948.html">Anton Sherwood: "Scientologists in Germany"</a>
<li> <b>Previous message:</b> <a href="0946.html">Damien Broderick: "egan site"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0962.html">Kennita Watson: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="0962.html">Kennita Watson: "Re: How can we deal with risks?"</a>
<li> <b>Reply:</b> <a href="0966.html">Anders Sandberg: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="0979.html">Dan Clemmensen: "Re: How can we deal with risks?"</a>
<li> <b>Maybe reply:</b> <a href="1024.html">Holger Wagner: "Re: How can we deal with risks?"</a>
<!-- reply="end" -->
</ul>
