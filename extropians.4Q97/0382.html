<!-- received="Fri Oct 10 12:32:03 1997 MDT" -->
<!-- sent="Fri, 10 Oct 1997 11:14:51 -0700 (PDT)" -->
<!-- name="Lee Daniel Crocker" -->
<!-- email="lcrocker@mercury.colossus.net" -->
<!-- subject="Re: "Morality?" - Composite Reply" -->
<!-- id="199710101814.LAA16131@mercury.colossus.net" -->
<!-- inreplyto="199710092229.SAA00894@gatecoms.gatecom.com" -->
<title>extropians: Re: "Morality?" - Composite Reply</title>
<h1>Re: "Morality?" - Composite Reply</h1>
Lee Daniel Crocker (<i>lcrocker@mercury.colossus.net</i>)<br>
<i>Fri, 10 Oct 1997 11:14:51 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#382">[ date ]</a><a href="index.html#382">[ thread ]</a><a href="subject.html#382">[ subject ]</a><a href="author.html#382">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0383.html">YakWaxx@aol.com: "FILTERS: Simple solution"</a>
<li> <b>Previous message:</b> <a href="0381.html">John K Clark: "Genius Dogs"</a>
<li> <b>In reply to:</b> <a href="0362.html">Eliezer S. Yudkowsky: "Re: Ampakines"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; His instincts are a part of him, and yet he cannot change them through his</i><br>
<i>&gt; choices, only be in compliance or conflict with them. They are AS IS.</i><br>
<i>&gt; </i><br>
<i>&gt; &gt;This is literally what every claim of discovered "objective value"</i><br>
<i>&gt; &gt;does. In other words, the concept, objective value, is an illusion and</i><br>
<i>&gt; &gt;inherently anti individual.</i><br>
<i>&gt; </i><br>
<i>&gt; Instincts are an AS IS part of the individual.</i><br>
<p>
True, but not of much use to me in determining a course of action.<br>
The problem is that evolution only looks backward: I am the result of<br>
those traits that succeeded in the past, under different conditions<br>
For example, throughout most of human evolution, food was scarce, so<br>
I have an instinct to eat whenever I can.  I choose not to do so<br>
(though I should choose not to a bit more often than I actually do)<br>
because I am able to evaluate the evidence of obesity not being<br>
favorable to my goals of health and long life.<br>
<p>
Greg's "natural values" of life and society are more rooted in the<br>
present reality, but that too is not the time frame I want to look<br>
at: I want values to be teleological, to tell me how to make my<br>
future different from my present.  True, I must reason from those<br>
teleological premises and my knowledge of reality /now/ to derive<br>
rational actions, but still the nature of reality now is no guide<br>
to making those moral choices.<br>
<p>
Max's "rational values" aren't very satisfying either, because they<br>
are still derived from underlying chosen values, but there is a sense<br>
in which they are valuable: simplicity.  Once someone goes through<br>
the task of showing that some derived value--say, wealth--follows<br>
from a core value of life, one can then use the derived value itself<br>
in making decisions without having to re-derive it every time.  Much<br>
the way a Mathematician would use a finished proof as a premise for<br>
more complex proofs, or the way a programmer would use completed<br>
subroutines to build more complex programs.  It is not even necessary<br>
that one know the derivation itself; in fact not spending the time<br>
to go through every such derivation would be advantageous--an example<br>
of what Friedman calls "rational ignorance", where the cost of a piece<br>
of knowledge exceeds its value.<br>
<p>
The game-threory arguments fail to get us out of our dilemma as well,<br>
because they are founded on the assumption of measurable payoffs, which<br>
are arbitrary.  "Find positive-sum games" is of little use to someone<br>
who has chosen values that prevent it.  Or for some, leads to completely<br>
different results than we would prefer (for example, if you choose to<br>
value the failure of others twice as much as they devalue it, then every<br>
interaction in which you victimize someone is positive-sum to you, and<br>
every cooperation is zero-sum).<br>
<p>
Where I depart from Mr. England is that while we agree that we cannot<br>
rationaly derive moral values, he then tries to derive moral values<br>
from that failure--even more irrational.  He says, in effect, that<br>
since your morals cannot be rational, be less judgmental of others<br>
and less committed to your own.  I say choose one and get on with it.<br>
I have no problem committing my life, my fortune, and my sacred honor<br>
to the values I have chosen; it is precisely that commitment, I<br>
believe, that enables me to accomplish the the things I want.  And<br>
since I need the cooperation of others to accomplish them, I will<br>
work to spread those values in others, and judge them without apology.<br>
I just refuse to claim any objective basis for them, because honesty<br>
is one of those core values I have chosen.<br>
<p>
I also have to agree with Max that this is pretty esoteric stuff,<br>
irrelevant to everyday use.  Since 90% of the actions of humans are<br>
demonstrably irrational based on their own expressed values, there is<br>
more to be accomplished by solving /that/ problem than by worrying<br>
about the derivation of those values.  The latter can be dealt with<br>
in places like this list; the rest of life can deal with the former.<br>
<p>
<pre>
--
Lee Daniel Crocker &lt;lee@piclab.com&gt; &lt;<a href="http://www.piclab.com/lcrocker.html">http://www.piclab.com/lcrocker.html</a>&gt;
"All inventions or works of authorship original to me, herein and past,
are placed irrevocably in the public domain, and may be used or modified
for any purpose, without permission, attribution, or notification."--LDC
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0383.html">YakWaxx@aol.com: "FILTERS: Simple solution"</a>
<li> <b>Previous message:</b> <a href="0381.html">John K Clark: "Genius Dogs"</a>
<li> <b>In reply to:</b> <a href="0362.html">Eliezer S. Yudkowsky: "Re: Ampakines"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
