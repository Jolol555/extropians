<!-- received="Tue Nov 11 18:51:51 1997 MDT" -->
<!-- sent="Tue, 11 Nov 1997 17:52:05 -0800" -->
<!-- name="Ramez Naam" -->
<!-- email="ramezn@EXCHANGE.MICROSOFT.com" -->
<!-- subject="RE: The copy paradox" -->
<!-- id="199711112349.SAA11675@ldl.net" -->
<!-- inreplyto="" -->
<title>extropians: RE: The copy paradox</title>
<h1>RE: The copy paradox</h1>
Ramez Naam (<i>ramezn@EXCHANGE.MICROSOFT.com</i>)<br>
<i>Tue, 11 Nov 1997 17:52:05 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1343">[ date ]</a><a href="index.html#1343">[ thread ]</a><a href="subject.html#1343">[ subject ]</a><a href="author.html#1343">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1344.html">Mark D. Fulwiler: "Population"</a>
<li> <b>Previous message:</b> <a href="1342.html">Ramez Naam: "RE: Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Brent, for a moment consider this proposition:<br>
<p>
The subjective experience of "Red" is a consequence of the<br>
neurophysiological state of seeing (or imagining) light of a certain<br>
frequency.<br>
<p>
If we traced this through your brain we would find that red light causes<br>
a certain neural firing pattern in the V1 area of your occipital cortex<br>
to fire, while blue light causes a different neural firing pattern.<br>
<p>
We can verify analogous neurophysiological states for various sounds,<br>
bodily sensations, smells, tastes, etc..<br>
<p>
Given this, can we not reasonably suppose that the subjective experience<br>
is a consequence of the neurophysiological state triggered by the<br>
stimuli?<br>
<p>
If this is the case, can we not learn to distinguish those "neuroqualia"<br>
which are essentially the same among all humans from those neuroqualia<br>
which vary among individuals?<br>
<p>
If so, would not the first set represent a set of "experiences" which we<br>
could then share with another individual by instantiating the same<br>
neurophysiological state in that individual?<br>
<p>
Indeed, among individuals of different species, or between (for example)<br>
a human and an AI, could we not construct a mapping table that allowed<br>
us to translate these experiences to the appropriate internal<br>
representation?<br>
<p>
Direct answers to some of your points below&gt;&gt;<br>
<p>
<i>&gt; From: Brent Allsop [SMTP:allsop@swttools.fc.hp.com]</i><br>
<i>&gt; </i><br>
<i>&gt; Anders Sandberg &lt;asa@nada.kth.se&gt; responded:</i><br>
<i>&gt; </i><br>
<i>&gt; &gt; Actually, I consider this "stuff of consciousness" to be</i><br>
<i>&gt; &gt; information, or more accurately instantiated information. So I have</i><br>
<i>&gt; &gt; no problem imagining a computer experiencing the color red if it has</i><br>
<i>&gt; &gt; the right software, and transferring my mind into the computer is</i><br>
<i>&gt; &gt; just a problem of replicating the pattern. But I cannot be sure</i><br>
<i>&gt; &gt; until I try.</i><br>
<i>&gt; </i><br>
<i>&gt; 	Yes "instantiated information" is more accurate.  Instantiated</i><br>
<i>&gt; information is represented by something fundamentally real.  The state</i><br>
<i>&gt; of a transistor can be an instantiation or representation of the word</i><br>
<i>&gt; stop.  So can the color red.  A distinguishably different state of</i><br>
<i>&gt; that same transistor can be an instantiation of the word go.  And</i><br>
<i>&gt; green could similarly be taken to represent go.  But, there are some</i><br>
<i>&gt; important qualities that red/green has that the particular states of</i><br>
<i>&gt; the transistors do not have.  It doesn't matter what the fundamental</i><br>
<i>&gt; state of the transistor is as long as it is interpreted correctly.  If</i><br>
<i>&gt; you reverse the interpretation and the setting of the value the</i><br>
<i>&gt; abstract meaning stays the same even though the fundamental or</i><br>
<i>&gt; physical representation is now opposite.  If we swap the meaning of</i><br>
<i>&gt; red and green, the abstract meaning can be the same, but the</i><br>
<i>&gt; fundamental subjective or phenomenal experience is very different.</i><br>
<i>&gt; Such phenomenal qualities of experience must be taken into account in</i><br>
<i>&gt; order to reproduce consciousness.</i><br>
<p>
I beg to differ on a number of grounds.  <br>
<p>
1)  This thought experiment may in fact be impossible.  Much like me<br>
imagining (If I could go 10x the speed of light..)<br>
<p>
2)  Research has demonstrated a psychological effect of color on humans.<br>
Different colors produce different levels of stress, relaxation,<br>
attention, arousal, etc.. in fairly predictable and consistent ways.  So<br>
I ask you, if I switch red and green, and all fires are now green,<br>
haven't I actually made some difference in the meaning of fire to the<br>
individual?  In the sense that the fire will now evoke a different<br>
response than when it was red?<br>
<p>
<i>&gt; </i><br>
<i>&gt; 	Would you really be happy if all you knew of "salty" was</i><br>
<i>&gt; whether or not some abstract salty bit was set or not and all you had</i><br>
<i>&gt; was a corresponding look up table containing all the strings people</i><br>
<i>&gt; had ever used to try to verbally describe what salty is like?  "It's</i><br>
<i>&gt; kind of a puckery non sweet taste" just contains no meaning at all</i><br>
<i>&gt; about what salty is really phenomenally like.  The difference is the</i><br>
<i>&gt; actual fundamental and phenomenal nature of the particular</i><br>
<i>&gt; "instantiation" and this difference is most definitely important to</i><br>
<i>&gt; consciousness.</i><br>
<p>
You assume a gulf between sensation and realization that I do not<br>
believe exists.  Imagine that sensation is a consequence of the physical<br>
system that instantiates the information that is represented in<br>
consciousness.   Or, put another way, sensation /is/ the stuff of<br>
consciousness.  A being that represents salty internally in a<br>
sufficiently rich manner necessarily has an "experience" of salty.<br>
<p>
<i>&gt; </i><br>
<i>&gt; 	How many abstract bits of information would it take to store</i><br>
<i>&gt; the various possible responses to the question: "What is salty?"  in a</i><br>
<i>&gt; discussion kind of way?  Wouldn't an abstract machine producing such</i><br>
<i>&gt; responses really be a liar since it really had no idea what salty was</i><br>
<i>&gt; phenomenally like?</i><br>
<i>&gt; </i><br>
<i>&gt; 	How many bits do you think the brain uses to reproduce such</i><br>
<i>&gt; "information"?  Or does it simply know what salty is like?  And might</i><br>
<i>&gt; such phenomenal abilities to "instantiate information" be one reason</i><br>
<i>&gt; for such "common sense" intelligence that abstract machines still</i><br>
<i>&gt; lack?</i><br>
<i>&gt; </i><br>
<i>&gt; 	Wouldn't an honest and intelligent abstract machine be able to</i><br>
<i>&gt; recognize that it doesn't really know what salty is like, just as you</i><br>
<i>&gt; must admit that you don't know what salty is like for me, unless salty</i><br>
<i>&gt; is the same for me as it is for you?</i><br>
<p>
Hmm.  You posit an incredibly simple machine and then grant it<br>
intelligence, which immediately strikes me as contradictory.<br>
<p>
Clearly humans do not represent "salty" with an on/off bit.  Instead we<br>
have thousands of sensors which trigger the firing of at least tens of<br>
thousands of neurons, with varying firing speeds of each neuron and<br>
various spatial firing patterns throughout the region.  This is a great<br>
deal of information.  To me it seems completely intuitive that we would<br>
represent this via what our folk psychology calls a "sensation" rather<br>
than some "abstract" knowledge as you suggest.  The closest thing we<br>
have to "abstract" knowledge of salty is the association of the<br>
word-label "salty" to the sensory state we experience upon tasting salt.<br>
<p>
<p>
So, long and short: if you had a significantly different neural<br>
structure from me, I would expect the experience of tasting something<br>
salty to be quite different for you from me.<br>
<p>
Given our species-born similarities (I'm just guessing here that you're<br>
of my species. :) ) I presume that our experiences are quite similar.<br>
<p>
mez<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1344.html">Mark D. Fulwiler: "Population"</a>
<li> <b>Previous message:</b> <a href="1342.html">Ramez Naam: "RE: Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
