<!-- received="Sat Oct  4 23:35:26 1997 MDT" -->
<!-- sent="Sat, 04 Oct 1997 21:55:16 -0700" -->
<!-- name="Freespeak" -->
<!-- email="f-prime@activist.com" -->
<!-- subject="Re: "MORALITY?"" -->
<!-- id="3.0.32.19971004215258.00e9f7d0@amug.org" -->
<!-- inreplyto=""MORALITY?"" -->
<title>extropians: Re: "MORALITY?"</title>
<h1>Re: "MORALITY?"</h1>
Freespeak (<i>f-prime@activist.com</i>)<br>
<i>Sat, 04 Oct 1997 21:55:16 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#133">[ date ]</a><a href="index.html#133">[ thread ]</a><a href="subject.html#133">[ subject ]</a><a href="author.html#133">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0134.html">Dan Clemmensen: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0132.html">John K Clark: "Morality?"</a>
<li> <b>Maybe in reply to:</b> <a href="0048.html">Delmar England: ""MORALITY?""</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0174.html">Gary Lloyd: "Re: "MORALITY?""</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 03:56 PM 10/4/97 -0700, Lee Daniel Crocker &lt;lee@piclab.com&gt; wrote:<br>
<i>&gt;</i><br>
<i>&gt;&gt;&gt; Thus one must claim personal values as the basis for "morality" or</i><br>
<i>&gt;&gt;&gt; concede a "superior being" as source. I know of none who claim</i><br>
<i>&gt;&gt;&gt; the former.</i><br>
<i>&gt;</i><br>
<i>&gt;You now know at least one.  Though I try to base my actions on solid</i><br>
<i>&gt;rational thought as much as possible, it is not possible to derive</i><br>
<i>&gt;normative values from descriptive premises, so I must have some basic</i><br>
<i>&gt;normative values which I cannot rationally justify.  In my case, that</i><br>
<i>&gt;value is life; I choose to value life, and to devalue death and</i><br>
<i>&gt;violence.  I have no reasons to do so, only personal choice.</i><br>
<i>&gt;</i><br>
<i>&gt;I can choose actions rationally to achieve my values, but one</i><br>
<i>&gt;cannot choose values by reason.  I refuse on rational grounds to</i><br>
<i>&gt;speculate about supernatural beings, so I am left with personal</i><br>
<i>&gt;choice as my source of values.  I choose life.</i><br>
<i>&gt;</i><br>
Descriptive premises: Cops carry guns; I've personally<br>
seen cops "rough up" victims who "crossed" the cops;<br>
Via media, I've received many descriptions of cops<br>
"roughing up" victims, or worse; Because of my lifestyle<br>
"outside the system," I am more at risk from cops than<br>
most.<br>
<p>
Normative values: Don't "cross" cops; If confronted by<br>
a cop, e.g., if pulled over for allegedly speeding, I<br>
should play the role of an obedient supplicant.<br>
<p>
Questions: Are my normative values rationally derived<br>
from my descriptive premises?<br>
<p>
Can I reasonably lump all me normative values together<br>
in a high-level abstraction called "morality?"<br>
<p>
Because individuals are unique and have unique<br>
circumstances, will they tend to have "moralities"<br>
that differ in some respects?<br>
<p>
Because humans have much in common, can we expect<br>
common denominators among "moralities" that are<br>
rationally derived via observation and prediction?<br>
<p>
Prediction may be a key here; is rational prediction<br>
possible?<br>
<p>
Suppose, e.g., statistical analysis indicates that<br>
behavior X tends to be followed by consequence Y (say,<br>
death) Z percent of time, while no other behaviors<br>
or characteristics correlate with Y.  Can we rationally<br>
predict that in future, ceteris paribus, X will cause Y<br>
with probability Z?<br>
<p>
Are there predictable cause-effect relationships<br>
(descriptive premises) from which normative values<br>
can be rationally derived? -- Don't do X because it<br>
tends to cause Y?<br>
<p>
Could you reasonably argue that all my "ises" (descriptive<br>
premises) are stated in a manner to include "oughts"<br>
(normative values), thus I'm really deriving "oughts"<br>
from "oughts?"<br>
<p>
Or, do certain "ises" by their nature automatically<br>
imply "oughts?"<br>
<p>
Is continued life an automatic "ought" for a living<br>
creature with human-like consciousness?<br>
<p>
Or, could it be an automatic "ought" only under<br>
certain conditions?<br>
<p>
Frederick Mann<br>
------------------------------------------------------------------------<br>
    LIVE FREE AND FLOURISH     |     ADVANCED FREEDOM SOLUTIONS LIST<br>
Practical Freedom - Live free. | Ideal meeting place to network &amp; brain-<br>
Practical knowledge, methods,  |   storm new, creative, and innovative<br>
skills - Millionaire Reports.  | freedom ideas &amp; initiatives. Subscribe:<br>
Expertise at your fingertips:  |  E-mail AFS-request@involved.com with<br>
<a href="http://www.buildfreedom.com/">http://www.buildfreedom.com/</a>   | SUBSCRIBE in the body of your message.<br>
------------------------------------------------------------------------<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0134.html">Dan Clemmensen: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0132.html">John K Clark: "Morality?"</a>
<li> <b>Maybe in reply to:</b> <a href="0048.html">Delmar England: ""MORALITY?""</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0174.html">Gary Lloyd: "Re: "MORALITY?""</a>
<!-- reply="end" -->
</ul>
