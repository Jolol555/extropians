<!-- received="Mon Nov 24 16:11:39 1997 MDT" -->
<!-- sent="25 Nov 1997 00:10:44 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Uploading, that's needed !!  -Reply -Reply -Reply" -->
<!-- id="199711242223.OAA19348@mercury.colossus.net" -->
<!-- inreplyto="Mon, 24 Nov 1997 13:39:54 -0700" -->
<title>extropians: Re: Uploading, that's needed !!  -Reply -Reply -Reply</title>
<h1>Re: Uploading, that's needed !!  -Reply -Reply -Reply</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>25 Nov 1997 00:10:44 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1780">[ date ]</a><a href="index.html#1780">[ thread ]</a><a href="subject.html#1780">[ subject ]</a><a href="author.html#1780">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1781.html">Leevi Marttila: "Re: The copy paradox"</a>
<li> <b>Previous message:</b> <a href="1779.html">Mark Crosby: "Re: Some thoughts on multi-agent systems and "hyper-economy""</a>
<li> <b>In reply to:</b> <a href="1774.html">Brent Allsop: "Re: Uploading, that's needed !!  -Reply -Reply -Reply"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Brent Allsop &lt;allsop@swttools.fc.hp.com&gt; writes:<br>
<p>
<i>&gt; 	Needed for what?  What is it that is "over" in 50 years?  Is</i><br>
<i>&gt; there some God or machine or something that will kill us because we</i><br>
<i>&gt; are not "needed"?  Why?  This all seems bassed on completely backwards</i><br>
<i>&gt; assumptions and absurdities.  We are the ones that have need aren't</i><br>
<i>&gt; we?  Not the other way around or not something that needs us!?</i><br>
<i>&gt; </i><br>
<i>&gt; 	In a world of plenty there is plenty to fulfill all needs.</i><br>
<i>&gt; There will be Gods and machines just waiting to do whatever it is each</i><br>
<i>&gt; and everyone on of *US* needs, whatever we are and whatever we freely</i><br>
<i>&gt; decide that we need.</i><br>
<p>
Your vision sounds nice, but can it be guaranteed? We live in a world<br>
where things do go wrong, where unexpected things happens despite<br>
precautions and where not everything is done with positive<br>
consequences in mind. Our development is linked with dangers, and<br>
the future tends to turn out vastly different than our predictions.<br>
<p>
I don't believe in the "robots peeling grapes for us scenario" nor the<br>
"humans red queened and darwinnowed scenario". But we better make sure<br>
the future turns out reasonably well (or better, unreasonably well) -<br>
we have a respondibility for it. And that includes analysing possible<br>
risks and taking steps to minimize or circumvent them.<br>
<p>
There is a lot of unreasonable fear about SI, even among<br>
transhumanists (we have had this debate often enough on this list),<br>
and it is quite natural that people worry about the future of the<br>
human species or its close descendants. While we can of course try to<br>
develop AI and other autonomous technology that serves us (say by<br>
being created already in love with humans or similar stuff), things<br>
can go wrong and nasty systems could be built for a variety of<br>
reasons. Even in the grape scenario it may turn out that the humans<br>
turn into traditional pets for the posthuman powers, and that doesn't<br>
appeal to our sense of dignity. So it is IMHO worthwhile to see if we<br>
can make sure humans remain an important and useful part of the future<br>
infra/ultra structure, whatever it is.<br>
<p>
My personal suggestion is to concentrate on intelligence amplification<br>
in various forms; it both has practical uses right away, and may be a<br>
good way to bootstrap superintelligence that has humans and human<br>
memetic complexes as integral parts. In the long run the human aspect<br>
may become insignificant compared to the rest of the entity, but it is<br>
still there after an exponential but continous development. How IA is<br>
implemented is another question, we already have plenty of tools:<br>
hypertext, agents, cognitive psychology, nootropics and expert<br>
systems; in the future we may add bionic interfaces and uploading -<br>
there is a broad research front here with a lot of worthwhile stuff<br>
both for the present and the uncertain future.<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1781.html">Leevi Marttila: "Re: The copy paradox"</a>
<li> <b>Previous message:</b> <a href="1779.html">Mark Crosby: "Re: Some thoughts on multi-agent systems and "hyper-economy""</a>
<li> <b>In reply to:</b> <a href="1774.html">Brent Allsop: "Re: Uploading, that's needed !!  -Reply -Reply -Reply"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
