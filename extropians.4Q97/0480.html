<!-- received="Mon Oct 13 00:17:22 1997 MDT" -->
<!-- sent="Mon, 13 Oct 1997 00:27:33 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Constraints on the "singularity"" -->
<!-- id="199710130544.WAA20381@mercury.colossus.net" -->
<!-- inreplyto="Constraints on the "singularity"" -->
<title>extropians: Re: Constraints on the "singularity"</title>
<h1>Re: Constraints on the "singularity"</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 13 Oct 1997 00:27:33 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#480">[ date ]</a><a href="index.html#480">[ thread ]</a><a href="subject.html#480">[ subject ]</a><a href="author.html#480">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0481.html">Eliezer S. Yudkowsky: "Re: Extropian Principles reading list"</a>
<li> <b>Previous message:</b> <a href="0479.html">Lee Daniel Crocker: "Re: Extropian Principles reading list"</a>
<li> <b>Maybe in reply to:</b> <a href="0447.html">Ramez Naam: "Constraints on the "singularity""</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0520.html">Anders Sandberg: "Re: Constraints on the "singularity""</a>
<li> <b>Reply:</b> <a href="0520.html">Anders Sandberg: "Re: Constraints on the "singularity""</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Ramez Naam (Exchange) wrote:<br>
<i>&gt; </i><br>
<i>&gt; But it's not really an event horizon.  It's more like an "event fog"</i><br>
<i>&gt; with our ability to predict getting dimmer and dimmer the deeper we look</i><br>
<i>&gt; into that cloud.  Thus my objection to the term "singularity"</i><br>
<p>
The problem is that any SI, after a few cycles of self-enhancement, is twenty<br>
trillion lightyears into the cloud.  The fog gradient is irrelevant at such<br>
distances, although I personally happen to think it's rather sharp.  If we<br>
have so much trouble predicting the actions of different cultures, how can we<br>
predict the actions of a transhuman?  Intuitively, if not formally, it would<br>
seem to be as mathematically impossible as an abacus simulating a PowerPC 604.<br>
<p>
<i>&gt; Possibly you're right, and the superintelligences are incomprehensible. </i><br>
<i>&gt; However it seems that we should be able to at least generate some</i><br>
<i>&gt; quantitative boundaries on their capabilities given our deepest current</i><br>
<i>&gt; understanding of the laws of physics and mathematics.</i><br>
<p>
You are incorrect.  I lay down this Continuing Challenge to all who listen: <br>
Before you place a physical constraint on the Powers, you must first place it<br>
on me.  And now, watch as I shoot all your "constraints" down.<br>
<p>
<i>&gt; E.g.:</i><br>
<i>&gt; </i><br>
<i>&gt; Given Planck space, c, and the maximum density matter can achieve before</i><br>
<i>&gt; collapsing into a black hole, what is the maximum achievable</i><br>
<i>&gt; computational power per unit volume?</i><br>
<p>
What about negative matter?  You can have an arbitary amount of computing<br>
material in a given volume, with net mass zero.<br>
<p>
<i>&gt; Given the likely mass, age, and size of the universe, and the</i><br>
<i>&gt; constraints listed above, what is the maximum achievable computational</i><br>
<i>&gt; power of the universe?</i><br>
<p>
Infinite.  There exist physical processes which are not<br>
simulable-to-arbitrary-accuracy by Turing machines.  Even if all physical<br>
processes *are* simulable, they still use real numbers.  Perhaps a clever<br>
Being could exploit a chaotic Mandelbrot-like boundary to perform calculations<br>
of arbitrary complexity in constant time.<br>
<p>
<i>&gt; Given c, the age, size, and rate of expansion of the universe, how long</i><br>
<i>&gt; would it take an earth-spawned power to infest the galaxy?  1/10e6 of</i><br>
<i>&gt; the universe?  1% of the universe?  10% of the universe?</i><br>
<p>
General relativity makes the speed of light fundamentally arbitrary.  They can<br>
infest the entire Universe in zero time, and finish before they started.<br>
<p>
<i>&gt; My understanding may be off here, but let me put forth the reason I see</i><br>
<i>&gt; chaotic computability entering into the picture with nanotech:</i><br>
<p>
[deleted]<br>
<p>
One being's "chaos" is another's "order".  The mechanical nanotech you mention<br>
is simply an enormous waste of computing power...molecularly speaking.  It<br>
takes thousands or millions of atoms to compute the position of an atom.  The<br>
theoretical maximum, of course, is one atom per atom.  (Unless, of course,<br>
you're using quantum computing.  See, even I start doing it!  Theoretical<br>
maximum?  Whose theory?)<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0481.html">Eliezer S. Yudkowsky: "Re: Extropian Principles reading list"</a>
<li> <b>Previous message:</b> <a href="0479.html">Lee Daniel Crocker: "Re: Extropian Principles reading list"</a>
<li> <b>Maybe in reply to:</b> <a href="0447.html">Ramez Naam: "Constraints on the "singularity""</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0520.html">Anders Sandberg: "Re: Constraints on the "singularity""</a>
<li> <b>Reply:</b> <a href="0520.html">Anders Sandberg: "Re: Constraints on the "singularity""</a>
<!-- reply="end" -->
</ul>
