<!-- received="Mon Nov 10 14:02:48 1997 MDT" -->
<!-- sent="Mon, 10 Nov 1997 12:43:22 -0800" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Penrose" -->
<!-- id="199711102043.MAA26712@s20.term1.sb.rain.org" -->
<!-- inreplyto="Penrose" -->
<title>extropians: Re: Penrose</title>
<h1>Re: Penrose</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Mon, 10 Nov 1997 12:43:22 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1312">[ date ]</a><a href="index.html#1312">[ thread ]</a><a href="subject.html#1312">[ subject ]</a><a href="author.html#1312">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1313.html">Wesley Schwein: "Jobs: Ling Engineer-Perspecta (fwd)"</a>
<li> <b>Previous message:</b> <a href="1311.html">Mark Crosby: "Re: MATH: Surreal numbers?"</a>
<li> <b>Maybe in reply to:</b> <a href="1310.html">John K Clark: "Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
John Clark, &lt;johnkc@well.com&gt;, writes:<br>
<i>&gt; Penrose's argument is that if people are algorithmic like a Turing machine</i><br>
<i>&gt; then we couldn't jump out of the system, look at ourselves and find the</i><br>
<i>&gt; inadequacies in the system as Godel seemed to do it his proof. I think at the</i><br>
<i>&gt; very lowest level we are the equivalent of Turing machines, however the</i><br>
<i>&gt; axioms are numerous but ridiculously simple at that level, "If you're in</i><br>
<i>&gt; state A and see a 0, change it to a 1, go to state B, and move one square to</i><br>
<i>&gt; the left". I don't think we can jump out of THAT system and change the basic</i><br>
<i>&gt; operating principles that Turing found 60 years ago, but that very low level</i><br>
<i>&gt; can't be the level the conscious mind operates. Something must be running on</i><br>
<i>&gt; top of that machinery, something that has few if any axioms and so is not a</i><br>
<i>&gt; formal system.</i><br>
<p>
It's not clear to me that minds and/or neurons can be expressed as formal<br>
systems.  Equivalently, there can be no computer program which _exactly_<br>
(exactly, exactly) simulates a brain.  This is because we do not have<br>
a full understanding of the laws of physics.  It is possible, as Penrose<br>
argues, that actually the laws of physics are nonlocal and/or have non<br>
algorithmic properties.  Therefore his argument does not apply even at the<br>
lowest level of our own brains.<br>
<p>
However, dealing with an upload or an AI is a different matter.  Now we<br>
have a full understanding of the substrate which is executing the program.<br>
It is a completely deterministic, mechanical and logical machine, and is<br>
even relatively simple at the lowest level - as little as a dozen or so<br>
opcodes is probably enough to be a universal machine able to run an<br>
upload, by our current understanding.<br>
<p>
Given that the substrate is deterministic and mechanical, it follows<br>
(I think) that any program loaded onto it shares these properties,<br>
even if it is a complicated brain simulation.  What you need to do is<br>
to produce some kind of concrete way of defining what it means for the<br>
simulated mind to believe a certain mathematical proposition.  This would<br>
require a complete understanding of how its consciousness worked, and<br>
what the neural (or lower level) structure was which mapped to conscious<br>
belief, but is possible in principle.  Given this, you can set up a formal<br>
system which expresses all possible beliefs that the simulated mind can<br>
have.<br>
<p>
The key idea here is that this is only possible because we know the mind<br>
is running on a deterministic, formally structured computer.  It follows<br>
that the mind is also deterministic and has a formal structure of its<br>
own.  A mind running on neurons and the laws of physics does not have<br>
this property (unless it turns out that the laws of physics are in the<br>
appropriate sense deterministic and algorithmic, which Penrose believes<br>
is not the case).<br>
<p>
The mind running on the computer, then, differs from the mind in the<br>
brain, because we can theoretically set up a formal system which expresses<br>
all the thoughts of the first, but we may not be able to do so (Penrose<br>
would say cannot) for the second.  Present the mind on the computer with<br>
a Godel statement based on the formal system which constrains it and<br>
it will not be able to believe its truth, while the mind in the brain<br>
supposedly has no such limitation.<br>
<p>
<i>&gt; Minds are problem solvers and I don't think non-algorithmic problem solving</i><br>
<i>&gt; is necessarily mystical. I doubt if we use axioms like "if A and B then C"</i><br>
<i>&gt; very much,  more important are billions of heuristics like  "if A and B  then</i><br>
<i>&gt; usually something close to C".</i><br>
<p>
True, but this is a very gross level of description.  To actually pin<br>
down those heuristics will turn them into immensely complicated but<br>
deterministic formulas.  (As discussed before, if the formula needs a<br>
random component, it can be supplied by a deterministic random number<br>
generator.)<br>
<p>
<i>&gt; If the mind is not a formal system, at least at the highest conscious level,</i><br>
<i>&gt; then Godel does not apply to us or to a intelligent program running on a</i><br>
<i>&gt; computer.</i><br>
<p>
Right, but Penrose would claim that a mind uploaded to a computer is a<br>
formal system, even at the highest conscious level, as I understand it.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1313.html">Wesley Schwein: "Jobs: Ling Engineer-Perspecta (fwd)"</a>
<li> <b>Previous message:</b> <a href="1311.html">Mark Crosby: "Re: MATH: Surreal numbers?"</a>
<li> <b>Maybe in reply to:</b> <a href="1310.html">John K Clark: "Penrose"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
