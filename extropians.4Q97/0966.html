<!-- received="Thu Oct 30 06:21:27 1997 MDT" -->
<!-- sent="30 Oct 1997 14:21:17 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: How can we deal with risks?" -->
<!-- id="199710301302.NAA23299@andromeda.ndirect.co.uk" -->
<!-- inreplyto="Thu, 30 Oct 1997 01:39:03 +0100" -->
<title>extropians: Re: How can we deal with risks?</title>
<h1>Re: How can we deal with risks?</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>30 Oct 1997 14:21:17 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#966">[ date ]</a><a href="index.html#966">[ thread ]</a><a href="subject.html#966">[ subject ]</a><a href="author.html#966">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0967.html">Anders Sandberg: "Call for European Transhumanists (Was: looking for...)"</a>
<li> <b>Previous message:</b> <a href="0965.html">Nicholas Bostrom: "Re: History of Transhumanism and Extropy"</a>
<li> <b>In reply to:</b> <a href="0947.html">Holger Wagner: "How can we deal with risks?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0979.html">Dan Clemmensen: "Re: How can we deal with risks?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Holger Wagner &lt;Holger.Wagner@lrz.uni-muenchen.de&gt; writes:<br>
<p>
<i>&gt; I actually don't want to sound pessimistic in my first posting to this</i><br>
<i>&gt; list (just today, I've read the article about dynamic optimism which I</i><br>
<i>&gt; found pretty good), but there's something I have been thinking about</i><br>
<i>&gt; since I first found out about Extropy - but so far, I couldn't find an</i><br>
<i>&gt; answer.</i><br>
<p>
Welcome! If an idea is valid, then it should be considered even if it<br>
sounds pessimistic; only passive optimists and pessimists reject ideas<br>
because of their mood.<br>
<p>
<i>&gt; 1) Today, humans are by no means perfect. They have a certain idea of</i><br>
<i>&gt; what they do and what the consequences are, but it happens quite often</i><br>
<i>&gt; that something "impredictable" happens. If you apply changes to the</i><br>
<i>&gt; ecologic system, can you really predict what consequences this will have</i><br>
<i>&gt; in the long run - and would you take the responsibility?</i><br>
<p>
We cannot predict the long-term consequences of our<br>
actions. Period. But we can do our best to avoid bad effects, and I<br>
think we are responsible for all our actions.<br>
<p>
<i>&gt; Possible solution: I assume that most scientists are very intelligent,</i><br>
<p>
As a scientist, I'm flattered but unfortunately this isn't very true<br>
(in fact it is a remain of the old romatic idea that artists and<br>
scientists are set apart; in reality scientists are fairly ordinary<br>
people in general).<br>
<p>
<i>&gt; so they should understand stuff like pancritical rationalism and should</i><br>
<i>&gt; be able to apply this to their work. By doing that, they at least</i><br>
<i>&gt; improve the chance of not doing anything that has extremely bad results</i><br>
<i>&gt; in the long run. </i><br>
<p>
This is what happens today, although PCR is not used as much as it<br>
ought to. It is just that we always hear about the disasters and not<br>
about the millions of potential disasters that are prevented.<br>
<p>
<i>&gt; Usually, it's the innovator who decides whether something should be</i><br>
<i>&gt; invented or not, right?</i><br>
<p>
Innovations, yes, but most discoveries are accidental or unexpected,<br>
and most technology is developed because somebody for some reason<br>
funds it (be it the market, an individual or a group like the<br>
military).<br>
<p>
<i>&gt; 2) Today, humans are by no means perfect. While I trust scientists to</i><br>
<i>&gt; have at least a vague idea of what they're doing, I do not trust people</i><br>
<i>&gt; in general. </i><br>
<p>
Thanks again, but I think you should nuance your position a bit<br>
more. I think one can trust all people (with a few exceptions) to some<br>
extent; being a scientist doesn't per se make you more trustworthy,<br>
just as being a government official doesn't per se make you less<br>
trustworthy.<br>
<p>
<i>&gt; Solution: Educate people accordingly. (easy to say - but I don't believe</i><br>
<i>&gt; it's possible until I see world-wide results).</i><br>
<p>
This is actually the solution to many other problems, like poverty and<br>
the spread of some bad memes. <br>
<p>
<i>&gt; If you want to overcome the fear most people have of technology, you</i><br>
<i>&gt; need to solve these problems and make people understand the solutions.</i><br>
<p>
A deeper understanding of the problems might do too - I know some<br>
people who react with "try harder!" when I explain that we cannot<br>
predict the long term consequences of technology even in principle. It<br>
would be useful if we could make people think more and better about<br>
these issues.<br>
<p>
<i>&gt; The major problem with this is that I can improve myself, but I can't</i><br>
<i>&gt; improve the rest of the world</i><br>
<p>
It is a good start to improve oneself and act as a catalyst for<br>
improvement in others.<br>
<p>
 - and only one insane person can do great<br>
<p>
<i>&gt; But what if there comes a day where we have to face an insane fool who</i><br>
<i>&gt; has the technology to wipe out all life on this planet? Someone who just</i><br>
<i>&gt; doesn't understand or just doesn't care about the responsibility?</i><br>
<p>
This is a real problem, since even if we solve the problems you<br>
discuss, there may always be somebody who is deranged or clumsy enough<br>
to mess things up. Even without sociopaths and zealots there will be<br>
accidents and people who do dangerous things for good reasons.<br>
<p>
The solution is likely to empower people in general, so that it will<br>
be hard for dictators, fanatics and error to overcome<br>
all. Unfortunately this only works if the technologies are not of the<br>
kind that the first use wins (this was the cause of our major<br>
nanotechnology debate a few months back; was nanotech inherently such<br>
a technology, or could even deliberate nasty nanodevices be<br>
contained?). In this case dispersal seems to be the only strategy.<br>
<p>
<i>&gt; o________________/        Trevor Goodchild in "Aeon Flux"       |</i><br>
<p>
"That which does not kill us makes us stranger" :-)<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0967.html">Anders Sandberg: "Call for European Transhumanists (Was: looking for...)"</a>
<li> <b>Previous message:</b> <a href="0965.html">Nicholas Bostrom: "Re: History of Transhumanism and Extropy"</a>
<li> <b>In reply to:</b> <a href="0947.html">Holger Wagner: "How can we deal with risks?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0979.html">Dan Clemmensen: "Re: How can we deal with risks?"</a>
<!-- reply="end" -->
</ul>
