<!-- received="Tue Nov 11 18:14:35 1997 MDT" -->
<!-- sent="Tue, 11 Nov 1997 17:14:48 -0800" -->
<!-- name="Ramez Naam" -->
<!-- email="ramezn@EXCHANGE.MICROSOFT.com" -->
<!-- subject="RE: Penrose" -->
<!-- id="199711112349.SAA11675@ldl.net" -->
<!-- inreplyto="" -->
<title>extropians: RE: Penrose</title>
<h1>RE: Penrose</h1>
Ramez Naam (<i>ramezn@EXCHANGE.MICROSOFT.com</i>)<br>
<i>Tue, 11 Nov 1997 17:14:48 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1342">[ date ]</a><a href="index.html#1342">[ thread ]</a><a href="subject.html#1342">[ subject ]</a><a href="author.html#1342">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1343.html">Ramez Naam: "RE: The copy paradox"</a>
<li> <b>Previous message:</b> <a href="1341.html">Gregory Sullivan: "Music: Computer composes music"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; From: Hal Finney [SMTP:hal@rain.org]</i><br>
<i>&gt; </i><br>
<i>&gt; It's not clear to me that minds and/or neurons can be expressed as</i><br>
<i>&gt; formal</i><br>
<i>&gt; systems.  Equivalently, there can be no computer program which</i><br>
_exactly_<br>
<i>&gt; (exactly, exactly) simulates a brain.  This is because we do not have</i><br>
<i>&gt; a full understanding of the laws of physics.  It is possible, as</i><br>
Penrose<br>
<i>&gt; argues, that actually the laws of physics are nonlocal and/or have non</i><br>
<i>&gt; algorithmic properties.  Therefore his argument does not apply even at</i><br>
<i>&gt; the</i><br>
<i>&gt; lowest level of our own brains.</i><br>
<i>&gt; </i><br>
<i>&gt; However, dealing with an upload or an AI is a different matter.  Now</i><br>
we<br>
<i>&gt; have a full understanding of the substrate which is executing the</i><br>
<i>&gt; program.</i><br>
<i>&gt; It is a completely deterministic, mechanical and logical machine, and</i><br>
is<br>
<i>&gt; even relatively simple at the lowest level - as little as a dozen or</i><br>
so<br>
<i>&gt; opcodes is probably enough to be a universal machine able to run an</i><br>
<i>&gt; upload, by our current understanding.</i><br>
<p>
Whoa.  If we use "we do not have a full understanding of the laws of<br>
physics" as a rationale, then the substrate of an AI is equally suspect<br>
of being a non-formal system.<br>
<p>
Penrose's argument strikes me as exceedingly disengenious.  It is the<br>
interconnections between neurons (rather than the neurons themselves)<br>
that result in the emergent information processing power of the brain.<br>
Those interconnections operate via molecular-level signaling, not QM.<br>
At some level quantum uncertainty affects everything, including a<br>
"deterministic" AI substrate.  But for all practical purposes, a<br>
computer is a formal system, even if quantum fluctuations will cause it<br>
to flip a memory bit every few thousand years.  Does Penrose present any<br>
compelling reason to think of the brain differently?<br>
<p>
mez<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1343.html">Ramez Naam: "RE: The copy paradox"</a>
<li> <b>Previous message:</b> <a href="1341.html">Gregory Sullivan: "Music: Computer composes music"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
