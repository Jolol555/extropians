<!-- received="Sun Oct 12 17:55:36 1997 MDT" -->
<!-- sent="Sun, 12 Oct 1997 23:55:23 +0000" -->
<!-- name="Nicholas Bostrom" -->
<!-- email="bostrom@mail.ndirect.co.uk" -->
<!-- subject="Re: "Morality?" - Composite Reply" -->
<!-- id="199710122256.XAA05457@andromeda.ndirect.co.uk" -->
<!-- inreplyto=""Morality?" - Composite Reply" -->
<title>extropians: Re: "Morality?" - Composite Reply</title>
<h1>Re: "Morality?" - Composite Reply</h1>
Nicholas Bostrom (<i>bostrom@mail.ndirect.co.uk</i>)<br>
<i>Sun, 12 Oct 1997 23:55:23 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#460">[ date ]</a><a href="index.html#460">[ thread ]</a><a href="subject.html#460">[ subject ]</a><a href="author.html#460">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0461.html">Gregory Sullivan: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0459.html">Tony Hollick: "TITLE: Resolving the Problems of Rritish Telecom and other megacorpora"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Max More wrote:<br>
<p>
<i>&gt; If there really were</i><br>
<i>&gt; vampires, and there survival really did depend on drinking the blood of</i><br>
<i>&gt; humans (in such a way that it killed them and there were no alternatives</i><br>
<i>&gt; like blood banks) then it would be *right* for vampires to attack humans.</i><br>
<i>&gt; It would also be *right* for humans to defend themselves. Differences in</i><br>
<i>&gt; nature produce different behaviors that are good for the beings that do</i><br>
<i>&gt; them. Given that humans have essentially the same nature, such moral</i><br>
<i>&gt; divergence is unlikely.</i><br>
<p>
Just to make sure I understand you correctly, is the following a <br>
correct interpretation of the above passage?<br>
<p>
Even if all humans were identical, it could still be the case that <br>
one human's deepest value is irrelevant to another. For example, if <br>
each is perfectly egoistic, then Mr. X's deepest value might be the <br>
flourishing of Mr X; whereas Mr. Y only cares about Mr. Y etc. The <br>
obvious sense in which you could say that these egosists have a <br>
common moral is that they could produce a set of norms that would <br>
apply to them all, such as "Don't steal! (Because if you do, the <br>
police will get you.)". I presume the point with the vampire example <br>
is to give an example of how there could be creatures with <br>
sufficiently different goals or abilities to make human morality <br>
irrelevant to them.<br>
<p>
If this is right then what distinguishes moral knowledge from <br>
other knowledge? Is it just that moral knowledge typically concerns <br>
life strategies or codes for interacting with other humans? Would <br>
"Take out an insurance!" or "Con thy neighbor subtly!" count as a <br>
moral imperative for humans, supposing that it would be good advise <br>
for most people (i.e. that each would better obtain her own values if <br>
she follows it than if she doesn't)?<br>
<p>
Nicholas Bostrom<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0461.html">Gregory Sullivan: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0459.html">Tony Hollick: "TITLE: Resolving the Problems of Rritish Telecom and other megacorpora"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
