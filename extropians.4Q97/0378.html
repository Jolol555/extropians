<!-- received="Fri Oct 10 10:51:49 1997 MDT" -->
<!-- sent="Fri, 10 Oct 1997 17:22:55 +0000" -->
<!-- name="Nicholas Bostrom" -->
<!-- email="bostrom@mail.ndirect.co.uk" -->
<!-- subject="Re: Genius Dogs" -->
<!-- id="199710101624.RAA00358@andromeda.ndirect.co.uk" -->
<!-- inreplyto="Genius Dogs" -->
<title>extropians: Re: Genius Dogs</title>
<h1>Re: Genius Dogs</h1>
Nicholas Bostrom (<i>bostrom@mail.ndirect.co.uk</i>)<br>
<i>Fri, 10 Oct 1997 17:22:55 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#378">[ date ]</a><a href="index.html#378">[ thread ]</a><a href="subject.html#378">[ subject ]</a><a href="author.html#378">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<li> <b>Previous message:</b> <a href="0377.html">EvMick@aol.com: "Re: feedback and sharing knowledge"</a>
<li> <b>Maybe in reply to:</b> <a href="0381.html">John K Clark: "Genius Dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<li> <b>Reply:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
 Hal Finney wrote:<br>
<p>
<i>&gt;[snip]</i><br>
<i>&gt;Interesting, although of course we all know that the infinitely fast</i><br>
<i>&gt;computer doesn't exist anyway.  </i><br>
<p>
How do we know that? (Do you mean that we know that no infinitely <br>
fast computer can exist physically, or that no such machine will in <br>
fact ever exist in our universe, or that the decendants of humanity <br>
will never build such a machine?)<br>
<p>
<i>&gt; A brute force technique, then, would have to simulate not only the brains,</i><br>
<i>&gt; but potentially a significant subset of the biosphere.  This would be many</i><br>
<i>&gt; orders of magnitude more difficult.  Volume considerations alone would</i><br>
<i>&gt; suggest 4 or 5 orders of magnitude (what fraction of the biosphere is</i><br>
<i>&gt; made of brains?).  A complicating factor is that the kinds of simulation</i><br>
<i>&gt; necessary or appropriate for things like muscles, trees and rivers may be</i><br>
<i>&gt; fundamentally different than the presumably neural-net based simulations</i><br>
<i>&gt; we would prefer to use for brains (and which probably formed the basis</i><br>
<i>&gt; of Drexler's estimate).</i><br>
<i>&gt; </i><br>
<i>&gt; The idea of evolving intelligence does seem to have potential, and may</i><br>
<i>&gt; turn out to be the easiest way of developing AI.  I'm sure that Drexler's</i><br>
<i>&gt; example is not meant literally, but is intended to motivate the intuition</i><br>
<i>&gt; that given nanocomputers, it should become practical to evolve AI.  This</i><br>
<i>&gt; may still be the case even if the example doesn't go all the way towards</i><br>
<i>&gt; establishing the point.</i><br>
<p>
Even apart from the fact that Drexler's estimate doesn't seem to <br>
have taken into account that the simulated creatures would need an <br>
environment to live in, it is clear it could never be a certain way <br>
of quickly evolving AI. There are something like 10^18 habitable <br>
planets out there, and as far as we know, intelligent life has <br>
evolved on only one, and we don't know how implausible that was.<br>
<p>
Another point is that I think that even though the volume of the <br>
non-brain parts of the biosphere are many orders of magnitude greater <br>
than the brain parts, it doesn't follow that it would take so much <br>
more computing power to simulate it. Brains are the most complex <br>
systems in the known universe; other biological phenomena could <br>
presumably be sufficiently closely approximated at a relatively low <br>
computational cost. Of course, if we start to make idealisations then <br>
the estimate loses its plausibility as an absolutely certain upper <br>
bound on how difficult it is to create AI.<br>
<p>
However, I don't see an reason why we should have a realistic <br>
biosphere in our simulation at all. Since the simulate <br>
evolution-argument doesn't seem to work anyway, we can just as well <br>
focus on more realistic ways of creating AI. Some kind of strategic <br>
multi-player game in an environment where some sort of simulated <br>
"physical" things can be constructed would seem a better place to <br>
evolve intelligence in than any realistic model of primordial earth. <br>
But even that is not how I expect AI to come into existence.<br>
<p>
<p>
Nicholas Bostrom<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<li> <b>Previous message:</b> <a href="0377.html">EvMick@aol.com: "Re: feedback and sharing knowledge"</a>
<li> <b>Maybe in reply to:</b> <a href="0381.html">John K Clark: "Genius Dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<li> <b>Reply:</b> <a href="0379.html">Anders Sandberg: "Re: Genius Dogs"</a>
<!-- reply="end" -->
</ul>
