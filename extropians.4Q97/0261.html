<!-- received="Tue Oct  7 19:17:40 1997 MDT" -->
<!-- sent="Tue, 7 Oct 1997 17:38:22 -0700" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Genius dogs" -->
<!-- id="199710080038.RAA00723@s20.term1.sb.rain.org" -->
<!-- inreplyto="Genius dogs" -->
<title>extropians: Re: Genius dogs</title>
<h1>Re: Genius dogs</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Tue, 7 Oct 1997 17:38:22 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#261">[ date ]</a><a href="index.html#261">[ thread ]</a><a href="subject.html#261">[ subject ]</a><a href="author.html#261">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0262.html">Eric Watt Forste: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0260.html">Max M: "Oh this narrow focusing on Moores Law"</a>
<li> <b>Maybe in reply to:</b> <a href="0157.html">Nicholas Bostrom: "Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0307.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Nicholas Bostrom writes:<br>
<p>
<i>&gt; (H) Take a person X of normal intelligence who knows the basics of </i><br>
<i>&gt; some standard programming language. Give him an arbitrarily powerful </i><br>
<i>&gt; computer, complete with camera eyes, microphones, robot arms etc. </i><br>
<i>&gt; Then it is possible to educate X in less than a week in such a way </i><br>
<i>&gt; that he will be able to program his computer to achieve </i><br>
<i>&gt; superintelligence.</i><br>
<p>
This is an interesting question.  I posed something similar on the list a<br>
year ago:<br>
<p>
<i>&gt; From hal Fri Oct 11 16:31:01 1996</i><br>
<i>&gt; To: extropians@extropy.org</i><br>
<i>&gt; Subject: Infinitely fast computer</i><br>
<i>&gt; </i><br>
<i>&gt; An idea I've been amusing myself with a bit, relating to the question</i><br>
<i>&gt; of how hard it will be to generate AI using nanotech is this: suppose a</i><br>
<i>&gt; genii gives you an infinitely fast computer.  This is a computer just</i><br>
<i>&gt; like today's, programmable in C or Lisp or some other language, which</i><br>
<i>&gt; had the property that it runs infinitely fast.  Any program you put on</i><br>
<i>&gt; it completes instantly (unless it is of the type which never completes,</i><br>
<i>&gt; in which case it runs forever until you halt it).  All computation is</i><br>
<i>&gt; done in zero time.  We'll also throw in infinite memory while we're at</i><br>
<i>&gt; it, although I'm not sure how big the C pointers have to be then :-).</i><br>
<i>&gt; </i><br>
<i>&gt; The question is, given such a miraculous device, how hard would it be</i><br>
<i>&gt; for you, meaning the typical programmer reading this, to produce a program</i><br>
<i>&gt; which could pass the Turing test, or better still one which is super-</i><br>
<i>&gt; intelligent?  Where would you start?  How long would it take you to write</i><br>
<i>&gt; the code?  What research would you have to do?  Could it even be done?</i><br>
<p>
The few people who replied seemed to think that it would not take long,<br>
maybe even just a few days.  I am more skeptical.  When I try to think<br>
through an actual, concrete plan, it is hard to know where to start.<br>
Tell me what the first program you would write is, what you would expect<br>
to learn from it, and where you would go from there.  How many lines of<br>
code would the program be?  Do you have the knowledge now to write it,<br>
or would you have to do research first?  How quickly could you write it?<br>
<p>
Maybe you could get a copy of Thomas Ray's a-life program Tierra,<br>
which lets various "program organisms" interact and reproduce under<br>
certain rules.  You fire it up and tell it to stop when the average<br>
organism size reaches some large value, with the program set up so<br>
that normally small organisms will have a reproductive advantage.<br>
Hopefully the only way a large organism could grow and spread would be<br>
if were doing something smart.<br>
<p>
Well, you'd probably end up with a real mess.  Zillions of programs, all<br>
interacting in some messy ways, various extreme flavors of meta-parasitism.<br>
It would likely be monstrously complex, and you'd have to study it for<br>
years to understand what was going on.  There could even be human-level<br>
intelligences in there, happily communicating in program fragments, while<br>
you can't even see object boundaries (like looking at a fourier transform<br>
of our world).<br>
<p>
On the other hand we don't know if any particular artificial world is<br>
even capable of evolving intelligence.  Tierra may be too simple to<br>
allow complexity to evolve (too many predators, or too much chaos).<br>
Some philosophers argue that our own world should be about as simple as<br>
it can be such that it is still able to support intelligence.  I don't<br>
give much weight to give this kind of reasoning, but it does weakly<br>
suggest that simple toy worlds will not be able to do it, otherwise most<br>
intelligent beings will live in such worlds.  (That's assuming that we don't<br>
have ultra-simple rules buried in the quantum foam, which we just haven't<br>
figured out yet.)<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0262.html">Eric Watt Forste: "Re: The Spike, nanotech, and a future scenario"</a>
<li> <b>Previous message:</b> <a href="0260.html">Max M: "Oh this narrow focusing on Moores Law"</a>
<li> <b>Maybe in reply to:</b> <a href="0157.html">Nicholas Bostrom: "Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0307.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
