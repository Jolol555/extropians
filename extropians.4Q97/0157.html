<!-- received="Sun Oct  5 18:18:01 1997 MDT" -->
<!-- sent="Sun, 5 Oct 1997 22:22:26 +0000" -->
<!-- name="Nicholas Bostrom" -->
<!-- email="bostrom@mail.ndirect.co.uk" -->
<!-- subject="Genius dogs" -->
<!-- id="199710052123.WAA22646@andromeda.ndirect.co.uk" -->
<!-- inreplyto="" -->
<title>extropians: Genius dogs</title>
<h1>Genius dogs</h1>
Nicholas Bostrom (<i>bostrom@mail.ndirect.co.uk</i>)<br>
<i>Sun, 5 Oct 1997 22:22:26 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#157">[ date ]</a><a href="index.html#157">[ thread ]</a><a href="subject.html#157">[ subject ]</a><a href="author.html#157">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0158.html">Michael Lorrey: "Re: MEDIA: Movies with augmented intelligence ?"</a>
<li> <b>Previous message:</b> <a href="0156.html">Dan Clemmensen: "Re: The Spike, nanotech, and a future scenario"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0161.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0161.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0168.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<li> <b>Reply:</b> <a href="0172.html">Anders Sandberg: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0194.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0199.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0239.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0261.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0307.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0312.html">Gregory Sullivan: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0332.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0420.html">Hara Ra: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
I'm writing a paper on superintelligence. One of the things that I <br>
want to do is to spell out in some detail exactly why most of thinks <br>
that we might very well have superintelligence within 30 or 40 years <br>
or sooner, even in the absense of nanotech. Then I want to address <br>
the problem of whether we can make any good guesses about what a <br>
superintelligence might do, whether we will be able to control it, <br>
etc.<br>
<p>
Here's one fun idea that might elicit some interesting comments:<br>
<p>
If we take a human brain and simply speed it up enough, will it be a<br>
superintelligence? Would a dog brain be?<br>
<p>
Any human of normal intelligence could function as a universal <br>
Turing machine, if augmented with enough scrap paper, time and <br>
patience. According to Church's thesis, Turing computability equals <br>
mechanical computability, so what the brain does is Turing <br>
computable. (I assume that Penrose's argument to the contrary is <br>
wrong, and we disregard possible exceptions that have to do with the <br>
feasibility of supertasks or the unavailability of enough matter in <br>
the universe.) What a (finite) superintelligence does would also be <br>
Turing computable, so a human scrap paper, time &amp; patience), if <br>
speeded up, could be a superintelligence, provided she run an <br>
appropriate program. We don't know that this program could be made <br>
short enough to be stored in human long-term memory, (else it would <br>
have to be provided as an input on the scrap paper), but I believe it <br>
could. My guess is that a universal intelligence algorithm could be <br>
made so simple that it would be an easy task for a human to memorize <br>
it. Perhaps it would suffice to specify some simple architectural<br>
 properties of a neural network, together with some fairly simple<br>
 learning rule -- something like combination of Backprop, Infomax and<br>
 Hebb's rule perhaps. But whether or not it could be made so concise,<br>
 by using some scrap paper input, I think that even dogs could be made<br>
 to perform on a genius level. Here's how:<br>
<p>
Recipe for Cani da Vinci, genius dogs<br>
<p>
Ingredients: 20 poodles, universal intelligence algorithm,<br>
nanotechnology<br>
<p>
1. Take a twenty poodles.<br>
<p>
2. First we need to put the dogs in training. We teach them the basic<br>
operations of a Turing machine: the inputs are given to the dogs as<br>
color-coded light signals, the output is a push with one of their<br>
paws. Poodles are clever dogs, and they should be able to learn this<br>
in a few months.<br>
<p>
3. When the learning task is completed, the dog's brains are uploaded<br>
onto a virtual computer that runs on a Jupiter brain.<br>
<p>
4. They are presented with input from a virtual tape ("scrap paper")<br>
by having their (virtual) nervus opticus stimulated. The output from<br>
each dog is defined by measuring the activity in their (virtual) motor<br>
nerves.<br>
<p>
5. The instructions the dogs have to perform are written on one side<br>
of the tape, so that they don't need to remember them. The dogs just<br>
(virtually) run back and forth between different parts of the tape,<br>
carrying out simple instructions.<br>
<p>
6. Here is why we need more than one dog: eventually a dog will get<br>
bored with the task and begin making mistakes. But all twenty dogs<br>
will not start to get bored at exactly the same time. Now, the output<br>
of the total dog house is defined as the output that most of the<br>
individual dogs gave for a the input in question. Any dog that gives<br>
an output different from the total output gets a (virtual) electric<br>
shock, so that it returns to the learned scheme.<br>
<p>
7. The Turing machine that is simulated runs the universal<br>
intelligence algorithm (or alternatively simulates the evolution of<br>
the brain states of an uploaded human genius). Amazing feats of genius<br>
are performed by this dog house.<br>
<p>
-- I anticipate that Anders will suggest that superintelligences will <br>
make entertainment out of shaping human organizations into <br>
entities that perform intelligent tasks, just as we have fun by <br>
watching circus animals behave. :-)<br>
<p>
Nicholas Bostrom<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0158.html">Michael Lorrey: "Re: MEDIA: Movies with augmented intelligence ?"</a>
<li> <b>Previous message:</b> <a href="0156.html">Dan Clemmensen: "Re: The Spike, nanotech, and a future scenario"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0161.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0161.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0168.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<li> <b>Reply:</b> <a href="0172.html">Anders Sandberg: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0194.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0199.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0239.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0261.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0307.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0312.html">Gregory Sullivan: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0332.html">Hal Finney: "Re: Genius dogs"</a>
<li> <b>Maybe reply:</b> <a href="0420.html">Hara Ra: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
