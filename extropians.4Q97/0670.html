<!-- received="Tue Oct 21 14:02:10 1997 MDT" -->
<!-- sent="Tue, 21 Oct 1997 12:37:22 -0700" -->
<!-- name="Eric Watt Forste" -->
<!-- email="arkuat@idiom.com" -->
<!-- subject="Re: ETHICS: value-sets and value-systems" -->
<!-- id="199710211937.MAA27422@idiom.com" -->
<!-- inreplyto="ETHICS: value-sets and value-systems" -->
<title>extropians: Re: ETHICS: value-sets and value-systems</title>
<h1>Re: ETHICS: value-sets and value-systems</h1>
Eric Watt Forste (<i>arkuat@idiom.com</i>)<br>
<i>Tue, 21 Oct 1997 12:37:22 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#670">[ date ]</a><a href="index.html#670">[ thread ]</a><a href="subject.html#670">[ subject ]</a><a href="author.html#670">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0671.html">Joao Pedro: "Re: AND THEN, JUST TRANSPLANT THE BRAIN..."</a>
<li> <b>Previous message:</b> <a href="0669.html">E. Shaun Russell: "Re: Government is  Possible and Necessary"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Mitchell Porter writes:<br>
<i> &gt; I'm intrigued by Eric's idea that "the summum bonum is </i><br>
<i> &gt; the generalizably extrinsic". I don't think it's any more </i><br>
<i> &gt; defensible as a proposed Absolute Good than any other candidate, </i><br>
<i> &gt; so I suppose I find it of interest as a psychological hypothesis </i><br>
<i> &gt; ("this is what we're really after") and as a hedonic heuristic </i><br>
<i> &gt; ("this is the thing to seek"). In fact, maybe so much emphasis</i><br>
<i> &gt; is placed on nano and AI in extropian/transhuman circles </i><br>
<i> &gt; because they promise to make so much else possible, and are</i><br>
<i> &gt; therefore further examples of powerful extrinsic goods.</i><br>
<p>
Thanks for diagnosing my thinking.  You're right, it probably is<br>
more of a psychological hypothesis or hedonic heuristic or both<br>
than a moral principle.  Your paraphrase identifying my clumsy<br>
English phrase with the old Latin one makes me a little<br>
uncomfortable, though I can see how I gave that impression, because<br>
I tried to head off that impression by quacking about how I found<br>
it quite likely that Aristotle's "summum bonum" is a meaningless<br>
phrase.  They might be the same though... that would just mean<br>
that my phrase is meaningless too.  ;)<br>
<p>
The possibility of a summum bonum would to me imply the possibility<br>
of a permanent end to all progress.  Whether my resisting this idea<br>
is merely wishful thinking on my part I am not sure yet.<br>
<p>
But you make an excellent diagnosis in pointing out the generalizable<br>
extrinsicity of proposed projects in nano and AI, because thinking<br>
about that is indeed one of things that prompted the development<br>
of this idea for me.<br>
<p>
<pre>
--
arkuat@idiom.com
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0671.html">Joao Pedro: "Re: AND THEN, JUST TRANSPLANT THE BRAIN..."</a>
<li> <b>Previous message:</b> <a href="0669.html">E. Shaun Russell: "Re: Government is  Possible and Necessary"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
