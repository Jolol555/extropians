<!-- received="Mon Oct  6 02:48:47 1997 MDT" -->
<!-- sent="06 Oct 1997 09:30:33 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Genius dogs" -->
<!-- id="199710060555.WAA15850@well.com" -->
<!-- inreplyto="Sun, 5 Oct 1997 22:22:26 +0000"" -->
<title>extropians: Re: Genius dogs</title>
<h1>Re: Genius dogs</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>06 Oct 1997 09:30:33 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#172">[ date ]</a><a href="index.html#172">[ thread ]</a><a href="subject.html#172">[ subject ]</a><a href="author.html#172">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0173.html">Mikael Johansson: "Re: Bill Gates"</a>
<li> <b>Previous message:</b> <a href="0171.html">John K Clark: "Ethics and Morality"</a>
<li> <b>In reply to:</b> <a href="0157.html">Nicholas Bostrom: "Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0194.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
"Nicholas Bostrom" &lt;bostrom@mail.ndirect.co.uk&gt; writes:<br>
<p>
<i>&gt; If we take a human brain and simply speed it up enough, will it be a</i><br>
<i>&gt; superintelligence? Would a dog brain be?</i><br>
<p>
One has to distinguish qualitative intelligence, the ability to<br>
come up with good solutions to problems, from quantitative intelligence,<br>
the ability to solve many problems in a certain period of time.<br>
Speeding up a mind will only increase quantitative intelligence.<br>
<p>
The archetypal example is of course the uploaded dog: it will<br>
remain a dog, even if it lives for millennia. <br>
<p>
<i>&gt; 7. The Turing machine that is simulated runs the universal</i><br>
<i>&gt; intelligence algorithm (or alternatively simulates the evolution of</i><br>
<i>&gt; the brain states of an uploaded human genius). Amazing feats of genius</i><br>
<i>&gt; are performed by this dog house.</i><br>
<p>
The man screamed "No! Not the Chinese Room! Not the Chinese Room!" as<br>
the guards carried him away. <br>
<p>
As others have pointed out, it is not the dogs that are intelligent in<br>
this system, just as our neurons are not intelligent. The intelligence<br>
resides on a higher level. <br>
<p>
<i>&gt; -- I anticipate that Anders will suggest that superintelligences will </i><br>
<i>&gt; make entertainment out of shaping human organizations into </i><br>
<i>&gt; entities that perform intelligent tasks, just as we have fun by </i><br>
<i>&gt; watching circus animals behave. :-)</i><br>
<p>
It seems like you have a quite good simulation of my thought processes.<br>
<p>
About Eliezer's view that this would be immoral: I think it can be<br>
ethical to do, as long as the humans voluntarily agree to form the<br>
organisation. "Wow! Look at this: that PostAnders entity has a really <br>
great idea about a selforganized democracy. Let's try it!"<br>
<p>
<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0173.html">Mikael Johansson: "Re: Bill Gates"</a>
<li> <b>Previous message:</b> <a href="0171.html">John K Clark: "Ethics and Morality"</a>
<li> <b>In reply to:</b> <a href="0157.html">Nicholas Bostrom: "Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0194.html">Eliezer S. Yudkowsky: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
