<!-- received="Thu Oct  9 12:17:17 1997 MDT" -->
<!-- sent="Thu, 9 Oct 1997 10:37:30 -0700 (PDT)" -->
<!-- name="John K Clark" -->
<!-- email="johnkc@well.com" -->
<!-- subject="Genius Dogs" -->
<!-- id="199710091737.KAA12722@well.com" -->
<!-- inreplyto="" -->
<title>extropians: Genius Dogs</title>
<h1>Genius Dogs</h1>
John K Clark (<i>johnkc@well.com</i>)<br>
<i>Thu, 9 Oct 1997 10:37:30 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#350">[ date ]</a><a href="index.html#350">[ thread ]</a><a href="subject.html#350">[ subject ]</a><a href="author.html#350">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0351.html">Hal Finney: "Re: Genius Dogs"</a>
<li> <b>Previous message:</b> <a href="0349.html">Anders Sandberg: "Ampakines"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
-----BEGIN PGP SIGNED MESSAGE-----<br>
<p>
On Wed, 8 Oct 1997  Hal Finney &lt;hal@rain.org&gt; Wrote:<br>
<p>
<p>
<i>        &gt;I seem to recall a claim that Eric Drexler had an idea for creating </i><br>
<i>        &gt;synthetic intelligence by means of an evolution simulation. [...] I </i><br>
<i>        &gt;haven't been able to find the exact description of Drexler's idea, </i><br>
<i>        &gt;but I think it was on this list sometime in the last few years.  </i><br>
<i>        &gt;Does anybody remember this?</i><br>
<p>
I found this old post of mine.<br>
<p>
<p>
<p>
Date: Sat, 30 Dec 1995 <br>
From: John K Clark &lt;johnkc@well.com&gt;<br>
Subject: Drexler's Timeline<br>
<p>
<p>
I was only made aware of Drexler's thoughts on this subject second hand, <br>
through  Carl Feynman , you're receiving it third hand from me,  <br>
so if I say anything stupid in this post it is my fault, not Drexler's.<br>
<p>
The idea that the Singularity could come in less that 20 years<br>
makes me weak in the knees, just like everybody else, and I'm<br>
not sure I really believe  it could come that soon, but Drexler<br>
didn't just pull this amazingly short  timeline out of a hat, it's based <br>
on calculations he made, even if they are informal and unpublished. <br>
<p>
Seeing no reason current trends could not be extrapolated and<br>
using  his considerable knowledge of the field, he expects to<br>
see the first  assembler able to reproduce itself sometime in<br>
the first 2 decades of the next  century. A full nanotech<br>
computer could be made almost immediately after that, because<br>
the design work will already be finished by then, as some people<br>
are working  on that already. He figures that once we have nano<br>
computers it will only  take a couple of years to develop<br>
superhuman artificial intelligence. At this point we have a mind<br>
(or minds) far more intelligent than you or me, and one that<br>
operates a billion times faster to boot.  A few hours of that<br>
and the universe will never be the same again.<br>
<p>
I can already hear the howls of protest. Even if you have the<br>
hardware, programming a nano computer to do anything useful<br>
would be a  monumental task, and developing AI, superhuman or<br>
otherwise would be an  astronomically difficult process. I think<br>
Drexler would agree with his critics that it will take many<br>
years to develop AI, many millions of years actually.<br>
<p>
Drexler  suggests we develop AI in the same way that nature<br>
developed  intelligence, by brute force. Nature didn't need any<br>
experts with a deep  understanding  of intelligence or<br>
consciousness, intelligence just evolved, using only mutation<br>
and natural selection. We can do the same. <br>
   <br>
A recipe for intelligence: Build a simulated world in your<br>
computer and fill  it with very simple creatures (programs).<br>
Make sure they must solve problems  in order to get "food". The<br>
creatures that are better at solving problems  leave more<br>
descendants. Now you do nothing, just step back and let it <br>
evolve. After evolving for a few hundred  million SIMULATED years <br>
you have intelligence, high order intelligence.  <br>
   <br>
<p>
How long would it take in real years? He calculated the amount<br>
of computer  power needed to  simulate ALL the brains that have<br>
ever existed before humanity, that is, all the  brains since<br>
brains were invented in the Cambrian Explosion 570 million years<br>
ago. He concluded that  10^38 machine instructions would do the<br>
trick. A  Nanotechnology computer the size of a large present<br>
day factory and using no  more power, could perform 10^38<br>
machine instructions in about 2 years. <br>
<p>
Bottom line, you start with a nano computer but no software to<br>
run on it  except a few simple minded programs, smaller than<br>
many you are using now on  your home PC . 2 years later you've<br>
got an AI running on the computer,  an AI at least as<br>
intelligent as a human and much, much faster. <br>
<p>
As breathtaking as these changes are, it's really just<br>
engineering, Drexler  invokes no new laws of physics and assumes<br>
no scientific breakthroughs.  If there is one things would<br>
become even wilder. For example, if all the  recent speculation<br>
about Quantum computers ever pans out and a practical  machine<br>
is  possible, it would make even Drexler look like an old fuddy duddy.<br>
<p>
Somebody mentioned that safety concerns might slow things down,<br>
I doubt that it would, but perhaps it should. We are about to<br>
enter a period  of gargantuan  change happening in an<br>
astonishingly short amount of time, and that is an  inherently<br>
dangerous situation, it would be foolish to deny it. The biggest<br>
danger is probably something that we haven't imagined yet,<br>
probably something we are incapable of imagining. In my darker<br>
moments I wonder if that could be an explanation of the Fermi<br>
paradox, the fact that we don't see any ET's  and  the fact that<br>
the universe has not yet been engineered.<br>
<p>
In spite of the dangers I admit I'm happy about the coming<br>
changes, we  might survive it, and the alternative after all,<br>
is certain death for all of us. If  nothing else things won't be<br>
dull. The truth  however is, it doesn't matter a  hill of beans<br>
if you or I think it's a good idea or not, somebody, somewhere, <br>
will do it, and do it as soon as he thinks he can. The best we<br>
can do is  prepare ourselves as well as we can. <br>
<p>
Speaking of preparation, I don't want to be accused of promoting<br>
complacency  as far as Cryonics is concerned. Even a man as<br>
brilliant as Drexler could be wrong, especially about something<br>
like a timeline, as it involves more than science and<br>
engineering, but economics and politics as well. It's safest if<br>
people plan  for the worse and hope for the best. This is even<br>
more important for the leaders of the Cryonics companies. They<br>
should operate under the assumption that  if it will take 1000<br>
years for Nanotechnology to develop. If events in the next 20<br>
years  prove that they are wrong about that, I am certain nobody<br>
will be very upset with them.<br>
<p>
Regardless of when the Singularity happens one thing is certain,<br>
we are one year closer to it. HAPPY NEW YEAR!<br>
<p>
<p>
                                           John K Clark       johnkc@well.com<br>
<p>
-----BEGIN PGP SIGNATURE-----<br>
Version: 2.6.i<br>
<p>
iQCzAgUBND0RAH03wfSpid95AQGyxgTvcqdAQvCoPn39Uetz5IRFSpl+nGFxdyBQ<br>
WsvwhzgN6GRJJBjRiAffRJNe4cHdIOcy9iBZKQnve2lEMwszC+R/Mi4YZW5cmA9z<br>
nzglEYaMmY6tlEjKh7hoXltVM6WQo2/mNyh0DqULVkBU1B2t+ONvEyqPf1cCV44L<br>
ehedmJ/kbOeB7YhgozWm08eTQnhEWSwV1z32/aNE7Z7voc7lJeg=<br>
=lkTO<br>
-----END PGP SIGNATURE-----<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0351.html">Hal Finney: "Re: Genius Dogs"</a>
<li> <b>Previous message:</b> <a href="0349.html">Anders Sandberg: "Ampakines"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
