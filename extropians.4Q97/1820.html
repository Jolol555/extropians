<!-- received="Tue Nov 25 13:16:35 1997 MDT" -->
<!-- sent="Tue, 25 Nov 1997 13:16:26 -0700" -->
<!-- name="Brent Allsop" -->
<!-- email="allsop@swttools.fc.hp.com" -->
<!-- subject="Re: Uploading, that's needed !!  -Reply -Reply -Reply" -->
<!-- id="199711252016.AA146598986@raptor.fc.hp.com" -->
<!-- inreplyto="Uploading, that's needed !!  -Reply -Reply -Reply" -->
<title>extropians: Re: Uploading, that's needed !!  -Reply -Reply -Reply</title>
<h1>Re: Uploading, that's needed !!  -Reply -Reply -Reply</h1>
Brent Allsop (<i>allsop@swttools.fc.hp.com</i>)<br>
<i>Tue, 25 Nov 1997 13:16:26 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1820">[ date ]</a><a href="index.html#1820">[ thread ]</a><a href="subject.html#1820">[ subject ]</a><a href="author.html#1820">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1821.html">Jason Plog: "Re: Clade ships"</a>
<li> <b>Previous message:</b> <a href="1819.html">Lee Daniel Crocker: "Re: octopod*"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Hal Finney &lt;hal@rain.org&gt; continued:<br>
<p>
<i>&gt; Each neuron works in this conceptually simple way.  The complexity</i><br>
<i>&gt; of the brain arises from the fact that billions or trillions of</i><br>
<i>&gt; neurons are all interacting in a very complex network.  But if we</i><br>
<i>&gt; zoom in on any small portion of it, we see that this simple,</i><br>
<i>&gt; essentially mechanical activity is all that is happening.</i><br>
<p>
	I'm sorry I don't have a reference, but there was recently a<br>
discovery made of some chemicals that neurons can release that effect<br>
large numbers of near by neurons, even ones that have no direct<br>
synaptic connections.  Any simulation would have to take into account<br>
such chemical behavior and properly simulate it's changing effect on<br>
the behavior of other neurons.  The fact that we are still discovering<br>
things like this still leaves open the possibility of many things.<br>
<p>
<i>&gt; Now it is true that this model is not complete nor is it fully</i><br>
<i>&gt; verified.  It could turn out that there are other important effects</i><br>
<i>&gt; that are not yet recognized.  But most people would agree that this</i><br>
<i>&gt; model is at least logically possible.  It might be wrong, but</i><br>
<i>&gt; equally it might be right.  There would be no logical inconsistency</i><br>
<i>&gt; if it turned out that brains and neurons actually do work this way,</i><br>
<i>&gt; that underlying the complexity of brains, with all their sensations</i><br>
<i>&gt; and qualia, are these simple neural interactions.</i><br>
<p>
	I'm not saying that what we know about the brain is wrong.<br>
I'm sure there are some kind of, what Crick calls, "Neural Correlates"<br>
to qualia.  We simply don't yet know how these phenomenal qualities<br>
arise from these Neural Correlates and how they unify themselves into<br>
our phenomenal awareness.<br>
<p>
<i>&gt; The reason is because he does not accept the obvious conclusion of</i><br>
<i>&gt; the neuron-substitution thought experiment.  Given that neurons work</i><br>
<i>&gt; as postulated above, it should be possible to replace a neuron with</i><br>
<i>&gt; an electro-mechanical device.  It works identically to biological</i><br>
<i>&gt; neurons at the inputs and outputs, sensing and emitting</i><br>
<i>&gt; neurotransmitter chemicals.  But inside it is a computer, which is</i><br>
<i>&gt; designed to exactly mimic the behavior of the biological neuron it</i><br>
<i>&gt; replaces.  When the inputs reach certain thresholds, it waits for an</i><br>
<i>&gt; appropriate delay to simulate the travel of the neural impulse over</i><br>
<i>&gt; the body of the biological neuron, and then triggers its output</i><br>
<i>&gt; mechanism to release neurotransmitters in the same amount and timing</i><br>
<i>&gt; that the biological neuron would have done.</i><br>
<p>
	Red has real qualities.  We directly experience Red.  We know<br>
what red is like.  We can even come up with textual responses to try<br>
to describe what red is and isn't like.  Any machine that was<br>
abstractly simulating the behavior of a consciousness that experienced<br>
red, rather than actually producing conscious red, would have to have<br>
very complex abstract representations to identically reproduce all the<br>
qualities of red itself.  Indeed, the fact that red is so phenomenal,<br>
that it is so different than green, and even more different than salty<br>
and all our other sensations, and the way it can all be unified into<br>
one awareness model of the world, is what makes us so intelligent.<br>
Abstract representations, though they theoretically could model this<br>
powerfully intelligent behavior, I don't think they could do it<br>
practically.  You'd be programming a computer to lie if you tried to<br>
make it describe what red was really like.  And we all know that it<br>
takes much more complexity to consistently lie, than it does to tell<br>
the truth.<br>
<p>
<i>&gt; Some philosophers suggest that what will happen is that the</i><br>
<i>&gt; consciousness in the partly electronic brain will get "out of sync"</i><br>
<i>&gt; with the brain firing patterns.  It will notice that the qualia are</i><br>
<i>&gt; gone, but somehow it won't be able to report it.  Apparently it will</i><br>
<i>&gt; have lost control of its mouth.  This would presumably lead very</i><br>
<i>&gt; quickly to a total disconnect between the true consciousness, which</i><br>
<i>&gt; is panicking at having lost control of its body, and some other sort</i><br>
<i>&gt; of simulated consciousness, which seems to be going about its life</i><br>
<i>&gt; quite normally.  This would then imply that consciousness apparently</i><br>
<i>&gt; has virtually nothing to do with brain activity since they can</i><br>
<i>&gt; behave so independently.  Most people will not go so far into this</i><br>
<i>&gt; form of dualism.</i><br>
<p>
	Yes, this is not at all what I'm trying to describe.  All I'm<br>
saying is the neurons, in some natural way, produce the conscious<br>
qualia that we experience.  That the information we consciously know<br>
is represented by the complex models built out of these qualia in some<br>
way.  That the "quality" of the phenomenon is important and what<br>
consciousness is.  I am saying that any simulation would have to take<br>
into account and represent all these qualities and their differences.<br>
I believe that such would be only theoretically possible and not<br>
practically so because of the rich diversity of all our sensations.<br>
<p>
<i>&gt; I think that Brent will suggest instead that the thought experiment</i><br>
<i>&gt; won't work.  It would be impossible to substitute an electronic</i><br>
<i>&gt; neuron for a biological neuron without disrupting the brain's</i><br>
<i>&gt; activity.</i><br>
<p>
	I'd bet that there are phenomenal qualities that our<br>
consciousness do not use.  That there are sensations that we have not<br>
yet discovered.  I look forward to the discovery of other color qualia<br>
so we can have something to represent wavelengths of light outside of<br>
the current visual spectrum.  We can abstractly represent light<br>
outside the visible spectrum by mapping the wavelengths onto what we<br>
use to represent the visible wavelengths, but this will not be<br>
anything like, what actual different qualia will be like.<br>
<p>
<i>&gt; This is a very strong assertion.  It's not just a matter of saying</i><br>
<i>&gt; "we may be wrong", it's saying, "we must be wrong".</i><br>
<p>
	I am saying that the common sense idea that the tree we are<br>
aware of that we think is beyond our eyes is wrong is not really<br>
beyond our eyes.  The tree we are aware of is a tree constructed of<br>
phenomenal qualia in our brain via certain not yet completely<br>
understood neural correlate.  This tree we are aware of only<br>
abstractly represents the real tree beyond our eyes.<br>
<p>
	I am also saying that the idea that phenomenal sensations can<br>
some how magically arise from "hypercomplex relatedness" is also very<br>
wrong.  What we know must be represented by something very real.  Our<br>
conscious knowledge is built out of this stuff, whatever it is.<br>
<p>
	I am not saying that our current understanding of neural<br>
phenomenon is wrong.  I'm simply saying there is a bit more that we<br>
haven't discovered yet, and that the phenomenal quality of this stuff<br>
is just as important as the abstract causality of this stuff.<br>
<p>
<i>&gt; Personally, I don't find this very convincing, </i><br>
<p>
	What and where, then, do you think red is and what do you<br>
think our conscious knowledge is represented with?<br>
<p>
		Brent Allsop<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1821.html">Jason Plog: "Re: Clade ships"</a>
<li> <b>Previous message:</b> <a href="1819.html">Lee Daniel Crocker: "Re: octopod*"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
