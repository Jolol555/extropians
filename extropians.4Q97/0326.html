<!-- received="Wed Oct  8 21:40:57 1997 MDT" -->
<!-- sent="09 Oct 1997 06:16:48 +0300" -->
<!-- name="Leevi Marttila" -->
<!-- email="lm+extropians@sip.fi" -->
<!-- subject="Re: Genius dogs" -->
<!-- id="199710090241.WAA15518@gatecoms.gatecom.com" -->
<!-- inreplyto="Mon, 6 Oct 1997 22:00:33 +0000" -->
<title>extropians: Re: Genius dogs</title>
<h1>Re: Genius dogs</h1>
Leevi Marttila (<i>lm+extropians@sip.fi</i>)<br>
<i>09 Oct 1997 06:16:48 +0300</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#326">[ date ]</a><a href="index.html#326">[ thread ]</a><a href="subject.html#326">[ subject ]</a><a href="author.html#326">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0327.html">Estacado66@aol.com: "Re: Seven (po) questions for Estacado (was Re: Re: The Spike, nanotech, and a fu"</a>
<li> <b>Previous message:</b> <a href="0325.html">Gary Lloyd: "Re: "Morality?" - Composite Reply"</a>
<li> <b>In reply to:</b> <a href="0199.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0239.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
"Nicholas Bostrom" &lt;bostrom@mail.ndirect.co.uk&gt; writes:<br>
<p>
<i>&gt; (H) Take a person X of normal intelligence who knows the basics of </i><br>
<i>&gt; some standard programming language. Give him an arbitrarily powerful </i><br>
<i>&gt; computer, complete with camera eyes, microphones, robot arms etc. </i><br>
<i>&gt; Then it is possible to educate X in less than a week in such a way </i><br>
<i>&gt; that he will be able to program his computer to achieve </i><br>
<i>&gt; superintelligence.</i><br>
<p>
If machine language instruction set is something like Tierra,<br>
then I think it would be inevitable that person would introduce<br>
bugs in program. Some of those bug would be able to spread to<br>
whole computer and evolute to superintelligence. So it is probably<br>
inevitable that he would do that in a week if he is only told to<br>
program something.<br>
<p>
Could he solve chess with that computer without introducing<br>
superintelligence?<br>
<p>
What about programming game of life and starting with empty world?<br>
In the middle of world would be 3x3 units randomly mutated.<br>
That would probably lead to superintelligence.<br>
Initially it produces mostly wanderers and different static things.<br>
What would be the next basic unit conceptually when they make <br>
collisions etc...?<br>
<p>
<pre>
-- 
LM lm@sip.fi
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0327.html">Estacado66@aol.com: "Re: Seven (po) questions for Estacado (was Re: Re: The Spike, nanotech, and a fu"</a>
<li> <b>Previous message:</b> <a href="0325.html">Gary Lloyd: "Re: "Morality?" - Composite Reply"</a>
<li> <b>In reply to:</b> <a href="0199.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0239.html">Nicholas Bostrom: "Re: Genius dogs"</a>
<!-- reply="end" -->
</ul>
