<!-- received="Tue Dec 30 01:24:07 1997 MDT" -->
<!-- sent="Tue, 30 Dec 1997 01:15:10 +0000" -->
<!-- name="Nick Bostrom" -->
<!-- email="bostrom@ndirect.co.uk" -->
<!-- subject="Re: Future Technologies of Death" -->
<!-- id="199712300824.IAA15821@andromeda.ndirect.co.uk" -->
<!-- inreplyto="Future Technologies of Death" -->
<title>extropians: Re: Future Technologies of Death</title>
<h1>Re: Future Technologies of Death</h1>
Nick Bostrom (<i>bostrom@ndirect.co.uk</i>)<br>
<i>Tue, 30 Dec 1997 01:15:10 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3054">[ date ]</a><a href="index.html#3054">[ thread ]</a><a href="subject.html#3054">[ subject ]</a><a href="author.html#3054">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3055.html">Guru George: "Re[2]: Child Rrearing"</a>
<li> <b>Previous message:</b> <a href="3053.html">Tony Hollick: "Re: Child Rrearing"</a>
<li> <b>Maybe in reply to:</b> <a href="2894.html">Lee Daniel Crocker: "Future Technologies of Death"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3058.html">Anders Sandberg: "Re: Future Technologies of Death"</a>
<li> <b>Reply:</b> <a href="3058.html">Anders Sandberg: "Re: Future Technologies of Death"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Alexander 'Sasha' Chislenko wrote:<br>
<p>
<i>&gt; Sometimes, one of the children may have resolved the problem that</i><br>
<i>&gt; the whole batch of them was created (the task could be, for example,</i><br>
<i>&gt; improving of default communication protocols between intelligent nodes</i><br>
<i>&gt; in a knowledge network - i.e. development of a basic ethical system).</i><br>
<i>&gt; After the solution is found and tested, it can be implemented, and the</i><br>
<i>&gt; rest of the children can be suspended or killed in mid-execution.</i><br>
<i>&gt; They won't feel "hurt" , and neither will the environment - so what's the</i><br>
<i>&gt; problem?</i><br>
<p>
I suppose that in some people's ethics there would be a problem here. <br>
If you live in the desert and nobody else knows you exist, and then <br>
somebody shoot you in the head from behind, then it seems (to much of<br>
conventional ethics) that you have been done wrong, even though you <br>
are not around to complain about it and nobody else cares about you.<br>
<p>
When you say "Nobody will feel hurt, so what's the problem?", does <br>
that mean that you are a hedonist? If so, then the optimal <br>
organization of the world might be one where there is some amount of <br>
emotionless AI, and the rest of the available matter is transformed <br>
into pleasure-maximal structures -- say simulations of <br>
human brains having orgasms, but highly optimized and without <br>
unecessary cognitive functions.<br>
<p>
<i>&gt; (I have a problem here, with entities trying to</i><br>
<i>&gt; exercise their freedom and get rid of their unwanted parts, with these</i><br>
<i>&gt; parts disagreeing.  Could I shave off my moustache if it was intelligent</i><br>
<i>&gt; and arguing for its right to continue its existence in its natural habitat?</i><br>
<i>&gt; Or I could only create a clone of myself without the moustache, leaving</i><br>
<i>&gt; the moustached original enslaved to a tuft of intelligent hair.  How intelligent</i><br>
<i>&gt; do we want the [sub-]entities to be to grant them such rights? )</i><br>
<p>
Interesting question. I think that Anders has the rule of thumb that <br>
an entity has rights if and only if it can demand them. That rule <br>
has some repugnant consequences though. It seems to imply that we <br>
could torture animals and butch humans who are retarded. (Perhaps the <br>
rule is only supposed to state a sufficient condition for having <br>
rights, not a necessary one?)<br>
<p>
<p>
<i>&gt;   Even in this situation of infinite resources though, all interesting and efficient</i><br>
<i>&gt; things/beings will be distinct from the ones created under "Rights of Continuing</i><br>
<i>&gt; Existence" or "Rights of Implementation" Acts.  Those entities will be all</i><br>
<i>&gt; garbage, and every single one of them that has any intelligence will be aware</i><br>
<i>&gt; of it.  They will represent practically all existing structures at any time, and may</i><br>
<i>&gt; occupy any point in the Universe, except that on its semantic map they will</i><br>
<i>&gt; never be on the frontier, always banished to the inner semantic junkyard/ the Slow</i><br>
<i>&gt; Zone, knowing that they are completely unneeded, their goals have no meaning,</i><br>
<i>&gt; and their wishes to attach themselves to anything else, though always granted,</i><br>
<i>&gt; create nothing but useless, ever-suffering cripples.</i><br>
<p>
But then again, they may be perfectly content with watching TV, or <br>
looking at their navels. There might be a pill that rids them of <br>
their extropian urge for achievement.<br>
<p>
BTW, we have the same problem today, with an increasing number of <br>
old, decrepit people vegetating away in the old people's homes. These <br>
people take up resources that could be used to sustain <br>
vibrant, productive, life-enjoying young men and women. But nobody <br>
seriously suggests that we massacre the old.<br>
<p>
 <br>
<i>&gt; If this all starts sounding like a bizarre dream, this must be for a reason.  I think</i><br>
<i>&gt; we should drop the remnants of anthropomorphism.  We made a step in this</i><br>
<i>&gt; direction when we started discussing evolution instead of static identities, and</i><br>
<i>&gt; another step - with transition from structure threads to goal threads as the</i><br>
<i>&gt; subjects of progress.</i><br>
<p>
Yes, I think that the view that in the future values will serve as <br>
the principium individuationis has much to be said for it.<br>
<p>
<p>
________________________________________________<br>
Nick Bostrom<br>
n.bostrom@lse.ac.uk<br>
<p>
          *Visit my transhumanist web site*<br>
            <a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3055.html">Guru George: "Re[2]: Child Rrearing"</a>
<li> <b>Previous message:</b> <a href="3053.html">Tony Hollick: "Re: Child Rrearing"</a>
<li> <b>Maybe in reply to:</b> <a href="2894.html">Lee Daniel Crocker: "Future Technologies of Death"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3058.html">Anders Sandberg: "Re: Future Technologies of Death"</a>
<li> <b>Reply:</b> <a href="3058.html">Anders Sandberg: "Re: Future Technologies of Death"</a>
<!-- reply="end" -->
</ul>
