<!-- received="Wed Apr  7 17:30:12 1999 MDT" -->
<!-- sent="Wed, 08 Apr 1998 18:32:05 -0500" -->
<!-- name="Darin Sunley" -->
<!-- email="umsunley@cc.umanitoba.ca" -->
<!-- subject="Geniebusters" -->
<!-- id="352C08F5.11B1@cc.umanitoba.ca" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=52 -->
<html><head><title>extropians: Geniebusters</title>
<meta name=author content="Darin Sunley">
<link rel=author rev=made href="mailto:umsunley@cc.umanitoba.ca" title ="Darin Sunley">
</head><body>
<h1>Geniebusters</h1>
Darin Sunley (<i>umsunley@cc.umanitoba.ca</i>)<br>
<i>Wed, 08 Apr 1998 18:32:05 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#271">[ date ]</a><a href="index.html#271">[ thread ]</a><a href="subject.html#271">[ subject ]</a><a href="author.html#271">[ author ]</a>
<!-- next="start" -->
<li><a href="0272.html">[ Next ]</a><!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0272.html">phoenix@ugcs.caltech.edu</a>
</ul>
<!-- body="start" -->

<p>
Mr. Burkhead maps back and forth between cost, intelligence and
complexity, between biological systems and nanites, and (especially!)
between robots and software agents so often, and with so little
justification, it's hard to see just WHAT he ends up establishing.

<p>
For the record:

<p>
Intelligence does not necessarily map to complexity, and NEITHER of them
necessarily map to cost. This is particularly relevant to the argument
in section 21 referring to bootstrapping intelligences.

<p>
For reasons given already, both on this list and in Mr. Yudkowsky's
"Coding a Transhuman AI", we have NO REASON WHATSOEVER to believe that
our brains are the minimum complexity required for our level of
intelligence.

<p>
Additionally, many engineering projects ARE mostly pre-designed. I can
assure Mr. Burkhead that almost all of the discrete components of my
computer were not specially designed for my particular configuration.
The re-use of component designs of established quality is one of the
cornerstones of computer engineering. This practice s in large part
responsible for the rapid pace of technological progress in computers
and personal electronics. One of the promises of nanotechnology is to
allow electronics-like design principles to be practiced on a wider
scale, with the corresponding benefits.

<p>
Furthermore, complexity does not map to cost. I would be most interested
to find out that my Pentium II 450Mhz, for which I paid approxiamately
$900 US, is approxiamately one half the complexity of my father's 80386
20Mhz, for which he paid ~$2000 US in the late 1980's.

<p>
The most flagrant abuse of this mapping, or "calibration", occurred in
section 19. While the macro-scale "Chinabots" of section 17 would
admittedly have the limitations discussed, it is not immediatly clear
that any of those limitations map to nanobots or nanites. They most
especially do not map to software agents performing complex actions
(programming) within a computer's memory. "Microserfs", once created,
are neither rare nor particularly expensive. Irrelevant licensing
agreements not withstanding, there is no reason I cannot have as many as
I want running concurrently. They can be duplicated as easily as any
other piece of software. This ease of duplication and tight coupling of
description to implementation (for computer programs, they are
identical) is another of the promises of this technology. 

<p>
While the latter section of Geniebusters does not have as many flagrant
errors as the earlier sections, its theorems and "proofs" are built upon
the badly fractured foundation of what has come before.

<p>
To conclude, what Mr. Burkhead refers to as "the calibration meme" seems
nothing more then the meme of constructing poor analogies, and hiding
them behind the prestige of "mathematical mappings."
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0272.html">[ Next ]</a><!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0272.html">phoenix@ugcs.caltech.edu</a>
</ul>
</body></html>
