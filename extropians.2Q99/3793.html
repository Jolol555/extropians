<!-- received="Mon Jun 14 00:29:21 1999 MDT" -->
<!-- sent="Sun, 13 Jun 1999 23:26:49 -0700" -->
<!-- name="hal@rain.org" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: TECH: Fractal Tardis Brains" -->
<!-- id="199906140626.XAA04829@226-132.adsl2.avtel.net" -->
<!-- inreplyto="TECH: Fractal Tardis Brains" -->
<!-- version=1.10, linesinbody=64 -->
<html><head><title>extropians: Re: TECH: Fractal Tardis Brains</title>
<meta name=author content="hal@rain.org">
<link rel=author rev=made href="mailto:hal@rain.org" title ="hal@rain.org">
</head><body>
<h1>Re: TECH: Fractal Tardis Brains</h1>
<i>hal@rain.org</i><br>
<i>Sun, 13 Jun 1999 23:26:49 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3793">[ date ]</a><a href="index.html#3793">[ thread ]</a><a href="subject.html#3793">[ subject ]</a><a href="author.html#3793">[ author ]</a>
<!-- next="start" -->
<li><a href="3794.html">[ Next ]</a><a href="3792.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3737.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky, &lt;sentience@pobox.com&gt;, writes, quoting me:
<br>
<a href="3737.html#3793qlink1">&gt; &gt; Or do you</a><br>
<i>&gt; &gt; mean that computational worlds holding intelligent entities may exist,</i><br>
<i>&gt; &gt; but that our own particular world is not computational, because of certain</i><br>
<i>&gt; &gt; specific characteristics that may not be shared with other worlds?</i><br>
<i>&gt;</i><br>
<i>&gt; Yes.  Turing machines can be intelligent, but "intelligence" is an</i><br>
<i>&gt; observer-relative property; there's no absolute property test for</i><br>
<i>&gt; "intelligence".  I think that having any sort of absolute property test</i><br>
<i>&gt; obviously requires an absolute test for "instantiation", a concept which</i><br>
<i>&gt; has no mathematical definition.  In fact, my attempts to construct a</i><br>
<i>&gt; definition led me to think that instantiation is fundamentally</i><br>
<i>&gt; observer-relative.  Since I believe in an absolute test for "reality"</i><br>
<i>&gt; and "consciousness", ergo reality and consciousness are noncomputable. </i><br>
<i>&gt; But I don't believe in an absolute test for "intelligence", and so I see</i><br>
<i>&gt; no reason why I can't construct a transhuman AI.</i><br>

<p>
<a name="3796qlink1">So your transhuman AI would be intelligent but not conscious?</a>

<p>
<a name="3796qlink2">Do you believe then in zombies, beings which act conscious but which
actually are not?  Or would you say that any intelligent computer program
would (in some sense) know that it is not conscious?</a>

<p>
<a name="3796qlink3">Moravec has an interesting thought experiment in which a CA model like
Conway's game of Life runs for long enough to evolve living organisms
which then develop intelligence.  Would you say that this is possible?</a>

<p>
<a name="3796qlink4">If so, could they then evolve communication, societies, emotions, fiction,
philosophical speculations about the meaning of life?  Or would some
of these avenues be foreclosed to them because they are computationally
bound?</a>

<p>
<a name="3796qlink5">I don't see where to draw the line here.  I don't see anything stopping
these beings from evolving intelligence and emotion and all the other
characteristics we would associate with consciousness.</a>  What gives us
<a name="3796qlink6">the privileged position to step in and say that although they act like
they are conscious, and claim to be conscious, they actually are not?</a>

<p>
<a name="3796qlink7">The one legitimate argument I could see along these lines would be the
idea that computability is simply too weak a mechanism to produce minds
<a name="3796qlink8">like ours.</a>  Penrose claims that our minds rely on some form of ultra
computability, which goes beyond Turing computability.  Presumably in
</a>
<a name="3796qlink9">this model no matter how long you let a computer evolve or how hard you
work at programming it, it will never show the full level of functional
mental competence that human beings have (including, per Penrose, the
ability to do mathematics as well as humans).  A more powerful primitive
is needed to allow that level of functionality.</a>

<p>
<a name="3796qlink10">Although I don't think there is much empirical evidence for this position,
it is more philosophically attractive than accepting the existence
of zombies.  It seems that rejecting computationalism requires you to
accept one of these two possibilities.</a>

<p>
<a name="3796qlink11"><a href="3737.html#3793qlink2">&gt; I'm extremely conservative when it comes to reality.  I'm willing to</a><br>
<i>&gt; believe that quarks are objectively real.  I'm willing to believe that</i><br>
<i>&gt; qualia are objectively real.  I don't believe in the laws of physics,</i><br>
<i>&gt; mathematical theorems, apples, or any other abstracted properties.</i><br>

<p>
I am having some trouble following you here.  What do you mean, you don't
believe in the laws of physics?  Didn't you say earlier that you thought
they were "real" (and hence malleable)?
</a>

<p>
Hal
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3794.html">[ Next ]</a><a href="3792.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3737.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
