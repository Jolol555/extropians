<!-- received="Sun Apr 18 11:57:45 1999 MDT" -->
<!-- sent="Sun, 18 Apr 1999 13:51:57 -0400" -->
<!-- name="Randall Randall" -->
<!-- email="wolfkin@freedomspace.net" -->
<!-- subject="Re: Near-Term Futility of AI Research" -->
<!-- id="99041814013605.00401@wolfkin" -->
<!-- inreplyto="Near-Term Futility of AI Research" -->
<!-- version=1.10, linesinbody=65 -->
<html><head><title>extropians: Re: Near-Term Futility of AI Research</title>
<meta name=author content="Randall Randall">
<link rel=author rev=made href="mailto:wolfkin@freedomspace.net" title ="Randall Randall">
</head><body>
<h1>Re: Near-Term Futility of AI Research</h1>
Randall Randall (<i>wolfkin@freedomspace.net</i>)<br>
<i>Sun, 18 Apr 1999 13:51:57 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#568">[ date ]</a><a href="index.html#568">[ thread ]</a><a href="subject.html#568">[ subject ]</a><a href="author.html#568">[ author ]</a>
<!-- next="start" -->
<li><a href="0569.html">[ Next ]</a><a href="0567.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0564.html">Quaenos@aol.com</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
I've lately thought that on Sun, 18 Apr 1999, Quaenos@aol.com wrote:
<br>
<a href="0564.html#0568qlink1">&gt;Eliezer Yudkoswky writes:</a><br>
<i>&gt;</i><br>
<i>&gt;&gt;Tell James Bradley that we are coming for him.  ("We", in this case,</i><br>
<i>&gt;&gt;being AI researchers.)  We are coming for the Mona Lisa.  We are coming</i><br>
<i>&gt;&gt;for music.  We are coming for laughter.  We are coming for love.  It's</i><br>
<i>&gt;&gt;only a matter of time.</i><br>
<i>&gt;</i><br>
<i>&gt;AI research is a dead end in the short term. Current AI research isn't </i><br>
<i>&gt;accomplishing anything. Until we have a better understanding of human </i><br>
<i>&gt;cognition and the brain in general AI is not going to make any significant </i><br>
<i>&gt;progress. Co-called AI researchers would perform a better service for </i><br>
<i>&gt;themselves and the AI field if they devoted their time and resources to </i><br>
<i>&gt;neuroscience.</i><br>
<i>&gt;</i><br>
<i>&gt;Think about it. Can anyone point to achievements made in the field of AI in </i><br>
<i>&gt;the last year? </i><br>

<p>
Great strides in voice recognition?

<p>
<i>&gt;5 years? </i><br>

<p>
Lessee...a coupla years ago some computer-driven vehicles were
allowed to drive across the US.

<p>
10 years? 

<p>
Um....optical character recognition.

<p>
<a href="0564.html#0568qlink2">&gt;There are no conceptual achievements. There </a><br>
<i>&gt;is an illusion of progress, but it is not conceptual. The illusion is created </i><br>
<i>&gt;by increases in computing power available to AI researchers. Implementing the </i><br>
<i>&gt;same AI concept on a faster machine yields a more productive result. On the </i><br>
<i>&gt;surface, it appears progress has been made in the AI field. But, in fact, </i><br>
<i>&gt;there has been no conceptual progress in some time. AI researchers are </i><br>
<i>&gt;justing tinkering with faster machines now.</i><br>

<p>
This is precisely AI researcher Hans Moravec's argument *for* AI.
After all, since great strides were made as soon as processing power
increased slightly (by the standards of the human brain), it would seem
that AI research is on the right track, and that they were too hopeful
that very low processing levels could achieve much.

<p>
<a href="0564.html#0568qlink3">&gt;Look at the deities of the AI pantheon, Minsky, Searle, what have</a><br>
<i>&gt;they produced in the last 5 or 10 or even 20 years? Who has </i><br>
<i>&gt;expanded on Turing's work? If Turing is the AI field's Newton, </i><br>
<i>&gt;where is the Einstein? All I see lately is discussions about the </i><br>
<i>&gt;limits of computation, club-handed discussions of consciousness, </i><br>
and starry-eyed fantasies of Powers. There is a disconnect. Where 
<br>
<a href="0564.html#0568qlink4">&gt;is the transhumanist explanation for lack of AI progress? Why don't </a><br>
<i>&gt;AI researchers realize they aren't getting *anywhere* until we  </i><br>
<i>&gt;understand the operation of the human mind? And if the transhumanists</i><br>
<i>&gt;don't even realize this quagmire, who else will?</i><br>

<p>
While AI seems inevitable in short order, I would tend to agree that
the current focus of the field is not going to produce consciousness,
but only great "intelligence".  

<pre>
--
Wolfkin.
wolfkin@freedomspace.net | Libertarian webhost? www.freedomspace.net
On a visible but distant shore, a new image of man;
The shape of his own future, now in his own hands.-- Johnny Clegg.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0569.html">[ Next ]</a><a href="0567.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0564.html">Quaenos@aol.com</a>
<!-- nextthread="start" -->
</ul>
</body></html>
