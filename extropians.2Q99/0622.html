<!-- received="Mon Apr 19 09:57:46 1999 MDT" -->
<!-- sent="Mon, 19 Apr 1999 08:57:37 -0700" -->
<!-- name="Peter C. McCluskey" -->
<!-- email="pcm@rahul.net" -->
<!-- subject="Re: Geniebusters" -->
<!-- id="199904191557.AA28934@foxtrot.rahul.net" -->
<!-- inreplyto="Geniebusters" -->
<!-- version=1.10, linesinbody=35 -->
<html><head><title>extropians: Re: Geniebusters</title>
<meta name=author content="Peter C. McCluskey">
<link rel=author rev=made href="mailto:pcm@rahul.net" title ="Peter C. McCluskey">
</head><body>
<h1>Re: Geniebusters</h1>
Peter C. McCluskey (<i>pcm@rahul.net</i>)<br>
<i>Mon, 19 Apr 1999 08:57:37 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#622">[ date ]</a><a href="index.html#622">[ thread ]</a><a href="subject.html#622">[ subject ]</a><a href="author.html#622">[ author ]</a>
<!-- next="start" -->
<li><a href="0623.html">[ Next ]</a><a href="0621.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0485.html">Lyle Burkhead</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->


<p>
 lybrhed@earthlink.net ("Lyle Burkhead") writes:
<br>
<a href="0485.html#0622qlink1">&gt;Is scenario #2 more plausible than #1? Why? Why would a mite-sized Exxon</a><br>
<i>&gt;take orders from me, when the actual Exxon wouldn't?</i><br>

<p>
 A decade ago it seemed implausible to me that search engines, mailing lists,
or my favorite OS would ever be free. So I'm rather skeptical of appeals to
intuition about what services will cost decades from now.

<p>
 Drexler assumes that with sufficient cpu power, creating an AI is
easy enough that someone will probably make one available as open source,
and the cost of creating new intelligence by copying one is near zero.
This implies that if the price of intelligence is set by supply and demand,
it will be roughly equal to the price of the required cpu/ram/disk resources.

<p>
 There's no trend towards AI, you say? (Or at least no Moore's Law style
trend?). It's hard to tell whether that's true, or whether it implies much
if true. There has been some clear progress in vision and speech recognition
software produced by Moore's Law. Does that represent the kind of progress
needed to produce AI around the time that Moore's Law gets us to atomic
precision? Or do we already know most of what's needed for AI, but simply
lack the hardware for it to be worthwhile completing an AI (the way it
wouldn't have been worthwhile building a spreadsheet or browser in 1965)?
 I don't see how to be confident of the answers to these questions.
 I can certainly imagine ways to produce digital intelligence that wouldn't
be expected to show any trend yet. Drexler estimates that nanotech will
produce enough cpu power that a simulation of the evolutionary processes
that produced humans would take about 2 years. Or scanning a human brain
and emulating it in software without needing to understand much more than
how to simulate a neuron.
<pre>
-- 
------------------------------------------------------------------------
Peter McCluskey          | Critmail (<a href="http://crit.org/critmail.html">http://crit.org/critmail.html</a>):
<a href="http://www.rahul.net/pcm">http://www.rahul.net/pcm</a> | Accept nothing less to archive your mailing list
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0623.html">[ Next ]</a><a href="0621.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0485.html">Lyle Burkhead</a>
<!-- nextthread="start" -->
</ul>
</body></html>
