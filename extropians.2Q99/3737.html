<!-- received="Sat Jun 12 20:50:07 1999 MDT" -->
<!-- sent="Sat, 12 Jun 1999 21:50:38 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: TECH: Fractal Tardis Brains" -->
<!-- id="37631C7C.C87605E8@pobox.com" -->
<!-- inreplyto="TECH: Fractal Tardis Brains" -->
<!-- version=1.10, linesinbody=105 -->
<html><head><title>extropians: Re: TECH: Fractal Tardis Brains</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: TECH: Fractal Tardis Brains</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sat, 12 Jun 1999 21:50:38 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3737">[ date ]</a><a href="index.html#3737">[ thread ]</a><a href="subject.html#3737">[ subject ]</a><a href="author.html#3737">[ author ]</a>
<!-- next="start" -->
<li><a href="3738.html">[ Next ]</a><a href="3736.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3722.html">hal@rain.org</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
hal@rain.org wrote:
<br>
<i>&gt; </i><br>
<a href="3722.html#3737qlink1">&gt; Eliezer S. Yudkowsky, &lt;sentience@pobox.com&gt;, writes:</a><br>

<p>
<a href="3722.html#3737qlink2">&gt; &gt; I entirely disagree.  These things aren't limits.  Laws, maybe, but not</a><br>
<i>&gt; &gt; limits.  This century's history has been the history of people realizing</i><br>
<i>&gt; &gt; that so-called "limits" had been obviously bankrupt from the beginning.</i><br>
<i>&gt; &gt; 100 years CRNS (current-rate no-Singularity) from now, everyone will be</i><br>
<i>&gt; &gt; laughing at us for believing in the lightspeed limit when there was</i><br>
<i>&gt; &gt; General Relativity, wormholes, Warp-Tardis Drive...</i><br>
<i>&gt; </i><br>
<i>&gt; I am confused here whether you consider lightspeed to be a limit or a law.</i><br>
<i>&gt; Is it something that we will transcend, or a law which we will use as</i><br>
<i>&gt; a tool?</i><br>

<p>
I consider it to be part of the structure of reality, but not
necessarily a limit.  Will anyone ever step on the gas and go faster
than "C"?  Not without magic.  But that doesn't mean you can't get to
Alpha Centauri in less than four years; you can compress space, warp
space, go to your destination in 4.3 years and then loop around a Tipler
cylinder, etc. etc.  Special Relativity imposes an absolute lightspeed
limit on instantaneous velocity relative to immediate space, but when
you consider actual travel, on a global scale, then you start dealing
with General Relativity - the speed of light is also relative.

<p>
<a href="3722.html#3737qlink3">&gt; &gt; As for the uncertainty principle, despite the name, it isn't a limit on</a><br>
<i>&gt; &gt; knowledge.  Not at all.  It describes a very specific process known as</i><br>
<i>&gt; &gt; state-vector reduction which randomizes certain quantities at a certain</i><br>
<i>&gt; &gt; point in time.  This process, in turn, has all kinds of interesting</i><br>
<i>&gt; &gt; potential - including an apparent FTL propagation, come to think of it.</i><br>
<i>&gt; &gt; Calling it a "limit" is abusing the term, if you ask me.  I say it's a tool.</i><br>
<i>&gt; </i><br>
<i>&gt; I can see that such things as quantum uncertainty, or conservation</i><br>
<i>&gt; of energy, or the law of gravity can be seen either as limits that</i><br>
<i>&gt; constrain what we do, or as tools that we can exploit to accomplish</i><br>
<i>&gt; our aims.  It is a bit harder to see how FTL limitations can be used</i><br>
<i>&gt; as a tool, but perhaps once we are able to bump up against them things</i><br>
<i>&gt; will look different.  Black hole engineering, for example, is intimately</i><br>
<i>&gt; intertwined with the FTL limits and may be an important tool someday.</i><br>

<p>
Precisely.  I don't think the term "physical limit" is appropriate for
anything on which a paper has been published showing a loophole.  Then
it's a "practical limit", and we know what happens to those...

<p>
<a href="3722.html#3737qlink4">&gt; &gt; Actually, my position that all laws are malleable isn't based on an</a><br>
<i>&gt; &gt; Extropian morality; it's based on my ontological belief that "laws" are</i><br>
<i>&gt; &gt; actually "stuff".  Anything real can be modified; if laws are real, they</i><br>
<i>&gt; &gt; can be modified.  A rigid, Turing-like distinction between "program" and</i><br>
<i>&gt; &gt; "content", or "rules" and "cells", starts getting you into the same</i><br>
<i>&gt; &gt; paradoxes that made me a noncomputationalist in the first place.</i><br>
<i>&gt; </i><br>
<i>&gt; This is an interesting speculation, but it is not really a philosophically</i><br>
<i>&gt; defensible derivation IMO.  You need to analyze the meaning of "real"</i><br>
<i>&gt; very carefully.  I suspect that when you do, you find that when you say</i><br>
<i>&gt; "anything real can be modified" you mean one thing, and when you say that</i><br>
<i>&gt; "laws are real" you mean something else by "real".</i><br>

<p>
That is *exactly* what I mean the same thing by, as it were.  I don't
believe in Platonic laws.  All laws are stuff.

<p>
<a href="3722.html#3737qlink5">&gt; When you say that you are a noncomputationalist, do you mean that it will</a><br>
<i>&gt; be impossible to construct a working AI which is conscious?</i><br>

<p>
I mean it'll take special hardware for old-fashioned qualia - probably
not very difficult hardware, either, since an ordinary brain can hack
it.  Almost certainly, human-equivalent intelligence won't take any
special hardware.

<p>
<a href="3722.html#3737qlink6">&gt; Or do you</a><br>
<a name="3793qlink1"><i>&gt; mean that computational worlds holding intelligent entities may exist,</i><br>
<i>&gt; but that our own particular world is not computational, because of certain</i><br>
<i>&gt; specific characteristics that may not be shared with other worlds?</i><br>

<p>
Yes.  Turing machines can be intelligent, but "intelligence" is an
observer-relative property; there's no absolute property test for
"intelligence".  I think that having any sort of absolute property test
obviously requires an absolute test for "instantiation", a concept which
has no mathematical definition.  In fact, my attempts to construct a
definition led me to think that instantiation is fundamentally
observer-relative.  Since I believe in an absolute test for "reality"
and "consciousness", ergo reality and consciousness are noncomputable. 
But I don't believe in an absolute test for "intelligence", and so I see
no reason why I can't construct a transhuman AI.</a>

<p>
I don't believe that "2 + 2 = 4" is a fundamental law, and I don't
believe that "2 + 2 = 4" is real.  I can't define "instantiation" and I
don't believe it can be defined; either everything Turing-computable is
real, or nothing Turing-computable is real, and I believe "nothing".  "2
+ 2 = 4" is Turing computable, so it's not real.  Arithmetic is an
abstracted property, a derivative of underlying reality, that is
"proved" by induction and that I use because it's convenient.  Maybe the
Turing laws and mathematics can be derived from the underlying laws in
some way; even so, it's still just an abstraction - and I don't believe
that abstractions are objectively real.

<p>
<a name="3793qlink2">I'm extremely conservative when it comes to reality.  I'm willing to
believe that quarks are objectively real.  I'm willing to believe that
qualia are objectively real.  I don't believe in the laws of physics,
mathematical theorems, apples, or any other abstracted properties.</a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3738.html">[ Next ]</a><a href="3736.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3722.html">hal@rain.org</a>
<!-- nextthread="start" -->
</ul>
</body></html>
