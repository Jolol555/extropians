<!-- received="Tue Apr 13 23:51:59 1999 MDT" -->
<!-- sent="Wed, 14 Apr 1999 02:00:07 -0400" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: LIST: the Gooies" -->
<!-- id="4.1.19990413221540.00a704e0@dgf4.mail.yale.edu" -->
<!-- inreplyto="199904132141.OAA20952@gull.prod.itd.earthlink.net" -->
<!-- version=1.10, linesinbody=133 -->
<html><head><title>extropians: Re: LIST: the Gooies</title>
<meta name=author content="Dan Fabulich">
<link rel=author rev=made href="mailto:daniel.fabulich@yale.edu" title ="Dan Fabulich">
</head><body>
<h1>Re: LIST: the Gooies</h1>
Dan Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Wed, 14 Apr 1999 02:00:07 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#493">[ date ]</a><a href="index.html#493">[ thread ]</a><a href="subject.html#493">[ subject ]</a><a href="author.html#493">[ author ]</a>
<!-- next="start" -->
<li><a href="0494.html">[ Next ]</a><a href="0492.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0481.html">Lyle Burkhead</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
At 02:40 PM 4/13/99 -0700, Lyle Burkhead wrote:
<br>
<a href="0481.html#0493qlink1">&gt;Dan Fabulich writes, </a><br>
<i>&gt;</i><br>
<i>&gt;&gt; I've got a new one for you. You've tried straw-man. </i><br>
<i>&gt;&gt; You've tried parody. You've even tried direct ad hominem. </i><br>
<i>&gt;&gt; Have you considered presenting your points in clear </i><br>
<i>&gt;&gt; straight-forward essay style?  </i><br>
<i>&gt;</i><br>
<i>&gt;See my reply to Eliezer on the Geniebusters thread.  Or, see Geniebusters</i><br>
<i>&gt;itself.  </i><br>

<p>
I did.  Is that your straight-forward essay?  Your use of "exercises" is
condescending, and backfires a lot of the time.  Indeed, the whole text was
apparently designed in such a way as to get readers to come up with exactly
the answers you want them to come up with (or to not come up with any
answer at all, when that was your intended effect).  As a result, I found
myself puzzling over several sections of your argument, where I had clearly
given an answer to one of your exercises that you didn't expect...  I
answered questions which you thought had no answer, or I thought of cheap
ways to do things you assumed were expensive.  Making your assumptions
clear, as well as your conclusions, is a better (and clearer) way to write
an argument.

<p>
<a href="0481.html#0493qlink2">&gt;You might try heeding your own advice, by the way.  You accuse me of using</a><br>
<i>&gt;straw-man arguments, but you don't say which arguments you are referring</i><br>
<i>&gt;to.  I'd like to see a clear, straightforward essay from you on that point.</i><br>
<i>&gt; Please show me which of my arguments are straw-man arguments.  </i><br>

<p>
OK, I'll give it a try.  Eliezer actually beat me to the punch on this one,
on most counts...  Though I'll actually jump in and defend the "genie
machine" concept where he wouldn't.

<p>
That is, I think we can make a machine with a whole lot of pre-programmed
products loaded in it.  You want to make a violin?  Say "I want a violin."
You want a submarine sandwich?  Say "make me a submarine sandwich with
everything on it."  It won't be able to make anything that it hasn't been
programmed to make, but it will be able to make anything that it has
already been programmed to make.  The only AI present will be a Natural
Language Parser, or, as Drexler put it, an AI with "both great technical
ability and the social ability needed to understand human speech and
wishes."  Ask it to make a submarine and it might say "I'm sorry, Lyle, I
can't do that."

<p>
[Straw Man: Where does Drexler say that the Shape Shifter, or the genie
machine, wouldn't have to be programmed?]

<p>
You claim that having the ability to move individual atoms won't make a
genie machine, because we'll still have to program it.

<p>
Now, nobody doubts that programming a nano-assembler will be expensive.  AI
might make this somewhat cheaper, but it might not.  No matter.  The point
is that programming a nano-assembler is expensive; you can't just summon up
a submarine sandwich by genie power alone.

<p>
However, as you surely realize, the whole point behind automating
production is that you can make automated stuff much cheaper than you can
make stuff manually, even though the cost of designing the automation
system is much greater than the cost of making one unit of stuff.

<p>
Thus, if some group of people, somewhere, ANYWHERE, managed to write a
program which could tell a universal assembler how to make a violin, (write
the program == automate the whole system) then from then on anybody who had
the program and some replicators could make a violin from raw materials.
Writing the violin program is thus a sunk cost; from then on, the cost of
making a violin would be small.  Now, you may still have to pay a lot to
get your hands on the violin program if intellectual property rights are
well enforced, but once you did, you could make a lot of violins very cheaply.

<p>
<i>&gt;The same considerations would apply to diamond trees, if they existed. If</i><br>
<i>&gt;diamonds are made by replicators, that does not imply that they will be</i><br>
<i>&gt;free, or as cheap as potatoes.</i><br>
<i>&gt;</i><br>
<i>&gt;In fact when you go from natural trees to diamond trees, the situation will</i><br>
<i>&gt;change for the worse. Natural trees don't require much of an investment.</i><br>
<i>&gt;Agricultural land is not expensive. Neither is fertilizer. Agriculture is a</i><br>
<i>&gt;fairly low-tech business. A "diamond tree" (i.e. a machine that uses</i><br>
<i>&gt;replicating atomic positioners to produce diamonds) will require an</i><br>
<i>&gt;enormously complex and expensive environment. Besides, an orange tree</i><br>
<i>&gt;doesn't have to be designed. A diamond tree does. (No, don't tell me about</i><br>
<i>&gt;Genies!) </i><br>

<p>
You make that claim about a nanite's "complex and expensive environment"
pretty offhandedly.  You didn't even make me do an exercise to try to guess
how complex or expensive you think it would be.  Can you justify the claim?

<p>
As for the fact that it would have to be designed: you're right.  But, once
designed, copies of the design, and copies of the tree, would be cheap.
Maybe even as cheap as potatoes.

<p>
You also make a big deal about the cost of retooling.  You seem to miss the
whole point of a universal assembler (though it's hard to tell, due to the
nature of your writing style).  The very premise behind a universal
assembler is that, once you've written the program for the assembler, you
can retool it very cheaply, since the program contains automatic
instructions telling the assembler how to retool.  The retooling
instructions *are* complicated, but I only have to figure them out once.

<p>
The upshot of this is that if you give a universal assembler a program to
make a violin, along with the raw materials required to build it, the
universal assembler can build a violin.  If you give it a program to make a
roast beef sandwich, and the raw materials with which to build that, it can
build a sandwich.  But, most important of all: as long as I don't throw
away the violin program, I can then go back and make more violins once I'm
done having it make my sandwich.

<p>
As for your AI arguments, I feel like the jury is still out on how
effective AI will be in fulfilling our wishes.  Maybe we'll be able to make
a pretty smart design system that's willing to work for free.  Maybe no
system smart enough to work on nanotech will be stupid enough to work for
free.  Maybe the very idea of making a bootstrapping transhuman AI do what
we want it to is folly.  You definitely don't prove your case online.

<p>
Oh, and as for that bootstrapping problem:  I don't think anyone ever will
prove the bootstrapping theorem, as you presented it.  "It will be possible
for human-equivalent robots to go beyond the point of human equivalence,
even though it is not possible for us."  Why?  Because I think that we
COULD improve our own intelligence, if we actually had the tools with which
to alter our brains in fine detail.  (Not the cognitive tools, just the
manipulation tools.)  I predict that we *will* be able to increase our own
intelligence given nanotech and lots of programming.

<p>
Fortunately, an AI could easily make detailed adjustments to its inner
workings.  Thus, an AI would have an even easier time bootstrapping than we
would: whereas we would need to both figure out how to change ourselves and
also which changes to make, an AI would only have to deal with the latter
problem regarding which details to adjust.

<p>
That's all for now...  I think I've probably wasted too much time on this
already.

<p>
-Dan
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0494.html">[ Next ]</a><a href="0492.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0481.html">Lyle Burkhead</a>
<!-- nextthread="start" -->
</ul>
</body></html>
