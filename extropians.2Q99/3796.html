<!-- received="Mon Jun 14 04:06:38 1999 MDT" -->
<!-- sent="Mon, 14 Jun 1999 05:07:12 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: TECH: Fractal Tardis Brains" -->
<!-- id="3764D44F.881B4532@pobox.com" -->
<!-- inreplyto="TECH: Fractal Tardis Brains" -->
<!-- version=1.10, linesinbody=130 -->
<html><head><title>extropians: Re: TECH: Fractal Tardis Brains</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: TECH: Fractal Tardis Brains</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 14 Jun 1999 05:07:12 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3796">[ date ]</a><a href="index.html#3796">[ thread ]</a><a href="subject.html#3796">[ subject ]</a><a href="author.html#3796">[ author ]</a>
<!-- next="start" -->
<li><a href="3797.html">[ Next ]</a><a href="3795.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3793.html">hal@rain.org</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
hal@rain.org wrote:
<br>
<i>&gt; </i><br>
<a href="3793.html#3796qlink1">&gt; So your transhuman AI would be intelligent but not conscious?</a><br>

<p>
Yep, although probably not for very long.

<p>
<a href="3793.html#3796qlink2">&gt; Do you believe then in zombies, beings which act conscious but which</a><br>
<i>&gt; actually are not?  Or would you say that any intelligent computer program</i><br>
<i>&gt; would (in some sense) know that it is not conscious?</i><br>

<p>
It'd notice differences between itself and humans.  It probably wouldn't
have an "I think therefore I am" certainty.  It certainly wouldn't stand
up and start debating qualia.  

<p>
<a name="3855qlink1"><a href="3793.html#3796qlink3">&gt; Moravec has an interesting thought experiment in which a CA model like</a><br>
<i>&gt; Conway's game of Life runs for long enough to evolve living organisms</i><br>
<i>&gt; which then develop intelligence.  Would you say that this is possible?</i><br>

<p>
Plain intelligence?  Sure.  Probably the vast majority of races across
the Reality are non-conscious until they Transcend.  We're exceptions,
but, quite obviously, the only consciously observed exceptions in the
absence of a Singularity.</a>

<p>
<a href="3793.html#3796qlink4">&gt; If so, could they then evolve communication, societies, emotions, fiction,</a><br>
<i>&gt; philosophical speculations about the meaning of life?  Or would some</i><br>
<i>&gt; of these avenues be foreclosed to them because they are computationally</i><br>
<i>&gt; bound?</i><br>

<p>
Meaning of life?  Nil problemo, although, not knowing about the qualia
of pleasure, they'd have considerably less reason to speculate that an
External morality exists.  On the other hand, just the existence of
reality would be enough to inform a really advanced thinker that life
ain't Turinc-computable.

<p>
<a href="3793.html#3796qlink5">&gt; I don't see where to draw the line here.  I don't see anything stopping</a><br>
<i>&gt; these beings from evolving intelligence and emotion and all the other</i><br>
<i>&gt; characteristics we would associate with consciousness.</i><br>

<p>
Speak for yourself.  A dog has emotion.  Does it have qualia?  Who
knows?  I don't see why emotions should be noncomputable.  In fact, I
think I understand emotions, and I don't see any noncomputable parts.

<p>
<i>&gt; What gives us</i><br>
<a href="3793.html#3796qlink6">&gt; the privileged position to step in and say that although they act like</a><br>
<i>&gt; they are conscious, and claim to be conscious, they actually are not?</i><br>

<p>
Nothing.  If an AI says it understands what qualia are and it has them,
and it supplies either a satisfying explanation for consciousness or a
good explanation of why we have a mental "blind spot" that prevents us
from understanding the explanation, I'd probably take its word for it. 
I just don't expect that to happen; I expect the AI to agree with me.

<p>
<a href="3793.html#3796qlink7">&gt; The one legitimate argument I could see along these lines would be the</a><br>
<i>&gt; idea that computability is simply too weak a mechanism to produce minds</i><br>
<i>&gt; like ours.</i><br>

<p>
Minds?  No.  Qualia?  Yes.

<p>
<a href="3793.html#3796qlink8">&gt; Penrose claims that our minds rely on some form of ultra</a><br>
<i>&gt; computability, which goes beyond Turing computability.</i><br>

<p>
Penrose is, no offense, being silly.  His whole argument from Godel is
silly.  It's been stomped into oblivion by any number of people.  I
respect his physics and his neurobiology, but his math and cognitive
science is absurd.  In other words, his reasons for believing in
noncomputability are stark wrong; he just happens to be right anyhow and
to have reasoned forwards in a useful way.

<p>
<a href="3793.html#3796qlink9">&gt; Presumably in</a><br>
<i>&gt; this model no matter how long you let a computer evolve or how hard you</i><br>
<i>&gt; work at programming it, it will never show the full level of functional</i><br>
<i>&gt; mental competence that human beings have (including, per Penrose, the</i><br>
<i>&gt; ability to do mathematics as well as humans).  A more powerful primitive</i><br>
<i>&gt; is needed to allow that level of functionality.</i><br>

<p>
I don't think that our qualia provide a whole lot of new functionality. 
Probably our brains take a physical shortcut for efficiency and the
qualia are a side effect.  So while it might take more computing power -
at worst, orders of magnitude more power - you wouldn't see any
qualitative difference in intelligence - no different *kind* of thinking.

<p>
<a href="3793.html#3796qlink10">&gt; Although I don't think there is much empirical evidence for this position,</a><br>
<i>&gt; it is more philosophically attractive than accepting the existence</i><br>
<i>&gt; of zombies.  It seems that rejecting computationalism requires you to</i><br>
<i>&gt; accept one of these two possibilities.</i><br>

<p>
Not really; I regard qualia as a sort of oddball side effect.  Not
epiphenomenal, but not tremendously important either.  No, let me
rephrase that - *extremely* intriguing, but our *current* minds aren't
doing much with it.

<p>
<a href="3793.html#3796qlink11">&gt; &gt; I'm extremely conservative when it comes to reality.  I'm willing to</a><br>
<i>&gt; &gt; believe that quarks are objectively real.  I'm willing to believe that</i><br>
<i>&gt; &gt; qualia are objectively real.  I don't believe in the laws of physics,</i><br>
<i>&gt; &gt; mathematical theorems, apples, or any other abstracted properties.</i><br>
<i>&gt; </i><br>
<i>&gt; I am having some trouble following you here.  What do you mean, you don't</i><br>
<i>&gt; believe in the laws of physics?  Didn't you say earlier that you thought</i><br>
<i>&gt; they were "real" (and hence malleable)?</i><br>

<p>
Let me actually amend that a bit.  Qualia are real, but they're fairly
exotic (read "really weird"), which in turn leads me to believe that it
may be possible to construct other exotic real things - such as,
perhaps, the things we call "the laws of physics", or trans-qualia for
transhumans, or the hypothesized External morality that underlies my
ethical system.

<p>
What I don't believe in is that physicists will someday write the One
Equation on a blackboard without knowing "what breathes fire into the
equations and makes them live".  The first cause, the breather of fire,
is experimentally detectable; it has to show up in the equations.  In
fact, the equations should be incomplete without it, or you've got the
wrong equations.

<p>
<a name="3855qlink2">The one thing that got seared into my memory by my attempt to formalize
instantiation is never, ever, ever believe in epiphenomena.  *Anything*
real has to be experimentally detectable, including the property of
reality itself.  Anything "real" has exhibit different behavior than
things that are "not real".  Otherwise you've got epiphenomena, a zombie
theory of reality.  A Turing computation, being a Platonic object,
proceeds just the same whether it's "instantiated" or "not instantiated"
in our reality.  This is probably the fundamental reason why nobody will
ever define instantiation; zombie theories of reality are as silly as
zombie theories of consciousness.</a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3797.html">[ Next ]</a><a href="3795.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3793.html">hal@rain.org</a>
<!-- nextthread="start" -->
</ul>
</body></html>
