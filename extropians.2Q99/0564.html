<!-- received="Sun Apr 18 06:29:00 1999 MDT" -->
<!-- sent="Sun, 18 Apr 1999 08:28:08 EDT" -->
<!-- name="Quaenos@aol.com" -->
<!-- email="Quaenos@aol.com" -->
<!-- subject="Near-Term Futility of AI Research" -->
<!-- id="6e163495.244b29d8@aol.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=36 -->
<html><head><title>extropians: Near-Term Futility of AI Research</title>
<meta name=author content="Quaenos@aol.com">
<link rel=author rev=made href="mailto:Quaenos@aol.com" title ="Quaenos@aol.com">
</head><body>
<h1>Near-Term Futility of AI Research</h1>
<i>Quaenos@aol.com</i><br>
<i>Sun, 18 Apr 1999 08:28:08 EDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#564">[ date ]</a><a href="index.html#564">[ thread ]</a><a href="subject.html#564">[ subject ]</a><a href="author.html#564">[ author ]</a>
<!-- next="start" -->
<li><a href="0565.html">[ Next ]</a><a href="0563.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0562.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0572.html">Eugene Leitl</a>
</ul>
<!-- body="start" -->

<p>
<a name="0590qlink1"><a name="0569qlink1"><a name="0568qlink1">Eliezer Yudkoswky writes:

<p>
<a href="0562.html#0564qlink1">&gt;Tell James Bradley that we are coming for him.  ("We", in this case,</a><br>
<i>&gt;being AI researchers.)  We are coming for the Mona Lisa.  We are coming</i><br>
<i>&gt;for music.  We are coming for laughter.  We are coming for love.  It's</i><br>
<i>&gt;only a matter of time.</i><br>

<p>
<a name="0572qlink1">AI research is a dead end in the short term. Current AI research isn't 
accomplishing anything. Until we have a better understanding</a> of human 
cognition and the brain in general AI is not going to make any significant 
progress. Co-called AI researchers would perform a better service for 
themselves and the AI field if they devoted their time and resources</a> to 
neuroscience.

<p>
Think about it. Can anyone point to achievements made in the field of AI in 
<a name="0568qlink2">the last year?</a> 5 years? 10 years? There are no conceptual achievements. There 
is an illusion of progress, but it is not conceptual. The illusion is created 
by increases in computing power available to AI researchers. Implementing the 
same AI concept on a faster machine yields a more productive result. On the 
surface, it appears progress has been made in the AI field. But, in fact, 
there has been no conceptual progress in some time. AI researchers are 
justing tinkering with faster machines now.
</a>

<p>
<a name="0569qlink2"><a name="0568qlink3">Look at the deities of the AI pantheon, Minsky, Searle, what have they 
produced in the last 5 or 10 or even 20 years? Who has expanded on Turing's 
<a name="0569qlink3">work? If Turing is the AI field's Newton, where is the Einstein?</a> All I see 
lately is discussions about the limits of computation, club-handed 
discussions of consciousness,</a> and starry-eyed fantasies of Powers. There is a 
disconnect. Where<a name="0568qlink4"> is the transhumanist explanation for lack of AI progress? 
<a name="0567qlink1">Why don't AI researchers realize they aren't getting *anywhere* until we 
understand the operation of the human mind?</a> And if the transhumanists don't 
even realize this quagmire, who else will?
</a>
</a>

<p>
Thierry Maxey, Ph.D.
<br>
CIO, Seradyne Systems, Inc.
</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0565.html">[ Next ]</a><a href="0563.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0562.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0572.html">Eugene Leitl</a>
</ul>
</body></html>
