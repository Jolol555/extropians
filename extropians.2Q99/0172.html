<!-- received="Mon Apr  5 12:49:55 1999 MDT" -->
<!-- sent="Mon, 5 Apr 1999 13:49:21 -0500" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="RE: Subjective counterfactuals" -->
<!-- id="000201be7f95$05329bd0$352501c0@mfg130" -->
<!-- inreplyto="3706FF73.3629DE34@pobox.com" -->
<!-- version=1.10, linesinbody=30 -->
<html><head><title>extropians: RE: Subjective counterfactuals</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>RE: Subjective counterfactuals</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Mon, 5 Apr 1999 13:49:21 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#172">[ date ]</a><a href="index.html#172">[ thread ]</a><a href="subject.html#172">[ subject ]</a><a href="author.html#172">[ author ]</a>
<!-- next="start" -->
<li><a href="0173.html">[ Next ]</a><a href="0171.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0103.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky wrote:

<p>
<a href="0103.html#0172qlink1">&gt; Now let's say we run the playback, and, at each step, consult the</a><br>
<i>&gt; original state transition diagram to find out what the results *would*</i><br>
<i>&gt; have been, but then discard that result and load in the tape.  In other</i><br>
<i>&gt; words, we compute each step, at each point along the recording, but we</i><br>
<i>&gt; don't connect them causally to each other; we discard the result and</i><br>
<i>&gt; load the recorded step, even though the two happen to be identical.</i><br>

<p>
<a name="0180qlink1">If this simulation is based on a human (or even animal) mind, the two states
will almost never be the same.  Most of what happens in the mind is
probabilistic, not mechanistic - so if you simulate the same 100ms of
processing a million times, you will get a million slightly different end
states.

<p>
Now, I don't know whether this is a necessary property of a conscious mind
or not, but it seems entirely plausible that it might be.  If it is, then
you need a Turing machine with a random number generator to run a mind as
software, and the whole system has very different properties than an
algorithmic program.</a>  However, we don't need to get lost in metaphysics to
figure out how this kind of system will behave - we just have to accept that
we can't predict its future states with any great degree of precision.

<p>
I don't think this observation actually solves the problem at hand, but it
does close off a lot of blind alleys.

<p>
Billy Brown, MCSE+I
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0173.html">[ Next ]</a><a href="0171.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0103.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
