<!-- received="Sun Jun 13 17:14:44 1999 MDT" -->
<!-- sent="Sun, 13 Jun 1999 16:14:43 -0700" -->
<!-- name="Stephen Adamson" -->
<!-- email="Stephen@futureweb.org" -->
<!-- subject="Robots in Social Positions" -->
<!-- id="37643B62.39D836B6@FutureWeb.org" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=66 -->
<html><head><title>extropians: Robots in Social Positions</title>
<meta name=author content="Stephen Adamson">
<link rel=author rev=made href="mailto:Stephen@futureweb.org" title ="Stephen Adamson">
</head><body>
<h1>Robots in Social Positions</h1>
Stephen Adamson (<i>Stephen@futureweb.org</i>)<br>
<i>Sun, 13 Jun 1999 16:14:43 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3786">[ date ]</a><a href="index.html#3786">[ thread ]</a><a href="subject.html#3786">[ subject ]</a><a href="author.html#3786">[ author ]</a>
<!-- next="start" -->
<li><a href="3787.html">[ Next ]</a><a href="3785.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3814.html">Anders Sandberg</a>
</ul>
<!-- body="start" -->

<p>
Robots in social positions

<p>
 I recently put up on my website a Survey about the Future.
<br>
(<a href="http://www.futureweb.org/fsurvey.html">http://www.futureweb.org/fsurvey.html</a>) I floated a pilot on our<br>
internal network at work and got more results than I currently have on
the survey on the Internet (because this one isn't in search engines
yet).

<p>
In one of the questions of interest, I asked as follows:

<p>
In 50 years, which of the following job positions will be completely and
independently filled by robots?
<br>
I proceeded to list a number of jobs, such as family doctor, surgeon,
technical support, waiter, menial / assembly line labor, policeman.

<p>
I intentionally said fifty years, although this is wildly overshooting
speculation. The correct answer, given fifty years (fifty years!), is
*all the above*. But most people don't think that way. Most people think
that even in 100 years the world will be relatively unchanged. They are
ignoring the rapid advancements coming at us like a freight train. (That
kind of ignorance has humanity in "Starship Troopers", in the 22nd
century, still using handheld grenades and guns that shoot projectiles
at high velocities. :) )

<p>
<a name="3814qlink1">What came about is that social jobs (police, waiter, doctor) are (by
80-90% of people) considered impossible to be filled by robots, ever.
</a>
Positions that I put in as tests which are *already* filled by robots
<br>
(like assembly line labor) get close to (but not exactly!) 100 percent.<br>
<a name="3814qlink2">Positions like, for instance, a family doctor, can be done now,
<a name="3814qlink3">reasonably well. But somehow people don't ever think that they will be
</a>
able to *talk* to a robot or respect a robot's decisions or authority.
</a>

<p>
<a name="3814qlink4">However, all of that will happen because robots will eventually be able
to do things so much better than people and people will always have the
tendency and desire to refer their work to others. How will social
attitudes change? Will it only be when people start owning robots (like
that new Sony dog)? Will there be people who refuse to EVER consent to
the authority of a robot policeman? Or will it take until we have
realistic androids that are indistinguishable from humans?
</a>

<p>
<a name="3814qlink5">Here's a specific thought: imagine a robot is made to be a babysitter.
It is specialized to know how to fix meals, generally clean, tell
stories, recognize and acknowledge physical danger, get kids dressed and
change diapers, and immediately notify authorities and parents in the
case of an  emergency. In fact, it would improve babysitting because the
parents could get an immediate report at any time from their computer at
work, and look through the robot's eyes on demand. I would speculate
that a design like this is not too far off.
</a>
 The question that comes up is: is that parent leaving the child
*alone*? I think that public opinion would be highly divided on the
issue. Where would a government step in (to "protect the children")? And
the big question: How much of that would be dependent on the degree to
which the babysitter is humanoid? Certainly it seems irrelevant (and
indeed there would be many better designs-- enough knees for all the
kids, four arms, eyes in the back of the head :) ) but you know that the
public would be more amenable to a humanoid or some semblance thereof.
And (it would seem) the more human-like the more acceptable.
 Does it make sense? No. Is there any stopping it? Some kind of mass
memetic pounding? Or would it take subtlety, introducing incrementally
complex "machines" into everyday life until people are talking to robots
without really realizing it.

<p>
Stephen Adamson
<br>
Stephen@FutureWeb.org
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3787.html">[ Next ]</a><a href="3785.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3814.html">Anders Sandberg</a>
</ul>
</body></html>
