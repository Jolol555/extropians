<!-- received="Wed Jun 23 18:53:23 1999 MDT" -->
<!-- sent="Thu, 24 Jun 1999 10:52:27 +1000" -->
<!-- name="O'Regan, Emlyn" -->
<!-- email="Emlyn.ORegan@actew.com.au" -->
<!-- subject="RE: Conscious of the hard problem" -->
<!-- id="65FD40142926D011AAB208002BE22D3201C975FD@mailcivic1.actew.oz.au" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropians: RE: Conscious of the hard problem</title>
<meta name=author content="O'Regan, Emlyn">
<link rel=author rev=made href="mailto:Emlyn.ORegan@actew.com.au" title ="O'Regan, Emlyn">
</head><body>
<h1>RE: Conscious of the hard problem</h1>
O'Regan, Emlyn (<i>Emlyn.ORegan@actew.com.au</i>)<br>
<i>Thu, 24 Jun 1999 10:52:27 +1000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4394">[ date ]</a><a href="index.html#4394">[ thread ]</a><a href="subject.html#4394">[ subject ]</a><a href="author.html#4394">[ author ]</a>
<!-- next="start" -->
<li><a href="4395.html">[ Next ]</a><a href="4393.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4366.html">Billy Brown</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Billy Brown wrote:

<p>
<a href="4366.html#4394qlink1">&gt; I highly recomment Douglas Hofstadter's "Godel, Escher, Back: An Eternal</a><br>
<i>&gt; Golden Braid" for its treatment of this topic.  His theory (in very</i><br>
<i>&gt; simplified form) is that consciousness is a natural result of the inherent</i><br>
<i>&gt; complexity of a sentient mind.  To make a system that can act in an</i><br>
<i>&gt; intelligent fashion you have to build in all sorts of low-level</i><br>
<i>&gt; self-reference, in the form of programs that modift other programs within</i><br>
<i>&gt; the mind.  Once the whole system reaches a certain level of complexity (a</i><br>
<i>&gt; "critical mass" for sentience) these self-referential systems become</i><br>
<i>&gt; sufficiently tangled (and therefore sufficiently complete) to support</i><br>
<i>&gt; consciousness.  Thus, making a human-level intelligence that is not</i><br>
<i>&gt; conscious would be an exceedingly difficult project, and it may turn out</i><br>
<i>&gt; to</i><br>
<i>&gt; be impossible in principle.</i><br>
<i>&gt; </i><br>
<i>&gt; Of course, all of this is still untestable, but he makes a much better</i><br>
<i>&gt; argument than most people in this field ever manage.</i><br>
<i>&gt; </i><br>
I'm actually reading this now, and understand the point that he's trying to
make; it is an excellent argument! I think that I agree with the idea that
consciousness will emerge, but there are still other problems that I wonder
about, like continuity of identity, which is highly related. Particularly
uploading highlights the problem, and Hofstader crosses this ground with
Aunt Hilary, the sentient ant colony (I think the joke here assumes the
American pronunciation of Aunt as "Ant"). She emerges from the ant colony
after the previous sentience is destroyed when the ants become temporarily
scattered. Loss of continuous identity.

<p>
I would think that libertarians would find continuity of identity paramount,
and transhumans like uploading, so there is a crucial problem which we will
have to solve in the near future.

<p>
Emlyn
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="4395.html">[ Next ]</a><a href="4393.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4366.html">Billy Brown</a>
<!-- nextthread="start" -->
</ul>
</body></html>
