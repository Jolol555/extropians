<!-- received="Tue Jun 22 22:32:15 1999 MDT" -->
<!-- sent="Wed, 23 Jun 1999 14:31:31 +1000" -->
<!-- name="O'Regan, Emlyn" -->
<!-- email="Emlyn.ORegan@actew.com.au" -->
<!-- subject="RE: Conscious of the hard problem" -->
<!-- id="65FD40142926D011AAB208002BE22D3201C975F8@mailcivic1.actew.oz.au" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: RE: Conscious of the hard problem</title>
<meta name=author content="O'Regan, Emlyn">
<link rel=author rev=made href="mailto:Emlyn.ORegan@actew.com.au" title ="O'Regan, Emlyn">
</head><body>
<h1>RE: Conscious of the hard problem</h1>
O'Regan, Emlyn (<i>Emlyn.ORegan@actew.com.au</i>)<br>
<i>Wed, 23 Jun 1999 14:31:31 +1000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4332">[ date ]</a><a href="index.html#4332">[ thread ]</a><a href="subject.html#4332">[ subject ]</a><a href="author.html#4332">[ author ]</a>
<!-- next="start" -->
<li><a href="4333.html">[ Next ]</a><a href="4331.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4320.html">Harvey Newstrom</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="4366.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
Harvey wrote:

<p>
<a href="4320.html#4332qlink1">&gt; I agree that both scenarios produce identical consciousness.  I claim that</a><br>
<i>&gt; one is a program of consciousness being run by the brain, while the other</i><br>
<i>&gt; is</i><br>
<i>&gt; a program of consciousness being run by a committee of humans.</i><br>
<i>&gt; </i><br>
I agree that in all of the neuron-in-a-bucket scenarios, which don't involve
any processing on the neuron's part, the neurons are entirely irrelevant -
the network is being created/executed by other agents (people in these
cases). But the consciousness should still exist somewhere.

<p>
Thanks for Hal's succinct summation of the causality-is-illusion idea. I
think that  was what I was getting at (although I am a bit vague on this -
my continuous sense of identity seems to be being undermined by these lines
of reasoning, and it is affecting my memory).

<p>
<a name="4531qlink1"><a name="4337qlink1">Something has been nagging at me. Most opinions seem to suggest here that,
if consciousness exists at all, it doesn't have a real purpose, in that you
could create a simulated intelligence which was exactly as functional, but
</a>with consciousness.</a> This doesn't sit right with me, and I'm not yet clear on
why.

<p>
<a name="4366qlink1">I'm sure that consciousness is entirely bound up in the way we operate,</a> but
<a name="4366qlink2">why is it necessary? I read Chalmers (Facing up to the problem of
consciousness - <a href="http://ling.ucsc.edu/~chalmers/consc-papers.html">http://ling.ucsc.edu/~chalmers/consc-papers.html</a>) on this,
with his theory of information having a functional and a phenomenal aspect.
</a>
<a name="4366qlink3">I like it, but I still can't see what the point is of the phenomenal aspect,
</a>
<a name="4366qlink4">and I think that there is a point to consciousness. I also agree with the
Zombike objection to Chalmers' reasoning.
</a>

<p>
Damien, you seem to have a good grip on what the various players have to say
about this - got some words of wisdom? 

<p>
Solving this problem will be as important a step as Darwin's discovery of
the principle of evolution, in my opinion, and we might find that the answer
has just as many unexpected implications.

<p>
Emlyn
<br>
By the way, does Darwin count as a proto-extropian? Or did he levy taxes or
some other such heresy? Maybe he told someone to do something once...
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="4333.html">[ Next ]</a><a href="4331.html">[ Previous ]</a>
<b>In reply to:</b> <a href="4320.html">Harvey Newstrom</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="4366.html">Billy Brown</a>
</ul>
</body></html>
