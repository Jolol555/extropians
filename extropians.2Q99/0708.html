<!-- received="Tue Apr 20 19:35:48 1999 MDT" -->
<!-- sent="Tue, 20 Apr 1999 21:33:52 EDT" -->
<!-- name="Quaenos@aol.com" -->
<!-- email="Quaenos@aol.com" -->
<!-- subject="Assessing the Current AI Approach" -->
<!-- id="95f44a2e.244e8500@aol.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=80 -->
<html><head><title>extropians: Assessing the Current AI Approach</title>
<meta name=author content="Quaenos@aol.com">
<link rel=author rev=made href="mailto:Quaenos@aol.com" title ="Quaenos@aol.com">
</head><body>
<h1>Assessing the Current AI Approach</h1>
<i>Quaenos@aol.com</i><br>
<i>Tue, 20 Apr 1999 21:33:52 EDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#708">[ date ]</a><a href="index.html#708">[ thread ]</a><a href="subject.html#708">[ subject ]</a><a href="author.html#708">[ author ]</a>
<!-- next="start" -->
<li><a href="0709.html">[ Next ]</a><a href="0707.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0569.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<i>&gt;&gt;	Quaenos@aol.com quotation</i><br>
<i>&gt;	Eliezer Yudkowsky quotation</i><br>

 
<p>
<i>&gt;&gt; So-called AI researchers would perform a better service for</i><br>
<a href="0569.html#0708qlink1">&gt;&gt; themselves and the AI field if they devoted their time and resources to</a><br>
<i>&gt;&gt; neuroscience.</i><br>
<i>&gt;</i><br>
<i>&gt;I disagree; I would substitute "cognitive science" for "neuroscience" in</i><br>
<i>&gt;the sentence above.  We need to work down, not up.  What good does it do</i><br>
<i>&gt;to know how neurons fire?  </i><br>

<p>
As we develop our understanding of neuroscience, forays into cognitive 
science will naturally follow.  We've been trying the "work down" approach 
for the last fifty years with no qualitative progress in the last two 
decades.  I don't think we should dismiss all efforts in cognitive science, 
but neuroscience is the near-term limiter on the progress in cognitive 
science.

<p>
<a href="0569.html#0708qlink2">&gt;Cognitive science is where it's at.  Hofstadter and Mitchell's Copycat,</a><br>
<i>&gt;one of the few real advances in the field (although, alas, not a recent</i><br>
<i>&gt;one), was created by observing what real people did when they were</i><br>
<i>&gt;making analogies, and using those observations to deduce what the</i><br>
<i>&gt;sub-elements of analogies were.  They worked down, not up.</i><br>

<p>
I agree with you on this point.  If there is worthwhile work being done in AI 
it is by those attempting to determine the computational bases of creativity. 
 I've not been swayed either way by the stochastic (Copycat) vs. 
deterministic (SME, SOAR, etc.) models of creativity. Additionally,research 
into the knowledge requirements for creative systems appears to be 
worthwhile.  But the emphasis on force feeding lots of basic rules or the 
"hardware" approach seems ill-conceived. The research area that would 
contribute to AI that, in turn,involves the least amount of philosophical 
haggling and the most science is neuroscience.

<p>
<a href="0569.html#0708qlink3">&gt;I don't know about Einstein, but someday I'd like to be the Drexler.</a><br>

<p>
We need the Einstein before we need the Drexler.  Einstein ushered a paradigm 
shift whereas Drexler is simply ruminating within a paradigm.  We need the 
paradigm shift first.  This leads me a theorem concerning scientific progress 
called the Paradigm Shift Singularity Axiom:  The ratio of philosophical 
haggling and nitpickery over the amount of scientific investigation increases 
over time as the current paradigm reachers its limits.  As the ratio becomes 
asymptotic, a paradigm shift hopefully/usually occurs elsewhise we begin to 
have "churches" of thought within fields of study.

<p>
<a href="0569.html#0708qlink4">&gt;I freely admit that most of the design in "Coding a Transhuman AI" is</a><br>
<i>&gt;directly derived from introspection, and the rest is derived indirectly.</i><br>
<i>&gt; But it's also possible to get too caught up in trying to duplicate the</i><br>
<i>&gt;human mind. </i><br>

<p>
Agreed. But given its the only current example we have of a working 
intelligence, it seems prudent to uncover its secrets when our efforts to 
create the beast from scratch are ailing something awful.

<p>
<a href="0569.html#0708qlink5">&gt;The accomplishment is not in creating something with a surface</a><br>
<i>&gt;similarity to humanity (classical AI) or that uses the same elements as</i><br>
<i>&gt;humanity (connectionist AI), but in reducing high-level complexity into</i><br>
<i>&gt;the complex interaction of less complex elements.</i><br>

<p>
If we can isolate the components in the human mind we can optimize them.  The 
random shot in the dark approach of evolution has certainly left huge room 
for improvement.  Since we can't even develop a system intelligent as a 
tapeworm I think its imprudent to start talking about developing a more 
efficient version of human-level intelligence.

<p>
<i>&gt; Both classical AI and</i><br>
<a href="0569.html#0708qlink6">&gt;connectionist AI take great pride in claiming to have found the</a><br>
<i>&gt;elements, but they usually toss out the complexity - the elements don't</i><br>
<i>&gt;interact in any interesting way.</i><br>

<p>
Recasting the element as complexity just rewords the problem but does not 
given a useful answer.  Describe, deduce, formalize all you want but until 
you have a seed AI or some other tangible product you are still just 
restating the problem.

<p>
Thierry Maxey, Ph.D.
<br>
CIO, Seradyne Systems, Inc.
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0709.html">[ Next ]</a><a href="0707.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0569.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
