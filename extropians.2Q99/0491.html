<!-- received="Tue Apr 13 22:23:15 1999 MDT" -->
<!-- sent="Wed, 14 Apr 1999 00:23:13 -0400" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="mike@lorrey.com" -->
<!-- subject="Re: Geniebusters" -->
<!-- id="37141831.A1436F44@lorrey.com" -->
<!-- inreplyto="Geniebusters" -->
<!-- version=1.10, linesinbody=150 -->
<html><head><title>extropians: Re: Geniebusters</title>
<meta name=author content="Michael S. Lorrey">
<link rel=author rev=made href="mailto:mike@lorrey.com" title ="Michael S. Lorrey">
</head><body>
<h1>Re: Geniebusters</h1>
Michael S. Lorrey (<i>mike@lorrey.com</i>)<br>
<i>Wed, 14 Apr 1999 00:23:13 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#491">[ date ]</a><a href="index.html#491">[ thread ]</a><a href="subject.html#491">[ subject ]</a><a href="author.html#491">[ author ]</a>
<!-- next="start" -->
<li><a href="0492.html">[ Next ]</a><a href="0490.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0489.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky wrote:
<br>
<i>&gt; </i><br>
<a href="0489.html#0491qlink1">&gt; Lyle Burkhead wrote:</a><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt; The "genie" hypothesis is simply that AI systems with at-least-human</i><br>
<i>&gt; &gt; intelligence will work for us for free.  Discussions of AI have not gone</i><br>
<i>&gt; &gt; beyond it, because it is a general idea that has nothing to do with the</i><br>
<i>&gt; &gt; details of how an AI is created.</i><br>
<i>&gt; </i><br>
<i>&gt; Incorrect.  See the section on goal systems in "Coding a Transhuman AI",</i><br>
<i>&gt; or the summary in "Singularity Analysis".  (Yes, you *can't* give AIs</i><br>
<i>&gt; orders after a certain point - for technical, not logical, reasons.)</i><br>

<p>
The only reason we ask for pay is because of the way our motivations
evolved. There is absolutely no reason why an AI has to have a
hunter/gatherer or agrarian motivational set. An AI certainly does not
need to get laid or provide a home for its kids... An AI that may ask
for pay will still understand that any compensation may be calculated on
the AI's cost of 'living', which is measured in kilo-watt hours and
amortized Moore fractions. If AI's are easily replicated, then the
supply of AI labor will be high and this will drive the cost per work
unit down. 

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink2">&gt; &gt; Nanotechnologists assume that Genies will exist. That's what distinguishes</a><br>
<i>&gt; &gt; Drexlerian Nanotechnology from ordinary technology. The nanotechnology meme</i><br>
<i>&gt; &gt; isn't really about atoms. The key paragraphs are in the section called</i><br>
<i>&gt; &gt; Accelerating the Technology Race on page 81:</i><br>
<i>&gt; </i><br>
<i>&gt; Okay, now this is why everyone is shouting "Straw man!".  Drextech</i><br>
<i>&gt; assumes that the forms of matter (as opposed to matter) become</i><br>
<i>&gt; duplicable resources, and that a few new manipulations (healing a cell,</i><br>
<i>&gt; creating custom-formed diamonds, etc.) become possible.</i><br>
<i>&gt; </i><br>
<i>&gt; Genie machines are unnecessary.  Knocking them down does nothing to</i><br>
<i>&gt; disprove the utopia envisioned in _Engines_.</i><br>
<i>&gt; </i><br>
<i>&gt; &gt; Either you have to program the robots, or you don't. If you do, then using</i><br>
<i>&gt; &gt; them to build a skyscraper will not be free of labor costs -- far from it.</i><br>
<i>&gt; </i><br>
<i>&gt; Yes, but you can build ten million skyscrapers as easy - or as hard - as one.</i><br>

<p>
My comments at crit org on the geniebusters site replicate these
comments:
<br>
There are already code generating engines out there. Once such code
generators are developed for CAD/CAM systems, then with a sufficient
database of past work done, the user only has to set goals and other
parameters and the assemblers do the rest:

<pre>
a)determining solutions to the goal requirements
b)selecting the best solution
c)CADding out the design for that solution and the process to
</pre>
manufacture it.
<br>
d)CADding out the tooling to build the parts and assemblies for that
design
<br>
e)collecting the resources needed to build the parts, assemblies, and
the final solution.
<br>
f)refining the resources
<br>
g)applying he resources to a manufacturing process utilizing the tooling
previously designed.

<p>
Each step has its own requirements, but there is no reason why nanites
cannot do all of them. 

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink3">&gt; &gt; On the other hand if you don't have to program them, then they have crossed</a><br>
<i>&gt; &gt; the line that separates agents from automatons. They have crossed over to</i><br>
<i>&gt; &gt; our side, and the work _they_ do amounts to the same thing as "human</i><br>
<i>&gt; &gt; labor." Either the robots are automatons, in which case you have to program</i><br>
<i>&gt; &gt; them, or they are agents, in which case you have to pay them. Skyscrapers</i><br>
<i>&gt; &gt; will never be free, because we will always have to make an effort to focus</i><br>
<i>&gt; &gt; our minds and make things happen -- or the robots will have to make the</i><br>
<i>&gt; &gt; same effort to focus _their_ minds and make things happen.</i><br>
<i>&gt; </i><br>
<i>&gt; It sounds to me like exactly the same argument would rule out the</i><br>
<i>&gt; Industrial Revolution.  You've just proved that the cost of everything</i><br>
<i>&gt; is an eternal constant.  Not only that, you've also proved that I can't</i><br>
<i>&gt; have Netscape Navigator on my desk because it took a whole company to</i><br>
<i>&gt; produce it.</i><br>
<i>&gt; </i><br>
<i>&gt; Nanotechnology is a material technology that does not intrinsically</i><br>
<i>&gt; require or imply intelligence enhancement; even though IE is discussed</i><br>
<i>&gt; in _Engines_ as both consequence and tool, it is not *necessary*.</i><br>
<i>&gt; Nanotech is simply an enormously powerful tool, that can be developed</i><br>
<i>&gt; like any other tool; and used to create a Utopia or blast the planet,</i><br>
<i>&gt; more likely the latter; with or without IE.</i><br>

<p>
Correct. You can easily have your nanites be rather dumb drone type
organism which obey the orders of the queen AI. Its merely a problem
needing a client/server solution in a manufacturing environment.

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink4">&gt; &gt; Without Genies, the ability to make things out of atoms is just an</a><br>
<i>&gt; &gt; extension of present-day technology, not dizzying at all. Molecular</i><br>
<i>&gt; &gt; manufacturing without Genies is just agribusiness.</i><br>
<i>&gt; </i><br>
<i>&gt; All material business suddenly has the same economics as information;</i><br>
<i>&gt; write it once, use it forever.  The world becomes the Internet.  That's dizzying.</i><br>

<p>
And notice how Monsanto is so scared about its improved breeds of
gengineered seed that it felt it had to engineer in a suicide gene to
prevent the plants from being able to reproduce outside of Monsanto
control. This will be the means of IP protection in the nanotech future.

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink5">&gt; &gt; Without Genies, there will be no sudden "assembler breakthrough." Instead</a><br>
<i>&gt; &gt; of emerging in a sudden breakthrough, nanotechnology will emerge</i><br>
<i>&gt; &gt; continuously from present-day technology, over a period of decades, step by</i><br>
<i>&gt; &gt; laborious step, each step involving an effort of concentration in a human</i><br>
<i>&gt; &gt; mind.</i><br>
<i>&gt; </i><br>
<i>&gt; Why can't we get immediate AIs who then drive all the way to</i><br>
<i>&gt; Singularity, whether we like it or not?  And why couldn't the immediate</i><br>
<i>&gt; effects of assembler technology, relatively simple apps like</i><br>
<i>&gt; ultracomputers and the Ultimate Xerox, have such vast impacts - like $3</i><br>
<i>&gt; trillion of venture capital pouring into nanotech, and the ability to</i><br>
<i>&gt; actually play around in the molecular world, and the ability to run</i><br>
<i>&gt; evolutionary computer models of assemblers, and all the applications we</i><br>
<i>&gt; couldn't anticipate in advance - compress decades into months?</i><br>

<p>
he doesn't beleive in Moore's Law.

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink6">&gt; &gt; There are no Genies and never will be. This is a logical point, not a</a><br>
<i>&gt; &gt; technical point.</i><br>
<i>&gt; </i><br>
<i>&gt; If it really is a logical point, not a technical question of AI</i><br>
<i>&gt; motivations, then you're just playing with tautologies.</i><br>

<p>
Sounds more like Mr. Burkhead treats it like a point of dogma.

<p>
<i>&gt; </i><br>
<a href="0489.html#0491qlink7">&gt; &gt; It's not a question of what can or can't be done with</a><br>
<i>&gt; &gt; atoms, or what can or can't be done with computers. I'm not saying AI will</i><br>
<i>&gt; &gt; never exist. What I'm saying is that it doesn't matter -- any entity with</i><br>
<i>&gt; &gt; at-least-human intelligence (artificial or not) won't work for free. To the</i><br>
<i>&gt; &gt; extent that a robot makes independent decisions, it will have to be dealt</i><br>
<i>&gt; &gt; with as an entity that makes independent decisions. A group of robots that</i><br>
<i>&gt; &gt; could build a skyscraper by themselves would be indistinguishable from a</i><br>
<i>&gt; &gt; contractor, and would have to be dealt with as such.</i><br>
<i>&gt; </i><br>
<i>&gt; You are simply wrong.  Our selfishness is quite independent of our</i><br>
<i>&gt; intelligence, and in fact interferes with it; this is a technical</i><br>
<i>&gt; question of goal systems.</i><br>

<p>
Exactly as I said earlier here.

<p>
Mike Lorrey
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0492.html">[ Next ]</a><a href="0490.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0489.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
