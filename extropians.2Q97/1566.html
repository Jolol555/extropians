<!-- received="Mon Jun  9 12:44:50 1997 MDT" -->
<!-- sent="Mon, 9 Jun 1997 11:15:31 -0700" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Why Not a Planet Of The Apes?" -->
<!-- id="199706091815.LAA29209@crypt.hfinney.com" -->
<!-- inreplyto="Why Not a Planet Of The Apes?" -->
<title>extropians: Re: Why Not a Planet Of The Apes?</title>
<h1>Re: Why Not a Planet Of The Apes?</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Mon, 9 Jun 1997 11:15:31 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1566">[ date ]</a><a href="index.html#1566">[ thread ]</a><a href="subject.html#1566">[ subject ]</a><a href="author.html#1566">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1567.html">Robin Hanson: "Re: Why Not a Planet Of The Apes?"</a>
<li> <b>Previous message:</b> <a href="1565.html">Robin Hanson: "Why Not a Planet Of The Apes?"</a>
<li> <b>Maybe in reply to:</b> <a href="1565.html">Robin Hanson: "Why Not a Planet Of The Apes?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1567.html">Robin Hanson: "Re: Why Not a Planet Of The Apes?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Robin Hanson, hanson@hss.caltech.edu, writes:<br>
<i>&gt; OK, given all this intelligent comment, I can reframe the puzzle.  Why</i><br>
<i>&gt; is it that it seems to most people more promising to build up smart</i><br>
<i>&gt; cooperative agents from scratch, as in an AI approach, than to</i><br>
<i>&gt; domesticate existing very smart but not cooperative-enough agents?  Is</i><br>
<i>&gt; domestication really that hard compared to learning how to organize</i><br>
<i>&gt; intelligence and acquiring all that common sense knowledge?</i><br>
<p>
I would think that Robin, as an AI researcher himself, would have the<br>
most insight into the motivations of that community.  My guess would be<br>
that AI would not be very interesting if we thought that the best we<br>
were ever going to do was to make something as smart as monkeys.  Sure,<br>
achieving monkey-level intelligence and abilities would be an amazing<br>
accomplishment by today's standards, but nobody expects progress to<br>
end there.  The real hope is to create human or super-human intelligence.<br>
<p>
Possibly if enough time goes by without any progress in AI, attitudes<br>
will change.  If AI is eventually seen as impossible then these other<br>
approaches may become more popular.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1567.html">Robin Hanson: "Re: Why Not a Planet Of The Apes?"</a>
<li> <b>Previous message:</b> <a href="1565.html">Robin Hanson: "Why Not a Planet Of The Apes?"</a>
<li> <b>Maybe in reply to:</b> <a href="1565.html">Robin Hanson: "Why Not a Planet Of The Apes?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1567.html">Robin Hanson: "Re: Why Not a Planet Of The Apes?"</a>
<!-- reply="end" -->
</ul>
