<!-- received="Wed May 14 22:24:52 1997 MDT" -->
<!-- sent="Thu, 15 May 1997 13:50:46 +0000" -->
<!-- name="Damien Broderick" -->
<!-- email="damien@ariel.ucs.unimelb.edu.au" -->
<!-- subject="Re: Is Software Generality Overrated?" -->
<!-- id="199705150311.UAA07211@igc3.igc.apc.org" -->
<!-- inreplyto="Is Software Generality Overrated?" -->
<title>extropians: Re: Is Software Generality Overrated?</title>
<h1>Re: Is Software Generality Overrated?</h1>
Damien Broderick (<i>damien@ariel.ucs.unimelb.edu.au</i>)<br>
<i>Thu, 15 May 1997 13:50:46 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1147">[ date ]</a><a href="index.html#1147">[ thread ]</a><a href="subject.html#1147">[ subject ]</a><a href="author.html#1147">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1148.html">John K Clark: "A True Believer"</a>
<li> <b>Previous message:</b> <a href="1146.html">Kathryn Aegis: "extropian stance on cloning"</a>
<li> <b>Maybe in reply to:</b> <a href="1138.html">Robin Hanson: "Is Software Generality Overrated?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1166.html">mlbowli1@cord.iupui.edu: "Re: extropian stance on cloning"</a>
<li> <b>Reply:</b> <a href="1166.html">mlbowli1@cord.iupui.edu: "Re: extropian stance on cloning"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 02:34 PM 5/14/97 -0700, Robin wrote:<br>
<p>
<i>&gt;People have a huge</i><br>
<i>&gt;"common sense" knowledge base to draw on, and writing it all down for</i><br>
<i>&gt;computers is a daunting task.</i><br>
<p>
Yes, and maybe `writing it down' explicitly is the wrong way to go, but<br>
hey--  The CYC system, last time I looked, was said to have swallowed a<br>
human-century of input, and not yet got all that far.  Still, using an<br>
amazingly rich organic neural net a human takes between 7 and 35 years to<br>
absorb the tacit knowledge needed for true functioning intelligence.<br>
That's *every single human*.  Once the knowledge base is compiled,<br>
compressed and debugged, AIs can (presumably) be die-stamped.  That might<br>
lead to dangerous conformity, so their common sense paradigms will need to<br>
be kept somewhat labile, but the advantages of xeroxing over long drawn-out<br>
experience seem to me to represent a truly gigantic jump forward in low<br>
cost utility.<br>
<p>
Damien Broderick<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1148.html">John K Clark: "A True Believer"</a>
<li> <b>Previous message:</b> <a href="1146.html">Kathryn Aegis: "extropian stance on cloning"</a>
<li> <b>Maybe in reply to:</b> <a href="1138.html">Robin Hanson: "Is Software Generality Overrated?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1166.html">mlbowli1@cord.iupui.edu: "Re: extropian stance on cloning"</a>
<li> <b>Reply:</b> <a href="1166.html">mlbowli1@cord.iupui.edu: "Re: extropian stance on cloning"</a>
<!-- reply="end" -->
</ul>
