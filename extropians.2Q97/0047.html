<!-- received="Thu Apr  3 04:00:15 1997 MDT" -->
<!-- sent="Thu, 3 Apr 1997 11:07:01 GMT" -->
<!-- name="Guru George" -->
<!-- email="gurugeorge@sugarland.idiscover.co.uk" -->
<!-- subject="Re[2]: Re[2]: Protean Self-Transformation" -->
<!-- id="199704031107.LAA16720@hal.9000series.idiscover.net" -->
<!-- inreplyto="3.0.1.32.19970402122923.0069a524@netwizards.net" -->
<title>extropians: Re[2]: Re[2]: Protean Self-Transformation</title>
<h1>Re[2]: Re[2]: Protean Self-Transformation</h1>
Guru George (<i>gurugeorge@sugarland.idiscover.co.uk</i>)<br>
<i>Thu, 3 Apr 1997 11:07:01 GMT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#47">[ date ]</a><a href="index.html#47">[ thread ]</a><a href="subject.html#47">[ subject ]</a><a href="author.html#47">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0048.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<li> <b>Previous message:</b> <a href="0046.html">Guru George: "Re[2]: LIT: Culture"</a>
<li> <b>In reply to:</b> <a href="0037.html">GeoffCobb@aol.com: "Re: disappointing responses"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0057.html">Perry E. Metzger: "Re: disappointing responses"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Wed, 02 Apr 1997 12:29:23 -0800<br>
Andrea Gallagher &lt;drea@alumni.stanford.org&gt; wrote:<br>
<p>
<i>&gt;At 11:08 PM 3/30/97 GMT, Guru George wrote:</i><br>
<i>&gt;&gt;</i><br>
<p>
[snip]<br>
<p>
<i>&gt;But isn't it all a matter of where you decide to draw the boundary between</i><br>
<i>&gt;mind and other?  What do you see the limbic system doing, processing input</i><br>
<i>&gt;and turning it into emotion, or packaging input into a form that lets the</i><br>
<i>&gt;brain turn it into emotion?  I don't really know much about the limbic</i><br>
<i>&gt;system, so it may well be true that a lot of the necessary processing for</i><br>
<i>&gt;emotion gets done there.</i><br>
<p>
The rule of thumb I always use is this:- you know how we *seem* to have<br>
emotional communication with our pets, like our cats and dogs, and<br>
it*seems* like it's reciprocated? Well, there really*is* emotional stuff<br>
going on there,and it's precisely the limbic system which we share with<br>
our pets that allows us to communicate in that way. (It may not be as<br>
fully anthropomorphic a communication event as pet lovers imagine, but<br>
it's definitely there.)<br>
<p>
As I understand it, the limbic system controls all those *bodily<br>
reactions* (e.g. tears, flushing, anxiety, excitement, etc.) that go to<br>
creating the complex entity we call an 'emotion'.  For us, certainly,<br>
there are lots of 'thoughts' strictly so-called mixed in with all those<br>
bodily reactions, so we as humans can hardly think of emotions separately<br>
<i>&gt;from thoughts, but as the pet example shows, that is not a sufficient</i><br>
distinction.  <br>
<p>
Emotion in the strict (cross-species) sense *is* those bodily reactions<br>
to external stimuli. They *are* cognitive - especially they are<br>
cognitive in the sense that they serve to allow mammals to cognise the<br>
'internal states' of their fellows - I believe that is their main<br>
evolutionary raison d'etre.  Empathy co-ordinates.<br>
<p>
(If you think about it, mammals are much more social creatures than<br>
lizards and such - even cats have a high degree of sociality, though not<br>
as much as dogs, which are pack animals to the core. I mean 'social'<br>
while being highly complex as individuals too, of course - birds and<br>
fish are highly social too, sometimes, but are not nearly such complex<br>
creatures as mammals.)<br>
<p>
They may also be at the root of mimicry, which is the foundation of<br>
culture.<br>
<p>
<i>&gt;I regect Gregory's arguement that emotion is non-cognitive, distinct from</i><br>
<i>&gt;"thought".  I suspect that what Gregory is calling "cognition" is only the</i><br>
<i>&gt;stuff that he is aware of, that sounds like language in his head, that</i><br>
<i>&gt;seems coherent and algorithmic.  Cognition is really a matter of</i><br>
<i>&gt;multitudinous processes acting on a wide variety data input, much of which</i><br>
<i>&gt;never percolates up to what we call consciousness.  If vision is part of</i><br>
<i>&gt;this process, there's no reason to think that emotion isn't.  Emotion is</i><br>
<i>&gt;just one way the mind/brain chooses to represent and respond to some of the</i><br>
<i>&gt;input it gets.  If we replicate the brain, I bet we replicate emotion.</i><br>
<p>
I agree with you.  I think Gregory is right that emotion is part of<br>
fully human experience, and would need to be duplicated somehow in any upload<br>
-capable system that claimed to replicate human experience; but since<br>
Anders' reply to my post, I now see that replicating emotion would<br>
actually be a good place for AI researchers to start, primarily because<br>
it is, in fact, a primitive form of cognition- it's like, just as they've<br>
discovered how valuable it is to model simple cognitive systems like<br>
those of insects, as things progress, they will move onto modelling reptilian<br>
control systems, then lower, then higher mammalian control systems, and<br>
only then will they be starting to get some handle on the way the<br>
neocortex functions.  (Who wants to bet that it's Darwin machines all the<br>
way?)<br>
<p>
[snip]<br>
<p>
<i>&gt;</i><br>
<p>
Guru George<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0048.html">Anders Sandberg: "Re: Re[2]: Protean Self-Transformation"</a>
<li> <b>Previous message:</b> <a href="0046.html">Guru George: "Re[2]: LIT: Culture"</a>
<li> <b>In reply to:</b> <a href="0037.html">GeoffCobb@aol.com: "Re: disappointing responses"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0057.html">Perry E. Metzger: "Re: disappointing responses"</a>
<!-- reply="end" -->
</ul>
