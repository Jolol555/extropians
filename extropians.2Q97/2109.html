<!-- received="Wed Jun 25 10:38:21 1997 MDT" -->
<!-- sent="Wed, 25 Jun 1997 08:51:05 -0700 (PDT)" -->
<!-- name="Mark Crosby" -->
<!-- email="crosby_m@rocketmail.com" -->
<!-- subject="Re: Deep Blue colmun in TIME, May 19th" -->
<!-- id="199706251500.IAA29364@well.com" -->
<!-- inreplyto="Deep Blue colmun in TIME, May 19th" -->
<title>extropians: Re: Deep Blue colmun in TIME, May 19th</title>
<h1>Re: Deep Blue colmun in TIME, May 19th</h1>
Mark Crosby (<i>crosby_m@rocketmail.com</i>)<br>
<i>Wed, 25 Jun 1997 08:51:05 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2109">[ date ]</a><a href="index.html#2109">[ thread ]</a><a href="subject.html#2109">[ subject ]</a><a href="author.html#2109">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2110.html">Perry E. Metzger: "money"</a>
<li> <b>Previous message:</b> <a href="2108.html">Michael Lorrey: "Re: Deep Blue colmun in TIME, May 19th"</a>
<li> <b>Maybe in reply to:</b> <a href="2055.html">Michael Lorrey: "Deep Blue colmun in TIME, May 19th"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2116.html">Michael Lorrey: "Re: Deep Blue colmun in TIME, May 19th"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Michael Lorrey wrote:<br>
&lt;David Gelernter may be a professor of computer science at Yale, but<br>
any informed individual can see that he is not only misinfomed about<br>
his own field, but hopelessly behind the times with respect to our<br>
knowledge of neurophysiology if his column in the May 19th issue is<br>
any indication of his knowledge of progress in artificial intelligence<br>
and brain/machine interface.&gt;<br>
<p>
I doubt very much if Gelernter writes a "column" for TIME! You should<br>
do a little more research about someone before you flame them based on<br>
a heavily-edited, popular-magazine sidebar.  As Damien Broderick<br>
pointed out, Gelernter is the author of _Mirror Worlds: Or the Day<br>
Software Puts the Universe Into a Shoebox: How It Will Happen and What<br>
it Will Mean_ (1992), one of the premier visions of cyberspace, and<br>
he’s also the developer of one of the first parallel processing<br>
languages, LINDA.  Gelernter’s also the author of _The Muse in the<br>
Machine_. <br>
<p>
A lot of serious AI and cybernetics researchers have doubts about<br>
whether human-level intelligence can be represented by anything<br>
resembling a traditional von Neumann computer. These doubts don’t<br>
necessarily imply that they’re worried about a soul or something.<br>
<p>
Mike, throughout your essay you equate AI with brain-machine<br>
interfacing, two very different subjects.<br>
<p>
&lt;Any computer professional has heard of Moore's Law ... This is the<br>
sort of technological progress that has the inflation and productivity<br>
estimators at the Bureau of Labor Statistics in apopleptic fits.&gt;<br>
<p>
So what does this have to do with the price of tea in China? (Are you<br>
suggesting us incompetent BLS bureaucrats would actually get<br>
apoplectic over our work? I thought we’re all supposed to be parasitic<br>
drones!  (-;)  I don’t doubt that microprocessors are becoming more<br>
and more ubiquitous, but, as I noted in our discussion on this earlier<br>
this year, the biggest chunk of the average person’s expenditures<br>
still go for such mundane necessities as food and shelter.<br>
<p>
&lt;Gelernter is right in saying it is silly to ascribe intelligence to<br>
Deep Blue, as that computer has as much processing power as say, a<br>
housefly or a maybe even a mouse.&gt;<br>
<p>
Deep Blue was not just a ‘computer’ - there was a muse in the machine,<br>
namely the team of people who programmed it with a knowledge of chess.<br>
<p>
&lt;While he has the right to claim some supernatural source of our<br>
being, so far he cannot prove that the human mind is nothing more than<br>
a biochemical computer with a neural net architecture. Given this, we<br>
can duplicate that architecture in other forms, even silicon.&gt;<br>
<p>
And you cannot yet prove that the human mind *is* nothing more than a<br>
biochemical computer with a neural net architecture.  So your "given<br>
this" assumption is hardly justified. There are serious scientists who<br>
don’t believe in "supernatural sources of our being" yet still have<br>
doubts about whether traditional computer architectures, and even<br>
neural nets, are adequate to duplicate what the human mind does.  You<br>
might check the Principia Cybernetica web for starters.<br>
<p>
&lt; Associative thinking is, in fact, largely how we think most of the<br>
time, but this can be duplicated by any relational database.&gt;<br>
<p>
Then why is it that hundreds of AI researchers working for decades<br>
have yet to build anything close to a human associative memory.  Why<br>
is it that cybernetic systems (real-time process control systems) and<br>
even management decision support systems shun relational DBMS for<br>
object-oriented or multidimensional approaches? <br>
<p>
&lt;The claim that thinking is dictated by emotion is utterly false. At<br>
best our thinking is muddied or even given greater color by our<br>
emotions. Studies have shown that heightened emotions tend to give<br>
greater reinforcement to certain memories, especially experiences<br>
heavily laden with adrenaline, but this behavior can also be easily<br>
accounted for in programming if needed.&gt; <br>
<p>
If there’s no emotion associated with it, you’re unlikely to remember<br>
it.  Again, you’re setting up a straw-man:  Most cognitive scientists<br>
don’t claim that thinking is *dictated* by emotion, but they do<br>
believe that the ‘emotional’ organs of the brain are an essential part<br>
of the long-term memory system.<br>
<p>
&lt;He goes on, in the end, to state that even if computers are ever<br>
capable of "simulating human thought", they will never be fully human.<br>
"The gap between human and surrogate is permanent and will never be<br>
closed." This is also false. There have been in the last year,<br>
breakthroughs in electronic interfaces between computer chips and<br>
human neurons.&gt;<br>
<p>
You’re mixing apples and oranges again.  Gelernter is talking about AI<br>
- simulating a human-level mind on a computer - a completely different<br>
subject from man-machine interfaces.  Gelernter is talking about the<br>
simulation vs. fabrication problem in systems science, what I call the<br>
issue of whether you can *program* a synthetic intelligence or whether<br>
you have to *grow* one. (Hardly a distinction that the average TIME<br>
reader would be aware of.)<br>
<p>
Actually, I like your cyborg scenario and think it’s probably the most<br>
likely path to becoming post-human; but, it’s has nothing to do with<br>
the ‘hard’ questions of AI because there’s still a ‘muse in the<br>
machine’; i.e., an ‘organically-grown’ human mind.<br>
<p>
Don’t get me wrong: I think machine intelligence is possible - we<br>
already have it, with some systems that are much more intelligent in<br>
particular domains than an un-augmented you or I could ever be - but<br>
true AI or SI or A-Life, with creativity and individual will and<br>
responsibility requires a lot more than just the raw processing power<br>
implied by your Moore’s law reference.<br>
<p>
Processing power is only a small part of the story - growing the right<br>
kind of network is far more important.  Those oriented toward<br>
mechanical engineering always seem to assume that the software will<br>
just automagically emerge if you build the hardware properly.  I was<br>
disappointed that _Nanosystems_ totally ignored software issues<br>
(actually, Drexler assumes backward-chaining, broadcast instructions<br>
from a pre-existing higher level - again, a muse in the machine!)<br>
<p>
&lt;Charges of racism and heresy will fly. Children and less<br>
sophisticated adults will call each other "chip-lover" and<br>
"bio-bigot".&gt;<br>
<p>
But (reread Bruce Sterling’s _Schismatrix_), "bio-bigots" don’t<br>
necessarily imply religious types who shun *any* change to their<br>
’God-given’ body - it could also refer to those who prefer genetic<br>
engineering and other bio-approaches to augmentation.<br>
<p>
&lt;To remove the augmentations will hobble these personalities as much<br>
as a lobotomy would do so to you or I. These transhumans will lead the<br>
way into this future whether neo-Luddites like Gelernter like it or<br>
not.&gt;<br>
<p>
Again, what does this have to do with the price of tea in China? <br>
Augmentations are not AI, and that’s what Gelernter was talking about.<br>
 If you’re going to label anyone who has concerns about whether<br>
traditional computing techniques can be used to implement AI as a<br>
neo-Luddite, well ...<br>
<p>
Mark Crosby<br>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
_____________________________________________________________________<br>
Sent by RocketMail. Get your free e-mail at <a href="http://www.rocketmail.com">http://www.rocketmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2110.html">Perry E. Metzger: "money"</a>
<li> <b>Previous message:</b> <a href="2108.html">Michael Lorrey: "Re: Deep Blue colmun in TIME, May 19th"</a>
<li> <b>Maybe in reply to:</b> <a href="2055.html">Michael Lorrey: "Deep Blue colmun in TIME, May 19th"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2116.html">Michael Lorrey: "Re: Deep Blue colmun in TIME, May 19th"</a>
<!-- reply="end" -->
</ul>
