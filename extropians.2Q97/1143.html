<!-- received="Wed May 14 19:36:02 1997 MDT" -->
<!-- sent="Wed, 14 May 1997 19:39:37 -0500" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Nootropics and Algernon's Law" -->
<!-- id="199705150050.RAA10022@hss.caltech.edu" -->
<!-- inreplyto="" -->
<title>extropians: Nootropics and Algernon's Law</title>
<h1>Nootropics and Algernon's Law</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Wed, 14 May 1997 19:39:37 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1143">[ date ]</a><a href="index.html#1143">[ thread ]</a><a href="subject.html#1143">[ subject ]</a><a href="author.html#1143">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1144.html">Michael Lorrey: "Re: Can't resist one more shot"</a>
<li> <b>Previous message:</b> <a href="1142.html">Robin Hanson: "Distant Gamma Ray Burster Nailed"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0997.html">Michael Lorrey: "Re: Nootropics and Algernon's Law"</a>
<li> <b>Maybe reply:</b> <a href="0997.html">Michael Lorrey: "Re: Nootropics and Algernon's Law"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; &gt; Anders Sandberg wrote:</i><br>
<i>&gt; &gt; &gt;In general, the idea of nootropics only</i><br>
<i>&gt; &gt; &gt;having positive cognitive effects and no side-effects is *very* unlikely,</i><br>
<i>&gt; Carl Feynman wrote:</i><br>
<i>&gt; &gt; In fact it is forbidden by Algernon's Law: All simple major enhancements of</i><br>
<i>&gt; &gt; human intelligence are net evolutionary disadvantages.</i><br>
Michael Bowling wrote:<br>
<i>&gt; Algernon's Hypothesis (sorry, it han't been around long enough) says</i><br>
<i>&gt; nothing about the ability of an individual to increase her/his</i><br>
<i>&gt; intelligence, nor does it place any limits on the magnitude of an</i><br>
<i>&gt; increase. Algernon simply states that a person with such an enhancement</i><br>
<i>&gt; will put the fitness of their genes at risk. Genes, remember, are the source</i><br>
<i>&gt; of many limits we extropians seek to overcome. As an extropian, the fitness of</i><br>
<i>&gt; my genes is a non-issue, if not an annoyance. Just b/c my genes suffer as</i><br>
<i>&gt; my intelligence expands does not mean I do.</i><br>
<p>
Um, "Algernon's Law" was invented by me, not the (mouse) Algernon.  Nor<br>
does it yet occupy the Theory/Hypothesis spectrum; that applies only to<br>
individual Algernic modifications, not Algernon's Guideline in general -<br>
which is aiming for a position in cognitive science similar to that of<br>
TANSTAFFL in politics, or Murphy's Law in engineering.  I.e, you can<br>
fool it six ways from Sunday, but you'd damn well better know about it<br>
to begin with.  Anyway...<br>
<p>
There are three basic ways an intelligence enhancement can be an<br>
evolutionary disadvantage; Galileo-martyrdom, biological limits, or<br>
cognitive tradeoffs.<br>
<p>
The first is the Galileo-martyrdom theory of genius.  That is, the<br>
intelligence enhancement either (1) causes the person to be lynched by<br>
an angry mob or (2) causes the person to realize there are more<br>
important things in life than reproduction.  Although this is a favorite<br>
note of science-fiction authors, many conditions would have to be<br>
satisfied before we could say with confidence that the only downside of<br>
some nootropic was that you'd be SO smart the normals just couldn't take<br>
it any more.  Like, the nootropic tampers with the serotonergic systems<br>
and turns you into a megalomaniac genius.  Even that wouldn't be enough,<br>
frankly, because it's too easy to ask why this form of genius requries<br>
some random emotional state.<br>
<p>
If the nootropic makes a specific chemical change that causes you to<br>
lose interest in reproduction, then that's fine - although, as above,<br>
one would have to show that this was *inherent* *to* *the* *advantage*,<br>
and not just a side effect of the particular chemical used - otherwise,<br>
why hasn't a similar but less devastating drug been invented by<br>
evolution long ago?  An example might be an improvement to the<br>
goal-processing system that causes the Algernon to dispassionately and<br>
perfectly evaluate the justification of every goal; such a person might<br>
not be responsive to his evolutionarily tuned, unjustified emotions.<br>
<p>
Next come biological limits, such as brain size/hip width.  Or neuron<br>
number/metabolic energy consumed.  A genuine nootropic would probably<br>
work by bypassing one of these limits.  Example:  Although this isn't a<br>
pill-type nootropic, it's still "add-to-brain" material, and the most<br>
obvious of all:  Extra brains.  Clone yourself, take the fetal neural<br>
tissue.  (Before it forms a brain, of course!  a) ethics b) won't<br>
integrate.)  Maybe you'd need to expand the skull somehow, maybe not;<br>
maybe the neurons would integrate, maybe not; it's still worth trying, I<br>
say.  And the reason brains haven't grown before is, of course, that the<br>
head would be too big to get out of the birth canal.<br>
<p>
Similarly, a nootropic that caused neurons to double in speed (or<br>
plasticity) at the expense of octupling energy consumed would also get<br>
around Algernon's Law.  You might need to walk around with a<br>
refrigerator on your head, or you might keel over from your heart<br>
beating twice as fast (until it all adjusted), but modern medical<br>
science could probably see you through it.<br>
<p>
Cognitive tradeoffs, however, are the main thrust of Algernon's Law. <br>
Too many old-time science fiction novels had Miraculous Brain<br>
Stimulators that just poured electricity into some section of the brain<br>
and, ta-da, your IQ doubled.  This isn't the reason I invented<br>
Algernon's Law, but it is the reason I felt it had to be published:  I<br>
was afraid that at some point in the near future, some wannabe<br>
transhuman would stick a wire into his frontal cortex, pour in the<br>
juice, and expect to be turned into a superman.  (I did NOT think<br>
Algernon's Law was absolute, most of the workarounds/disproofs I get are<br>
actually pointed out on the Web page, and Algernon's Law is a tool, not<br>
a message of despair.  OK?)<br>
<p>
Well, as is not surprising, pouring juice into the frontal cortex<br>
actually degrades performance by adding noise.  Proof by induction: <br>
They used induction to stimulate currents in the frontal cortex and<br>
performance went down.  Part of "Algernon's Law: The Web Page" deals<br>
with where you pour the juice in to actually stimulate some ability. <br>
(Answer:  The limbic system - emotions can trigger cognitive abilities<br>
and can be evoked by electrical current.)<br>
<p>
So, that being said, what happens when you "stimulate" some ability?  My<br>
answer is that this ability consumes more than its fair share of<br>
cognitive resources that would ordinarily be distributed evenly among<br>
many abilities.  For the sake of discussion, let's suppose that two<br>
mental abilities use a "search tree" among identical subject material,<br>
but one mental ability works best with a wide, shallow, breadth-first<br>
search, while another works best with a narrow, deep, depth-first<br>
search.  If the "stimulation" locks ability A on "always on", ability B<br>
will suffer, because - again by hypothesis - neural formations are not<br>
easily reprogrammable serial computers; a given connective architecture<br>
is either wide and shallow or narrow and deep.  Thus, each ability can<br>
prosper only at the expense of the other.<br>
<p>
Moreover, any artificial amplification will result in a net evolutionary<br>
disadvantage, in this case for deep mathematical reasons.  In search<br>
trees, doubling the resources available results in a small increase in<br>
performance.  A tree of depth 10 and breadth 2 consumes 1000 neurons. <br>
Add another thousand neurons and the new tree is only of depth 11 - a<br>
10% increase from a doubling of resource.  So say one ability uses a<br>
million-neuron tree of depth 10 and breadth 4, while another uses a<br>
million-neuron tree of depth 5 and breadth 16.<br>
<p>
Locking ability A into position at the expense of B - assuming the<br>
entire neural resources of B are devoted to A - will result in a trivial<br>
increase in ability A - around .5 depth in the first case, and a 2.2<br>
increase in breadth for the other.<br>
<p>
The basic framework may vary from ability to ability, but the message of<br>
Algernon's Law is the same:  "Things are the way they are for a reason;<br>
the human brain was designed by evolution to operate at capacity, and<br>
you can't get huge performance increases by wishing for them, any more<br>
than you can speed up a computer by doubling the wattage.  You have to<br>
actually add resources, and then you have to explain why evolution<br>
hasn't added them already."<br>
<p>
So - what nootropics might actually work, getting around Algernon's<br>
Law?  I see a few:<br>
<p>
1)  Additional neurons.  Either fetal neural tissue transplants or<br>
something that coaxes the nerve tissue into regenerating - though the<br>
latter is suspect.  (You might run a 85% risk of brain cancer.)<br>
<p>
2)  High-speed neurons.  Maybe a drug that myelinates all the<br>
unmyelinated neurons, or a complex nanotechnological fix replacing<br>
neurons with transistors and axons with optical fibers.<br>
<p>
3)  Increased plasticity.  A drug might cause the brain to revert to<br>
childhood, temporarily decreasing actual intelligence, but vastly<br>
increasing one's ability to learn.  Or the drug might delay puberty<br>
until age 22; I think that would be a wonderful idea.  Teenagers, after<br>
all, are the result of having all these physically mature but<br>
not-ready-to-join-society types around.<br>
<p>
4)  Altered states of consciousness.  The brain is full of<br>
evolutionarily advantageous distractions such as boredom, lust, and so<br>
on.  A nootropic might remove the ability to be bored - although one<br>
would have to be careful that boredom didn't stimulate some mental<br>
ability.  Removing frustration, for example, would be very iffy indeed. <br>
But some high-tech derivative of cocaine, without being addictive or<br>
pleasurable, might still give programmers the ability to work frantic<br>
16-hour days for years on end without even beginning to feel "burned<br>
out".  See David Pearce's "The Hedonistic Imperative", my own discussion<br>
of "Iron-Willed Algernons", and a certain hyperoptimistic member of this<br>
list.<br>
<p>
5)  One might also lock some given ability on high - not to enhance it,<br>
but simply because cognitive research has shown that that is the best<br>
approach to some problem.<br>
<p>
6)  Finally, there's my original proposal - lock some ability on high,<br>
and if this nukes out half the brain, deal with it.  Would you sacrifice<br>
your ability to understand "Godel, Escher, Bach" if it would make you<br>
the world's greatest designer of program architectures?  Would you do it<br>
if *someone* with ability of that level was needed for us to make it to<br>
the Singularity?  Call 1-800-555-SURE or 1-800-555-NOPE to register your<br>
opinion.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1144.html">Michael Lorrey: "Re: Can't resist one more shot"</a>
<li> <b>Previous message:</b> <a href="1142.html">Robin Hanson: "Distant Gamma Ray Burster Nailed"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0997.html">Michael Lorrey: "Re: Nootropics and Algernon's Law"</a>
<li> <b>Maybe reply:</b> <a href="0997.html">Michael Lorrey: "Re: Nootropics and Algernon's Law"</a>
<!-- reply="end" -->
</ul>
