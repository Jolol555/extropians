<!-- received="Wed Jun 25 18:41:22 1997 MDT" -->
<!-- sent="Wed, 25 Jun 1997 17:14:20 -0700" -->
<!-- name="Eric Watt Forste" -->
<!-- email="arkuat@pobox.com" -->
<!-- subject="Re: Where's God?" -->
<!-- id="199706260014.RAA17649@idiom.com" -->
<!-- inreplyto="Where's God?" -->
<title>extropians: Re: Where's God?</title>
<h1>Re: Where's God?</h1>
Eric Watt Forste (<i>arkuat@pobox.com</i>)<br>
<i>Wed, 25 Jun 1997 17:14:20 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2130">[ date ]</a><a href="index.html#2130">[ thread ]</a><a href="subject.html#2130">[ subject ]</a><a href="author.html#2130">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2131.html">Rick Knight: "RE: How Important is Money?"</a>
<li> <b>Previous message:</b> <a href="2129.html">Rick Knight: "Meanlingless Abstractions?"</a>
<li> <b>Maybe in reply to:</b> <a href="1883.html">Meisner@act.org: "Where's God?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2145.html">Tony Hollick: "Re: Where's God?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Erik Moeller writes:<br>
<i> &gt; So you say that computing power and high quality information are the</i><br>
<i> &gt; same? </i><br>
<p>
I said nothing of the kind. I said that you can't define the<br>
sense of the word "quality" that you are using, and you've done<br>
nothing so far to convince me otherwise.<br>
<p>
<i> &gt; And why should any posthuman entity talk to non-posthuman entities?</i><br>
<p>
Comparative advantage. Of course, that's a term of art from the<br>
field of economics, which you can't be bothered to study,<br>
because you're so smart you've already figured out that it's all<br>
crap. <br>
<p>
<i> &gt; High-quality information is the only *scarce* resource. One planet, one</i><br>
<i> &gt; solar space station, provides enough energy for a posthuman think tank.</i><br>
<i> &gt; The sensors will need some more but it will never get into the area of</i><br>
<i> &gt; scarcity. This trend is visible even today. Look at the internet. OK, it</i><br>
<i> &gt; needs some energy with all those computers and telephone lines, but it's</i><br>
<i> &gt; a HUGE information storage, even without nanotechnology, and it doesn't</i><br>
<i> &gt; take any considerable part of this planet's total energy.</i><br>
<p>
Oh, yeah, all the computers and storage media devices will just<br>
grow on trees. St. Drexler says so! (I hope that if Eric Drexler<br>
reads this, he will forgive me for calling attention to a popular<br>
misapprehension of his work, a misapprehension against which he<br>
has worked and for which he is not to be blamed.) And yeah, the<br>
"quality" will just happen magically. Never mind, Erik Moeller,<br>
that you have no clue what the causes of quality are. If you do<br>
have a clue as to what causes quality, perhaps you'd like to share<br>
it with us.<br>
<p>
<i> &gt; &gt; When you give me an apple and I give you an orange, and this happens</i><br>
<i> &gt; &gt; voluntarily, then you have an orange (which you prefer to an apple)</i><br>
<i> &gt; &gt; and I have an apple (which I prefer to an orange).  We both benefit,</i><br>
<i> &gt; &gt; positive sum game, and furthermore because our act (a transaction)</i><br>
<i> &gt; &gt; has infinitesimally affected the market price of apples and oranges,</i><br>
<i> &gt; &gt; we have anonymously transmitted some information to the world about</i><br>
<i> &gt; &gt; our relative preferences for apples and oranges. There's an</i><br>
<i> &gt; &gt; information-communication feat very difficult to pull off reliably</i><br>
<i> &gt; &gt; in an engineered system.</i><br>
<p>
<i> &gt; Problem number one is, as I already said, that I think posthumans will</i><br>
<i> &gt; only appear as collectives. If you assume that there is something like a</i><br>
<i> &gt; "meaning of life", then all posthumans will proabably search for it and</i><br>
<i> &gt; act like a collective.</i><br>
<p>
Well, your faith is very touching, Erik, but some of us have open<br>
minds. It is entirely possible that I will be absorbed into some<br>
delicious ubercollective in the next forty years, and I might even<br>
decide that this is the right thing to do before it comes down to<br>
that. But right now, I don't know, and right now, that is not to<br>
my taste (in part because it does not accord with my theories about<br>
how quality emerges, which I will keep to myself because I haven't<br>
tested them for long enough yet), and I certainly wouldn't expect<br>
to win any arguments by handing people my Article of Faith that<br>
We're All Going to End Up in a Big Collective Anyway.<br>
<p>
<i> &gt; Problem number two is that money is simply dispensable. If you assume</i><br>
<i> &gt; that there aren't collectives but individuals, you must also accept that</i><br>
<i> &gt; there is nothing like a "meaning of life" or that not everyone wants to</i><br>
<i> &gt; search for it. In this case, every posthuman has different interests. It</i><br>
<i> &gt; is likely, or "probably unavoidable", that those with the same interests</i><br>
<i> &gt; will form collectives _again_.</i><br>
<p>
I think every posthuman has different interests, and the thing that<br>
I find particularly annoying about you is how determinedly you<br>
throw yourself into the world trying to force everyone to have the<br>
same interests. "Not everyone wants to search for it"... you have<br>
hit the nail on the head, right there, Erik, but apparently you<br>
don't realize this. Different people, even different postpeople,<br>
have different values, and this is PERFECTLY OKAY. It's only a<br>
problem when they start killing each other over their differences...<br>
I think you and I agree on that.  But trying to smoosh everyone's<br>
values into one Big Collective Value just makes everyone desperately<br>
afraid that the final Big Collective Value is not going to end up<br>
looking even remotely like their current values, and then their<br>
egos are terrified and they start fussing and fighting and blowing<br>
things up. We are still just apes with our heads bloated with<br>
absorbed partial computational results (culture) from the big<br>
memetic evolutionary process. And we can do a hell of a lot of<br>
wonderful things with that... but not if we pretend that it's not<br>
so, or that we are somehow perfect already. You can't force people<br>
to be boddhisattvas, especially not by taking away all their money.<br>
They have to do it from their own hearts or not at all.<br>
<p>
Money is a communications medium that helps to automatically and<br>
nonviolently reconcile the differing, varied values of different<br>
people.  You can only dispense with it if you accept the Moeller<br>
Dogma that Everyone Ought to Have the Same Values. I utterly reject<br>
that Dogma at present, so if you want to talk me into believing<br>
it, I invite you to get down to business. So far you've used that<br>
dogma to defend your arguments, but you haven't defended the dogma<br>
itself.<br>
<p>
It would be a hell of a lot easier to explain money to people if<br>
we still used chemical elements instead of gummint counterfeit,<br>
because in a chemical-element currency system it's fairly easy to<br>
see that money is just a special-case refinement and technical<br>
improvement of ordinary barter. And barter is just a means by which<br>
people can cooperate to use their varied resources to fulfill their<br>
varied values.<br>
<p>
<i> &gt; If you think a world with several posthuman individuals is likely,</i><br>
<i> &gt; similar to today's world just with cleverer inhabitants, you must</i><br>
<i> &gt; consider that other posthuman collectives might be worried about this.</i><br>
<i> &gt; For those high-powered individuals might destroy information sources the</i><br>
<i> &gt; collectives need. In this case, the individuals would be "assimilated". </i><br>
<p>
Why is this concern of the collectives more legitimate than the<br>
concern of the individuals that the high-powered  collectives might<br>
destroy information sources the individuals need? Your argument is<br>
curiously one-sided.<br>
<p>
<i> &gt; If posthumans leave the collective for a while to gather information</i><br>
<i> &gt; separately, and they meet other posthumans, they will try to find out</i><br>
<i> &gt; their interests, and if they are equal again, they will probably join.</i><br>
<p>
<i> &gt; And for the exchange between several different collectives: that's the</i><br>
<i> &gt; same like exchange between individuals. Assimilation or ignorance. Only</i><br>
<i> &gt; in very few cases it will work like "I tell you this, you tell me that",</i><br>
<i> &gt; or "Give me 10$ (!!!) and I will tell you this, for with the 10 $ I can</i><br>
<i> &gt; buy that other information from the posthuman guy next door, positive</i><br>
<i> &gt; sum game, but consider inflation, too".</i><br>
<p>
I see a lot of assertions above, and a couple of nice just-so<br>
stories, but I don't see anything that looks like deduction,<br>
argument, or evidence. Am I supposed to believe this stuff just<br>
because you say so? "They will probably do this, they will<br>
probably do that, this other thing probably won't happen." Why<br>
are you bothering to post such drivel?<br>
<p>
Another interesting thing about this argument is that I'm not making<br>
any claims about what sorts of things posthumans are likely to<br>
value (except that they'll probably value more than JUST ONE THING),<br>
whereas you seem to be claiming that not only do you know that<br>
all posthumans will value JUST ONE THING, but also that you know<br>
what that ONE THING is. A rather presumptuous claim, it seems to<br>
me. It's entirely possible that posthumans will spend all their<br>
time chasing after things you and I simply haven't got the<br>
conceptual apparatus to even begin to imagine. Can we have a<br>
little acknowledgement of that, please? To quote Dr. Evil,<br>
"Throw me a bone here."<br>
<p>
I mean, "I'm Erik Moeller, smartest collectivist uebermensch in<br>
the galaxy. You people are all helpless-minded, like children."<br>
might make you feel good, and it might even be true for all I know,<br>
but it's certainly not going to persuade anybody on the Internet.<br>
<p>
<i> &gt; And you bet that Microsoft would run around shooting and bombing</i><br>
<i> &gt; (kidnapping would be too expensive) people in a "UIF" world. OK, that's</i><br>
<i> &gt; exaggeration, but it is obvious that they would develop some nasty</i><br>
<i> &gt; tricks to stop illegal copying.</i><br>
<p>
I'm no fan of Microsoft's, but you're just making yourself look<br>
like a paranoid 2600 reader, like that guy who was writing in to<br>
say that the Federal government ought to take over the American<br>
phone companies. Microsoft really don't care about illegal copying<br>
unless it hurts sales, which means the only illegal copying they<br>
worry about is illegal copying within large corporate and governmental<br>
organizations (such as is rampant in China, for instance). Microsoft<br>
are hardly going to be shooting or bombing punks like you and me<br>
(except for the unfortunate few who are "made examples of"), and<br>
large corporations and some governments respond to lawyers much<br>
better than they do to troops. People who hack corporate systems<br>
for a living (like Bill Gates does) understand this.<br>
<p>
<i> &gt; The government is not the evil player in our world's game. It's those</i><br>
<i> &gt; who are supporting it, the big industry and the banks, who are "evil" in</i><br>
<i> &gt; the sense that their actions endanger mankind. </i><br>
<p>
I think the things that endanger mankind are considerably more<br>
complex than capsule summaries such as this one. Socrates and my<br>
dad both claim that evil is illusory, and that it is only<br>
ignorance that endangers mankind, and I haven't been able to<br>
refute either one of them yet, although I do maintain my doubts.<br>
You might like to know that the world is full of people who<br>
immediately turn off their ears whenever they see someone on a<br>
soapbox prating about good and evil (not that I'm one of them or<br>
antyhing).<br>
<p>
<i> &gt; In order to reach posthumanity [as soon as possible], we must avoid the</i><br>
<i> &gt; destruction of our home planet. </i><br>
<p>
Maybe. I would like to believe this is true. Expectation foils<br>
perception. I am quite fond of our home planet, except for the<br>
inconveniently intense gravitational field (which I understand was<br>
necessary to get things started). I'm also not quite sure that<br>
Reaching Posthumanity (quickly or otherwise) is the Main Thing,<br>
since no one seems to agree on what that means, much to my<br>
approval.<br>
<p>
<i> &gt; I'm not saying that I don't want to use knowledge. Using knowledge is</i><br>
<i> &gt; what I do every day. I say that any posthuman entity has no interest</i><br>
<i> &gt; whatsoever in using knowledge, except for obtaining more knowledge (so</i><br>
<i> &gt; the knowledge is just a BASIS [upon which new knowledge is placed] or a</i><br>
<i> &gt; TOOL [for instance to build special external sensors], but never [or</i><br>
<i> &gt; rarely] a CURRENCY).</i><br>
<p>
Well, if knowledge is the only thing you value, then why are you<br>
blathering instead of studying? I know that's a terribly snide<br>
thing to say, but value-monists are always leaving themselves<br>
open for remarks like that.<br>
<p>
Oh, right, you're a *collectivist* value-monist, so you want to<br>
make sure that *I* learn your knowledge too. Look at the little<br>
memetic salmon rushing madly upstream, propagate, propagate,<br>
propagate, MUST SPAWN! (Not that I disapprove of literary<br>
ambitions... far from it. I was once there too. I just try to be<br>
a little more leisurely and deliberate about it these days.)<br>
<p>
Just please don't send me to room 101 for my indoctrination. I<br>
actually like all the salmon, but I don't care for rats. Or<br>
stool pigeons.<br>
<p>
<i> &gt; &gt; What you want is power to help the poor and suffering: stop</i><br>
<i> &gt; &gt; pretending otherwise. You mean to rule wisely and well, but you</i><br>
<i> &gt; &gt; mean to rule.</i><br>
<p>
<i> &gt; I don't want to rule. I want the rulers to rule better.</i><br>
<p>
Same damn thing. <br>
<p>
I want the rulers to stop ruling, so people can learn how to rule<br>
themselves. You want to keep them "helpless-minded like children"<br>
(as you once asserted most people already are) so you can inculcate<br>
them with your Values, which are, after all, Correct.<br>
<p>
<pre>
--
Eric Watt Forste ++ arkuat@pobox.com ++ expectation foils perception -pcd
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2131.html">Rick Knight: "RE: How Important is Money?"</a>
<li> <b>Previous message:</b> <a href="2129.html">Rick Knight: "Meanlingless Abstractions?"</a>
<li> <b>Maybe in reply to:</b> <a href="1883.html">Meisner@act.org: "Where's God?"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2145.html">Tony Hollick: "Re: Where's God?"</a>
<!-- reply="end" -->
</ul>
