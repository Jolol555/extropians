<!-- received="Tue Aug 26 12:25:11 1997 MDT" -->
<!-- sent="Tue, 26 Aug 1997 19:29:46 +0200" -->
<!-- name="den Otter" -->
<!-- email="otter@globalxs.nl" -->
<!-- subject="Re: Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<!-- id="199708261735.TAA17168@ravian.globalxs.nl" -->
<!-- inreplyto="Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<title>extropians: Re: Goo prophylaxis (was: Hanson antiproliferation method?)</title>
<h1>Re: Goo prophylaxis (was: Hanson antiproliferation method?)</h1>
den Otter (<i>otter@globalxs.nl</i>)<br>
<i>Tue, 26 Aug 1997 19:29:46 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2488">[ date ]</a><a href="index.html#2488">[ thread ]</a><a href="subject.html#2488">[ subject ]</a><a href="author.html#2488">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2489.html">YakWaxx@aol.com: "Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2487.html">The Low Golden Willow: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
----------<br>
Nicholas Bostrom &lt;bostrom@mail.ndirect.co.uk&gt; wrote:<br>
<p>
<i>&gt; Safe Libertarian Future:</i><br>
<i>&gt; The scenario assumes that many humans value freedom and independent </i><br>
<i>&gt; personal existence higher than anything else. When nanotechnology </i><br>
<i>&gt; approaches, they realise that if freedom is allowed in a world with </i><br>
<i>&gt; strong nanotech, then some mad person will certainly design the </i><br>
<i>&gt; doomsday virus. So they realise they have to give up on freedom. But </i><br>
<i>&gt; then some bright person comes up with the idea that all people upload </i><br>
<i>&gt; and that only a robot is left with the ability to operate in the real </i><br>
<i>&gt; world. The whole system is hardwired so that the robot only executes </i><br>
<i>&gt; instructions that have been agreed upon by the majority of the </i><br>
<i>&gt; uploads. In their virtual reality, the uploads can do anything they </i><br>
<i>&gt; want: each one has unlimited individual freedom. The only thing they </i><br>
<i>&gt; can't do in the virtual reality is to mass murder a lot of other </i><br>
<i>&gt; uploads (the virtual physics doesn't allow destructive nanomachines </i><br>
<i>&gt; to be built, for example). The uploads cannot influence the external </i><br>
<i>&gt; world either, except when a majority decision can be made. But for </i><br>
<i>&gt; many decisions, this should be feasible: e.g. colonising the galaxy </i><br>
<i>&gt; to provide more Lebensraum etc. One can even imagine refinements of </i><br>
<i>&gt; this scheme such that each individual would have his own robot that </i><br>
<i>&gt; he could to what he liked with; though this presupposes that the </i><br>
<i>&gt; robots could be built in such a way that nobody could use their robot </i><br>
<i>&gt; to do anything that would endanger the computer on which they all </i><br>
<i>&gt; existed.</i><br>
<i>&gt; </i><br>
<i>&gt; This is the only way I can think of that a very nearly </i><br>
<i>&gt; completely libertarian society, without any guardian or international </i><br>
<i>&gt; government, can exist long after the arrival of strong nanotech.</i><br>
<p>
There will always be (plenty) of people who'll refuse to get uploaded<br>
into some virtual reality asylum, what about them? Would they be<br>
forced to upload (upload or die!)? After all, if these people had the<br>
same level of technology they could be a serious threat to the virtual<br>
libs. The same goes for "alien" entities. IMHO a democratic system<br>
like the one above is almost by definition a severe handicap in case<br>
of a conflict with "free" outsiders, because while the democrates are<br>
busy debating and voting, the enemy has already launched his proton<br>
torpedoes or whatever. <br>
<p>
What would happen if someone trashed the robot (the only outside link),<br>
would the VRs be trapped in their "dreamworld" forever?<br>
<p>
Anyway, I think the only way you can stay reasonably free *and* safe is<br>
when everybody (possibly in small like-minded groups) leaves earth and goes<br>
in different directions. A 1.000.000 lightyears or so seem (with the<br>
current laws of physics) like a pretty safe barrier. Maybe by the<br>
time we run out of "space" (if this is possible at all), we'll also be<br>
smart<br>
enough to avoid an all-out conflict (Universal War 1).<br>
<p>
-----------------------------------------------------<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2489.html">YakWaxx@aol.com: "Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2487.html">The Low Golden Willow: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
