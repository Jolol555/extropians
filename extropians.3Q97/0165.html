<!-- received="Mon Jul  7 13:00:31 1997 MDT" -->
<!-- sent="Mon, 7 Jul 1997 11:19:41 -0700" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Uploading" -->
<!-- id="199707071819.LAA22598@crypt.hfinney.com" -->
<!-- inreplyto="Uploading" -->
<title>extropians: Re: Uploading</title>
<h1>Re: Uploading</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Mon, 7 Jul 1997 11:19:41 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#165">[ date ]</a><a href="index.html#165">[ thread ]</a><a href="subject.html#165">[ subject ]</a><a href="author.html#165">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0166.html">Richard G. Bunker, Jr.: "Re: GUNS: University of Chicago study"</a>
<li> <b>Previous message:</b> <a href="0164.html">Robin Hanson: "Re: GUNS: University of Chicago study"</a>
<li> <b>Maybe in reply to:</b> <a href="3847.html">YakWaxx@aol.com: "Uploading"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0170.html">Brent Allsop: "Re: Uploading"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Brent Allsop, &lt;allsop@swttools.fc.hp.com&gt;, writes:<br>
<i>&gt; 	"the only feelings I can objectively observe is my own" is</i><br>
<i>&gt; precisely the point.  We will so thoroughly understand the laws of</i><br>
<i>&gt; physical consciousness and how they correspond and predict what WE</i><br>
<i>&gt; feel as we observe, manipulate and stimulate our own brain that there</i><br>
<i>&gt; will be no other possibility but that others with similar neural</i><br>
<i>&gt; correlates are experiencing similar sensations.</i><br>
<p>
I agree that if a theory were developed which accurately predicted the<br>
subjective sensations for a variety of brain types, conditions, and<br>
circumstances, confirmed in their accuracy by the people experiencing<br>
these events, that it would become widely accepted as a valid theory<br>
of consciousness.  There might still be some doubters who maintain that<br>
we have no way of being certain that the theory is accurate.  (Other)<br>
people might be zombies who would claim that the theory was correct when<br>
in fact they had no consciousness at all.  But I think they would not<br>
be any more than a tiny minority, like the people today who believe that<br>
they are the only conscious beings.<br>
<p>
(It would, however, be difficult to know how to extend the theory to the<br>
more interesting cases of less-conscious beings, like animals.)<br>
<p>
<i>&gt; 	Also, just as our brain integrates many sense representations</i><br>
<i>&gt; into one single conscious world, eventually we'll be able to integrate</i><br>
<i>&gt; multiple conscious brains into single conscious worlds.  Just like we</i><br>
<i>&gt; know in our own minds that a red sensation is not anything like a</i><br>
<i>&gt; salty sensation, or just like we know that red produced by one eye is</i><br>
<i>&gt; the same as red produced by the other eye, we will be able to design</i><br>
<i>&gt; ways to experience, first hand, what other minds are experiencing.</i><br>
<p>
Perhaps so.  In an earlier debate on this topic, I suggested that<br>
technologically mediated mind-reading might similarly allow direct<br>
perception of other people's consciousness.  However it raises complicated<br>
issues of whether I can be said to actually perceive your consciousness<br>
in the same way you perceive it, or whether I am inherently filtering it<br>
through my own consciousness, so that ultimately what I experience is not<br>
identical to what you do.<br>
<p>
<i>&gt; 	These are only two possible techniques to accomplish what you,</i><br>
<i>&gt; for some unknown reason, apparently claim will be forever impossible.</i><br>
<i>&gt; I'm sure if one is creative enough one can think of many other ways to</i><br>
<i>&gt; do this kind of stuff.  Once we understand how to manipulate,</i><br>
<i>&gt; engineer, improve, and upload minds and all that, all this kind of</i><br>
<i>&gt; understanding and proof must come to pass just like we know that the</i><br>
<i>&gt; earth is not the center of the universe because we are finally dancing</i><br>
<i>&gt; around in our heliocentric solar system and beyond.</i><br>
<p>
It reminds me of a disagreement I had a few years ago on<br>
comp.ai.philosophy (where discussing such issues is their bread and<br>
butter) about whether computer simulations of conscious brains would<br>
be conscious.  I suggested that it would theoretically possible to do<br>
reversible uploading.  A brain is scanned into a form where it can<br>
be modelled (abstractly!) on a computer.  It undergoes interactions<br>
and has experiences in this virtual form.  Then, using nanotech, the<br>
resulting consciousness is downloaded back into the brain, the neural<br>
pathways remodelled to the conditions described by the virtual form.<br>
This could be repeated multiple times, transitioning between body and<br>
computer (and in fact this might even be a common form of transportation<br>
under some circumstances).<br>
<p>
I argued that people would have the sense that the transition between meat<br>
to computer was not significant, that their memories and experiences would<br>
seem much the same in both circumstances.  Hence it would strike them as<br>
absurd to suggest that they had not been conscious while in the computer,<br>
since they had exactly the same evidence for their consciousness in that<br>
form as they did when they were in a body, namely their memories of their<br>
sense of self.<br>
<p>
The person I was debating with maintained that the people might not be<br>
conscious while in the computer, that the downloading process actually<br>
would end up inserting false memories of earlier conscious experiences.<br>
While logically possible, I think the discrepancy between this point<br>
of view and the sense people had of their experiences would make it<br>
effectivelly unsupportable.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0166.html">Richard G. Bunker, Jr.: "Re: GUNS: University of Chicago study"</a>
<li> <b>Previous message:</b> <a href="0164.html">Robin Hanson: "Re: GUNS: University of Chicago study"</a>
<li> <b>Maybe in reply to:</b> <a href="3847.html">YakWaxx@aol.com: "Uploading"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0170.html">Brent Allsop: "Re: Uploading"</a>
<!-- reply="end" -->
</ul>
