<!-- received="Sun Aug 24 17:19:27 1997 MDT" -->
<!-- sent="Sun, 24 Aug 1997 18:09:53 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<!-- id="199708242102.WAA03200@andromeda.ndirect.co.uk" -->
<!-- inreplyto="Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<title>extropians: Re: Goo prophylaxis (was: Hanson antiproliferation method?)</title>
<h1>Re: Goo prophylaxis (was: Hanson antiproliferation method?)</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 24 Aug 1997 18:09:53 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2416">[ date ]</a><a href="index.html#2416">[ thread ]</a><a href="subject.html#2416">[ subject ]</a><a href="author.html#2416">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2417.html">EvMick@aol.com: "Re: Government's war against it citizens"</a>
<li> <b>Previous message:</b> <a href="2415.html">Len Flatley: "Re: Government's war against it citizens"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Nicholas Bostrom wrote:<br>
<i>&gt; </i><br>
<i>&gt; Anders Sandberg wrote:</i><br>
<i>&gt; </i><br>
<i>&gt; &gt; Design is good at jumping over deserts in the fitness landscape,</i><br>
<i>&gt; &gt; while evolution is good at searching it</i><br>
<i>&gt; </i><br>
<i>&gt; This would seem to lead to the prediction that the more that is known</i><br>
<i>&gt; the less useful will evolutionary computing be.</i><br>
<p>
Very true.  The power of evolutionary computing lies in its blind speed. <br>
Let's say we have a million-organism brew that evolves for a thousand<br>
generations.  Now let's say we have a hundred thousand programmers, each of<br>
whom chooses an organism out of the stew and redesigns it.  The latter<br>
situation will proceed more slowly than the first, and be vastly more<br>
expensive, but it will also be far more powerful and capable of reaching<br>
loftier goals.<br>
<p>
Evolution - in at least one way of doing it - is a vast, random, search tree,<br>
with each branch growing a number of leaves that depends on how profitable<br>
that branch is right now.  An AI might use the same tree, but with<br>
intelligently redesigned versions of each leaf.  Ultimately, guided evolution<br>
and design converge to the same cognitive ability.  How do we ourselves ask<br>
the "What-if?" questions that are key to creative design?  Some kind of<br>
immense semantic search tree - perhaps guided, perhaps not - would be my guess.<br>
<p>
<i>&gt; &gt; As an example, assume the worst scenario happens and an escaped badly</i><br>
<i>&gt; &gt; programmed dishwashing nanite</i><br>
<i>&gt; </i><br>
<i>&gt; This does not seem to be the worst scenario to me. The worst</i><br>
<i>&gt; scenario would be something deliberately built to eliminate all</i><br>
<i>&gt; life. (It would be even worse if it was designed to torture it.)</i><br>
<p>
Very, very true.  A lot of people on this list seem to lack a deep-seated<br>
faith in the innate perversity of the universe.  I shudder to think what would<br>
happen if they went up against a perverse Augmented human.  Field mice under a<br>
lawn mower.<br>
<p>
<i>&gt; &gt; It will spread with the speed of an bacterial</i><br>
<i>&gt; &gt; infection, and be quite deadly.</i><br>
<i>&gt; </i><br>
<i>&gt; Why couldn't it spread much faster? Bacteria are limited to some</i><br>
<i>&gt; specifid kinds of hosts, the nanites could attack any organic</i><br>
<i>&gt; material and many inorganic ones too.And if they were deliberately</i><br>
<i>&gt; designed, they could transform themself to missiles after they had</i><br>
<i>&gt; eaten enough, and then swoosh accross the seven sees in a very short</i><br>
<i>&gt; time.</i><br>
<p>
I'd actually think that the infection would spread in multiple waves.  The<br>
first wave might be small pellets travelling at hypersonic speeds, or even<br>
lightspeed computer viruses travelling to existing replicators.  The second<br>
wave would be a softening-up wave that would reproduce very quickly and at<br>
high speed, taking small bites out of things and leaving third-wave<br>
replicators behind.  The third wave would be immensely destructive, the actual<br>
gray goo.  The fourth wave, if any, would assemble things out of the raw<br>
material thus produced.<br>
<p>
Note that these don't need to be different types of replicator.  Each "wave"<br>
could be a different mode of action, evoked by circumstances.<br>
<p>
<i>&gt; &gt;Of course, as soon as this becomes</i><br>
<i>&gt; &gt; known there will be several groups who quickly enclose themselves in</i><br>
<i>&gt; &gt; their already built underground bases (Cheyenne mountain is an</i><br>
<i>&gt; &gt; example that exists today, and with this level of nanotech I think</i><br>
<i>&gt; &gt; there will be more "nanosurvivalists" waiting for the disaster).</i><br>
<i>&gt; </i><br>
<i>&gt; They might have to go there pretty quickly, like after a nuclear</i><br>
<i>&gt; alert. They will have to make sure that not a single little nanite</i><br>
<i>&gt; finds a way in. They will have to hope that the nanite doesn't eat</i><br>
<i>&gt; rocks and cement. They will have a limited time to figure out how to</i><br>
<i>&gt; use their very limited resources to eliminate a enemy that already</i><br>
<i>&gt; forms a think deadly layer over the whole earth. They have to hope</i><br>
<i>&gt; that the nanites weren't deliberately designed to pile up explosives</i><br>
<i>&gt; on top of their bunker and blow it all away. --Yes, they *could* make</i><br>
<i>&gt; it, at least in a Hollywood movie...</i><br>
<p>
I agree, except that they'll be using nukes, not ordinary explosives.  Or the<br>
nanites could surround the entire compound, lift it into space, and toss it<br>
into the Sun.<br>
<p>
<i>&gt; &gt; So</i><br>
<i>&gt; &gt; while the biosphere turns to dishwashing goo there will be people</i><br>
<i>&gt; &gt; around who are very motivated to find a weapon against it, for</i><br>
<i>&gt; &gt; example a tailored "predator nanite" or something similar. It doesn't</i><br>
<i>&gt; &gt; appear likely that the goo could wipe out all the people (just a very</i><br>
<i>&gt; &gt; large amount of them)</i><br>
<i>&gt; </i><br>
<i>&gt; I'm sorry, but it does seem to me a bit like wishful thinking (and</i><br>
<i>&gt; reading to much SF?). I think I will call this the</i><br>
<i>&gt; go-hide-in-your-basement solution to the antiproliferation problem.</i><br>
<p>
Same here.  It's immensely easier to destroy than create.  You couldn't "hide"<br>
from a predatory nanite.  You could slow it down, keep it from getting to your<br>
bunker, surround it with a continuous wall of nuclear flame, and then make<br>
your escape into space and blast the gooey Earth into bits... then try to<br>
rebuild civilization in the new asteroid belt.<br>
<p>
But most likely, the nanite would get into your bunker before blossoming.  And<br>
then you're dead.  (Unless you're an upload, but it seems to me that that<br>
issue is for the uploads to worry about.  While this very discussion, on the<br>
other hand, could be read by some genius at Foresight who's made a<br>
breakthrough we haven't been told about.)<br>
<p>
<i>&gt; The remarks you made seem predicated on the assumption that the</i><br>
<i>&gt; nanites will be comparable to a particularly virulent biological</i><br>
<i>&gt; plague. Suppose that this isn't true. Then the only method for</i><br>
<i>&gt; avoiding disaster in a society where there are many independet</i><br>
<i>&gt; individuals with full technological access is to have some kind of</i><br>
<i>&gt; active nanotech immune system. It seems to me that the reactions</i><br>
<i>&gt; towards higher binding energy would always have an advantage, so in</i><br>
<i>&gt; this situation there would only be two ways of maintaing status quo.</i><br>
<i>&gt; </i><br>
<i>&gt; The first is if all the material were already very close to its</i><br>
<i>&gt; lowest energy state, so that no more reactions were economical. Does</i><br>
<i>&gt; anyone have a good design for a computer that would work under those</i><br>
<i>&gt; circumstances (we would all be uploads then).</i><br>
<i>&gt; </i><br>
<i>&gt; The second is to have the immune system quickly eliminating any</i><br>
<i>&gt; plagues, and it could use the fact that it has access to more energy.</i><br>
<i>&gt; A good design for this?</i><br>
<i>&gt; </i><br>
<i>&gt; Aha, I just thought of a third way. The independent folks could all</i><br>
<i>&gt; live in a virtual reality that were designed so they could do no</i><br>
<i>&gt; major harm. They would have no access to the real reality, which</i><br>
<i>&gt; would be ruled by a single entity.</i><br>
<p>
Yeah, I noted - and rejected - that possibility, some time ago.  My theory was<br>
that if you said you were going to do THAT, nobody would help you do it.  It<br>
is true that nanotechnology will most likely be controlled by a single entity<br>
or a small group of them.<br>
<p>
"Who will guard the guardians?" - maybe nanotechnology would give us a perfect<br>
lie detector.  Nanotechnology in everyone's hands would be just like giving<br>
every single human a complete set of "launch" buttons for the world's nuclear<br>
weapons.  Like it or not, nanotechnology cannot be widely and freely<br>
distributed or it will end in holocaust.  Nanotechnology will be controlled by<br>
a single entity or a small group... just as nuclear weapons are today.<br>
<p>
If that entity is benevolent and Libertarian, utility nanites would be<br>
released as they were programmed - to eliminate hunger, starvation, old age,<br>
death, etc.  The world would remain much the same, except most forms of<br>
physically based pain and coercion would be eliminated.  Other utilities might<br>
be more flexible.  No utility will give access to the forbidden molecular<br>
level, but many might give access to higher levels.  People might be able to<br>
edit their synapses or their tissue-level body structure.  (The former<br>
scenario might result in Singularity in fairly short order.)<br>
<p>
If that entity is benevolent and authoritarian, we'd probably wind up with the<br>
scenario you just described.  One guy stays in real life, the rest play tennis<br>
in VR.  Life goes on "hold" while everyone waits for the King to do a Singularity.<br>
<p>
If that entity is malevolent, immediate and indiscriminate use of nuclear<br>
weapons would be free humanity's only hope of survival.  Humanity can survive<br>
nuclear war and fallout.  It cannot survive molecular warfare.  Just as<br>
nuclear war would utterly destroy the geopolitical balance made of governments<br>
made of humans, so molecular warfare would destroy all humans made of tissues<br>
made of cells made of molecules.<br>
<p>
I should note that none of this is proposing a "Divine Right of Kings"<br>
situation.  It is not justification for the King retaining all power.  Power<br>
should still never be in the hands of one person.  It's just that in this<br>
case, the King wouldn't have any choice.  The King remains bound by the usual<br>
ethical restraints, and cannot impose any form of coercion.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2417.html">EvMick@aol.com: "Re: Government's war against it citizens"</a>
<li> <b>Previous message:</b> <a href="2415.html">Len Flatley: "Re: Government's war against it citizens"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
