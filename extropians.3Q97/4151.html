<!-- received="Sun Sep 21 19:04:33 1997 MDT" -->
<!-- sent="Sun, 21 Sep 1997 18:23:25 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: SPACE: Cassini Mission Consequences" -->
<!-- id="199709212039.NAA00436@well.com" -->
<!-- inreplyto="SPACE: Cassini Mission Consequences" -->
<title>extropians: Re: SPACE: Cassini Mission Consequences</title>
<h1>Re: SPACE: Cassini Mission Consequences</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 21 Sep 1997 18:23:25 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4151">[ date ]</a><a href="index.html#4151">[ thread ]</a><a href="subject.html#4151">[ subject ]</a><a href="author.html#4151">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4152.html">me: "Re: [Meta] testing email program"</a>
<li> <b>Previous message:</b> <a href="4150.html">Laws, David: "META: Philosophy...GOD is an upload"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Anders Sandberg wrote:<br>
<i>&gt; </i><br>
<i>&gt; I think much of the problem here is due to the fact that humans are</i><br>
<i>&gt; bad at risk analysis. We tend to worry too much about rare, dramatic</i><br>
<i>&gt; disasters and too little about common, undramatic problems. So while</i><br>
<i>&gt; people quarrel about Cassini and nuclear power, they think it is</i><br>
<i>&gt; quite natural to drive a car or eat all food they like.</i><br>
<p>
The problem is simple:  Neurons can't multiply.<br>
<p>
Logic says a millionth chance of losing a thousand lives works out to one<br>
thousandth of a life lost.<br>
<p>
Our cognitive risk-analysis mechanisms aren't wired up that way.  Neurons<br>
can't multiply.<br>
<p>
My guess is that there are seven states of probability:  Impossible,<br>
improbable, unlikely, unknown, likely, probable, and certain.  Likewise,<br>
disasters are measured as apocalypse, horror, death, torture, pain, discomfort<br>
and twinge.  Make a "multiplication table" and it won't look anything like<br>
linear, or even N equations in N unknowns.<br>
<p>
Not only that, but when it comes time to "balance" risks, it will turn out<br>
that neurons can't even add.<br>
<p>
<i>&gt; I really wonder what would happen if we could rewire our brains to</i><br>
<i>&gt; become rational risk-analysts. I think society would turn *very*</i><br>
<i>&gt; different...</i><br>
<p>
I think that rational risk-analysis, despite the monicker, is an evolutionary<br>
disadvantage.  The way we work these models was optimized over a *very* long<br>
time to account for rationalization, repression, phobia, greed, and all the<br>
other forces that act to distort our "rational" analysis of the model.  Make<br>
us rational risk-analysts without making us rational, and society would indeed<br>
turn very different - but perhaps not in the direction you wanted.<br>
<p>
As a simple example:  How can the chances of the probe malfunctioning be a<br>
million to one?  Do you really believe NASA on this one?  Probably the<br>
engineers are guessing something like three hundred to one, and management is<br>
substituting their own elaborate calculations from the reliability of each<br>
individual screw.<br>
<p>
Read Feynman on the Challenger disaster.  I'm practically quoting him.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4152.html">me: "Re: [Meta] testing email program"</a>
<li> <b>Previous message:</b> <a href="4150.html">Laws, David: "META: Philosophy...GOD is an upload"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
