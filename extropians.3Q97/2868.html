<!-- received="Fri Sep  5 12:08:32 1997 MDT" -->
<!-- sent="Fri, 5 Sep 1997 11:00:06 -0700 (PDT)" -->
<!-- name="Mark Crosby" -->
<!-- email="crosby_m@rocketmail.com" -->
<!-- subject="Re: Goo prophylaxis:consensus" -->
<!-- id="199709051607.JAA04850@crypt.hfinney.com" -->
<!-- inreplyto="Goo prophylaxis:consensus" -->
<title>extropians: Re: Goo prophylaxis:consensus</title>
<h1>Re: Goo prophylaxis:consensus</h1>
Mark Crosby (<i>crosby_m@rocketmail.com</i>)<br>
<i>Fri, 5 Sep 1997 11:00:06 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2868">[ date ]</a><a href="index.html#2868">[ thread ]</a><a href="subject.html#2868">[ subject ]</a><a href="author.html#2868">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2869.html">The Low Golden Willow: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2867.html">Anders Sandberg: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2874.html">Eric Watt Forste: "Re: Goo prophylaxis:consensus"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Hal Finney wrote:<br>
&lt; Similarly, a nanotech power which is so paranoid and aggressive as<br>
to take the step of eradicating everyone else on the planet may find<br>
it difficult to survive on its own terms. [SNIP] The result would be a<br>
nightmare Borgism, a nearly mindless plague whose only goal was<br>
conquest, spreading throughout the universe.  This would all flow from<br>
that first step of destruction. &gt;<br>
<p>
Echoing Forrest, thanks Hal.  That was the most focused argument I’ve<br>
seen yet against some elements of the Hedonistic Imperative that I’ve<br>
always found very disconcerting.<br>
<p>
(The concerns I’m talking about were also briefly mentioned in<br>
<a href="http://www.lucifer.com/exi-lists/extropians.96/3984.html">http://www.lucifer.com/exi-lists/extropians.96/3984.html</a> )<br>
<p>
But then Forrest Bishop wrote:<br>
&lt; I think an SI would at least have the brainpower to know that it<br>
cannot know the consequences of its information destruction. (The<br>
notion that it could reconstruct that information is garbage, IMO.) &gt;<br>
<p>
And Hal replied <br>
&lt; I seem to recall a proposal by Drexler for a "brute force" route to<br>
AI via simulation. [SNIP] If this is really possible (I'm not sure the<br>
numbers work) then it suggests to me that the loss of information<br>
caused by the destruction of some portion of the human race is<br>
insignificant compared to the amount which will be created and<br>
manipulated routinely by a nanotech culture.&gt;<br>
<p>
If the time from now to ‘The Eschaton’ is longer than the time since<br>
the beginning of the universe, or if the universe continues<br>
indefinitely, then, sure, the loss of past ‘information’ will seem<br>
"insignificant compared to" the future ‘information’ to be created. <br>
But, as you also point out, look how much could flow from "that first<br>
step of destruction". Life could probably recover but I can only echo<br>
Forrest in thinking that it could never be the same.  Brute-force<br>
resurrection only seems possible within an Omega-Point situation of<br>
infinite computational resources, if then. <br>
<p>
Hal also asks:<br>
&lt; Well, that's my question.  When would it [past knowledge] be useful?<br>
 How would it be useful? Give me some ideas of what you're thinking<br>
of, here.  My conception is that the Power is so, well, Powerful that<br>
I can't see how the historical knowledge would matter.  But most other<br>
people seem to disagree, so I'd appreciate some examples.&gt;<br>
<p>
To me it's debatable just how much 'power' these future Powers can<br>
have.  But aside from that, it's not so much going back and<br>
reaccessing past information, it's what would be lost in the future in<br>
terms of diversity if certain elements of the past or present are<br>
*expunged* from continuing into the future. (Not a very good<br>
'example', hopefully someone else will be more clever - which is why I<br>
hope for a diverse future and not some monistic Power calling all the<br>
shots :-)<br>
<p>
Mark Crosby<br>
<p>
_____________________________________________________________________<br>
Sent by RocketMail. Get your free e-mail at <a href="http://www.rocketmail.com">http://www.rocketmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2869.html">The Low Golden Willow: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2867.html">Anders Sandberg: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2874.html">Eric Watt Forste: "Re: Goo prophylaxis:consensus"</a>
<!-- reply="end" -->
</ul>
