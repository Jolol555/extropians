<!-- received="Sun Aug 31 09:53:52 1997 MDT" -->
<!-- sent="Sun, 31 Aug 1997 11:36:01 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="Dan@Clemmensen.ShireNet.com" -->
<!-- subject="Re: Black Goo" -->
<!-- id="199708311453.HAA08807@well.com" -->
<!-- inreplyto="Black Goo" -->
<title>extropians: Re: Black Goo</title>
<h1>Re: Black Goo</h1>
Dan Clemmensen (<i>Dan@Clemmensen.ShireNet.com</i>)<br>
<i>Sun, 31 Aug 1997 11:36:01 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2679">[ date ]</a><a href="index.html#2679">[ thread ]</a><a href="subject.html#2679">[ subject ]</a><a href="author.html#2679">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2680.html">Carl Feynman: "Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2678.html">Mark Grant: "NONSENSE: Re: Crop Circles"</a>
<li> <b>Maybe in reply to:</b> <a href="2693.html">John K Clark: "Black Goo"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2690.html">YakWaxx@aol.com: "Re: Black Goo"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
John K Clark wrote:<br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; Let's assume sometime after the singularity, around breakfast, a suicidal nut</i><br>
<i>&gt; case makes some black goo with the intention of destroying the world. About</i><br>
<i>&gt; the only thing I can say with any confidence about the world after the</i><br>
<i>&gt; singularity is that life will be fast and things will change, so by lunch</i><br>
<i>&gt; time this black goo would seem comically old fashioned, positively stone age</i><br>
<i>&gt; compared to the vastly improved nanotechnology that had been developed in the</i><br>
<i>&gt; following 4 hours, an eon of subjective time. The black goo might look pretty</i><br>
<i>&gt; scary in the first few milliseconds after it was made, but after a geological</i><br>
<i>&gt; age (a minute or two) it would seem more pitiful than scary, like a man armed</i><br>
<i>&gt; with a flint ax trying to concur the world.</i><br>
<i>&gt; </i><br>
A problem with this argument is that some things<br>
speed up, and others don't. It's the differential rates<br>
that are dangerous. I can't predict past the singularity,<br>
but the current discussion has been pre-singularity. It<br>
has assumed that the evil goo would be designed by<br>
humans, not by an SI. In the human-design era, the<br>
design rate remains in the days-to-years regime, while<br>
the replication rate is in the minutes-to-hours regime.<br>
This is why I'm concerned. We won't have time to design<br>
defenses for the goo after the fact.<br>
<p>
I see only one way past this problem. We must strive to<br>
precipitate the singularity before the advent of the ability<br>
to design evil goo. Probably the best way to do this is<br>
already underway: see to it that designs for a nanotech<br>
computer technology are already available prior to the<br>
existance of the first assembler. Then we have at least<br>
a chance to build massive nanotech computing capacity<br>
prior to the release of evil goo or grey goo. Fortunately,<br>
most goo scenarios appear to depend on the availability of<br>
this computing infrastructure to build the control elements<br>
to the goo. So the "only" remaining problem is finding<br>
a way to get to the SI from the nanotech computer base,<br>
or at least to get to an ability to design goo defenses<br>
in the minutes-to-hours time regime.<br>
<p>
You are correct that in the post-singularity era, the<br>
self-enhancing SI or SIs will operate in yet another<br>
regime. In that regime, there are still rate differences,<br>
but of a different order. You speak of effectively<br>
unbounded increase after the singularity. I agree that<br>
the rate will continue to increase but the increase IMO<br>
will be so rapid that it will shortly reach the constraints<br>
imposed by the laws of physics. So while is disagree with<br>
your unbounded rate increase, I agree that there will be<br>
no post-singularity era in which our current concepts of<br>
intelligence, art, freedom, individuality, etc. will have<br>
any meaning. These concepts will be completely superceeded<br>
by whatever abstract concepts the SI or SIs choose.<br>
<p>
As a matter of definition, I use the term "Singularity"<br>
as Vinge does: the point in the future past which prediction<br>
becomes meaningless.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2680.html">Carl Feynman: "Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2678.html">Mark Grant: "NONSENSE: Re: Crop Circles"</a>
<li> <b>Maybe in reply to:</b> <a href="2693.html">John K Clark: "Black Goo"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2690.html">YakWaxx@aol.com: "Re: Black Goo"</a>
<!-- reply="end" -->
</ul>
