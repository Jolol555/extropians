<!-- received="Mon Aug 25 08:00:36 1997 MDT" -->
<!-- sent="Mon, 25 Aug 1997 15:47:24 +0200 (MET DST)" -->
<!-- name="Anders Sandberg" -->
<!-- email="nv91-asa@nada.kth.se" -->
<!-- subject="Re: Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<!-- id="199708250947.LAA08846@ravian.globalxs.nl" -->
<!-- inreplyto="3400BF3D.5EB60CFD@pobox.com" -->
<title>extropians: Re: Goo prophylaxis (was: Hanson antiproliferation method?)</title>
<h1>Re: Goo prophylaxis (was: Hanson antiproliferation method?)</h1>
Anders Sandberg (<i>nv91-asa@nada.kth.se</i>)<br>
<i>Mon, 25 Aug 1997 15:47:24 +0200 (MET DST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2444">[ date ]</a><a href="index.html#2444">[ thread ]</a><a href="subject.html#2444">[ subject ]</a><a href="author.html#2444">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2445.html">Anders Sandberg: "Re: Small Comets source of earth's ocean"</a>
<li> <b>Previous message:</b> <a href="2443.html">Anders Sandberg: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Sun, 24 Aug 1997, Eliezer S. Yudkowsky wrote:<br>
<p>
<i>&gt; Very true.  The power of evolutionary computing lies in its blind speed. </i><br>
<i>&gt; Let's say we have a million-organism brew that evolves for a thousand</i><br>
<i>&gt; generations.  Now let's say we have a hundred thousand programmers, each of</i><br>
<i>&gt; whom chooses an organism out of the stew and redesigns it.  The latter</i><br>
<i>&gt; situation will proceed more slowly than the first, and be vastly more</i><br>
<i>&gt; expensive, but it will also be far more powerful and capable of reaching</i><br>
<i>&gt; loftier goals.</i><br>
<p>
Well, that depends on how much redesign the programmers could do. If<br>
you have ever looked at genetically evolved programs, you know they<br>
are a mess. Structured programming? Bah! Sphagetti code? Not even<br>
that - angel hair code! (slightly overcooked too...)<br>
<p>
<i>&gt; Very, very true.  A lot of people on this list seem to lack a deep-seated</i><br>
<i>&gt; faith in the innate perversity of the universe.  I shudder to think what would</i><br>
<i>&gt; happen if they went up against a perverse Augmented human.  Field mice under a</i><br>
<i>&gt; lawn mower.</i><br>
<p>
I don't think the universe is perverse. We just like to think it is,<br>
since it takes the blame :-)<br>
<p>
Perverse posthumans might be a problem, which is yet another reason<br>
to learn everything we can about how to create healthy humans that<br>
can get along, and the psychology of self-augmentation. <br>
<p>
<i>&gt; Same here.  It's immensely easier to destroy than create.  You couldn't "hide"</i><br>
<i>&gt; from a predatory nanite.  You could slow it down, keep it from getting to your</i><br>
<i>&gt; bunker, surround it with a continuous wall of nuclear flame, and then make</i><br>
<i>&gt; your escape into space and blast the gooey Earth into bits... then try to</i><br>
<i>&gt; rebuild civilization in the new asteroid belt.</i><br>
<p>
Sigh. Who has read too much sf and seen too many movies now? You seem<br>
to attribute the nanites with tremendous reproduction capabilities<br>
and a very high level of intelligence, hell-bent on finding the last<br>
survivors and killing them. Yes, such a nanoweapon could in principle<br>
be created, but is it the realistic standard immune systems should be<br>
measured against? In that case we obviously have to look out for the<br>
heat-seeking, contagious-like-common-cold, fast-mutating retroviral<br>
ebola viruses... <br>
<p>
<i>&gt; "Who will guard the guardians?" - maybe nanotechnology would give us a perfect</i><br>
<i>&gt; lie detector.  Nanotechnology in everyone's hands would be just like giving</i><br>
<i>&gt; every single human a complete set of "launch" buttons for the world's nuclear</i><br>
<i>&gt; weapons.  Like it or not, nanotechnology cannot be widely and freely</i><br>
<i>&gt; distributed or it will end in holocaust.  Nanotechnology will be controlled by</i><br>
<i>&gt; a single entity or a small group... just as nuclear weapons are today.</i><br>
<p>
It is this assumption I want to challenge. If it has the tremendous<br>
destructive potential you assume, it is a fairly logical assumption.<br>
But can you really back it up with some hard calculations? <br>
<p>
You might be worrying about an imaginary ultra-danger, which will<br>
suggest a course of action which is less than optimal but sounds<br>
plausible Remember that we humans consistently overestimate the risks<br>
of huge disasters and underestimate small, common disasters, and that<br>
fear is the best way of making people flock to an "obvious solution",<br>
especially if it is nicely authoritarian.<br>
<p>
I think you are partially right, nanotech will be dangerous, but we<br>
have to estimate the threat levels and what countermeasures that can<br>
be created before we jump to conclusions about future politics. For<br>
example, if decent immune systems can be created then the dishwasher<br>
goo scenario is unlikely, and if relatively few have the twisted<br>
genius and expertise to design Hollywood goo then it is a potential<br>
danger but with a likeliehood of occuring that is low enough for some<br>
planning to be done (like moving outwards, which ought to be feasible<br>
at the assumed tech level). We need to get some estimates of these<br>
factors. <br>
<p>
<p>
-----------------------------------------------------------------------<br>
Anders Sandberg                                      Towards Ascension!<br>
asa@nada.kth.se              <a href="http://www.nada.kth.se/~nv91-asa/main.html">http://www.nada.kth.se/~nv91-asa/main.html</a><br>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2445.html">Anders Sandberg: "Re: Small Comets source of earth's ocean"</a>
<li> <b>Previous message:</b> <a href="2443.html">Anders Sandberg: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
