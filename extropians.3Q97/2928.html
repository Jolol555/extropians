<!-- received="Sat Sep  6 08:54:59 1997 MDT" -->
<!-- sent="Sat, 6 Sep 1997 09:52:57 -0400 (EDT)" -->
<!-- name="YakWaxx@aol.com" -->
<!-- email="YakWaxx@aol.com" -->
<!-- subject="Re: Goo prophylaxis:consensus" -->
<!-- id="9709068735.AA873555381@smtpgate.netcon.co.za" -->
<!-- inreplyto="Goo prophylaxis:consensus" -->
<title>extropians: Re: Goo prophylaxis:consensus</title>
<h1>Re: Goo prophylaxis:consensus</h1>
<i>YakWaxx@aol.com</i><br>
<i>Sat, 6 Sep 1997 09:52:57 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2928">[ date ]</a><a href="index.html#2928">[ thread ]</a><a href="subject.html#2928">[ subject ]</a><a href="author.html#2928">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2929.html">YakWaxx@aol.com: "The Authoritarian Point"</a>
<li> <b>Previous message:</b> <a href="2927.html">adrian_karth_at_netconnect@smtpgate.netcon.co.za: "cc:Mail Link to SMTP Undeliverable Message"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
phoenix@ugcs.caltech.edu wrote:<br>
<p>
<i>&gt; On Sep 5,  4:54pm, "Nicholas Bostrom" wrote:</i><br>
<i>&gt;  </i><br>
<i>&gt;  } Yes, that would be a very bad outcome. In the EoC, Drexler mentions </i><br>
<i>&gt;  } the possibility that a state choose to get rid of its people and </i><br>
<i>&gt;  } replace them with obediant AIs. This is a real danger. -Another </i><br>
<i>&gt;  </i><br>
<i>&gt;  Actually I thought this was a ridiculous idea, as stated.  A single</i><br>
<i>&gt;  dictator, or cabal, might try this, but this is a subset of "nanopower</i><br>
<i>&gt;  tries to take over the world".  Even in massively totalitarian states</i><br>
<i>&gt;  there is a strong connection between the rulers and a large mass of the</i><br>
<i>&gt;  people -- in fact, one might argue that especially in modern totalitarian</i><br>
 <br>
<i>&gt;  states is this the case.  Hitler might have replaced Germans with AIs if</i><br>
<i>&gt;  you let the idea sit in his cracked head for long enough, but he</i><br>
<i>&gt;  wouldn't have right away.  I doubt the Chinese rulers would replace the</i><br>
<i>&gt;  Chinese.  I don't think these people think entirely in terms of slave</i><br>
<i>&gt;  labor, and replacing one's own people by robots would frighten or creep</i><br>
<i>&gt;  out most members of the human race.  The world is not run by psychotic</i><br>
<i>&gt;  extropians.</i><br>
<p>
And then there's the psychological factor.  Dictators don't get their kicks<br>
from telling obediant AI's what to do, they get their kicks from breaking the<br>
free will of _real_ people.<br>
<p>
--Wax<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2929.html">YakWaxx@aol.com: "The Authoritarian Point"</a>
<li> <b>Previous message:</b> <a href="2927.html">adrian_karth_at_netconnect@smtpgate.netcon.co.za: "cc:Mail Link to SMTP Undeliverable Message"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
