<!-- received="Sun Aug 31 20:10:39 1997 MDT" -->
<!-- sent="Sun, 31 Aug 1997 18:56:47 -0700 (PDT)" -->
<!-- name="Mark Crosby" -->
<!-- email="crosby_m@rocketmail.com" -->
<!-- subject="Re: PHIL: Eliminative Materialism" -->
<!-- id="l03102803b02dedf8f7cf@[24.1.1.26]" -->
<!-- inreplyto="PHIL: Eliminative Materialism" -->
<title>extropians: Re: PHIL: Eliminative Materialism</title>
<h1>Re: PHIL: Eliminative Materialism</h1>
Mark Crosby (<i>crosby_m@rocketmail.com</i>)<br>
<i>Sun, 31 Aug 1997 18:56:47 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2699">[ date ]</a><a href="index.html#2699">[ thread ]</a><a href="subject.html#2699">[ subject ]</a><a href="author.html#2699">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2700.html">Abraham Moses Genen: "Re: Got a question mr. retired civil servant."</a>
<li> <b>Previous message:</b> <a href="2698.html">Kennita Watson: "Kevorkian's assistant dies"</a>
<li> <b>Maybe in reply to:</b> <a href="2740.html">Eric Watt Forste: "PHIL: Eliminative Materialism"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2734.html">Mark Crosby: "Re: PHIL: Eliminative Materialism"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Eric Watt Forste wrote: <br>
&lt; Personally, I'm very interested in looking at some of the psychology<br>
and philosophy of Buddhist scholars, and this stuff is not as<br>
accessible to me (for various reasons) as the work of European<br>
scholars, so I haven't yet done much of it. &gt;<br>
<p>
This certainly sounds like an interesting approach (see below after my<br>
brief ‘review’ of Churchland). <br>
<p>
In criticizing eliminative materialism I wanted to note that I wasn’t<br>
against departing from the traditional science paradigms in some<br>
areas. Especially regarding ‘folk psychology’, there’s certainly some<br>
Jungian and Freudian concepts that could be better replaced with<br>
computationalist terms.  I was primarily ranting against the tendency<br>
of some (not Eric, probably not Churchland) to say that talking about<br>
anything other than bare ‘brain states’ would amount to some sort of<br>
vitalism.<br>
<p>
After my post, I decided it was time to pull Churchland’s book out of<br>
my to-read stack and see what he actually had to say in this regard.<br>
<p>
The last section of ch.9 in Paul Churchland's _The Engine of Reason,<br>
the Seat of the Soul_ argues that "human massively parallel prototype<br>
activators" are different from "serial algorithm executors", or Turing<br>
machines, and that this can account for the superiority of human<br>
pattern recognition over rule-based machines: "this capacity for<br>
activating relevant prototype vectors, makes algorithmic plodding<br>
largely unnecessary". This insight is one of Churchland's greatest<br>
contributions to cognitive science.<br>
<p>
Churchland also makes excellent points about fallacies held by the old<br>
functionalists. But, that's because they "cared relatively little<br>
about exactly what processes take place inside us, so long as they<br>
implement the right input-output function [and their] presumption<br>
about the nature of those processes was mistaken: it portrayed them as<br>
algorithmic to the core." I would agree with Churchland that "it does<br>
matter what physical processes take place inside us, and they are not<br>
just executing a program" (p251). <br>
<p>
BUT, on the other hand, I don't think "high-dimension activation<br>
vectors [only] have intrinsic meaning within the human neural<br>
architecture" (p244). Churchland probably does not imply that 'only'<br>
that I have inserted because, at the end of ch.9, he adds: "No one<br>
claims that the silicon retina is conscious ... Its representations<br>
will not be a target of or a part of something's consciousness until<br>
it is embedded in a larger cognitive system..."<br>
<p>
This "larger cognitive system" also has its own degrees of freedom,<br>
including the ability to ALSO use rule-based approaches, plans (cf.<br>
Bruce Bridgeman ON THE EVOLUTION OF CONSCIOUSNESS AND LANGUAGE in<br>
Psycoloquy at<br>
<a href="http://www.cogsci.soton.ac.uk/psyc-bin/newpsy?article=3.15">http://www.cogsci.soton.ac.uk/psyc-bin/newpsy?article=3.15</a>&amp;submit=View+Article<br>
) and goals that subvert the "intrinsic meaning" by adapting existing<br>
tools to perform new functions in a constructivist manner. Some, e.g.,<br>
Patrick Hayes, see this larger cognitive system as a virtual machine.<br>
It is in this sense - some independence, the ability to form abstract<br>
representations, and to both select ones environment and ones<br>
responses to it - that the larger cognitive system can be considered<br>
'software' *in comparison* to the lower-level 'hardware'. Having<br>
programs and algorithmic repertoires can actually free us up to think<br>
of other things when engaged in mundane tasks. The key to freedom here<br>
is having various levels of processing.<br>
<p>
It is important not to take this software / hardware dichotomy too<br>
rigidly, but applied in moderation it can allow adaptive functions to<br>
emerge. Contrary to what Churchland supposedly says elsewhere about<br>
eliminative materialism, I would suggest that, at these higher levels<br>
of aggregation, Churchland's "prototype activation vectors" become the<br>
symbols, schemas, analogies &amp; stories of the linguistic levels of the<br>
mind. This emergent array of functionality is how I define 'software'<br>
as opposed to some strictly deterministic program.<br>
<p>
-------------------<br>
Regarding Buddhist philosophy and AI, perhaps the psychophysicists<br>
have done the most to apply some of these principles to neuroscience. <br>
For example, one intriguing paper by Robert A.M. Gregson is called<br>
"n-Dimensional Nonlinear Psychophysics: Intersensory interaction as a<br>
network at the edge of chaos".  BTW, if you do a search on<br>
Robert+Gregson, you’ll mostly get back links to stuff by an old<br>
Extropians list participant, Ben Goertzel, who has a lot of stuff<br>
online along these lines.  He’s back in the U.S. (at<br>
<a href="http://altair.comoc.com/People/ben/">http://altair.comoc.com/People/ben/</a> ) and working on an AI /<br>
Web-search project called WebMind.  Another serious psychophysics<br>
researcher, whose works seem more practical to me than the Roger<br>
Penrose school of quantum consciousness, is psychiatrist Gordon Globus.<br>
<p>
Another essay I recently found that tries to reconcile<br>
computationalism with Eastern philosophies is Copthorne Macdonald's<br>
"An Energy / Awareness / Informational Interpretation of Physical and<br>
Mental Reality" essay ( <a href="http://www.cop.com/zygon1.html">http://www.cop.com/zygon1.html</a> ). Macdonald<br>
used to write for Mother Earth News and despite some spiritualist red<br>
flags, the essay is really pretty good. He does endorse the<br>
psychophysics of Gordon Globus, but he also develops the systems<br>
science notion of levels of reality, and systems, that I find so<br>
important. He points, in particular, to the work of Ervin Laszlo in<br>
the 70s &amp; 80s (cf. _The Systems View of the World_) and develops the<br>
notions of directed evolution that I find intriguing.<br>
<p>
Macdonald also describes Roger Sperry's emergent interactionalism:<br>
"emergent entities then interact causally with each other at their own<br>
level". But then he proposes: "The assumption that awareness is<br>
fundamental suggests a somewhat simpler and more direct explanation of<br>
brain/mind relationship". Basically, he takes the line, similar to<br>
that of Globus, that "[neural] correlates represent physically<br>
embodied information about the attended-to quale, and are available<br>
for use in unconscious 'computational' processing - perhaps to<br>
initiate behavior, or to flag (by creating an emotion) a danger or<br>
opportunity. I am suggesting that ... qualia are generated in<br>
relatively simple neuronal systems and that the selective attention to<br>
these qualia produces neuronal data that is used in the [higher-level]<br>
computational phase of the evaluation process."<br>
<p>
This is very similar to what I was proposing for 'hardware' vs<br>
'software' levels of the mind in regards to Churchland and the claims<br>
of eliminative materialism. Macdonald cites Libet's work on sensation<br>
vs. decision lag time to conclude: "The implication here is that even<br>
though conscious intentions may arise from unconscious sources, if one<br>
is sufficiently alert it is possible to make a conscious choice to<br>
abort the intended behavior before it actually begins".<br>
<p>
This is made possible by having a system with multiple levels of<br>
control, as described in the current thread about Stephen Thayer’s<br>
Creativity Machine.<br>
<p>
Mark Crosby<br>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
_____________________________________________________________________<br>
Sent by RocketMail. Get your free e-mail at <a href="http://www.rocketmail.com">http://www.rocketmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2700.html">Abraham Moses Genen: "Re: Got a question mr. retired civil servant."</a>
<li> <b>Previous message:</b> <a href="2698.html">Kennita Watson: "Kevorkian's assistant dies"</a>
<li> <b>Maybe in reply to:</b> <a href="2740.html">Eric Watt Forste: "PHIL: Eliminative Materialism"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2734.html">Mark Crosby: "Re: PHIL: Eliminative Materialism"</a>
<!-- reply="end" -->
</ul>
