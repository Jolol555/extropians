<!-- received="Wed Aug 27 12:29:03 1997 MDT" -->
<!-- sent="Tue, 26 Aug 1997 19:32:54 +0000" -->
<!-- name="Mark Grant" -->
<!-- email="mark@unicorn.com" -->
<!-- subject="Re: Goo prophylaxis (was: Hanson antiproliferation method?)" -->
<!-- id="2.2.32.19970827151615.00b44050@atg.com" -->
<!-- inreplyto="199708261459.PAA20479@andromeda.ndirect.co.uk" -->
<title>extropians: Re: Goo prophylaxis (was: Hanson antiproliferation method?)</title>
<h1>Re: Goo prophylaxis (was: Hanson antiproliferation method?)</h1>
Mark Grant (<i>mark@unicorn.com</i>)<br>
<i>Tue, 26 Aug 1997 19:32:54 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2511">[ date ]</a><a href="index.html#2511">[ thread ]</a><a href="subject.html#2511">[ subject ]</a><a href="author.html#2511">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2512.html">Mark Grant: "Re: Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2510.html">Carl Feynman: "Re: Goo prophylaxis"</a>
<li> <b>In reply to:</b> <a href="2484.html">Nicholas Bostrom: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Tue, 26 Aug 1997, Nicholas Bostrom wrote:<br>
<p>
<i>&gt; My intuitions are exactly the opposite. Your prediction seems to </i><br>
<i>&gt; presuppose that the first nanopower won't obtain world dominion, an </i><br>
<i>&gt; assumption I find very dubious.</i><br>
<p>
[From the extropians list of a parallel universe, 26/8/1937: <br>
<p>
"Your prediction seems to presuppose that the first nuclear power won't<br>
obtain world dominion, an assumption I find very dubious." <br>
<p>
[From the extropians list of a parallel universe, 26/8/1337]<br>
<p>
"Your prediction seems to presuppose that the first gunpowder power won't<br>
obtain world dominion, an assumption I find very dubious." <br>
<p>
Hopefully you get the point; we've seen this all before, throughout<br>
history. Time and again a technological advance has occured which scared<br>
people because it seemed that the advance would inevitably give the<br>
possessor vast power which they could use to take over the world. Yet for<br>
good reasons, this hasn't happened; provided there are multiple groups who<br>
can develop a new technology, a balance of power soon occurs and<br>
eliminates this possibility. The only difference today is that your<br>
preferred scenario could come to pass and one group could already be<br>
powerful enough to prevent competitive research. <br>
<p>
Frankly I think you're caught up in 'singularity-ism'; being able to build<br>
nanothings will not lead to 'gray goo' overnight, and while the bad guys<br>
are working on it the rest of us will be putting together defences. The<br>
first nanotech world war wouldn't be a good place to be, but it won't be<br>
one-sided unless we deliberately make it so. I really don't see any good<br>
reason to believe the 'nanotech followed by human-level AI a few seconds<br>
later followed by the singularity just before lunch' scenario which has<br>
been proposed many times on the list. <br>
<p>
	Mark<br>
<p>
<i>|-----------------------------------------------------------------------|</i><br>
<i>|Mark Grant M.A., U.L.C.	  	       EMAIL: mark@unicorn.com  |</i><br>
<i>|WWW: <a href="http://www.unicorn.com/">http://www.unicorn.com/</a>	  	       MAILBOT: bot@unicorn.com	|</i><br>
<i>|-----------------------------------------------------------------------|</i><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2512.html">Mark Grant: "Re: Goo prophylaxis"</a>
<li> <b>Previous message:</b> <a href="2510.html">Carl Feynman: "Re: Goo prophylaxis"</a>
<li> <b>In reply to:</b> <a href="2484.html">Nicholas Bostrom: "Re: Goo prophylaxis (was: Hanson antiproliferation method?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
