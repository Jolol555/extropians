<!-- received="Thu Jul 31 13:20:22 1997 MDT" -->
<!-- sent="Thu, 31 Jul 1997 11:13:01 -0700" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Everett" -->
<!-- id="199707311813.LAA03838@crypt.hfinney.com" -->
<!-- inreplyto="Everett" -->
<title>extropians: Re: Everett</title>
<h1>Re: Everett</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Thu, 31 Jul 1997 11:13:01 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1418">[ date ]</a><a href="index.html#1418">[ thread ]</a><a href="subject.html#1418">[ subject ]</a><a href="author.html#1418">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1419.html">Hagbard Celine: "Re: MIXILS? Nanofog/MEMS in SCIENCE NEWS"</a>
<li> <b>Previous message:</b> <a href="1417.html">Prof. Jose Gomes Filho: "Polygamy ?"</a>
<li> <b>Maybe in reply to:</b> <a href="1492.html">John K Clark: "Everett"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1438.html">Nicholas Bostrom: "Re: Everett"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Nicholas Bostrom, &lt;bostrom@mail.ndirect.co.uk&gt;, writes:<br>
<i>&gt; Apart from the staggering ontological implications, there is one </i><br>
<i>&gt; objection that many philosophers of physics consider fatal: The </i><br>
<i>&gt; Everett theory fails to make sense of the probabilities. For </i><br>
<i>&gt; instance, take a particle that can undergo either of two processes, </i><br>
<i>&gt; and say that according to quantum mechanics the first event (A) has </i><br>
<i>&gt; an 80% chance of occuring, and the second (B) 20%. Now, according to </i><br>
<i>&gt; the Everett interpretation what happens (basically)  is that the </i><br>
<i>&gt; universe splits into two universes; and there is one copy of me in </i><br>
<i>&gt; each of these universes. But if this were the case, then there should </i><br>
<i>&gt; be a 50% chance for me (i.e. *this* copy of Nicholas Bostrom)  to </i><br>
<i>&gt; find that A had happened and a 50% chance that B had happened; which </i><br>
<i>&gt; we know from experiment is not true.</i><br>
<i>&gt;</i><br>
<i>&gt; I don't know of any good reply to this objection that would save the </i><br>
<i>&gt; Everett interpretation.</i><br>
<p>
Actually, Everett spent considerable effort in his original paper to<br>
address this issue.  (Later authors have muddied the waters, though,<br>
particularly DeWitt's claim that the probabilities follow from the<br>
formalism itself, which no one takes seriously today.)<br>
<p>
The idea is that as the state function evolves into a mixture of<br>
non-coherent states, a measure function can be applied to the various<br>
components of the mixture, based on the probability amplitudes.  Everett<br>
shows that, in the limit, the probability results observed from a series<br>
of measurements will match the squared-amplitude of the relative state,<br>
exactly as required by conventional QM; this is true except in a set of<br>
branches of total measure zero.  So you then only have to assume that<br>
branches with amplitude zero never exist, and you derive that observed<br>
probabilities will follow the predictions of conventional QM.  (This is<br>
the basis for DeWitt's claim, since he takes the premise as obvious.)<br>
<p>
Other authors have suggested that this solution is not quite enough, since<br>
it only applies in the limit of an infinite series of measurements.  They<br>
suggest that a more powerful assumption is needed, namely that the<br>
measure of a branch, defined as amplitude-squared, determines the subjective<br>
likelihood of a conscious observer finding himself in the branch.<br>
<p>
(You might think of this as indicating that the "degree of reality" of<br>
a branch is proportional to the square of the amplitude.)<br>
<p>
In either case, it is necessary to add a postulate to the simple QM<br>
rules which describe evolution by means of the Schrodinger equation.  We<br>
have to say something about this measure function and its implications.<br>
<p>
Some argue that this destroys the Occam's razor argument that the Everett<br>
interpretation is simpler than conventional QM.  In place of the projection<br>
postulate (state function collapse) we introduce a statement about<br>
subjective probabilities.  Both interpretations need something beyond<br>
the deterministic evolution of the Schrodinger equation.<br>
<p>
I feel though that the Everett interpretation still wins out on grounds<br>
of simplicity.  The projection postulate claims that an actual physical<br>
process occurs during measurement, and that the results are distributed<br>
with a certain probability.  With the Everett interpretation we need<br>
instead to append an understanding of how the different amplitudes<br>
affect our perceptions of reality.  Both include some comment about<br>
squared-amplitude and observed probability, but Everett leaves out the<br>
part about the universe changing.  So it does have a simplicity advantage,<br>
although not as great as some people claim.<br>
<p>
The bigger problem with the conventional interpretation IMO is that it is<br>
inconsistent; the two different processes produce different results, and<br>
it is not clear exactly when we should use one or the other.  Furthermore,<br>
as more delicate measuring devices are used, it may be that the definition<br>
of what consistutes a measurement will become less clear.  Then there are<br>
potential future experiments such as the one described by John Clark which<br>
intentionally muddy the waters so much that the conventional interpretation<br>
is pretty much at a loss.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1419.html">Hagbard Celine: "Re: MIXILS? Nanofog/MEMS in SCIENCE NEWS"</a>
<li> <b>Previous message:</b> <a href="1417.html">Prof. Jose Gomes Filho: "Polygamy ?"</a>
<li> <b>Maybe in reply to:</b> <a href="1492.html">John K Clark: "Everett"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1438.html">Nicholas Bostrom: "Re: Everett"</a>
<!-- reply="end" -->
</ul>
