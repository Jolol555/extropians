<!-- received="Mon Sep 22 00:20:26 1997 MDT" -->
<!-- sent="Mon, 22 Sep 1997 00:26:53 -0400" -->
<!-- name="Richard Plourde" -->
<!-- email="rplourde@andesign.mv.com" -->
<!-- subject="Re: SPACE: Cassini Mission Consequences" -->
<!-- id="3.0.3.32.19970922002653.0077fe7c@pop.mv.net" -->
<!-- inreplyto="Chameleon.874855086.wincat@wincat.icsi.net" -->
<title>extropians: Re: SPACE: Cassini Mission Consequences</title>
<h1>Re: SPACE: Cassini Mission Consequences</h1>
Richard Plourde (<i>rplourde@andesign.mv.com</i>)<br>
<i>Mon, 22 Sep 1997 00:26:53 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4159">[ date ]</a><a href="index.html#4159">[ thread ]</a><a href="subject.html#4159">[ subject ]</a><a href="author.html#4159">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4160.html">Eliezer S. Yudkowsky: "SF:  Where's the books?"</a>
<li> <b>Previous message:</b> <a href="4158.html">jaan.ranniko@smtpgw.aftrs.edu.au: "RE: BIO: Help wanted"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 10:17 AM 9/21/97 -0600, wincat@icsi.net wrote:<br>
<i>&gt;</i><br>
<i>&gt;</i><br>
<i>&gt;------------------------</i><br>
<i>&gt;  From: Damien Broderick &lt;damien@ariel.ucs.unimelb.edu.au&gt;</i><br>
<i>&gt;  Subject: Re: SPACE: Cassini Mission Consequences </i><br>
<i>&gt;  Date: Sun, 21 Sep 1997 22:11:33 +0000 </i><br>
<i>&gt;  To: extropians@lucifer.com</i><br>
<i>&gt;</i><br>
<i>&gt;</i><br>
<i>&gt;At 12:19 PM 9/20/97 -0800, Amara wrote:</i><br>
<i>&gt;</i><br>
<i>&gt;&gt;My personal opinion is that the antagonists are using this as a</i><br>
banner for<br>
<i>&gt;&gt;their personal causes.  I honestly don't know why it has carried</i><br>
so far.<br>
<i>&gt;&gt;My scientist friends are perplexed also. You may be interested</i><br>
<i>&gt;&gt;in a "back-of-the-envelope" calculation that Jeff Cuzzi</i><br>
performed<br>
<i>&gt;&gt;to demonstrate that the Plutonium risk is pretty small. </i><br>
<i>&gt;</i><br>
<i>&gt;If I have understood this risk evaluation, we learn the following</i><br>
bottom line:<br>
<i>&gt;</i><br>
<i>&gt;There seems to be a one in a million chance of a plutonium</i><br>
dispersal<br>
<i>&gt;accident into the biosphere, which would be the direct cause of</i><br>
100 to 500<br>
<i>&gt;deaths during the next half century.  </i><br>
<i>&gt;</i><br>
<i>&gt;Despite the waffle about this being the same odds of a billion</i><br>
people dying<br>
<i>&gt;in a dino-killer asteroid impact, we have no control over an</i><br>
asteroid and<br>
<i>&gt;every control over Cassini.</i><br>
<p>
Not necessarily true.<br>
<p>
For example, in 1997 we have no control over a killer-asteroid.<br>
If, on the other hand, we had continued developing<br>
out-of-earth-orbit space craft in 1970, then very possibly we<br>
would have control over such a killer asteroid.<br>
<p>
A choice to curtail knowledge-development at any particular point<br>
in time has the consequence of having that knowledge not available<br>
at a later point in time.  We just don't notice, because we tend<br>
not to consider our environments today a consequence of our<br>
choices yesterday.  And, when we do consider consequences, we<br>
generally consider the consequences of activity as carrying more<br>
'responsibility' than the consequences of passivity.<br>
<p>
The difficulty with such biases in our unconsidered philosophies<br>
becomes apparent when we recognize that the 'ideal'-behaviors for<br>
a human, based on a proposition of responsibility-free passivity,<br>
comes out as something startlingly similar to the behaviors of a<br>
clam.<br>
<p>
Now, the question comes up, "How will the launching of some rocket<br>
improve our knowledge to the degree that we would, at some time<br>
when that knowledge becomes necessary, have the knowledge to turn<br>
aside a killer asteroid?"<br>
<p>
The answer, very simply, is, "we don't know."  We *do* know,<br>
however, that we do not have the knowledge or the tools to stop a<br>
killer asteroid today.<br>
<p>
We don't know *what* knowledge will come out of any particular<br>
scientific experiment.  Knowledge generally grows when what we<br>
measure differs from what we expected to measure.  An experiment<br>
that yields exactly the anticipated results works to build<br>
confidence in a theory -- but an experiment that yields an<br>
unexpected result can have, as a consequence, an explosion in<br>
knowledge where we have no way of predicting what direction our<br>
knowledge will grow.<br>
<p>
Apparently killer asteroids have hit the earth in the past.<br>
Asteroids (and comets and etc.) continue to exist in the solar<br>
system, and to intrude on our space.  We do not have sufficient<br>
knowledge to deal with them.  If one hits, then we're not talking<br>
about 500 people;  we're talking, very possibly, about the<br>
survival of higher life-forms, including us, on earth.<br>
<p>
Now, do we *really* want to take a chance with the survival of the<br>
entirety of mankind?  Granted, it's probably only a million-to-one<br>
chance that the knowledge gained from this particular mission<br>
would make the difference, but can we afford to take even that<br>
kind of a chance with the entire future of humanity at stake?<br>
<p>
    ------------------------------------------------<br>
<p>
Comment:<br>
<p>
Whenever indulging in a non-quantified rhetorical argument,<br>
remember that the lack of quantification generally allows an<br>
inversion of the rhetoric.  When we speak nonsense, we invite<br>
nonsense.  Particular forms of nonsense include "zero risk"<br>
arguments;  zero-risk can only occur when you decline to evaluate<br>
all possible risks.  Zero-risk does not come from our actions, but<br>
from the ways we present our arguments.  When we develop our<br>
linguistic skills to the point where we can rule the tide to<br>
change, and, in response to our words, the tides change, then we<br>
might accept such propositions as valuable.  Otherwise, I think it<br>
best to accept them as trivially faulty.<br>
<p>
The rhetoric I offered calls for irrational evaluation as much as<br>
the original rhetoric.  Rhetoric doesn't serve if we want to make<br>
sane decisions.  Those sane decisions don't necessarily always<br>
come out right -- but we have better odds when we look at what we<br>
can find, calculate probabilities, determine what *most* *likely*<br>
will get us from where we are to where we want to be, and<br>
recognize that fears and ignorance are not the stuff of effective<br>
choice.<br>
<p>
-R<br>
<p>
<p>
<p>
Richard Plourde .. rplourde@andesign.mv.com<br>
<p>
   "The word is not the thing, the map is not the territory"<br>
            <a href="http://www.crl.com/~isgs/isgshome.html">http://www.crl.com/~isgs/isgshome.html</a><br>
            <a href="http://www.general-semantics.org/">http://www.general-semantics.org/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4160.html">Eliezer S. Yudkowsky: "SF:  Where's the books?"</a>
<li> <b>Previous message:</b> <a href="4158.html">jaan.ranniko@smtpgw.aftrs.edu.au: "RE: BIO: Help wanted"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
