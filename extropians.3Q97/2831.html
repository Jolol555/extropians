<!-- received="Thu Sep  4 16:40:08 1997 MDT" -->
<!-- sent="Thu, 4 Sep 1997 14:12:20 -0700" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: Goo prophylaxis:consensus" -->
<!-- id="199709042112.OAA00256@crypt.hfinney.com" -->
<!-- inreplyto="Goo prophylaxis:consensus" -->
<title>extropians: Re: Goo prophylaxis:consensus</title>
<h1>Re: Goo prophylaxis:consensus</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Thu, 4 Sep 1997 14:12:20 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2831">[ date ]</a><a href="index.html#2831">[ thread ]</a><a href="subject.html#2831">[ subject ]</a><a href="author.html#2831">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2832.html">Eliezer S. Yudkowsky: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2830.html">The Low Golden Willow: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2832.html">Eliezer S. Yudkowsky: "Re: Goo prophylaxis:consensus"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Damien Sullivan writes:<br>
<i>&gt; [Issue of nanotech power preemptively taking out its neighbors]</i><br>
<i>&gt; I raise the possibility of disagreement precisely because our ethical</i><br>
<i>&gt; systems militate against it so strongly.  Our evolved morality may know</i><br>
<i>&gt; more than you do.</i><br>
<p>
This is an interesting question.  Surely at many times in the past,<br>
circumstances have arisen in which one power has an overwhelming but<br>
temporary military advantage over another.  It would be tempting to<br>
engage in a preemptive strike and destroy the potential competitor.<br>
Yet most ethical systems would condemn such behavior as wrong.<br>
<p>
If we think of ethics as distilling our experience of the long-term<br>
consequences of our actions, then this suggests that there is something<br>
mistaken with the reasoning in favor of preemptive strikes.<br>
<p>
A recent historical example would be the situation immediately after<br>
WWII, when the U.S. had sole possession of the atomic bomb.  There was<br>
undoubtedly debate about using this power preemptively against the USSR,<br>
our allies during the war, but inherent ideological adversaries.<br>
<p>
Indeed, the cost of not conquering the Soviet Union was considerable:<br>
the Cold War; years of mistreatment of its population and its ecology<br>
by the Soviet government; justification of American excesses as necessary<br>
to stop the Red menace.<br>
<p>
However, if the U.S. had preemptively attacked Russia after WWII,<br>
destroyed it as a potential competitor for at least decades, things<br>
might easily have been worse.  Certainly the U.S. would have been a less<br>
trusted ally and partner in the world, more a heavy-handed, feared tyrant.<br>
<p>
And as things turned out, the USSR eventually fell apart, with its<br>
countries haltingly moving towards democracy.  This is a victory for<br>
our ethical standards, as the USSR learned that its policies were wrong<br>
in an absolute sense, that is, they were not in accordance with nature.<br>
Even with all the years of suffering caused by the existence of the USSR,<br>
the world is very likely a better place today than it would have been<br>
after 50 years under a nuclear-enforced Pax Americana.<br>
<p>
The question remains whether (to make the case most starkly) some power<br>
in sole possession of vastly sophisticated nanotech would be making a<br>
similar mistake to unilaterally destroy its competition.<br>
<p>
What is the crux of the mistake in preemptive attack?  What is it<br>
about such actions which makes us instinctively feel that there will be<br>
negative consequences?<br>
<p>
One is a pragmatic issue.  Any attack is going to be imperfect.  There<br>
will always be some residual resentment and hatred, and the less justified<br>
the attack, the worse that will be.  This will fester for years, and<br>
eventually the resistance may get enough power to strike back effectively.<br>
<p>
It seems though that the nanotech case is different.  It is hard<br>
to imagine a takeover which allows cells of resistance to remain.<br>
Consider a time- and space-limited gray goo which destroys some region<br>
utterly, then decomposes into useful raw materials for new construction.<br>
Nano is so much more powerful and thorough than any previous technology,<br>
this pragmatic concern does not seem relevant.<br>
<p>
Another issue is less tangible.  It could be argued that by taking an<br>
action which is evil, you make yourself more likely to take other evil<br>
actions in the future.  In the nuclear American empire scenario, we can<br>
easily imagine that after using nuclear weapons on first Japan and then<br>
Russia, they might be used against China, Vietnam, Cuba, or any other<br>
country which dares to resist.  It may be necessary to crack down on<br>
dissent at home, as these outrageous actions lead to protests.  You could<br>
end up with the worst tyranny imaginable.<br>
<p>
Similarly, a nanotech power which is so paranoid and aggressive as to<br>
take the step of eradicating everyone else on the planet may find it<br>
difficult to survive on its own terms.  Paranoia would rule, and lacking<br>
external enemies it may either imagine them (potential alien species) or<br>
create them internally (subsystems which seem to have too much autonomy).<br>
The conflict between the need to extend power as rapidly as possible<br>
across star systems (in order to be strong when alien enemies are met)<br>
and the need to keep complete uniformity of purpose and will (to prevent<br>
internal dissension) will be difficult to resolve.  The power may be<br>
forced into a rigid, simplified mental stance which can be replicated<br>
reliably and applied uniformly, with multiple safeguards against evolution<br>
and alteration.<br>
<p>
The result would be a nightmare Borgism, a nearly mindless plague whose<br>
only goal was conquest, spreading throughout the universe.  This would<br>
all flow from that first step of destruction.<br>
<p>
Consider, in contrast, an entity which takes the harder road from the<br>
beginning, seeking to embrace diversity and work with competitors who<br>
are its equals.  Its survival is less certain; the resources it will be<br>
able to command directly will be more limited.  But the diversity which<br>
results will be a positive benefit in and of itself.  And the need to<br>
deal flexibly and creatively with competitors will arguably make it<br>
better prepared to deal with surprises which the universe throws at it<br>
in the future.<br>
<p>
Granted, this is a pretty fuzzy argument.  In particular, the notion<br>
of being tainted by evil actions sounds melodramatic and old fashioned.<br>
But as Damien says, our ethical systems do embody a considerable history<br>
of experience, even when wrapped in mystical or religious trappings.<br>
An ethical meme which kills its host is less likely to survive.  So we<br>
should not ignore our ethical views too easily.  Evil actions may have<br>
subtle negative consequences which we tend to overlook.<br>
<p>
Hal<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2832.html">Eliezer S. Yudkowsky: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2830.html">The Low Golden Willow: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Maybe in reply to:</b> <a href="2771.html">Nicholas Bostrom: "Goo prophylaxis:consensus"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2832.html">Eliezer S. Yudkowsky: "Re: Goo prophylaxis:consensus"</a>
<!-- reply="end" -->
</ul>
