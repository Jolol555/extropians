<!-- received="Sat Sep 27 18:40:39 1997 MDT" -->
<!-- sent="Sun, 28 Sep 1997 00:20:19 +0000" -->
<!-- name="Nicholas Bostrom" -->
<!-- email="bostrom@mail.ndirect.co.uk" -->
<!-- subject="Re: copying related probability question" -->
<!-- id="199709272321.AAA09993@andromeda.ndirect.co.uk" -->
<!-- inreplyto="copying related probability question" -->
<title>extropians: Re: copying related probability question</title>
<h1>Re: copying related probability question</h1>
Nicholas Bostrom (<i>bostrom@mail.ndirect.co.uk</i>)<br>
<i>Sun, 28 Sep 1997 00:20:19 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4454">[ date ]</a><a href="index.html#4454">[ thread ]</a><a href="subject.html#4454">[ subject ]</a><a href="author.html#4454">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4455.html">Geoff Smith: "Re: The Free Market"</a>
<li> <b>Previous message:</b> <a href="4453.html">Eric Watt Forste: "Re: Innocent excursions in analysis and speculation"</a>
<li> <b>Maybe in reply to:</b> <a href="4116.html">Wei Dai: "copying related probability question"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4474.html">Nicholas Bostrom: "Re: copying related probability question"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
I have at last had time to read the interesting postings by Wei, Hal <br>
and Eliezer on this thread. Here are two preliminary remarks:<br>
<p>
(1)<br>
Hal wrote:<br>
<i>&gt;In effect, cloning makes it a non-zero-sum game.  The changes</i><br>
<i>&gt;introduced by cloning in potential future earnings cause the gains </i><br>
<i>&gt;or losses of the bet to be evaluated differently.  The result is </i><br>
<i>&gt;that it may be rational to take a bet which gives an expected profit </i><br>
<i>&gt;to the other player.</i><br>
<p>
The utility functions of the individual clones may <br>
or may not assign equal utility to the money that goes to the other <br>
clones. It is not necessary that a clone must think an outcome is <br>
only half as good  just because it means he has to give <br>
half of the money to his clone. E. g., he might regard his clone <br>
as another part of himself. Thus it appears that the fact that <br>
earnings might need to be divided in the cloning example is not <br>
essential to the rationality problem. It might therefore be better to <br>
shift the example to one where this confusing aspect does not occur.<br>
<p>
(2)<br>
Wei wrote:<br>
<i>&gt;Nicholas wrote:</i><br>
<i>&gt;&gt; This thread is closely related to the Carter-Leslie Doomsday </i><br>
<i>&gt;&gt; argumen. I have a paper about this:</i><br>
<i>&gt;&gt; </i><br>
<i>&gt;&gt; <a href="http://www.hedweb.com/nickb/140797/doomsday.html">http://www.hedweb.com/nickb/140797/doomsday.html</a></i><br>
<i>&gt;&gt; </i><br>
<i>&gt;&gt; (If anybody has any idea on how we might solve the so-called</i><br>
<i>&gt;&gt; "problem of the reference class", I would be all ears.)</i><br>
<p>
<i>&gt;I agree with Nicholas that these two problems are closely related. </i><br>
<i>&gt;The nice thing about the copying problem is that the reference class </i><br>
<i>&gt;is very clear. It is the class of your (potential) clones.</i><br>
<p>
If the thought experiment is supposed to occur in the actual world, <br>
then there will also be other members of the reference class, namely <br>
all those people not involved in the copying procedure. These are the <br>
"outsiders". As I argued at length in the Doomsday paper, the <br>
Doomsday argument only works (at full strength) if we postulate the <br>
"no-outsider requirement": that there be no outsiders in the world.<br>
<p>
<i>&gt; It's</i><br>
<i>&gt;interesting that if answer set B is correct, then something like the</i><br>
<i>&gt;self-indication axiom does apply in the copying problem.</i><br>
<p>
Well, that would be exactly the way things would appear if there is a <br>
large number of outsiders. Let us consider the following thought <br>
experiment (due to John Leslie):<br>
<p>
God's coin toss:<br>
In an otherwise lifeless universe, God decides to toss a coin and <br>
create 10 humans if it lands head and one human if it lands tail. <br>
(Really, we should take "God" to mean a randomised human breeder <br>
machine, in order not to need to consider the possibility that you <br>
might be God Himself.) Now, suppose you find yourself in such a <br>
universe but you havn't seen how the coin landed.<br>
<p>
The self-indication axiom says that you should think it much more <br>
likely it landed head. The self-indication axiom is very dubious <br>
(and probably false).<br>
<p>
On the other hand, if there will exist a million humans independently <br>
of how the coin landed, then it is likely that you will not have been <br>
created as a result of the coin toss. But given that you were created <br>
as a result of the coin toss then it is ten times more likely that <br>
the coin landed head .For consider the conditional probability Pr(I <br>
was created because of the coin toss. | There are 1010 humans.). This <br>
is clearly greater than Pr(I was created because of the coin toss. | <br>
There are 1001 humans.) If there are 1010 humans then about 1% of <br>
them will be coin-toss humans; if there are1001, then the figure is <br>
about 0.1%. By Bayes' theorem, we conclude that after <br>
conditionalising on "I was created as a result of the coin toss." it <br>
is more likely (by about a factor 10) that the coin showed head than <br>
that it landed tail.<br>
<p>
If this is right then it is important to distinguish the case where <br>
the no-outsider requirement is satisfied from cases where it isn't.<br>
<p>
Nicholas Bostrom<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4455.html">Geoff Smith: "Re: The Free Market"</a>
<li> <b>Previous message:</b> <a href="4453.html">Eric Watt Forste: "Re: Innocent excursions in analysis and speculation"</a>
<li> <b>Maybe in reply to:</b> <a href="4116.html">Wei Dai: "copying related probability question"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4474.html">Nicholas Bostrom: "Re: copying related probability question"</a>
<!-- reply="end" -->
</ul>
