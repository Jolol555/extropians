<!-- received="Sun Aug 17 18:33:51 1997 MDT" -->
<!-- sent="Sun, 17 Aug 1997 16:50:01 -0700 (PDT)" -->
<!-- name="Mark Crosby" -->
<!-- email="crosby_m@rocketmail.com" -->
<!-- subject="Symbol Grounding (was Re: complexity and heat)" -->
<!-- id="199708172042.NAA25616@well.com" -->
<!-- inreplyto="complexity and heat)" -->
<title>extropians: Symbol Grounding (was Re: complexity and heat)</title>
<h1>Symbol Grounding (was Re: complexity and heat)</h1>
Mark Crosby (<i>crosby_m@rocketmail.com</i>)<br>
<i>Sun, 17 Aug 1997 16:50:01 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2142">[ date ]</a><a href="index.html#2142">[ thread ]</a><a href="subject.html#2142">[ subject ]</a><a href="author.html#2142">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2143.html">Dan Clemmensen: "Re: My Crazy Idea"</a>
<li> <b>Previous message:</b> <a href="2141.html">CALYK@aol.com: "Re: My Crazy Idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Eric Watt Forste writes:<br>
&lt;[Paul M. Churchland's work] Psychological phenomena might easily be<br>
concrete, real, physical, computational phenomena *without* having any<br>
kind of one-to-one correspondence with any of the words we currently<br>
use to talk about psychological phenomena. In other words, they might<br>
*matter* without being *real*, in the sense that there might not<br>
*really* be anything that corresponds to the words. &gt;<br>
<p>
This sounds somewhat like a "symbol-grounding" problem.  Here’s the<br>
abstract of a fascinating Internet dialog, "Virtual Symposium on the<br>
Virtual Mind", from 1992 [1]:<br>
&lt; When certain formal symbol systems (e.g., computer programs) are<br>
implemented as dynamic physical symbol systems (e.g., run on a<br>
computer) their activity can be interpreted at higher levels . . .<br>
called "virtual" systems. If such a virtual system is interpretable as<br>
if it had a mind, is such a "virtual mind" real? This is the question<br>
addressed in this "virtual" symposium, originally conducted<br>
electronically among four cognitive scientists: Donald Perlis, a<br>
computer scientist, argues that according to the computationalist<br>
thesis, virtual minds are real . . . Stevan Harnad, a psychologist,<br>
argues that . . . virtual minds are just hermeneutic<br>
overinterpretations, and symbols must be grounded in the real world of<br>
objects, not just the virtual world of interpretations. Computer<br>
scientist Patrick Hayes argues that . . . A real implementation must<br>
not be homuncular but mindless and mechanical, like a computer. Only<br>
then can it give rise to a mind at the virtual level. Philosopher Ned<br>
Block suggests that there is no reason a mindful implementation would<br>
not be a real one.&gt;<br>
<p>
Harnad has a more formal paper on the symbol-grounding problem [2]<br>
where he says:<br>
&lt; Symbolic representations must be grounded bottom-up in nonsymbolic<br>
representations of two kinds:  (1) "iconic representations," which are<br>
analogs of the proximal sensory projections of distal objects and<br>
events, and (2) "categorical representations," which are learned and<br>
innate feature-detectors that pick out the invariant features of<br>
object and event categories from their sensory projections. Elementary<br>
symbols are the names of these object and event categories, assigned<br>
on the basis of their (nonsymbolic) categorical representations.<br>
Higher-order (3) "symbolic representations," grounded in these<br>
elementary symbols, consist of symbol strings describing category<br>
membership relations. Connectionism is one natural candidate for the<br>
mechanism that learns the invariant features underlying categorical<br>
representations, thereby connecting names to the proximal projections<br>
of the distal objects they stand for. In this way connectionism can be<br>
seen as a complementary component in a hybrid nonsymbolic/symbolic<br>
model of the mind, rather than a rival to purely symbolic modeling.&gt;<br>
<p>
But, I also like Patrick Hayes’ reasoning about the evolutionary<br>
advantages of ‘virtual machines’ which is nicely summarized in a<br>
recent JCS Online thread [3]:<br>
<p>
Hayes cites Sam Salt saying: <br>
&lt; I do not believe that programs 'learn', 'adapt', 'pounce' and so on,<br>
except by very broad analogy to how humans do these things. Programs<br>
mostly implement only three things (sequence, selection and iteration)<br>
by the way in which they can be pushed through a central processing<br>
unit(CPU) which only accepts inputs sequentially.&gt;<br>
<p>
Hayes responds:<br>
&lt; [SNIP] Salt, like many electrical engineers, stops at the processor<br>
circuitry . . . One can't reverse engineer software from hardware . .<br>
. Much software doesn't run on the electronic hardware; it runs on one<br>
or another virtual machine . . . [Salt says: regardless of] your<br>
high-level language . . . the low-level implementation uses the same<br>
lowly sequential CPU.  [And Hayes responds:] This is to be celebrated!<br>
Here we have a simple physical mechanism which can produce<br>
extraordinarily complex, symbolically significant, behaviors which can<br>
grow and change, without altering the machine at all! All it needs is<br>
more and more memory, which itself is a simple mechanism. Isnt this<br>
more like a brain that any other mechanism we have ever come across? &gt;<br>
<p>
Mark Crosby<br>
<p>
References:<br>
<p>
[1] Hayes, P., Harnad, S., Perlis, D. &amp; Block, N. (1992) "Virtual<br>
Symposium on the Virtual Mind". Minds and Machines 2(3) 217-238.  From<br>
Harnad’s abstract.<br>
<a href="ftp://cogsci.soton.ac.uk/pub/harnad/Harnad/harnad92.virtualmind">ftp://cogsci.soton.ac.uk/pub/harnad/Harnad/harnad92.virtualmind</a><br>
<p>
[2] Harnad, S. (1990) "The Symbol Grounding Problem", Physica D 42:<br>
335-346.<br>
<a href="ftp://cogsci.soton.ac.uk/pub/harnad/Harnad/harnad90.sgproblem">ftp://cogsci.soton.ac.uk/pub/harnad/Harnad/harnad90.sgproblem</a><br>
<p>
[3] The "Computational Theory and Connectionism" thread on The Journal<br>
of Consciousness Studies Online (early 1996). Pat Hayes,  "Rubbing<br>
Salt in the wound",<br>
<a href="http://www.zynet.co.uk/imprint/online/hayes3.html">http://www.zynet.co.uk/imprint/online/hayes3.html</a><br>
<p>
_____________________________________________________________________<br>
Sent by RocketMail. Get your free e-mail at <a href="http://www.rocketmail.com">http://www.rocketmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2143.html">Dan Clemmensen: "Re: My Crazy Idea"</a>
<li> <b>Previous message:</b> <a href="2141.html">CALYK@aol.com: "Re: My Crazy Idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
