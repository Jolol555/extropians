<!-- received="Wed Sep  3 08:16:05 1997 MDT" -->
<!-- sent="Wed, 3 Sep 1997 06:54:45 -0700 (PDT)" -->
<!-- name="Mark Crosby" -->
<!-- email="crosby_m@rocketmail.com" -->
<!-- subject="Re: Creativity Machine Patented" -->
<!-- id="199709031334.OAA06615@andromeda.ndirect.co.uk" -->
<!-- inreplyto="Creativity Machine Patented" -->
<title>extropians: Re: Creativity Machine Patented</title>
<h1>Re: Creativity Machine Patented</h1>
Mark Crosby (<i>crosby_m@rocketmail.com</i>)<br>
<i>Wed, 3 Sep 1997 06:54:45 -0700 (PDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2773">[ date ]</a><a href="index.html#2773">[ thread ]</a><a href="subject.html#2773">[ subject ]</a><a href="author.html#2773">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2774.html">Anders Sandberg: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2772.html">Nicholas Bostrom: "Re:  Re:  Re: Goo prophylaxis"</a>
<li> <b>Maybe in reply to:</b> <a href="2684.html">Kennita Watson: "Creativity Machine Patented"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Regarding my my complaint that "researchers seem to be modeling the<br>
brain as a vast network of general-purpose neurons", Anders Sandberg<br>
takes me to task: <br>
<p>
&lt;Hmm, what models of the brain are you talking about? All the models I<br>
have seen in my work as a computational neuroscientist tends to be<br>
filled with little boxes of semi-independent systems; nobody tries to<br>
model the brain as a "single" neural net (both because it would be too<br>
hard, and because the neuroscientific data shows that everything is<br>
not connected to everything else).&gt;<br>
<p>
You're right again ;)  I'm sitting on the sidelines, not directly<br>
involved in the nitty gritty of neural network modeling, probably<br>
creating a strawman based on cursory glances at the few fragments I've<br>
had time to glimpse and my impatience to see someone put it all<br>
together into practical applications.<br>
<p>
Still, what I was partially referring to were the apparent biases of<br>
some neural and Alife modelers against *anything* that looks like a<br>
rule-based  or 'software' approach in favor of strictly memoryless<br>
local learning, for example.<br>
<p>
In that Connectionist List summary post that I mentioned before (<br>
<a href="http://neuro.psy.soton.ac.uk/~at/Archive/0026.html">http://neuro.psy.soton.ac.uk/~at/Archive/0026.html</a> ), Professor Danny<br>
Silver notes:<br>
<p>
&lt; I beleive the larger and more important context involves the issues<br>
of what has been called "life-long learning" and "learning to learn"<br>
and "consolidation and transfer of knowledge". I have no idea why so<br>
many researchers continue to pursue the development of the next best<br>
inductive algorithm or archiecture (be it ANN or not) when many of<br>
them understand that the percentage gains on predictive accuracy based<br>
solely on an example set is marginal in comparison to the use of prior<br>
knowledge (selection of inductive bias). &gt;<br>
<p>
Prof. Vassilis G. Kaburlasos adds:<br>
<p>
&lt; That is, to simulate convincingly a biological system we should not<br>
probably be dealing solely with vectors of real numbers. The capacity<br>
to deal with symbols and other types of data merits also attention. In<br>
other words, besides memory and more global learning capabilities, it<br>
will be advantageous to be able to handle jointly disparate data such<br>
as real numbers, fuzzy sets, propositional statements, etc. &gt;<br>
<p>
Dr. Peter Cariani mentions a host of additional assumptions in<br>
connectionist research that need to be challenged, such as: place<br>
coding, scalar signals, synchronous or near-synchronous operation, and<br>
fan-out of the same signals to all target elements.  Cariani concludes:<br>
<p>
&lt; I definitely agree with you that once we understand the functional<br>
organization of the brain as an information processing system, then we<br>
will be able to build devices that are far superior to the biological<br>
ones. My motto is: "keep your hands wet, but your mind dry" -- it's<br>
important to pay attention to the biology, to not project one's<br>
preconceptions onto the system, but it's equally important to keep<br>
one's eyes on the essentials, to avoid getting bogged down in largely<br>
irrelevant details. &gt;<br>
<p>
The 'you' in the above citations refers to Asim Roy, organizer of a<br>
discussion panel, "Connectionist Learning: Is It Time to reconsider<br>
the Foundations?", at the June 1997 International Conference on Neural<br>
Networks.  This panel discussed the following three questions:<br>
<p>
&lt;1. Should memory be used for learning? Is memoryless learning an<br>
unnecessary restriction on learning algorithms? [Snip]<br>
2. Is local learning a sensible idea? Can better learning algorithms<br>
be developed without this restriction? [Snip]<br>
3. Who designs the network inside an autonomous learning system such<br>
as the brain?&gt;<br>
<p>
But, I have to admit I'm just an observer, not really a participant,<br>
and shouldn't be so critical of people doing very *difficult* work.<br>
<p>
Mark Crosby<br>
_____________________________________________________________________<br>
Sent by RocketMail. Get your free e-mail at <a href="http://www.rocketmail.com">http://www.rocketmail.com</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2774.html">Anders Sandberg: "Re: Goo prophylaxis:consensus"</a>
<li> <b>Previous message:</b> <a href="2772.html">Nicholas Bostrom: "Re:  Re:  Re: Goo prophylaxis"</a>
<li> <b>Maybe in reply to:</b> <a href="2684.html">Kennita Watson: "Creativity Machine Patented"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
