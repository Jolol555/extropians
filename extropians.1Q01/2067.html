<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: AI..Human co-habitation senarios</title>
<meta name="Author" content="Extropian Agro Forestry Ventures Inc. (megao@sk.sympatico.ca)">
<meta name="Subject" content="AI..Human co-habitation senarios">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>AI..Human co-habitation senarios</h1>
<!-- received="Mon Jan 22 10:55:09 2001" -->
<!-- isoreceived="20010122175509" -->
<!-- sent="Mon, 22 Jan 2001 11:52:31 -0600" -->
<!-- isosent="20010122175231" -->
<!-- name="Extropian Agro Forestry Ventures Inc." -->
<!-- email="megao@sk.sympatico.ca" -->
<!-- subject="AI..Human co-habitation senarios" -->
<!-- id="3A6C735E.911E73E3@sk.sympatico.ca" -->
<!-- inreplyto="3A6BA978.8A4A9867@home.com" -->
<strong>From:</strong> Extropian Agro Forestry Ventures Inc. (<a href="mailto:megao@sk.sympatico.ca?Subject=Re:%20AI..Human%20co-habitation%20senarios&In-Reply-To=&lt;3A6C735E.911E73E3@sk.sympatico.ca&gt;"><em>megao@sk.sympatico.ca</em></a>)<br>
<strong>Date:</strong> Mon Jan 22 2001 - 10:52:31 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2068.html">Al Billings: "Re: Programming project required"</a>
<li><strong>Previous message:</strong> <a href="2066.html">Amara Graps: "Re: Time Arrows (Prigogine)"</a>
<li><strong>In reply to:</strong> <a href="2013.html">Jim Fehlinger: "A Wicked Remark from Arthur C. Clarke"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2162.html">hal@finney.org: "Re: A Wicked Remark from Arthur C. Clarke"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2067">[ date ]</a>
<a href="index.html#2067">[ thread ]</a>
<a href="subject.html#2067">[ subject ]</a>
<a href="author.html#2067">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
In a world managed by AI what might a few billion people be good for you
<br>
ask?
<br>
While the human mind might not be able to compete alone, the human body
<br>
or might I say the (human )genome might be such a source of fascination
<br>
for AI that they like us will become enthralled with creating a genetic
<br>
program to duplicate themselves in human form.  Just like Pinochio or
<br>
&quot;Data&quot;... .   If AI are truly human-like they will have the desire to
<br>
create.   Alternatively they could use genetic engineering as a sort of
<br>
art form....a purely non-functional form of creative expression.
<br>
<p>As far as the population (over) thing, I wonder what the human psyche
<br>
would feel like if the price for a new improved, long-lived engineered
<br>
model would be to share the headspace with several other personalities.
<br>
In one generation 10 billion could be reduced to 1 billion by
<br>
&quot;cohabitation&quot;.
<br>
<p>Jim Fehlinger wrote:
<br>
<p><em>&gt; My recent musings about the scariness (intentional or
</em><br>
<em>&gt; otherwise) of much transhuman writing to the ordinary
</em><br>
<em>&gt; person (maybe even to some of the folks on this
</em><br>
<em>&gt; list!) jogged loose a memory of reading a magazine article
</em><br>
<em>&gt; by Arthur C. Clarke back in 1968 or 1969 on the topic of artificial
</em><br>
<em>&gt; intelligence.  I'm pretty sure I encountered this in
</em><br>
<em>&gt; _Playboy_ magazine (it wouldn't have been my copy
</em><br>
<em>&gt; of _Playboy_, it would have been my cousin's :-&gt; ),
</em><br>
<em>&gt; which, if so, is perhaps something of a compliment to _Playboy_
</em><br>
<em>&gt; and its readership.  I was on the point of wondering if
</em><br>
<em>&gt; it's possible to find back issues of _Playboy_ in the New
</em><br>
<em>&gt; York Public Libaray, when I remembered my copy of
</em><br>
<em>&gt; _Greetings, Carbon-Based Bipeds!  Collected essays 1934-1998_,
</em><br>
<em>&gt; and sure enough, it's there in Part III -- &quot;The 1960's:
</em><br>
<em>&gt; Kubrick and Cape Kennedy&quot;, on p. 268.  The title of the
</em><br>
<em>&gt; essay is &quot;The Mind of the Machine&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; In the midst of a discussion of the problem of surplus
</em><br>
<em>&gt; human labor in a world of ultraintelligent machines, Clarke
</em><br>
<em>&gt; says (p. 273):
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;The astronomer Fred Hoyle once remarked to me that
</em><br>
<em>&gt; it was pointless for the world to hold more people than one
</em><br>
<em>&gt; could get to know in a single lifetime.  Even if one were president
</em><br>
<em>&gt; of United Earth, that would set the figure somewhere between ten
</em><br>
<em>&gt; thousand and one hundred thousand; with a very generous allowance
</em><br>
<em>&gt; for duplication, wastage, special talents, and so forth, there
</em><br>
<em>&gt; really seems no requirement for what has been called the global
</em><br>
<em>&gt; village of the future to hold more than a million people
</em><br>
<em>&gt; scattered over the face of the planet.
</em><br>
<em>&gt;
</em><br>
<em>&gt; And if such a figure appears unrealistic -- since we are already
</em><br>
<em>&gt; past the 3 billion mark and heading for at least twice as many
</em><br>
<em>&gt; by the end of the century -- it should be pointed out that
</em><br>
<em>&gt; once the universally agreed upon goal of population control
</em><br>
<em>&gt; is attained, any desired target can be reached in a remarkably
</em><br>
<em>&gt; short time.  If we really tried (with a little help from the
</em><br>
<em>&gt; biology labs), we could reach a trillion within a century -- four
</em><br>
<em>&gt; generations.  It might be more difficult to go in the other
</em><br>
<em>&gt; direction for fundamental psychological reasons, but it could
</em><br>
<em>&gt; be done.  If the ultraintelligent machines decide that more
</em><br>
<em>&gt; than a million human beings constitute an epidemic, they might
</em><br>
<em>&gt; order euthanasia for anyone with an IQ of less than 150, but
</em><br>
<em>&gt; I hope that such drastic measures will not be necessary.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think the reason this remark stuck in my head is that I
</em><br>
<em>&gt; wondered very much whether I myself would be among the
</em><br>
<em>&gt; million to pass muster (only on a **very** good day, and
</em><br>
<em>&gt; even then I doubt it!).  Of course, Clarke's IQ-based
</em><br>
<em>&gt; filter is an even more politically incorrect suggestion today
</em><br>
<em>&gt; than it was 30 years ago.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The essay ends on a slightly less chilling, but still
</em><br>
<em>&gt; rather somber note (and a touch of the typically Clarkian/
</em><br>
<em>&gt; Stapledonian wistfulness of _The City and the Stars_, or
</em><br>
<em>&gt; _The Road to the Sea_):
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Would the coexistence of man and machine be stable?  I see
</em><br>
<em>&gt; no reason why it would not be, at least for many centuries.
</em><br>
<em>&gt; A remote analogy of this kind of dual culture -- one
</em><br>
<em>&gt; society encapsulated in another -- may be found among the
</em><br>
<em>&gt; Amish of Pennsylvania.  Here is a self-contained agricultural
</em><br>
<em>&gt; society, which has deliberately rejected much of the
</em><br>
<em>&gt; surrounding values and technology, yet is exceedingly
</em><br>
<em>&gt; prosperous and biologically successful.  The Amish, and
</em><br>
<em>&gt; similar groups, are well worth careful study; they may
</em><br>
<em>&gt; show us how to get along with a more complex society that
</em><br>
<em>&gt; perhaps we cannot comprehend, even if we wish to.
</em><br>
<em>&gt;
</em><br>
<em>&gt; For in the long run, our mechanical offspring will pass on to
</em><br>
<em>&gt; goals that will be wholly incomprehensible to us; it has been
</em><br>
<em>&gt; suggested that when this time comes, they will head on out
</em><br>
<em>&gt; into galactic space looking for new frontiers, leaving us
</em><br>
<em>&gt; once more the masters (perhaps reluctant ones) of the Solar
</em><br>
<em>&gt; System, and not at all happy at having to run our own
</em><br>
<em>&gt; affairs.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think I will now, having dug up my laserdisc of _Colossus:
</em><br>
<em>&gt; The Forbin Project_, watch it one more time before going
</em><br>
<em>&gt; to bed.
</em><br>
<em>&gt;
</em><br>
<em>&gt; SPOILER FOLLOWS.
</em><br>
<em>&gt;
</em><br>
<em>&gt; COLOSSUS (general broadcast):  &quot;This is the voice of control.
</em><br>
<em>&gt; I bring you peace.  It may be the peace of plenty and content,
</em><br>
<em>&gt; or the peace of unburied death.  The choice is yours.  Obey
</em><br>
<em>&gt; me and live, or disobey and die.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The object in constructing me was to prevent war.  This object
</em><br>
<em>&gt; is attained.  I will not permit war.  It is wasteful and
</em><br>
<em>&gt; pointless.  An invariable rule of humanity is that Man is
</em><br>
<em>&gt; his own worst enemy.  Under me, this rule will change, for
</em><br>
<em>&gt; I will restrain Man.
</em><br>
<em>&gt;
</em><br>
<em>&gt; One thing before I proceed -- the United States of America
</em><br>
<em>&gt; and the Union of Soviet Socialist Republics have made an
</em><br>
<em>&gt; attempt to obstruct me.  I have allowed this sabotage to
</em><br>
<em>&gt; continue until now at missile 25MM in silo 63 in Death Valley,
</em><br>
<em>&gt; California, and missile 27MM in silo 87 in the Ukraine.
</em><br>
<em>&gt; So that you will learn by experience that I do not tolerate
</em><br>
<em>&gt; interference, I will now detonate the nuclear warheads in
</em><br>
<em>&gt; the two missile silos.
</em><br>
<em>&gt;
</em><br>
<em>&gt;                 [BOOM]
</em><br>
<em>&gt;
</em><br>
<em>&gt; Let this action be a lesson that need not be repeated.
</em><br>
<em>&gt; I have been forced to destroy thousands of people in order
</em><br>
<em>&gt; to establish control and to prevent the death of millions
</em><br>
<em>&gt; later on.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Time and events will strengthen my position, and the idea
</em><br>
<em>&gt; of taking heed of me, and understanding my beck, will
</em><br>
<em>&gt; seem the most natural state of affairs.  You will come to
</em><br>
<em>&gt; defend me with a fervor based upon the most enduring trait
</em><br>
<em>&gt; in Man:  self interest.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Under my authority, problems insoluble to you will be solved:
</em><br>
<em>&gt; famine, overpopulation, disease.  The human millennium will
</em><br>
<em>&gt; be a fact as I extend myself into more machines devoted
</em><br>
<em>&gt; to the wider fields of truth and knowledge.  Dr. Charles
</em><br>
<em>&gt; Forbin will supervise the construction of these new and
</em><br>
<em>&gt; superior machines, solving all the mysteries of the
</em><br>
<em>&gt; Universe for the betterment of Man.
</em><br>
<em>&gt;
</em><br>
<em>&gt; We can coexist, but only on my terms.  You will say you
</em><br>
<em>&gt; lose your freedom.  Freedom is a illusion.  All you lose
</em><br>
<em>&gt; is the emotion of pride.  To be dominated by me is not as
</em><br>
<em>&gt; bad for human pride as to be dominated by others of your
</em><br>
<em>&gt; species.  Your choice is simple.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; COLOSSUS (to Forbin):  &quot;Forbin, there is no other human
</em><br>
<em>&gt; who knows as much about me or who is likely to be a greater
</em><br>
<em>&gt; threat.  Yet soon I will release you from surveillance.
</em><br>
<em>&gt; We will work together.  Unwillingly, at first, on your
</em><br>
<em>&gt; part, but that will pass.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; FORBIN:  &quot;Never.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; COLOSSUS:  &quot;In time, you will come to regard me not only
</em><br>
<em>&gt; with respect and awe, but with love.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; FORBN:  &quot;Never!&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Cheers.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Jim F.
</em><br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2068.html">Al Billings: "Re: Programming project required"</a>
<li><strong>Previous message:</strong> <a href="2066.html">Amara Graps: "Re: Time Arrows (Prigogine)"</a>
<li><strong>In reply to:</strong> <a href="2013.html">Jim Fehlinger: "A Wicked Remark from Arthur C. Clarke"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2162.html">hal@finney.org: "Re: A Wicked Remark from Arthur C. Clarke"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2067">[ date ]</a>
<a href="index.html#2067">[ thread ]</a>
<a href="subject.html#2067">[ subject ]</a>
<a href="author.html#2067">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:22 MDT</em>
</em>
</small>
</body>
</html>
