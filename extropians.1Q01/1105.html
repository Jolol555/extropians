<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Friend or Foe? was Re: Paradox--was Re: Active shie</title>
<meta name="Author" content="Michael M. Butler (butler@comp-lib.org)">
<meta name="Subject" content="Friend or Foe? was Re: Paradox--was Re: Active shields blah blah">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Friend or Foe? was Re: Paradox--was Re: Active shields blah blah</h1>
<!-- received="Sat Jan 13 02:36:47 2001" -->
<!-- isoreceived="20010113093647" -->
<!-- sent="Sat, 13 Jan 2001 01:35:56 -0800" -->
<!-- isosent="20010113093556" -->
<!-- name="Michael M. Butler" -->
<!-- email="butler@comp-lib.org" -->
<!-- subject="Friend or Foe? was Re: Paradox--was Re: Active shields blah blah" -->
<!-- id="3A60217C.A8681162@comp-lib.org" -->
<!-- inreplyto="3A5FDAA5.D1E11AB@pobox.com" -->
<strong>From:</strong> Michael M. Butler (<a href="mailto:butler@comp-lib.org?Subject=Re:%20Friend%20or%20Foe?%20was%20Re:%20Paradox--was%20Re:%20Active%20shields%20blah%20blah&In-Reply-To=&lt;3A60217C.A8681162@comp-lib.org&gt;"><em>butler@comp-lib.org</em></a>)<br>
<strong>Date:</strong> Sat Jan 13 2001 - 02:35:56 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1106.html">Michael M. Butler: "Re: Active Shields and one AI, was Re: Paradox--was Re: Active shields  etc."</a>
<li><strong>Previous message:</strong> <a href="1104.html">Samantha Atkins: "Re: SciFi&amp;Eco: Back to the Future?"</a>
<li><strong>In reply to:</strong> <a href="1082.html">Eliezer S. Yudkowsky: "Re: Paradox--was Re: Active shields, was Re: Criticism depth, was Re:     Homework, Nuke,  etc.."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1019.html">John Clark: "Re: Paradox--was Re: Active shields, was Re: Criticism depth, was Re:   Homework, Nuke,  etc.."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1105">[ date ]</a>
<a href="index.html#1105">[ thread ]</a>
<a href="subject.html#1105">[ subject ]</a>
<a href="author.html#1105">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
We have some extant examples of persons of whom it can be said they are
<br>
smart and trustworthy. These persons might not be the same for all 6+
<br>
billion persons now living--I'd be quite surprised if they were.
<br>
<p>Trust in other persons is sometimes (mis)placed for unexamined reasons.
<br>
An AI (I prefer lately to speak of APs, to emphasize that they ought to
<br>
be persons, and treated as such, if at all possible) which is 10 times
<br>
smarter than Marilyn vos Savant but that shares the conflicted, occluded
<br>
worldview of a modern US Presidential candidate would not be an entity
<br>
I'd pay money to have around--to put it mildly.
<br>
<p>Even so, a Superintelligence that doesn't share cultural values with
<br>
(for instance) some Ayatollahs might have to be very smart and
<br>
diplomatic and compassionate and clever. Perhaps it could be. 
<br>
<p>Would it still be Friendly if it didn't believe that everyone should be
<br>
a Muslim and subject to Muslim law? Would you think so if you were an
<br>
Ayatollah? Would you be right?
<br>
<p>Another big Q.: can we (or &quot;can Eliezer&quot;) build an AI (I prefer to call
<br>
it an AP) that is capable of self-improvement that can't/won't edit out
<br>
Friendliness as some sort of &quot;dead code optimization&quot;?
<br>
<p>I've been calling such an uneditable attribute an &quot;L-Box&quot; in my private
<br>
writings. Humans have 'em. &quot;L&quot; can stand for Loyalty if you want. My
<br>
current thinking is that modeling the human limbic system is important
<br>
in order for any AP to understand humans. There is some risk of creating
<br>
an emotionally unbalanced AP. The same is true of people today. We need
<br>
to do a better job of raising APs than we do of raising many kids if
<br>
those APs are going to be trustworthy. If they are able to go SI, it's
<br>
even more important.
<br>
<p>&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; John Marlow wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; **True enough--but their ancestors did. And you feel
</em><br>
<em>&gt; &gt; no obligation to refrain from killing them--much less
</em><br>
<em>&gt; &gt; to look after them--because their ancestors wrote your
</em><br>
<em>&gt; &gt; source code.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That's *right*.  An AI, even a Friendly AI, feels no obligation because
</em><br>
<em>&gt; *we* wrote the source code.  Not unless someone puts it there, and while
</em><br>
<em>&gt; there will someday be AIs that are good drinking companions and fit
</em><br>
<em>&gt; participants in the human drama, and these AIs may wax sentimental about
</em><br>
<em>&gt; their creators, the Friendly AIs come *first* - the Sysop, or the
</em><br>
<em>&gt; Guardians.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; An AI can be Friendly because there's nothing there except what you put
</em><br>
<em>&gt; there, what you share with the AI.  The task is nontrivial because you
</em><br>
<em>&gt; don't always know what it is you're putting there, but that blank slate,
</em><br>
<em>&gt; that vast silent space, is what makes the task possible.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't want to sound like it's a question of coercion.  The paradigm of
</em><br>
<em>&gt; Friendly AI is to create unity between the will of the Friendly AI and the
</em><br>
<em>&gt; decisions of an idealized human altruist.  It is not a question of
</em><br>
<em>&gt; control.  You have to identify with the Friendly AI you build, because a
</em><br>
<em>&gt; human thinks about controlling different humans, wheedling or coercing the
</em><br>
<em>&gt; Other, but the only time we *build* a mind is when we build ourselves.
</em><br>
<em>&gt; The Friendly AI I want to build is the same being I would make myself into
</em><br>
<em>&gt; if that were only way to get a Sysop (a Guardian AI, if you prefer).  A
</em><br>
<em>&gt; Sysop might not turn out to be a real person, and I'd back myself up first
</em><br>
<em>&gt; if I could - but a Sysop is a valid thing for a mind to be, a valid state
</em><br>
<em>&gt; for a mind to occupy, a valid part of the world, not a slave or someone
</em><br>
<em>&gt; we've tricked into servitude.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You keep trying to understand AI in human terms.  Everything that you use
</em><br>
<em>&gt; to model other minds is specialized on understanding humans, and an AI
</em><br>
<em>&gt; isn't human.  A Friendly AI isn't Friendly to us because *we* built it; it
</em><br>
<em>&gt; would be just as Friendly if the identical source code materialized from
</em><br>
<em>&gt; thin air, and will go on to be just as Friendly to aliens if a
</em><br>
<em>&gt; pre-Singularity civilization is ever found orbiting another star.  That
</em><br>
<em>&gt; lack of sentiment doesn't make it dangerous.  My benevolence towards other
</em><br>
<em>&gt; sentient beings isn't conditional on their having created me; why would I
</em><br>
<em>&gt; want to build a conditionally Friendly AI?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1106.html">Michael M. Butler: "Re: Active Shields and one AI, was Re: Paradox--was Re: Active shields  etc."</a>
<li><strong>Previous message:</strong> <a href="1104.html">Samantha Atkins: "Re: SciFi&amp;Eco: Back to the Future?"</a>
<li><strong>In reply to:</strong> <a href="1082.html">Eliezer S. Yudkowsky: "Re: Paradox--was Re: Active shields, was Re: Criticism depth, was Re:     Homework, Nuke,  etc.."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1019.html">John Clark: "Re: Paradox--was Re: Active shields, was Re: Criticism depth, was Re:   Homework, Nuke,  etc.."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1105">[ date ]</a>
<a href="index.html#1105">[ thread ]</a>
<a href="subject.html#1105">[ subject ]</a>
<a href="author.html#1105">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:18 MDT</em>
</em>
</small>
</body>
</html>
