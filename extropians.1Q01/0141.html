<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Placebo effect not physical</title>
<meta name="Author" content="Dan Fabulich (daniel.fabulich@yale.edu)">
<meta name="Subject" content="Re: Placebo effect not physical">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Placebo effect not physical</h1>
<!-- received="Wed Jan  3 14:12:26 2001" -->
<!-- isoreceived="20010103211226" -->
<!-- sent="Wed, 3 Jan 2001 16:12:16 -0500 (EST)" -->
<!-- isosent="20010103211216" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Placebo effect not physical" -->
<!-- id="Pine.GSO.4.10.10101031420280.21798-100000@morpheus.cis.yale.edu" -->
<!-- inreplyto="002201c07060$0c8ccfa0$2ea7403e@i6x7m6" -->
<strong>From:</strong> Dan Fabulich (<a href="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Placebo%20effect%20not%20physical&In-Reply-To=&lt;Pine.GSO.4.10.10101031420280.21798-100000@morpheus.cis.yale.edu&gt;"><em>daniel.fabulich@yale.edu</em></a>)<br>
<strong>Date:</strong> Wed Jan 03 2001 - 14:12:16 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0142.html">Michael S. Lorrey: "Re: CULTURE: Interesting Chicago Statistics"</a>
<li><strong>Previous message:</strong> <a href="0140.html">Emlyn: "Re: Thanks all (was Re: bacteria question)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0211.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0211.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Reply:</strong> <a href="0268.html">J. R. Molloy: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0323.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0534.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="1045.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="1224.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#141">[ date ]</a>
<a href="index.html#141">[ thread ]</a>
<a href="subject.html#141">[ subject ]</a>
<a href="author.html#141">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
I lost track of this thread when you changed the Subject line without
<br>
adding &quot;was: MVT: all-conquering philosophy&quot;  I don't read everything
<br>
that comes through this list, especially over the holidays.  :)  Let's
<br>
try to restrict this discussion to just one or two Subject lines.
<br>
<p>Steve Nichols wrote:
<br>
<p><em>&gt; S&gt; OK. I also think that language is faulty and misleading in general,
</em><br>
<em>&gt; S&gt; which I why I am starting to develop a word-free visual philosophy
</em><br>
<em>&gt; S&gt; (some examples at www.extropia.net vis phil sector).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;Being visual is not enough.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Nor is being wordy .....  but philosophy does not allow itself
</em><br>
<em>&gt; to use pictures, but in my approach I can use any symbolic forms.
</em><br>
<p>On the contrary: philosophers DO avail themselves of pictures, if they
<br>
think it will help them make their point clearer.  Plenty of
<br>
philosophical articles have diagrams.  However, once they insert their
<br>
diagrams, they use words to refer to the diagram, or make up new words
<br>
to refer to concepts which the diagrams describe.
<br>
<p>So, again, I assert that the difference here is in the formality of
<br>
the discussion.
<br>
<p><em>&gt; &gt;All the ordinary philosophical problems
</em><br>
<em>&gt; &gt;can be translated into, for example, American Sign Language, with only
</em><br>
<em>&gt; &gt;a few complications.  After all, writing is visual.  The difference is
</em><br>
<em>&gt; &gt;in how much formal structure your language has, and how much is left
</em><br>
<em>&gt; &gt;to be inferred from humanity and charity.  On the formal end, you've
</em><br>
<em>&gt; &gt;got the propositional calculus and Lojban.  On the informal end,
</em><br>
<em>&gt; &gt;you've got abstract dance, jazz,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Purely visual &amp; auditory surely ... we use our musical judgements not
</em><br>
<em>&gt; verbal ....
</em><br>
<p>I'm not sure what you're trying to get across here.  Sure, music is
<br>
different from words.  (Though, when the words are spoken only, both
<br>
are &quot;auditory.&quot;)  But the relevant difference is their formality.
<br>
Certainly it would make no difference if I spelled out my words using
<br>
piano chords.  (This would sound awful, of course, but...)
<br>
<p><em>&gt; &gt;painting, and others.  In the middle
</em><br>
<em>&gt; &gt;towards the formal end you've got speech; ASL is a little less formal
</em><br>
<em>&gt; &gt;than speech, and more dependent on &quot;context&quot; (ie charity and humanity)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But I allow myself all the mediums ... so my analysis is more complete
</em><br>
<em>&gt; than one limited to linguistic analysis...
</em><br>
<p>Again, we've already got it.
<br>
<p>What does that completeness get you?  Does it answer some
<br>
philosophical questions?  Then write an article and use some diagrams.
<br>
This would work because all you'd be doing is writing in an invented
<br>
picture-language.  In the past, when people have invented languages in
<br>
which to discuss philosophical problems, e.g. the propositional
<br>
calculus, we have used these languages in articles written in English.
<br>
These articles have been especially convincing by virtue of their use
<br>
of the invented language.  So, if your picture-language does the same
<br>
for philosophy as symbolic logic does (which I doubt, but, who knows)
<br>
you should be able to write an article in English using diagrams that
<br>
helps us ordinary language philosophers out.
<br>
<p>Does it create new philosophical questions which cannot be answered or
<br>
even named verbally?  If your language is as formal as English or
<br>
symbolic logic, it probably cannot be done, since your langugage could
<br>
simply be structurally translated into English.  German has words with
<br>
no single-word equivalent in English, but they may be structurally
<br>
analyzed and explained in English.  We may even keep the German name,
<br>
or create a new English word to refer to the German referent.  If your
<br>
picture-language is like that, then you haven't created something
<br>
radically new, expect possibly to shift our attention to a certain
<br>
class of questions that can be written down in English, but which
<br>
haven't been before.
<br>
<p>Finally, your language may be considerably less formal than English.
<br>
But then, your language is so different from philosophy as we know it
<br>
that it becomes its own entity, distinct from philosophy entirely, as
<br>
jazz and abstract dance are to philosophy.
<br>
<p>Now, conclusively settling the matter on an old philosophical question
<br>
and raising new ones that no one has thought of before IS quite
<br>
valuable.  But, even so, one shouldn't be under the misconceptions
<br>
that the language raises questions that cannot be named in English, or
<br>
presents arguments which CANNOT be stated in modern philosophy
<br>
as-we-know-it.
<br>
<p><em>&gt; But you can't have an analytic discussion about mind if you
</em><br>
<em>&gt; are a physicalist either ... and maybe you can have a purely
</em><br>
<em>&gt; diagrammatic discussion about the mind using pictures ...
</em><br>
<p>Again, we physicalists can be anti-realists about minds.  Then we
<br>
*can* have analytic discussions about &quot;minds.&quot;  (Henceforth, I'll try
<br>
to use scare quotes to keep you from making the fallacy I referred to
<br>
last time.)
<br>
<p><em>&gt; &gt;On philosophical grounds, then, I say that MVT doesn't seem very
</em><br>
<em>&gt; &gt;elegant to me; that it doesn't even seem to be right on philosophical
</em><br>
<em>&gt; &gt;terms, on account of the qualitative differences between &quot;holes&quot; (as
</em><br>
<em>&gt; &gt;missing functionality) and feelings.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Forget &quot;holes&quot; .. this was one of my arguments about your atomism.
</em><br>
<em>&gt; Substitute &quot;abstract&quot; or &quot;absent&quot; .. and consider that &quot;symbols&quot; are the
</em><br>
<em>&gt; medium of all types of mentation and that the pineal unitary sense organ
</em><br>
<em>&gt; has become symbolic rather than actual.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Or does your type of physicalism deny symbols?
</em><br>
<p>Well, my physicalism denies that symbols are anything more than their
<br>
physical part.  e.g. Writing is nothing more than scratches on paper.
<br>
The words which I've sent to you are nothing more than bits on a disk,
<br>
signal down a wire, glowing phosphors on a screen, and are also stored
<br>
in the layout of our purely physical brains.
<br>
<p>My physicalism denies that there is some non-physical meaning-object
<br>
which is out there somewhere, attached to the word.  The word has a
<br>
use, an effect on ourselves and others, but nothing more.
<br>
<p><em>&gt; &gt;Determinism doesn't rule out the possibility of history any more than
</em><br>
<em>&gt; &gt;it demands fatalism; all I've described here is a bit of history of
</em><br>
<em>&gt; &gt;science.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I repeat my question: &quot;Are &quot;principles&quot; physical then? &quot;
</em><br>
<p>Yes.  Principles are arrays of physical symbols, which may be stored
<br>
in the physical brain.
<br>
<p><em>&gt; I don't think you are using &quot;metaprogram&quot; in the accepted
</em><br>
<em>&gt; psychotherapeutic sense here, but are changing the idea to try
</em><br>
<em>&gt; and fit with your philosophical bias. Brains can not only change
</em><br>
<em>&gt; their &quot;programming&quot; but can reconfigure their own *hardware*
</em><br>
<p>The brain can't *arbitrarily* change its hardware.  It's obviously
<br>
restricted by the laws of physics, but it also suffers from many other
<br>
more restrictive limitations.  The Turing machine has some obvious
<br>
limitations, but the fact that it can't change THOSE doesn't mean that
<br>
it's not just like a brain (in all the relevant ways).
<br>
<p>More to the point, you say that the brain changes its &quot;hardware.&quot;  I
<br>
say that the very changes which you call changes in &quot;hardware&quot; are
<br>
really changes in &quot;software.&quot;  They're software because they CAN be
<br>
changed internally.  The hardware is, by definition, the stuff that
<br>
has to be changed externally.
<br>
<p>So, I'm not telling you that the brain's circuitry is analogous to the
<br>
circuitry of a Turing machine, but that the brain's hardware, the part
<br>
that cannot be changed internally, is equivalent to the Turing
<br>
machine's hardware.
<br>
<p><em>&gt; &gt;Yes, but I don't share those feelings with you.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Ah, so you adopt an *Intuitionist * stance here .. your words have
</em><br>
<em>&gt; given out so you appeal to feelings. I happen to think most
</em><br>
<em>&gt; philosophical so-called analysis does come down to feelings
</em><br>
<em>&gt; and aesthetics ...
</em><br>
<p>Now, I want to remind you that I don't share those &quot;feelings&quot; with
<br>
you.  I'm an anti-realist about feelings.  We should reinterpret them
<br>
as purely physical.
<br>
<p>But, once we do that, yes, I take it that this discussion, as all
<br>
other (philosophical?) discussions, relies inherently on &quot;intuitions.&quot;
<br>
But that doesn't mean that the discussion ends here.  I suspect that
<br>
we agree enough on our intuitions that by drawing attention to the
<br>
right sorts of facts we can come to agree on the same conclusion, or
<br>
at least clearly identify in what way our intuitions diverge.
<br>
<p><em>&gt; &gt;I do think that they're all physical; that they share
</em><br>
<em>&gt; &gt;that one property in common.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Time is the *measurement* of movement in space .. therefore
</em><br>
<em>&gt; must be subjective because measurement is integral, not
</em><br>
<em>&gt; incidental to the concept of time. There is no &quot;time&quot; out there
</em><br>
<em>&gt; that you can point to  ... it is just a concept ... not physical.
</em><br>
<p>My incapacity to point to something doesn't mean that it's not
<br>
physical.  But no matter.  I'm not picky about whether time is merely
<br>
the measurement or whether there's something to measure.  This has
<br>
nothing to do with the fact that holes have places, whereas feelings,
<br>
in the ordinary mental realist sense, don't.
<br>
<p><em>&gt; &gt; I take it that the correct move in a
</em><br>
<em>&gt; &gt;phenomenological scenario is to be an anti-realist about physics: to
</em><br>
<em>&gt; &gt;say &quot;when you say matter, you really mean such-and-such matter
</em><br>
<em>&gt; &gt;qualia...&quot; or &quot;when you say physical, you really mean having
</em><br>
<em>&gt; &gt;such-and-such sensations in common...&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I won't use the qualia jargon, but yes, I largely agree with the above.
</em><br>
<p>Well, I'll just adopt this phenomenologist strategy to answer you
<br>
point above, then.  Time may be a measurement, but it's a &quot;physical&quot;
<br>
measurement, whatever &quot;physical&quot; means.
<br>
<p><em>&gt; &gt;Anyway, the very fact that &quot;holes&quot; have a &quot;location&quot; by definition
</em><br>
<em>&gt; &gt;whereas &quot;feelings&quot; don't, is enough to show that &quot;holes&quot; are
</em><br>
<em>&gt; &gt;analytically different from &quot;feelings,&quot; whatever other properties
</em><br>
<em>&gt; &gt;these things have.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure, except that the only knowledge you have of the hole is
</em><br>
<em>&gt; indirect, via your feelings/ perceptions/ logical reasoning and
</em><br>
<em>&gt; depth perception &amp;c. The illusion of the hole has an illusionary
</em><br>
<em>&gt; location .. there isn't any &quot;hole&quot; independent of the illusion, or
</em><br>
<em>&gt; if there is it is impossible to know. Same with any so-called
</em><br>
<em>&gt; &quot;physical objects&quot; .. but MVT idealism explains how the illusion
</em><br>
<em>&gt; is produced. I don't need to deny the existence of physical objects,
</em><br>
<em>&gt; maybe they are there, or maybe we hallucinate them, who knows
</em><br>
<em>&gt; and who cares. The physical brain is necessary, but not sufficient
</em><br>
<em>&gt; for consciousness. A self-referential  and abstract component is
</em><br>
<em>&gt; needed in order to interact with the world of symbols &amp; abstraction.
</em><br>
<p>Again, you cannot get away from this problem by using idealism,
<br>
because you still have all the same problems, slightly modified for
<br>
idealism.  What's the connection between sensations-of-brains and
<br>
sadness?  How can you solve the problem of other minds with idealism?
<br>
All you have access to is sensations of their behavior, and of their
<br>
brains.  How can you conclude that they have a mind on that basis?
<br>
<p>You might be taking a page from the anti-realist's book and say &quot;I
<br>
cannot be wrong about there being a mind there, because the mind
<br>
itself is on the same ontological level as an illusion.  If I believe
<br>
that there's a mind there, then there's an illusion of a mind there,
<br>
so there's a mind there, because a mind is just an illusion of a
<br>
mind.&quot;
<br>
<p>But then I can make a similar move back in the physical realm: &quot;I
<br>
can't be wrong in making belief statements about minds, because having
<br>
a mind is just the same as our 'believing' that there's a mind there.&quot;
<br>
(Again, scare quotes to remind you that I'm reinterpreting 'belief' to
<br>
be purely physical.)  This, obviously, is just the Turing test: if it
<br>
&quot;seems&quot; to have a mind to us, then it does.
<br>
<p>If you didn't find the Turing test satisfying, then you shouldn't find
<br>
your &quot;mind-as-illusion&quot; account satisfying.  Both are &quot;psychological,&quot;
<br>
whatever we think that means, but neither of them hit the nail on the
<br>
head in conversation with a dualist.
<br>
<p><em>&gt; S&gt; Anyway, you are not consistent saying that &quot;we use our minds to
</em><br>
<em>&gt; S&gt; demarcate&quot; if your system does not include &quot;minds&quot; ... conscious
</em><br>
<em>&gt; S&gt; organs.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;We anti-realists get this a lot.  It's completely fallacious.
</em><br>
<em>&gt; &gt;Anti-realists about Xs assert that there aren't really Xs, AND that we
</em><br>
<em>&gt; &gt;should reinterpret claims about Xs to be claims about Ys.  So when
</em><br>
<em>&gt; &gt;somebody says &quot;The anti-realist contradicts himself when he says
</em><br>
<em>&gt; &gt;such-and-such about Xs, yet maintains that there are no Xs!&quot; they're
</em><br>
<em>&gt; &gt;making a flat-out mistake.  It is not wrong to talk about
</em><br>
<em>&gt; &gt;consciousness or pain or other feelings; all I ask is that we remember
</em><br>
<em>&gt; &gt;that these are handy terms for physical phenomena.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't accept that &quot;consciousness&quot; is a handy term for a physical
</em><br>
<em>&gt; phenomena at all ..
</em><br>
<p>Fine.  But don't accuse me of contradicting myself, because when *I*
<br>
use the word &quot;consciousness,&quot; I'm referring to physical
<br>
characteristics.
<br>
<p><em>&gt; and have an example that might prove my case.
</em><br>
<em>&gt; With chemical medicine you can establish causal links between
</em><br>
<em>&gt; relief of symptoms or cure of illness and the physical properties of
</em><br>
<em>&gt; a drug.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; However, all experiments ever done on the subject have shown
</em><br>
<em>&gt; that a &quot;placebo effect&quot; operates .... but the sugar pill has no
</em><br>
<em>&gt; chemical effects in the cure, only psychological.
</em><br>
<p>No strictly *chemical* effects, but the &quot;psychological&quot; effects are
<br>
physical effects.  The placebo has an indirect physical effect to cure
<br>
the patient, by making the patient &quot;think&quot; that they are being cured,
<br>
and, for example, relieving stress, and bolstering the immune system.
<br>
<p>All physical all the time.  The placebo effect *is* physical.
<br>
<p><em>&gt; &gt;The way to avoid this mistake is to remember that it is *very* rare
</em><br>
<em>&gt; &gt;that an intelligent person will assert an outright contradiction,
</em><br>
<em>&gt; &gt;especially an intelligent philosopher; they're probably saying
</em><br>
<em>&gt; &gt;something else similar.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Disagree. The wisest men in history have made glaring errors
</em><br>
<em>&gt; and believed crass theories. Especially philosophers.
</em><br>
<p>Look, when reading and interpreting what other people say, especially
<br>
people from other cultures, you have to employ principles of humanity
<br>
and charity.  You have to assume that they acquire beliefs in more or
<br>
less the same way that you do, and that you and they are largely
<br>
correct in your beliefs.
<br>
<p>Suppose I just tell you that &quot;my gavagai is red,&quot; but you assume that
<br>
I'm wrong about that.  How will you find out what my gavagai is?  You
<br>
might come up with some reasonable guess about what I might be wrong
<br>
about, but you'll do much better if you assume I'm right and look for
<br>
some red thing that might be my gavagai.
<br>
<p>Similarly, if you read those &quot;crass theories&quot; with an eye towards
<br>
interpreting them with charity, with interpreting them as if they're
<br>
saying something basically right, you'll not only have a more
<br>
interesting time at it, but you might learn something as well.
<br>
<p><em>&gt; But holes have no &quot;substance&quot; and are JUST their boundaries.
</em><br>
<p>Who cares?  They have a location, whereas the realist's &quot;feelings&quot; don't.
<br>
<p><em>&gt; &gt;But forgive me if I slip back into such handy phrases as &quot;Imagine that
</em><br>
<em>&gt; &gt;...&quot; &quot;I feel differently ...&quot; or &quot;... they both feel the same.&quot;  I'm
</em><br>
<em>&gt; &gt;being an anti-realist about these phrases.  We both get to say them,
</em><br>
<em>&gt; &gt;but we get to say them for different reasons.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, but when I say them I mean what I say, and when you say them
</em><br>
<em>&gt; they are packed  together with a unwieldy bunch of provisos &amp;c. in
</em><br>
<em>&gt; that you should really qualify each statement before using it.
</em><br>
<p>No.  I take the stronger view that my definition is right, and that
<br>
yours is wrong.  It's you, I argue, who should qualify your beliefs
<br>
about feelings to point out that you don't just mean the physical
<br>
stuff, but something MORE.  But until we agree about this, we'll just
<br>
have to interpret what the other says with charity and humanity.
<br>
<p><em>&gt; There is less work for the hypnotist .. but yes, works either case.
</em><br>
<em>&gt; The point I am making is for the primacy of the mental/ conscious.
</em><br>
<em>&gt; If I suggested to you under somnambulistic trance that I was burning
</em><br>
<em>&gt; a cigarette stub on your hand, not only would you experience it,
</em><br>
<em>&gt; but might well manifest burn marks! (See placebo effect argument).
</em><br>
<p>Still, it would all be physical.  Physical words would affect my
<br>
physical brain, which would affect my physical body.
<br>
<p><em>&gt; &gt;I make truth claims because I'm following my intuitions, and my
</em><br>
<em>&gt; &gt;program.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Where is this program located? Or do you just mean cultural
</em><br>
<em>&gt; conditioning and things you have learnt or been told?
</em><br>
<p>In the brain.  It is encoded in the layout of the neurons and their
<br>
connections, just as computer code is encoded in the layout of
<br>
transistors on a chip.  The program is there.  It can be changed
<br>
externally, by culture, experience, etc. but the program is there,
<br>
just as a robot's program is on its hard disk.
<br>
<p><em>&gt; &gt;Do I make justified truth claims?  I think I do, and that
</em><br>
<em>&gt; &gt;has to be pretty much good enough for me.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Are you conscious of making these justified truth claims?
</em><br>
<p>Yes, I'm &quot;conscious&quot; of doing so.
<br>
<p><em>&gt; &gt;Nobody's arguing that nature has actually designed a tape-reader, or
</em><br>
<em>&gt; &gt;that the human brain has any tape.  But nature might be stuck using a
</em><br>
<em>&gt; &gt;million tape-reader-equivalents instead of something better because
</em><br>
<em>&gt; &gt;Turing machine equivalents (the collection of which, in turn, is one
</em><br>
<em>&gt; &gt;big Turing machine equivalent) are all that are physically available.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You are wrong in fact here ... neurons are mini-transputers, more like
</em><br>
<em>&gt; transistors than Turing machine heads. And they flock together to work
</em><br>
<em>&gt; on particular problems. Talk of Turing machines is positively misleading.
</em><br>
<p>Misleading in a description of state, but not at all in description of
<br>
functions, limitations, capacity, etc.
<br>
<p><em>&gt; &gt;Your anti-functionalist view suffers from all the same problems as
</em><br>
<em>&gt; &gt;functionalism; all the same objections.  Maybe it has all the same
</em><br>
<em>&gt; &gt;intuitive support.  Certainly it's worth noting that missing
</em><br>
<em>&gt; &gt;pineal-eye functionality seems to cause positive physical
</em><br>
<em>&gt; &gt;functionality like the kind Putnam was interested in.  That's what led
</em><br>
<em>&gt; &gt;us to conclude that the pineal eye was interesting: missing that
</em><br>
<em>&gt; &gt;physical functionality seemed to grant us another functionality:
</em><br>
<em>&gt; &gt;intelligent behavior.  But we can't really use this as a solution for
</em><br>
<em>&gt; &gt;the mind/body problem, or even as intuitive support for a solution,
</em><br>
<em>&gt; &gt;because you'd just be arguing for functionalism: you'd be using
</em><br>
<em>&gt; &gt;functionalism to argue that you'd solved the mind/body problem.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I accept some of this ... but still feel it is worth exploring which
</em><br>
<em>&gt; types of problems can be cleared up by MVT .. and even if it
</em><br>
<em>&gt; provides a better analogy than existing ones, this is of value. I do
</em><br>
<em>&gt; think it answers the Leibnitz Law objection to Descartes, and on
</em><br>
<em>&gt; this (the original formulation of the mind-body problem) point I do
</em><br>
<em>&gt; think it overcomes Leibnitz objection .... which was that the pineal
</em><br>
<em>&gt; GLAND, or any other physical part of the brain by extension, cannot
</em><br>
<em>&gt; interact with &quot;psychological&quot; events which are not physical.
</em><br>
<p>It only answers Leibnitz as well as functionalism does.  But if you
<br>
understood the objections against functionalism, you'll see that you
<br>
still haven't captured what mental realists want to capture about
<br>
&quot;feelings.&quot;  To have certain physical capacities is not to have a
<br>
feeling.  It's easy to imagine someone with (or without) those
<br>
capacities who has or doesn't have feelings.  They're different in
<br>
definition, in principle.  And you haven't explained the link.
<br>
<p><em>&gt; The abstract, phantom pineal eye is not physical in the same way that
</em><br>
<em>&gt; the pineal gland is physical: thus it could interact ....
</em><br>
<p>Sure, not physical the same way capacities are not physical.  But
<br>
that's not enough.
<br>
<p><em>&gt; &gt;Because the Turing-Church thesis tells us of what we human beings are
</em><br>
<em>&gt; &gt;capable (namely, nothing more than of what a bunch of Turing machines
</em><br>
<em>&gt; &gt;are capable, and therefore nothing more than of what one great big
</em><br>
<em>&gt; &gt;fast Turing machine is capable) and what can possibly act like us.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think you are making an unjustified leap to conclusion here. An
</em><br>
<em>&gt; malefic demon is capable of acting exactly like us, or maybe
</em><br>
<em>&gt; if we had your fairy physics that could explain everything ... but in
</em><br>
<em>&gt; fact what we have are brains that are massively parallel distributed
</em><br>
<em>&gt; systems, and not any of the other things. We have the solution already,
</em><br>
<em>&gt; so why do philosophers continue to look for worse solutions?
</em><br>
<p>The Turing analogy tells us what we can and cannot do.  That's the
<br>
use.  We can't do anything more or less than what one big fast Turing
<br>
machine can do.
<br>
<p><em>&gt; &gt;They WOULD behave the same way, though
</em><br>
<em>&gt; &gt;one would do so much much slower (but that's all).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; NO ... I won't allow this. Turing machines do not reconfigure their
</em><br>
<em>&gt; circuitry, they do not compute in parallel, and I do not think it
</em><br>
<em>&gt; possible for them to be instantiated biologically ...
</em><br>
<p>They can absolutely be instantiated biologically.  A few years ago
<br>
people were toying around with DNA computers that could perform
<br>
Boolean operations encoded in DNA.  The whole thing was DNA only.  The
<br>
tape was there as DNA, the head was there as polymerase, the whole
<br>
deal.  This was literally a biological Turing machine.
<br>
<p>But as for Turing equivalents, computing in parallel is still
<br>
equivalent to a big fast Turing machine (that is, equivalent in the
<br>
way they behave, which is what I said above).  The brain can
<br>
reconfigure some &quot;hardware,&quot; but there is other hardware that the
<br>
brain cannot reconfigure.  That hardware is equivalent to the hardware
<br>
that the Turing machine cannot reconfigure.  Everything the brain can
<br>
reconfigure can be simulated on a big fast Turing machine.
<br>
<p><em>&gt; Furthermore, and the key point, they aren't CONSCIOUS but
</em><br>
<em>&gt; we are ... our neural wetware is capable of manifesting non-physical
</em><br>
<em>&gt; components and the associated phantom illusions ... do you claim
</em><br>
<em>&gt; that Turing machines could have, then lose but remember, a pineal
</em><br>
<em>&gt; eye (or any other body part come to that). I think not.
</em><br>
<p>When we design a functional human-equivalent AI, it will obviously be
<br>
a Turing equivalent.  Will you be in the camp of philosophers who will
<br>
insist that it still cannot be conscious?
<br>
<p>-Dan
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-unless you love someone-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;-nothing else makes any sense-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.e. cummings
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0142.html">Michael S. Lorrey: "Re: CULTURE: Interesting Chicago Statistics"</a>
<li><strong>Previous message:</strong> <a href="0140.html">Emlyn: "Re: Thanks all (was Re: bacteria question)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0211.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0211.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Reply:</strong> <a href="0268.html">J. R. Molloy: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0323.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="0534.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="1045.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<li><strong>Maybe reply:</strong> <a href="1224.html">Steve Nichols: "Re: Placebo effect not physical"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#141">[ date ]</a>
<a href="index.html#141">[ thread ]</a>
<a href="subject.html#141">[ subject ]</a>
<a href="author.html#141">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:16 MDT</em>
</em>
</small>
</body>
</html>
