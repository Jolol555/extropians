<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Singularity optimization [Was: Colossus and the</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Singularity optimization [Was: Colossus and the Singularity]">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Singularity optimization [Was: Colossus and the Singularity]</h1>
<!-- received="Sat Jan 27 11:43:52 2001" -->
<!-- isoreceived="20010127184352" -->
<!-- sent="Sat, 27 Jan 2001 13:43:15 -0500" -->
<!-- isosent="20010127184315" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity optimization [Was: Colossus and the Singularity]" -->
<!-- id="3A7316C3.3189DB12@pobox.com" -->
<!-- inreplyto="b49wvbg513g.fsf_-_@sans04.nada.kth.se" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Singularity%20optimization%20[Was:%20Colossus%20and%20the%20Singularity]&In-Reply-To=&lt;3A7316C3.3189DB12@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 27 2001 - 11:43:15 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2631.html">John Clark: "The Spike"</a>
<li><strong>Previous message:</strong> <a href="2629.html">Michael Lorrey: "Re: Phony deregulation - Fwd: James Bennett's UPI Column for01-26-01"</a>
<li><strong>In reply to:</strong> <a href="2625.html">Anders Sandberg: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2651.html">Damien Broderick: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<li><strong>Reply:</strong> <a href="2651.html">Damien Broderick: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2630">[ date ]</a>
<a href="index.html#2630">[ thread ]</a>
<a href="subject.html#2630">[ subject ]</a>
<a href="author.html#2630">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Anders Sandberg wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; The problem here with the search is that if the current program is P
</em><br>
<em>&gt; (which maps integers to candidate new programs which are then
</em><br>
<em>&gt; evaluated), the empirical search process is of the form Pnew =
</em><br>
<em>&gt; argmax_i V(P(i)) where V is the estimated value of solution
</em><br>
<em>&gt; P(i). Hill-climbing can be seen as having programs that generate
</em><br>
<em>&gt; programs similar to themselves, genetic algorithms would have
</em><br>
<em>&gt; 'programs' P that are really populations of programs and the deductive
</em><br>
<em>&gt; 'rationalist' approach would be a program that generates a single
</em><br>
<em>&gt; successor that has a higher V than itself. Now, where does this search
</em><br>
<em>&gt; end up? In the general case the landscape will not be amenable to
</em><br>
<em>&gt; *efficient* optimization at all (due to the TANSTAAFL theorems) - any
</em><br>
<em>&gt; initial program in the set of all seed programs will statistically do
</em><br>
<em>&gt; just as well as any other. This is simply because most optimization
</em><br>
<em>&gt; landscapes are completely random.
</em><br>
<p>&quot;Any form of cognition which is mathematically formalizable or has a
<br>
provably correct implementation is too simple to contribute materially to
<br>
intelligence.&quot;
<br>
<p>It's interesting that the people who try to visualize the process
<br>
mathematically are the ones who are most likely to deny the &quot;hard takeoff&quot;
<br>
scenario.  I myself have always believed that if you can't solve the
<br>
three-body problem for gravitation, you sure as heck can't solve the
<br>
trillion-transistor problem for intelligence.  The process you describe
<br>
bears no recognizable resemblance to the way that I, a general
<br>
intelligence, write code.
<br>
<p>In the &quot;general case&quot;, the landscape is not subject to optimization. 
<br>
Intelligence is an evolutionary advantage because it enables the organism
<br>
to model, predict, and manipulate regularities in reality.  In a
<br>
maximum-entropy Universe, which is what you're talking about, intelligence
<br>
is impossible and so is evolution.  The fitness landscape you're talking
<br>
about, and that the paper you cited is talking about, bears no useful
<br>
resemblance to our own low-entropy reality.
<br>
<p>If you drain out all the interesting complexity of intelligence and
<br>
abstract the scenario to the point that it talks about the space of all
<br>
possible Universes, then I guess a fast Singularity is impossible - as
<br>
impossible as intelligence or evolution, two other cases of directed
<br>
improvement.
<br>
<p>Here in our own world, I find it much easier to visualize concretely the
<br>
effect of a human being capable of reprogramming vis own neurology, or
<br>
switching axons for optical fibers to get a millionfold subjective
<br>
speedup, or an AI developing the visualization process needed to invent
<br>
nanotechnology and moving to a 10^21 ops/sec rod logic.  That's a pretty
<br>
darn fast Singularity, regardless of whether the abstract curve exhibits
<br>
any recognizable mathematical behavior.
<br>
<p>You completely left recursive self-enhancement out of your description of
<br>
the process.  You described a constant (and pretty darn blind-looking)
<br>
function trying to improve a piece of code, rather than a piece of code
<br>
improving itself, or a general intelligence improving vis component
<br>
subprocesses.
<br>
<p>Finally, if the improvement curve is so horribly logarithmic, then why
<br>
didn't the vast majority of BLIND evolution on this planet take place in
<br>
the first million years?  If increasing complexity or increasing
<br>
improvement renders further improvements more difficult to find, then why
<br>
doesn't BLIND evolution show a logarithmic curve?  These mathematical
<br>
theories bear no resemblance to *any* observable reality.
<br>
<p>If BLIND evolution is historically observed to move at a linear or better
<br>
rate, then self-improvement should proceed at an exponential or better
<br>
rate.  Differential equations don't get any simpler than that.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2631.html">John Clark: "The Spike"</a>
<li><strong>Previous message:</strong> <a href="2629.html">Michael Lorrey: "Re: Phony deregulation - Fwd: James Bennett's UPI Column for01-26-01"</a>
<li><strong>In reply to:</strong> <a href="2625.html">Anders Sandberg: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2651.html">Damien Broderick: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<li><strong>Reply:</strong> <a href="2651.html">Damien Broderick: "Re: Singularity optimization [Was: Colossus and the Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2630">[ date ]</a>
<a href="index.html#2630">[ thread ]</a>
<a href="subject.html#2630">[ subject ]</a>
<a href="author.html#2630">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:25 MDT</em>
</em>
</small>
</body>
</html>
