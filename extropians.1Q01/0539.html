<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Will we be viped out by SI? WAS: RE: CULTURE: C</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ...">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ...</h1>
<!-- received="Sun Jan  7 10:46:26 2001" -->
<!-- isoreceived="20010107174626" -->
<!-- sent="Sun, 7 Jan 2001 09:47:36 -0800" -->
<!-- isosent="20010107174736" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..." -->
<!-- id="147f01c078d1$edeffd40$39bc473f@jrmolloy" -->
<!-- inreplyto="3A588E67.79697E84@lrz.uni-muenchen.de" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Will%20we%20be%20viped%20out%20by%20SI?%20WAS:%20RE:%20CULTURE:%20Chicago%20Tribune%20...&In-Reply-To=&lt;147f01c078d1$edeffd40$39bc473f@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Sun Jan 07 2001 - 10:47:36 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0540.html">Harvey Newstrom: "RE: Extremism"</a>
<li><strong>Previous message:</strong> <a href="0538.html">Barbara Lamar: "Compatibility"</a>
<li><strong>In reply to:</strong> <a href="0528.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0588.html">Eliezer S. Yudkowsky: "AI: The generic conversation (was: Will we be viped out by SI?)"</a>
<li><strong>Reply:</strong> <a href="0588.html">Eliezer S. Yudkowsky: "AI: The generic conversation (was: Will we be viped out by SI?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#539">[ date ]</a>
<a href="index.html#539">[ thread ]</a>
<a href="subject.html#539">[ subject ]</a>
<a href="author.html#539">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
From: &lt;<a href="mailto:Eugene.Leitl@lrz.uni-muenchen.de?Subject=Re:%20Will%20we%20be%20viped%20out%20by%20SI?%20WAS:%20RE:%20CULTURE:%20Chicago%20Tribune%20...&In-Reply-To=&lt;147f01c078d1$edeffd40$39bc473f@jrmolloy&gt;">Eugene.Leitl@lrz.uni-muenchen.de</a>&gt;
<br>
<em>&gt; &gt; I see no reason why a SI should wipe out humanity.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Strange, I don't see a single reason why it shouldn't. And a lot
</em><br>
<em>&gt; of reasons why it should.
</em><br>
<p>How many is a lot? How about six?
<br>
OK, I'd settle for just three.
<br>
<p>Let's see... psychosis would be one reason. But psychotics don't always
<br>
want to wipe out humanity, and even a psychotic SI could be contained via
<br>
producing multiple SIs, some of which could monitor the others. Or perhaps
<br>
the SI decides that it would be the intelligent thing to do... rather like
<br>
some people who'd like to wipe out the entire family of biting insects
<br>
such as mosquitoes. But during the time it takes to create a working SI,
<br>
more stringent tests than those given to humans could be employed to
<br>
ensure the psychonomic balance of the SI. Or maybe the SI decides that it
<br>
needs all the atoms incorporated in the bodies of humans. So it sets about
<br>
disassembling humanity. That's almost, but not quite as scary as the grey
<br>
goo scenario. Personally, I don't feel so antagonistic or prejudiced
<br>
against alien intelligence that I'd smear it with such intentions even
<br>
before it's born.
<br>
<p>Human nature being what it is, I think it more likely that genetic
<br>
programming experimenters will try to build an SI if it's illegal than if
<br>
building one is actually encouraged. It seems to me the military finds
<br>
AI/SI very attractive, and I've heard that the US Navy has begun a Human
<br>
Brain Project which could readily lead to alien intelligence.
<br>
<p>Why should SI *not* wipe out humanity? Because literally billions of human
<br>
hours will be spent in developing and testing the system, much more
<br>
attention than is given to any ordinary mortal. With so much attention
<br>
directed toward it by so many brains, its mental health would easily
<br>
outdistance that of any human (except for good ol' buddha). At this point
<br>
I'm reminded of the harm &quot;2001, A Space Odyssey&quot; has done to AI research.
<br>
What a preposterous notion that HAL would have a nervous breakdown rather
<br>
than the far less extensively tested crew members of the mission. Human
<br>
error remains the greatest cause of malfunctions in complex systems.
<br>
That's why we use these kinds of machines in the first place. They're more
<br>
reliable than humans.
<br>
<p><em>&gt; And why have I to repeat above arguments, all of time, year after year?
</em><br>
<p>I understand your frustration very well (because you've expressed it very
<br>
clearly.)
<br>
&lt;put a dumb smiley here&gt;
<br>
Let me take this opportunity to offer help and collaboration in putting
<br>
together a paper on this subject that you can upload to the extropy web.
<br>
Why, we can do it online, right here in front of everyone. You can use me
<br>
as a sounding board. How about it? Let's beat this horse to death,
<br>
finally.
<br>
<p>Cheers,
<br>
<p>--J. R.
<br>
<p>PS: I don't think we need to go as far as Jupiter brains and Diaspora and
<br>
so forth. Just a careful explanation of how to go about preventing the
<br>
human race creating Robo sapiens, Mind Children, Artilects, and Spiritual
<br>
Machines, and the reasons for doing so.
<br>
No hurry... we've got until next year, right?
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0540.html">Harvey Newstrom: "RE: Extremism"</a>
<li><strong>Previous message:</strong> <a href="0538.html">Barbara Lamar: "Compatibility"</a>
<li><strong>In reply to:</strong> <a href="0528.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0588.html">Eliezer S. Yudkowsky: "AI: The generic conversation (was: Will we be viped out by SI?)"</a>
<li><strong>Reply:</strong> <a href="0588.html">Eliezer S. Yudkowsky: "AI: The generic conversation (was: Will we be viped out by SI?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#539">[ date ]</a>
<a href="index.html#539">[ thread ]</a>
<a href="subject.html#539">[ subject ]</a>
<a href="author.html#539">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:17 MDT</em>
</em>
</small>
</body>
</html>
