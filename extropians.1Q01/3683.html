<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Six theses on superintelligence</title>
<meta name="Author" content="Ross A. Finlayson (raf@tiki-lounge.com)">
<meta name="Subject" content="Re: Six theses on superintelligence">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Six theses on superintelligence</h1>
<!-- received="Sat Feb 10 17:51:19 2001" -->
<!-- isoreceived="20010211005119" -->
<!-- sent="Sat, 10 Feb 2001 17:50:53 -0800" -->
<!-- isosent="20010211015053" -->
<!-- name="Ross A. Finlayson" -->
<!-- email="raf@tiki-lounge.com" -->
<!-- subject="Re: Six theses on superintelligence" -->
<!-- id="3A85EFFD.D486635C@tiki-lounge.com" -->
<!-- inreplyto="b49itmib573.fsf@sans04.nada.kth.se" -->
<strong>From:</strong> Ross A. Finlayson (<a href="mailto:raf@tiki-lounge.com?Subject=Re:%20Six%20theses%20on%20superintelligence&In-Reply-To=&lt;3A85EFFD.D486635C@tiki-lounge.com&gt;"><em>raf@tiki-lounge.com</em></a>)<br>
<strong>Date:</strong> Sat Feb 10 2001 - 18:50:53 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3684.html">E. Shaun Russell: "Re: Cryonics on ABC World News Tonight"</a>
<li><strong>Previous message:</strong> <a href="3682.html">Spike Jones: "Re: Cryonics on ABC World News Tonight"</a>
<li><strong>In reply to:</strong> <a href="3676.html">Anders Sandberg: "Re: Six theses on superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3727.html">scerir: "Re: Six theses on superintelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3683">[ date ]</a>
<a href="index.html#3683">[ thread ]</a>
<a href="subject.html#3683">[ subject ]</a>
<a href="author.html#3683">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Anders Sandberg wrote:
<br>
<p><em>&gt; &quot;Mitchell Porter&quot; &lt;<a href="mailto:mitchtemporarily@hotmail.com?Subject=Re:%20Six%20theses%20on%20superintelligence&In-Reply-To=&lt;3A85EFFD.D486635C@tiki-lounge.com&gt;">mitchtemporarily@hotmail.com</a>&gt; writes:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Anders said
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt;Why is this isomorphic to Chaitin approximations? I
</em><br>
<em>&gt; &gt; &gt;might have had too
</em><br>
<em>&gt; &gt; &gt;little sleep for the last nights, but it doesn't
</em><br>
<em>&gt; &gt; &gt;seem clear to me.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If you know the halting probability for a Turing
</em><br>
<em>&gt; &gt; machine, you can solve the halting problem for
</em><br>
<em>&gt; &gt; any program on that machine. (&quot;... knowing Omega_N
</em><br>
<em>&gt; &gt; [first N bits of the halting probability] enables
</em><br>
<em>&gt; &gt; one to solve the halting problem for all N-bit
</em><br>
<em>&gt; &gt; programs&quot; --<a href="http://www.cs.umaine.edu/~chaitin/nv.html">http://www.cs.umaine.edu/~chaitin/nv.html</a>)
</em><br>
<em>&gt;
</em><br>
<em>&gt; Aha!
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; The idea is that a superintelligence would have
</em><br>
<em>&gt; &gt; a 'computational core' which spends its time
</em><br>
<em>&gt; &gt; approximating Omega, and modules which take general
</em><br>
<em>&gt; &gt; problems, encode them as halting problems, and look
</em><br>
<em>&gt; &gt; them up in Approximate Omega.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ah, that's where the rub is: how do you convert a general problem into
</em><br>
<em>&gt; a halting problem in an efficient way? For example, how does &quot;What
</em><br>
<em>&gt; actions will give me the largest probability of having more than one
</em><br>
<em>&gt; million dollars within ten years?&quot; or &quot;How do I build a
</em><br>
<em>&gt; nanoassembler?&quot; convert into halting problems?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would guess that the sum of work often remains constant in the
</em><br>
<em>&gt; general case: the amount of work needed to encode a problem into a
</em><br>
<em>&gt; form solvable by an algorithm and the amount of work in using the
</em><br>
<em>&gt; algorithm tend to be fairly constant. Intelligence is about finding
</em><br>
<em>&gt; ways of getting around this by exploiting patterns that make the
</em><br>
<em>&gt; problem non-general, such as in mathematical tricks where a simple
</em><br>
<em>&gt; transformation makes a hard problem simple.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt;I'm not as certain as you are that there exists an
</em><br>
<em>&gt; &gt; &gt;unique optimal
</em><br>
<em>&gt; &gt; &gt;strategy. Without working within a certain problem
</em><br>
<em>&gt; &gt; &gt;domain the no free
</em><br>
<em>&gt; &gt; &gt;lunch theorems get you. Taking the problem domain to
</em><br>
<em>&gt; &gt; &gt;be 'the entire
</em><br>
<em>&gt; &gt; &gt;physical universe' doesn't really help, since you
</em><br>
<em>&gt; &gt; &gt;also have to include
</em><br>
<em>&gt; &gt; &gt;the probability distribution of the environment, and
</em><br>
<em>&gt; &gt; &gt;this will be very
</em><br>
<em>&gt; &gt; &gt;dependent not just on the interests but also actions
</em><br>
<em>&gt; &gt; &gt;of the being.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I think approximating Omega is precisely the sort of
</em><br>
<em>&gt; &gt; task where a no-free-lunch theorem is likely to apply.
</em><br>
<em>&gt; &gt; The optimal strategy probably involves nothing more
</em><br>
<em>&gt; &gt; intelligent than simulating all possible programs, and
</em><br>
<em>&gt; &gt; incrementing Approximate Omega appropriately when one
</em><br>
<em>&gt; &gt; is seen to terminate. The no-free-lunch theorem might
</em><br>
<em>&gt; &gt; be: even if you have an approximation strategy which
</em><br>
<em>&gt; &gt; outperforms blind simulation in calculating some finite
</em><br>
<em>&gt; &gt; number of Omega bits, its asymptotic performance can't
</em><br>
<em>&gt; &gt; beat blind simulation.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Sounds possible.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt;What if this strategy is hard to compute
</em><br>
<em>&gt; &gt; &gt;efficiently, and different
</em><br>
<em>&gt; &gt; &gt;choices in initial conditions will produce
</em><br>
<em>&gt; &gt; &gt;noticeable differences in
</em><br>
<em>&gt; &gt; &gt;performance?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If the No-Free-Omega Hypothesis :) is correct, then
</em><br>
<em>&gt; &gt; such differences in performance will disappear
</em><br>
<em>&gt; &gt; asymptotically (assuming hardware equality, and assuming
</em><br>
<em>&gt; &gt; no-one pursues a *sub*optimal strategy).
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ah, egalitarian transcendence! I wonder what we libertarians on the
</em><br>
<em>&gt; list should make of it :-)
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt;Some goals are not much helped by intelligence
</em><br>
<em>&gt; &gt; &gt;beyond a certain level
</em><br>
<em>&gt; &gt; &gt;(like, say, gardening), so the self-enhancement
</em><br>
<em>&gt; &gt; &gt;process would peter
</em><br>
<em>&gt; &gt; &gt;out before it reached any strong limits.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Only if self-enhancement was strictly a subgoal of
</em><br>
<em>&gt; &gt; the gardening goal. But perhaps this is more precise:
</em><br>
<em>&gt; &gt; self-enhancement will not be hindered if it is a
</em><br>
<em>&gt; &gt; subgoal of an open-ended goal, or a co-goal of just
</em><br>
<em>&gt; &gt; about anything.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Beings with closed goals will eventually run out of expansion, I
</em><br>
<em>&gt; think. Only beings with open-ended goals will be motivated to grow and
</em><br>
<em>&gt; persist indefinitely. Playing Carse's &quot;infinite games&quot; might be a
</em><br>
<em>&gt; survival trait for posthumans.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; (Okay, that's a retreat from 'You don't have to do
</em><br>
<em>&gt; &gt; anything *but* approximate Omega!' But this is what
</em><br>
<em>&gt; &gt; I want a general theory of self-enhancement to tell me -
</em><br>
<em>&gt; &gt; in what sort of environments will you *always* need
</em><br>
<em>&gt; &gt; domain-specific modules that do something more than
</em><br>
<em>&gt; &gt; consult the Omega module? Maybe this will even prove
</em><br>
<em>&gt; &gt; to be true in the majority of environments.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; A very interesting question. I'll have to think hard on that one, it
</em><br>
<em>&gt; seems to relate to some of my own issues with how to set learning
</em><br>
<em>&gt; parameters dependent on the information learned from the environment.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; -----------------------------------------------------------------------
</em><br>
<em>&gt; Anders Sandberg                                      Towards Ascension!
</em><br>
<em>&gt; <a href="mailto:asa@nada.kth.se?Subject=Re:%20Six%20theses%20on%20superintelligence&In-Reply-To=&lt;3A85EFFD.D486635C@tiki-lounge.com&gt;">asa@nada.kth.se</a>                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
</em><br>
<em>&gt; GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</em><br>
<p>I was thinking about it, and having hundreds of thousands of free
<br>
processors waiting for you to cast them a thread, in a physical computer
<br>
of the future.  The processors are very fast.
<br>
<p>Ross
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3684.html">E. Shaun Russell: "Re: Cryonics on ABC World News Tonight"</a>
<li><strong>Previous message:</strong> <a href="3682.html">Spike Jones: "Re: Cryonics on ABC World News Tonight"</a>
<li><strong>In reply to:</strong> <a href="3676.html">Anders Sandberg: "Re: Six theses on superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3727.html">scerir: "Re: Six theses on superintelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3683">[ date ]</a>
<a href="index.html#3683">[ thread ]</a>
<a href="subject.html#3683">[ subject ]</a>
<a href="author.html#3683">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:38 MDT</em>
</em>
</small>
</body>
</html>
