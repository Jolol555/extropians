<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: CULTURE: Chicago Tribune on Futurists (Includes</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: CULTURE: Chicago Tribune on Futurists (Includes Extropians)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: CULTURE: Chicago Tribune on Futurists (Includes Extropians)</h1>
<!-- received="Sun Jan  7 04:14:06 2001" -->
<!-- isoreceived="20010107111406" -->
<!-- sent="Sun, 7 Jan 2001 03:15:13 -0800" -->
<!-- isosent="20010107111513" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: CULTURE: Chicago Tribune on Futurists (Includes Extropians)" -->
<!-- id="0d2701c0789b$20122d20$39bc473f@jrmolloy" -->
<!-- inreplyto="3A569F5A.6BB2EE0A@attglobal.net" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20CULTURE:%20Chicago%20Tribune%20on%20Futurists%20(Includes%20Extropians)&In-Reply-To=&lt;0d2701c0789b$20122d20$39bc473f@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Sun Jan 07 2001 - 04:15:13 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0510.html">CYMM: "2001 ...A CR Odyssey"</a>
<li><strong>Previous message:</strong> <a href="0508.html">Joe Dees: "RE: Extremism"</a>
<li><strong>In reply to:</strong> <a href="0357.html">Spike Jones: "Re: CULTURE: Chicago Tribune on Futurists (Includes Extropians)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0516.html">Max M: "Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<li><strong>Reply:</strong> <a href="0516.html">Max M: "Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#509">[ date ]</a>
<a href="index.html#509">[ thread ]</a>
<a href="subject.html#509">[ subject ]</a>
<a href="author.html#509">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
From: &quot;Spike Jones&quot; &lt;<a href="mailto:spike66@attglobal.net?Subject=Re:%20CULTURE:%20Chicago%20Tribune%20on%20Futurists%20(Includes%20Extropians)&In-Reply-To=&lt;0d2701c0789b$20122d20$39bc473f@jrmolloy&gt;">spike66@attglobal.net</a>&gt;
<br>
<em>&gt; My reasoning goes thus: since silicon based intelligence and carbon
</em><br>
<em>&gt; based intelligence have different diets and different habitats.  I have
</em><br>
<em>&gt; a notion that emotion is seated in intelligence.  Super intelligence
</em><br>
<em>&gt; then means super emotions, and so... I hope this is how it works...
</em><br>
<em>&gt; a super AI would love us.  It (or they) would see how it (or they)
</em><br>
<em>&gt; and humans could work together, help each other, etc.  There
</em><br>
<em>&gt; is no reason why we and Si-AI should be enemies, since we
</em><br>
<em>&gt; can coexist.
</em><br>
<p>I agree. This seems to be a perennial topic central to extropy. The
<br>
subject has come up several times in the last few years, and I've
<br>
commented that the most compassionate and trustworthy people that I've
<br>
known were also the most intelligent.
<br>
Of course SI is all hypothetical stuff, but what the hell, let's talk
<br>
about it anyway.
<br>
I think alien intelligence (I prefer that term to artificial intelligence
<br>
because it's *all* artificial once you send children to school) will
<br>
become human-competitive in a few more years. Genetic programming has
<br>
already yielded patentable solutions to problems, solutions which humans
<br>
failed to produce. So, alien intelligence, as manifested in Artilects,
<br>
Robo sapiens, Mind Children, or Spiritual Machines, may (no, shall) evolve
<br>
to SI soon after becoming 100% human-competitive.
<br>
<p>Since intelligence means the ability to solve problems, an SI would be a
<br>
super problem solver (SPS), and therefore, if it was real, it wouldn't
<br>
pose a problem; on the contrary it would solve the problem. Want to know
<br>
how to deal with accelerating technological progress? Ask the super
<br>
problem solver.
<br>
<p><em>&gt; Another angle is this: a more advanced civilization has the luxury
</em><br>
<em>&gt; of trying to protect and preserve wildlife.  The western world
</em><br>
<em>&gt; does this.  Those societies where people are starving have little
</em><br>
<em>&gt; regard for preserving wildlife, eh?  So the AI would be a very
</em><br>
<em>&gt; advanced civilization, and we would be the wildlife.  Temporarily
</em><br>
<em>&gt; that is, until we merge with the AI.
</em><br>
<p>Well, let's pursue this a bit further. An alien intelligence (or SPS)
<br>
would look upon Homo sapiens in ways unimaginable to us, not just with a
<br>
view to preservation. In addition, advanced extraterrestrial alien life
<br>
forms have been there, done that. The fact that Homo sapiens have been
<br>
permitted (by superior ET intelligence) to flourish on Earth provides
<br>
evidence that alien intelligence does not threaten human life.
<br>
<p>Incidentally, in regard to the &quot;paradox&quot; about where all the ETs are, I
<br>
think such information would be extremely important and valuable. So, why
<br>
would they tell us about it? I mean, information that crucial doesn't need
<br>
to be shared with mere humans. Pearls before swine, and all that.
<br>
<p><em>&gt; Of course this analysis could be wrong, we just dont know what
</em><br>
<em>&gt; will happen.  On the other hand, we *do* know exactly what
</em><br>
<em>&gt; will happen if we fail to develop nanotech and/or AI.  spike
</em><br>
<p>Right, developing alien intelligence is by far the lessor evil.
<br>
<p>From: &lt;<a href="mailto:Eugene.Leitl@lrz.uni-muenchen.de?Subject=Re:%20CULTURE:%20Chicago%20Tribune%20on%20Futurists%20(Includes%20Extropians)&In-Reply-To=&lt;0d2701c0789b$20122d20$39bc473f@jrmolloy&gt;">Eugene.Leitl@lrz.uni-muenchen.de</a>&gt;
<br>
<em>&gt; There is no silicon based intelligence now, I doubt there will ever
</em><br>
<em>&gt; be. Silicon doesn't do intricate stable 3d structures very well, so
</em><br>
<em>&gt; it probably has to be carbon
</em><br>
<p>Good point. That's why I think alien intelligence will come from organic
<br>
(biological) genetic programming. Why build something when you can simply
<br>
grow it?
<br>
<p><em>&gt; You can't build a super AI, no one is that smart. You can only create
</em><br>
<em>&gt; a seed AI, an AI child, if you wish. If you make it basically human,
</em><br>
<em>&gt; by looking which structures are created during neuromorphogenesis and
</em><br>
<em>&gt; replicate their functions, and rear the AI child amongst the humans,
</em><br>
<em>&gt; it will have similiar emotions. Initially. (Unless you broke something,
</em><br>
<em>&gt; and raised a psychopathic AI without knowing it).
</em><br>
<p>I think the psychosis resides mostly in the human brain which has a phobia
<br>
about AI.
<br>
<p><em>&gt; No sir, superintelligence is something qualitatively different.
</em><br>
<em>&gt; The positive autofeedback runaway which you cannot follow soon
</em><br>
<em>&gt; confronts you with something incomprehensible. A supernatural
</em><br>
<em>&gt; force of nature, if you so wish.
</em><br>
<p>Because &quot;super&quot; signifies a quantitative difference, not a qualitative
<br>
difference, it makes sense to think of superintelligence as something
<br>
quantitatively different from human intelligence. If it's qualitatively
<br>
different, then you should call it something other than intelligence, or
<br>
at least qualify if as such. A supernatural force of nature that solves
<br>
problems sounds like a very friendly entity to me.
<br>
<p><em>&gt; Thank you, but the wildlife is dying just fine, despite the protection.
</em><br>
<p>Right, and Homo sapiens may be killing itself, despite the best efforts of
<br>
alien intelligence (which may supercede human life).
<br>
<p><em>&gt; So let's merge with the ants, and the nematodes, and the gastropods.
</em><br>
<p>It's not so much that we merge with the ants and so forth... but notice
<br>
that they have merged with us: we have dogs, cats, parrots, etc., for
<br>
pets; we have horses, cattle, sheep, etc., as farm animals; we have
<br>
cockroaches, ants, dustmites, etc., as parasitic fellow travelers.
<br>
Symbiosis prevails on Earth as it probably does throughout the universe.
<br>
<p><em>&gt; Yes, lowtech scenarios are more easily understandable, and none
</em><br>
<em>&gt; of them look very pretty nor sustainable.
</em><br>
<p>Nor do lowtech scenarios include the GNR that preoccupies Futurists and
<br>
provokes Bill Joy to advocate his particular brand of relinquishment.
<br>
<p>Stay hungry,
<br>
<p>--J. R.
<br>
3M TA3
<br>
<p>=====================
<br>
Useless hypotheses: consciousness, phlogiston, philosophy, vitalism, mind,
<br>
free will
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0510.html">CYMM: "2001 ...A CR Odyssey"</a>
<li><strong>Previous message:</strong> <a href="0508.html">Joe Dees: "RE: Extremism"</a>
<li><strong>In reply to:</strong> <a href="0357.html">Spike Jones: "Re: CULTURE: Chicago Tribune on Futurists (Includes Extropians)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0516.html">Max M: "Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<li><strong>Reply:</strong> <a href="0516.html">Max M: "Will we be viped out by SI? WAS: RE: CULTURE: Chicago Tribune ..."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#509">[ date ]</a>
<a href="index.html#509">[ thread ]</a>
<a href="subject.html#509">[ subject ]</a>
<a href="author.html#509">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:17 MDT</em>
</em>
</small>
</body>
</html>
