<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: more on Brand and the Singularity idea</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: more on Brand and the Singularity idea">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: more on Brand and the Singularity idea</h1>
<!-- received="Wed Jan 17 01:37:03 2001" -->
<!-- isoreceived="20010117083703" -->
<!-- sent="Wed, 17 Jan 2001 00:36:37 -0800" -->
<!-- isosent="20010117083637" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: more on Brand and the Singularity idea" -->
<!-- id="3A655995.BDA302D1@objectent.com" -->
<!-- inreplyto="3A6440CF.6AD13F55@home.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20more%20on%20Brand%20and%20the%20Singularity%20idea&In-Reply-To=&lt;3A655995.BDA302D1@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Wed Jan 17 2001 - 01:36:37 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1462.html">Samantha Atkins: "Re: PREFIX: More Suggested Prefixes"</a>
<li><strong>Previous message:</strong> <a href="1460.html">Samantha Atkins: "Re: Immortality decay (was Re: Stewart Brand's The Clock of the Long  Now)"</a>
<li><strong>In reply to:</strong> <a href="1373.html">Jim Fehlinger: "Re: more on Brand and the Singularity idea"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1347.html">Emlyn: "Optimism, was Re: more on Brand and the Singularity idea"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1461">[ date ]</a>
<a href="index.html#1461">[ thread ]</a>
<a href="subject.html#1461">[ subject ]</a>
<a href="author.html#1461">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Jim Fehlinger wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Charlie Stross wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I'm just saying that new technologies have side-effects, sometimes disastrous
</em><br>
<em>&gt; &gt; ones, and insisting that their deployment is *always* beneficial isn't going
</em><br>
<em>&gt; &gt; to fool anyone (and is going to make us look like idiots).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Also, effects that some folks on this list can contemplate with
</em><br>
<em>&gt; equanimity
</em><br>
<em>&gt; are events that would horrify many people outside of extreme
</em><br>
<em>&gt; sci-fi/technophilic
</em><br>
<em>&gt; circles.  For example, Eliezer Yudkowsky has said on many occasions
</em><br>
<em>&gt; that,
</em><br>
<em>&gt; as long as the human race survives long enough to give birth to some
</em><br>
<em>&gt; sort
</em><br>
<em>&gt; of superintelligence, the ultimate fate of humanity is of no consequence
</em><br>
<em>&gt; (to him or, presumably, in the ultimate scheme of things).  I suspect
</em><br>
<em>&gt; that this
</em><br>
<em>&gt; attitude is part of what gives folks like Bill Joy the willies.
</em><br>
<p>Actually, Bill Joy gets the willies considering that some of this tech
<br>
in the hands of we mortals is at least as likely to get us all killed as
<br>
it is to lead to a transcendent species.
<br>
<p>If I am going to leave this mortal coil I would rather leave it to
<br>
transhumans (better yet become one) than to gray goo.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; When I heard Ray Kurzweil speak at the PC Expo last summer, he showed
</em><br>
<em>&gt; transparencies
</em><br>
<em>&gt; of various graphs he had prepared of historical data, which he claimed
</em><br>
<em>&gt; showed
</em><br>
<em>&gt; that progress on various fronts is exponential.  One of these graphs was
</em><br>
<em>&gt; of
</em><br>
<em>&gt; economic data, in which (as Kurzweil pointed out) the Great Depression
</em><br>
<em>&gt; was
</em><br>
<em>&gt; a visible glitch, but one which was more than made up for by the surge
</em><br>
<em>&gt; in
</em><br>
<em>&gt; economic growth which took place after its end.  It crossed my mind then
</em><br>
<em>&gt; that,
</em><br>
<em>&gt; if the evolution of post-human intelligence involves the extermination
</em><br>
<em>&gt; of most
</em><br>
<em>&gt; or all of the human race (as in the scenarios of Hugo de Garis or Kevin
</em><br>
<em>&gt; Warwick),
</em><br>
<em>&gt; a retrospective Kurzweil graph of the event might still show it as a
</em><br>
<em>&gt; barely-visible
</em><br>
<em>&gt; glitch in the exponential curve -- if the Singularitarians are right,
</em><br>
<em>&gt; the
</em><br>
<em>&gt; sheer computational capacity of the entities swarming through the solar
</em><br>
<em>&gt; system
</em><br>
<em>&gt; a few years after the extinction of humanity might be such that to them,
</em><br>
<em>&gt; the
</em><br>
<em>&gt; loss of several billion human brains' worth of processing capacity might
</em><br>
<em>&gt; be no
</em><br>
<em>&gt; more than the ongoing quota of traffic fatalities that the human race
</em><br>
<em>&gt; (or the
</em><br>
<em>&gt; industrialized part of it) is willing to bear as the price of having
</em><br>
<em>&gt; cars.  Or maybe
</em><br>
<em>&gt; even less -- no more than the unnoticed and unmourned loss of a few
</em><br>
<em>&gt; cells from an
</em><br>
<em>&gt; individual human being.
</em><br>
<p>It is possible but I rather doubt it.  For one thing, there is no simple
<br>
way to get to the place where the non-humans (not trans-humans) are
<br>
superior to us in all ways and no longer need humans at all.  For
<br>
another I would bet that diversity has some value especially when
<br>
diverse groups are not competing as directly for precisely the same
<br>
resources.  
<br>
<p>My own grounding is in expanding the capacities of humankind endlessly
<br>
(including changing what is and is not thought of as human) , not of
<br>
wiping humanity out as a useless bridge to something better.   But I
<br>
cannot logically preclude that some sentients will not be inclined to
<br>
tolerate the existence of &quot;mere humans&quot; indefinitely.  Humans that do
<br>
not wish to transcend their &quot;natural&quot; state might be especially
<br>
problematic if they also wish to stop others from seeking trancendence
<br>
or if they will insist on being singularly miserable mischief makers if
<br>
they find themselves even knowing of such beings.  At some point their
<br>
rantings will simply and safely be ignored, although they will certainly
<br>
not like this outcome and will feel terribly and even murderously
<br>
aggrieved.  Sometimes I think the nearest you could come to keeping the
<br>
peace and making everyone reasonably happy is to upload them into a VR
<br>
meeting their specifications until they decide they want to try
<br>
something different.  &lt;sigh&gt;  
<br>
<p>- samantha
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt;From an individual's perspective, the Great Depression was a period of
</em><br>
<em>&gt; almost unimaginable suffering, as would de Garis' Cosmist-vs-Terran
</em><br>
<em>&gt; war (either between pro- and anti-AI humans, or between humans and AIs).
</em><br>
<em>&gt; Many mainstream people would say that anybody who can contemplate such
</em><br>
<em>&gt; an
</em><br>
<em>&gt; event with detachment must be a bit of a monster.  Be that as it may,
</em><br>
<em>&gt; it may prove to be an unbridgeable gulf between Singularitarians
</em><br>
<em>&gt; and the rest of humanity (even technologically sophisticated folks like
</em><br>
<em>&gt; Bill
</em><br>
<em>&gt; Joy), if the former are seen as taking a cold-blooded,
</em><br>
<em>&gt; &quot;che sera, sera&quot; attitude toward the possibility of the extinction of
</em><br>
<em>&gt; the
</em><br>
<em>&gt; human race.  I think the motives of enthusiastic Singularitarians are
</em><br>
<em>&gt; always going to be mistrusted by the mainstream, and Extropians and
</em><br>
<em>&gt; Singularitarians are likely to continue to be portrayed by journalists
</em><br>
<em>&gt; and
</em><br>
<em>&gt; authors as they are, for instance, in Ken Macleod's _The Cassini
</em><br>
<em>&gt; Division_.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Jim F.
</em><br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1462.html">Samantha Atkins: "Re: PREFIX: More Suggested Prefixes"</a>
<li><strong>Previous message:</strong> <a href="1460.html">Samantha Atkins: "Re: Immortality decay (was Re: Stewart Brand's The Clock of the Long  Now)"</a>
<li><strong>In reply to:</strong> <a href="1373.html">Jim Fehlinger: "Re: more on Brand and the Singularity idea"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1347.html">Emlyn: "Optimism, was Re: more on Brand and the Singularity idea"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1461">[ date ]</a>
<a href="index.html#1461">[ thread ]</a>
<a href="subject.html#1461">[ subject ]</a>
<a href="author.html#1461">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:20 MDT</em>
</em>
</small>
</body>
</html>
