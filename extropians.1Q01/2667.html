<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Singularity optimization [Was: Colossus and the</title>
<meta name="Author" content="Anders Sandberg (asa@nada.kth.se)">
<meta name="Subject" content="Re: Singularity optimization [Was: Colossus and the Singularity]">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Singularity optimization [Was: Colossus and the Singularity]</h1>
<!-- received="Sun Jan 28 09:04:53 2001" -->
<!-- isoreceived="20010128160453" -->
<!-- sent="28 Jan 2001 17:04:50 +0100" -->
<!-- isosent="20010128160450" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Singularity optimization [Was: Colossus and the Singularity]" -->
<!-- id="b49snm3fysd.fsf@sans04.nada.kth.se" -->
<!-- inreplyto="Sat, 27 Jan 2001 19:19:22 -0500&quot;" -->
<strong>From:</strong> Anders Sandberg (<a href="mailto:asa@nada.kth.se?Subject=Re:%20Singularity%20optimization%20[Was:%20Colossus%20and%20the%20Singularity]&In-Reply-To=&lt;b49snm3fysd.fsf@sans04.nada.kth.se&gt;"><em>asa@nada.kth.se</em></a>)<br>
<strong>Date:</strong> Sun Jan 28 2001 - 09:04:50 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2668.html">Eliezer S. Yudkowsky: "Re: selling an idea"</a>
<li><strong>Previous message:</strong> <a href="2666.html">Michael B. Hubbard: "Re: selling an idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2667">[ date ]</a>
<a href="index.html#2667">[ thread ]</a>
<a href="subject.html#2667">[ subject ]</a>
<a href="author.html#2667">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20Singularity%20optimization%20[Was:%20Colossus%20and%20the%20Singularity]&In-Reply-To=&lt;b49snm3fysd.fsf@sans04.nada.kth.se&gt;">sentience@pobox.com</a>&gt; writes:
<br>
<p><em>&gt; Anders Sandberg wrote:
</em><br>
<em>&gt; &gt; True. My point is that if you want to build something that functions
</em><br>
<em>&gt; &gt; in the real low-entropy world, then you have a good chance. But if it
</em><br>
<em>&gt; &gt; is only going on inside the high-entropy world of algorithms then you
</em><br>
<em>&gt; &gt; will likely not get any good results. This is why I consider
</em><br>
<em>&gt; &gt; &quot;transcendence in a box&quot; scenarios so misleading. Having stuff
</em><br>
<em>&gt; &gt; transcend in the real world is another matter - but here we also get
</em><br>
<em>&gt; &gt; more slow interactions as a limiting factor.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Okay, I don't understand this at all.  I don't understand why you think
</em><br>
<em>&gt; that there's higher entropy inside the box than outside the box.  The box
</em><br>
<em>&gt; is a part of our Universe, isn't it?  And one that's built by highly
</em><br>
<em>&gt; unentropic programmers and sealed away from thermodynamics by a layer of
</em><br>
<em>&gt; abstraction.
</em><br>
<p>One of the odd things about algorithmic complexity is that a very
<br>
complex (or more properly, random) pattern can be a part of a very
<br>
simple pattern. The whole set of natural numbers has a very low
<br>
complexity, it can easily be generated using a simple program, but the
<br>
majority of numbers are complex - you need a program almost as long as
<br>
the number to generate it. 
<br>
<p>The universe encompasses a lot of environments of different entropy,
<br>
some very regular, some very chaotic. On the whole, I guess it is
<br>
fairly simple but that simplicity doesn't help much since it is likely
<br>
a simplicity on the level of fundamental physics. All the contingent
<br>
and emergent stuff that is going on has a higher level of complexity,
<br>
and pose challenges for intelligent systems. In particular, while the
<br>
code in a computer may be implemented on a very clean system the space
<br>
of possible programs is definitely an example of a high entropy
<br>
environment. It is a complex system on top of a simple one, and likely
<br>
hard to learn. 
<br>
<p>As I mentioned in my previous post, human programmers of course deal
<br>
with this by writing redundant, simple code keeping to the more
<br>
well-behaved subspaces of programming. Very few venture out into the
<br>
rest (the obfuscated code contensts sometimes show how &quot;generic&quot; code
<br>
likely looks). I guess you can do the same with your AI (I don't see
<br>
any alternative), but it will then be limited by what can be expressed
<br>
simply. 
<br>
<p><em>&gt; &gt; Hmm, my description may not have been clear enough then. What I was
</em><br>
<em>&gt; &gt; looking at was a sequence where program P_n searches for a replacement
</em><br>
<em>&gt; &gt; program P_{n+1}.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yep, and it's possible to say all kinds of reasonable things about P_x
</em><br>
<em>&gt; searching for P_y that suddenly become absurd if you imagine a specific
</em><br>
<em>&gt; uploaded human pouring on the neurons or a seed AI transferring itself
</em><br>
<em>&gt; into a rod logic.  Does it even matter where the curve tops out, or
</em><br>
<em>&gt; whether it tops out at all, when there are all these enormous improvements
</em><br>
<em>&gt; dangling *just* out of reach?  The improvements we *already know* how to
</em><br>
<em>&gt; make are more than enough to qualify for a Singularity.
</em><br>
<p>Exactly which improbements are dangling just out of reach? I disagree
<br>
with you that we would get a Singularity with capital 'S' from
<br>
improvements we currently know. Sure, million-fold speedups would make
<br>
a great deal of difference, but I have not seen any evidence that they
<br>
would not be eaten up by software complexity. Just adding neurons to a
<br>
brain doesn't make it smarter at all (just look at the whales), you
<br>
need structure (gained through experience) to get any
<br>
benefit. Currently we have not the faintest idea to do a Vingean
<br>
intelligence amplification - sure, some improvements in memory and
<br>
thinking appear doable given enough technology, but will they really
<br>
provide any qualitative breakthrough?  What is really needed to get an
<br>
intelligence bootstrap going is improvements in the quality of the
<br>
bootstrapping entity. Quantity helps, but an uploaded dog will remain
<br>
a dog even after a billion subjective years.
<br>
<p><em>&gt; &gt; &gt; Finally, if the improvement curve is so horribly logarithmic, then why
</em><br>
<em>&gt; &gt; &gt; didn't the vast majority of BLIND evolution on this planet take place in
</em><br>
<em>&gt; &gt; &gt; the first million years?  If increasing complexity or increasing
</em><br>
<em>&gt; &gt; &gt; improvement renders further improvements more difficult to find, then why
</em><br>
<em>&gt; &gt; &gt; doesn't BLIND evolution show a logarithmic curve?  These mathematical
</em><br>
<em>&gt; &gt; &gt; theories bear no resemblance to *any* observable reality.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; You see it very much in alife simulations. This is why so many people
</em><br>
<em>&gt; &gt; try to find ways of promoting continual evolution in them; the holy
</em><br>
<em>&gt; &gt; grail would be to get some kind of cambrian explosion of
</em><br>
<em>&gt; &gt; complexity.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, and you see it in Eurisko as well.  Where you don't see it is
</em><br>
<em>&gt; real-life evolution, the accumulation of knowledge as a function of
</em><br>
<em>&gt; existing knowledge, human intelligence as a function of time, the progress
</em><br>
<em>&gt; of technology (*not* some specific bright idea, but the succession of
</em><br>
<em>&gt; bright ideas over time), and all the other places where sufficient seed
</em><br>
<em>&gt; complexity exists for open-ended improvement.
</em><br>
<p>I have my serservations against human intelligence as a function of
<br>
time increasing exponentially; the Flynn effect seems to be linear
<br>
which of course is better than logarithmic growth but that could just
<br>
be due to a too short sampling period.
<br>
<p>I think open-ended improvement is possible. We have no disagreements
<br>
there. But I think it is as yet unknown what makes it possible. Here
<br>
is my own theory: the reason human knowledge and culture seems to be
<br>
so steadily and exponentially expanding is that it is a sum of a
<br>
myriad of these small logaithmic or sigmoidal evolutions. The
<br>
occasional breakthrough enables a fast expansion into a new part of
<br>
the space of thought, or even enables it (like writing or the
<br>
computer). But this process is expensive (in time and effort) and it
<br>
takes a lot of diverse approaches to dig up these breakthroughs.
<br>
<p><em>&gt; &gt; The question is how you measure evolutionary improvement. In alife you
</em><br>
<em>&gt; &gt; can just measure fitness. In real life the best thing is to look at
</em><br>
<em>&gt; &gt; the rate of extinction, which could be seen as a measure of the
</em><br>
<em>&gt; &gt; average fitness of entire species. In
</em><br>
<em>&gt; &gt; <a href="http://xxx.lanl.gov/abs/adap-org/9811003">http://xxx.lanl.gov/abs/adap-org/9811003</a> it is mentioned that we see a
</em><br>
<em>&gt; &gt; general decrease in extinction rate in the phanerozoic; it seems to be
</em><br>
<em>&gt; &gt; a 1/t decline according to them.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I looked over this (cool) paper, but it seems a bit suspect when
</em><br>
<em>&gt; considered as a measure of evolutionary improvement rates, given that I've
</em><br>
<em>&gt; yet to hear any argument for functional complexity accumulating at
</em><br>
<em>&gt; inverse-t (*across* successions of punctuated equilibria, not within a
</em><br>
<em>&gt; single equilibrium).  It sure doesn't show up in any graphs of
</em><br>
<em>&gt; progress-with-time that I'm familiar with; those graphs usually resemble
</em><br>
<em>&gt; the more familiar picture where half the total progress happened merely
</em><br>
<em>&gt; within the last century or the last million years or whatever.
</em><br>
<p>Remember that we are looking at a fairly small piece of a much longer
<br>
period. I expect that if you extend it across the entire history of
<br>
life on Earth you would get something like you say. But it could also
<br>
be that its behavior is due to being the sum of many small punctuated
<br>
equilibria.
<br>
<p><em>&gt; I'm sorry, but this still looks to me like the &quot;Each incremental
</em><br>
<em>&gt; improvement in human intelligence required a doubling of brain size&quot;
</em><br>
<em>&gt; argument.
</em><br>
<p>How?
<br>
<p><pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<a href="mailto:asa@nada.kth.se?Subject=Re:%20Singularity%20optimization%20[Was:%20Colossus%20and%20the%20Singularity]&In-Reply-To=&lt;b49snm3fysd.fsf@sans04.nada.kth.se&gt;">asa@nada.kth.se</a>                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2668.html">Eliezer S. Yudkowsky: "Re: selling an idea"</a>
<li><strong>Previous message:</strong> <a href="2666.html">Michael B. Hubbard: "Re: selling an idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2667">[ date ]</a>
<a href="index.html#2667">[ thread ]</a>
<a href="subject.html#2667">[ subject ]</a>
<a href="author.html#2667">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:26 MDT</em>
</em>
</small>
</body>
</html>
