<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Parallel Universes</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Parallel Universes">
<meta name="Date" content="2003-02-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Parallel Universes</h1>
<!-- received="Tue Feb 11 21:13:34 2003" -->
<!-- isoreceived="20030212041334" -->
<!-- sent="Tue, 11 Feb 2003 23:13:32 -0500" -->
<!-- isosent="20030212041332" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Parallel Universes" -->
<!-- id="3E49C9EC.1080701@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20030212030350.GH21708@weidai.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Parallel%20Universes"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Feb 11 2003 - 21:13:32 MST
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2572.html">Damien Broderick: "RE: John Clute's novel APPLESEED: a blooper"</a>
<ul>
<li><strong>Previous message:</strong> <a href="2570.html">Damien Broderick: "John Clute's novel APPLESEED: a review"</a>
<li><strong>In reply to:</strong> <a href="2567.html">Wei Dai: "Re: Parallel Universes"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2583.html">Lee Corbin: "RE: Parallel Universes"</a>
<li><strong>Reply:</strong> <a href="2583.html">Lee Corbin: "RE: Parallel Universes"</a>
<li><strong>Reply:</strong> <a href="2584.html">Wei Dai: "Re: Parallel Universes"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2571">[ date ]</a>
<a href="index.html#2571">[ thread ]</a>
<a href="subject.html#2571">[ subject ]</a>
<a href="author.html#2571">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Wei Dai wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I find it interesting that probabilities must work differently for these
</em><br>
<em>&gt; two types of people. Consider a thought experiment where you're shown a
</em><br>
<em>&gt; computer printout which is supposed to be the millionth bit in the binary
</em><br>
<em>&gt; expansion of pi. However the computer is somewhat faulty and in 1% of the
</em><br>
<em>&gt; branches of the multiverse it gives an incorrect answer. Now you're asked
</em><br>
<em>&gt; to guess the true value of the millionth bit of pi (let's call this X). If
</em><br>
<em>&gt; you guess correctly you'll be rewarded, otherwise punished, with about
</em><br>
<em>&gt; equal severity. Suppose you see the number 0 on your printout, and that
</em><br>
<em>&gt; you don't have any other information about what X is, and you can't
</em><br>
<em>&gt; compute it in your head. Obviously both the egoist-temporalist and the
</em><br>
<em>&gt; altruist-Platonist would choose to guess 0, but their reasoning process
</em><br>
<em>&gt; would be different.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Before seeing the printout, both types believe that the probability of X
</em><br>
<em>&gt; being 0 is .5. After seeing the printout, the egoist-temporalist would
</em><br>
<em>&gt; apply Bayes's rule and think that the probability of X being 0 is .99.  
</em><br>
<em>&gt; He reasons that guessing 0 lead to a .99 probability of reward and .01
</em><br>
<em>&gt; probability of punishment. His expected utility of choosing 0 is 
</em><br>
<em>&gt; .99*U(reward) + .01*U(punishment).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; An altruist-Platonist would instead continue to believe that the
</em><br>
<em>&gt; probability of X being 0 is .5.
</em><br>
<p>No.
<br>
<p><em> &gt; He reasons that if X is 0, then his
</em><br>
<em>&gt; current measure is .99m (where m is the measure of himself before seeing
</em><br>
<em>&gt; the printout), and if X is 1, then his current measure is .01m. So
</em><br>
<em>&gt; guessing 0 would lead to a .5 probability of .99m people being rewarded
</em><br>
<em>&gt; and .5 probability of .01m people being punished. His expected utility of
</em><br>
<em>&gt; choosing 0 is .5*U(.99m people rewarded) + .5*U(.01m people punished).
</em><br>
<em>&gt; Note that if he did apply Bayes's rule, then his expected utility would
</em><br>
<em>&gt; instead become .99*U(.99m people rewarded) + .01*U(.01m people punished)
</em><br>
<em>&gt; which would weight the reward too heavily. It doesn't matter in this case
</em><br>
<em>&gt; but would matter in other situations.
</em><br>
<p>If he chooses to apply Bayes's rule, then his expected *global* utility is 
<br>
p(1)*u(.99m rewarded) + p(1)*u(.01m punished), while his expected *local* 
<br>
utility is p(.99)*(1 rewarded) + p(.01)*(1 punished).  If he sees X=0 
<br>
locally it doesn't change his estimate of the global truth that .99m 
<br>
observers see the true value of X and .01m observers see a false value of 
<br>
X.  Roughly speaking, if a Bayesian altruist-Platonist sees X=0, his 
<br>
expected global utility is:
<br>
<p>p(.99)*u(.99m observers see 0 =&gt; .99m observers choose 0 =&gt; .99m observers 
<br>
are rewarded &amp;&amp; .01m observers see 1 =&gt; .01m observers choose 1 =&gt; .01m 
<br>
observers are punished)
<br>
+
<br>
p(.01)*u(.99m observers see 1 =&gt; .99m observers choose 1 =&gt; .99m observers 
<br>
are rewarded &amp;&amp; .01m observers see 0 =&gt; .01m observers choose 0 =&gt; .01m 
<br>
observers are punished)
<br>
=
<br>
p(1)*u(.99m observers are rewarded &amp;&amp; .01m observers are punished)
<br>
=
<br>
p(1)*u(.99m observers rewarded) + p(1)*u(.01m observers are punished)
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2572.html">Damien Broderick: "RE: John Clute's novel APPLESEED: a blooper"</a>
<li><strong>Previous message:</strong> <a href="2570.html">Damien Broderick: "John Clute's novel APPLESEED: a review"</a>
<li><strong>In reply to:</strong> <a href="2567.html">Wei Dai: "Re: Parallel Universes"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2583.html">Lee Corbin: "RE: Parallel Universes"</a>
<li><strong>Reply:</strong> <a href="2583.html">Lee Corbin: "RE: Parallel Universes"</a>
<li><strong>Reply:</strong> <a href="2584.html">Wei Dai: "Re: Parallel Universes"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2571">[ date ]</a>
<a href="index.html#2571">[ thread ]</a>
<a href="subject.html#2571">[ subject ]</a>
<a href="author.html#2571">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 11 2003 - 21:16:04 MST
</em></small></p>
</body>
</html>
