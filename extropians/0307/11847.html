<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Fermi &quot;Paradox&quot;</title>
<meta name="Author" content="Kevin Freels (megaquark@hotmail.com)">
<meta name="Subject" content="Re: Fermi &quot;Paradox&quot;">
<meta name="Date" content="2003-07-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Fermi &quot;Paradox&quot;</h1>
<!-- received="Tue Jul 22 11:36:39 2003" -->
<!-- isoreceived="20030722173639" -->
<!-- sent="Tue, 22 Jul 2003 12:44:42 -0500" -->
<!-- isosent="20030722174442" -->
<!-- name="Kevin Freels" -->
<!-- email="megaquark@hotmail.com" -->
<!-- subject="Re: Fermi &quot;Paradox&quot;" -->
<!-- id="LAW8-OE33dDOIeqqeRH0000327c@hotmail.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Pine.LNX.4.44.0307220746510.17144-100000@server.aeiveos.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Kevin Freels (<a href="mailto:megaquark@hotmail.com?Subject=Re:%20Fermi%20&quot;Paradox&quot;"><em>megaquark@hotmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jul 22 2003 - 11:44:42 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11848.html">Kevin Freels: "Re: The establishment of a Historical Database/Discussion"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11846.html">Rafal Smigrodzki: "RE: Optimism [Was: flame wars]"</a>
<li><strong>In reply to:</strong> <a href="11840.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11851.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<li><strong>Reply:</strong> <a href="11851.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11847">[ date ]</a>
<a href="index.html#11847">[ thread ]</a>
<a href="subject.html#11847">[ subject ]</a>
<a href="author.html#11847">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;I think it relates to the transition from a &quot;randomly evolved&quot; intelligence
<br>
(i.e. mutation and &quot;natural&quot; selection) into a &quot;self-directed&quot; evolutionary
<br>
process intelligence.
<br>
<p>Question -- if you knew you were likely to survive until the &quot;end of the
<br>
universe&quot;
<br>
with high probability -- would you actively seek to create future problems
<br>
that
<br>
you would eventually have to deal with?
<br>
<p>I don't think I would.
<br>
<p>Robert&quot;
<br>
<p>This thread is the best solution to the Fermi paradox I have heard yet. But
<br>
it seems a bit chopped up. Here is what I get from this discussion:
<br>
<p>Once an intelligent species enters into a period of &quot;self-directed&quot;
<br>
evolution, it becomes a &quot;master of matter&quot;. At this point, all that is
<br>
needed is raw materials to create all the resources it needs to survive. It
<br>
becomes cheaper and more efficient to stay where they are than it is to
<br>
expand throughout the universe. Especially since almost unlimited energy can
<br>
be drawn from what we would consider finite resources.
<br>
<p>This change occurs long before the capability to &quot;travel&quot; the universe, so
<br>
intelligent species tend to stay &quot;close to home&quot;
<br>
<p>Anyways, that's what I read into it and it makes sense. Either that, or I'm
<br>
a crackpot and I imagined reading that into it. Still, it seems to make some
<br>
sort of sense. Anyone want to elaborate?
<br>
<p>----- Original Message ----- 
<br>
From: &quot;Robert J. Bradbury&quot; &lt;<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20Fermi%20&quot;Paradox&quot;">bradbury@aeiveos.com</a>&gt;
<br>
To: &lt;<a href="mailto:extropians@extropy.org?Subject=Re:%20Fermi%20&quot;Paradox&quot;">extropians@extropy.org</a>&gt;
<br>
Sent: Tuesday, July 22, 2003 10:16 AM
<br>
Subject: Re: Fermi &quot;Paradox&quot;
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; On Tue, 22 Jul 2003, Anders Sandberg wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; The problem lies in determining whether the die out account or the
</em><br>
<em>&gt; &gt; become invisible account is true.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Perhaps neither -- you have to allow that ATC can *see* &quot;everything&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As I point out in the MBrains paper -- 100 billion telescopes the
</em><br>
<em>&gt; diameter of the moon are well within the reach of an ATC.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Given speed-of-light delays limiting foresight are you going to
</em><br>
<em>&gt; expend a lot of resources going someplace only to get there and
</em><br>
<em>&gt; find it already occupied?
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Historical evidence doesn't tell us much, since the rise and fall of
</em><br>
<em>&gt; &gt; civilisations on average has not had much effect on humanity as a whole.
</em><br>
<em>&gt; &gt; It is now when civilisations become global that the risks go up for
</em><br>
<em>&gt; &gt; permanent failures.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It is very difficult to eliminate ATC that have gotten to our level.
</em><br>
<em>&gt; There are thousands of people in submarines with nuclear power as an
</em><br>
<em>&gt; energy resource would likely survive a GRB -- and then there are the
</em><br>
<em>&gt; people within Cheyenne Mountain and similar facilities.
</em><br>
<em>&gt;
</em><br>
<em>&gt; And then there is the rapid evolution of humanity -- a few million
</em><br>
<em>&gt; years (and we know that multiple experiments were being conducted
</em><br>
<em>&gt; in the primate lineage during the period).  Knock us back down to
</em><br>
<em>&gt; the chimpanzee level -- reasonably good odds nature would reivent us.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; But it is not enough to assume that the probability
</em><br>
<em>&gt; &gt; of civilisation crashing is high; it has to be so high that it results
</em><br>
<em>&gt; &gt; in *no* expanding starfarers.
</em><br>
<em>&gt;
</em><br>
<em>&gt; They don't have to &quot;crash&quot; -- all advanced civilizations can simply reach
</em><br>
<em>&gt; the conclusion that there is *no point* to expansion.  The reason that
</em><br>
<em>&gt; humans colonize is to have more resources for replication -- once one
</em><br>
<em>&gt; realizes that replication (beyond limited forms of self-replication that
</em><br>
<em>&gt; which allows one to trump the galactic hazard function) is pointless
</em><br>
<em>&gt; then one would logically stop doing it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Given the awesome multiplicative power of
</em><br>
<em>&gt; &gt; even simple self-replication, once a civilisation can start sending out
</em><br>
<em>&gt; &gt; large numbers it is very hard to get rid of it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It is easy to produce lots of &quot;simple&quot; self-replicators -- but it isn't
</em><br>
<em>&gt; a good idea to do so.  At least some of the bacteria in my gut would
</em><br>
<em>&gt; attempt to consume me if they could get around my immune system.  Better
</em><br>
<em>&gt; not to give then lots of opportunities to do so.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Complex&quot;, and more importantly &quot;trustable&quot;, self-replicators may be a
</em><br>
<em>&gt; very difficult problem.  Do you *really* want to be standing toe-to-toe
</em><br>
<em>&gt; with a copy of yourself when the resources of the universe start drying
</em><br>
<em>&gt; up *knowing* that they know exactly what you know and you both know
</em><br>
<em>&gt; &quot;there can be only one&quot; (to steal a line from The Highlander)...
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &quot;(//((! Have you seen the new gamma ray burster in the Milky Way?&quot;
</em><br>
<em>&gt; &gt; &quot;Yes /||\, I have. I hope there were no intelligent life around there.&quot;
</em><br>
<em>&gt; &gt; &quot;We will know when we send out or probes...&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; There seems to be a reasonable argument for the &quot;galactic club&quot; enforcing
</em><br>
<em>&gt; a &quot;Thou shalt not send out self-replicating probes&quot; interdiction -- 
</em><br>
because
<br>
<em>&gt; any advanced civilization isn't going to want to deal with the problems
</em><br>
<em>&gt; they create in the future.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; But in general I think we are lacking something in the philosophy of the
</em><br>
<em>&gt; &gt; Fermi paradox. We need to think better here.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think it relates to the transition from a &quot;randomly evolved&quot;
</em><br>
intelligence
<br>
<em>&gt; (i.e. mutation and &quot;natural&quot; selection) into a &quot;self-directed&quot;
</em><br>
evolutionary
<br>
<em>&gt; process intelligence.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Question -- if you knew you were likely to survive until the &quot;end of the
</em><br>
universe&quot;
<br>
<em>&gt; with high probability -- would you actively seek to create future problems
</em><br>
that
<br>
<em>&gt; you would eventually have to deal with?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't think I would.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Robert
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11848.html">Kevin Freels: "Re: The establishment of a Historical Database/Discussion"</a>
<li><strong>Previous message:</strong> <a href="11846.html">Rafal Smigrodzki: "RE: Optimism [Was: flame wars]"</a>
<li><strong>In reply to:</strong> <a href="11840.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11851.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<li><strong>Reply:</strong> <a href="11851.html">Robert J. Bradbury: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11847">[ date ]</a>
<a href="index.html#11847">[ thread ]</a>
<a href="subject.html#11847">[ subject ]</a>
<a href="author.html#11847">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Jul 22 2003 - 11:44:36 MDT
</em></small></p>
</body>
</html>
