<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: RE: Optimism [Was: flame wars]</title>
<meta name="Author" content="Paul Grant (shade999@optonline.net)">
<meta name="Subject" content="RE: Optimism [Was: flame wars]">
<meta name="Date" content="2003-07-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Optimism [Was: flame wars]</h1>
<!-- received="Tue Jul 22 00:44:05 2003" -->
<!-- isoreceived="20030722064405" -->
<!-- sent="Tue, 22 Jul 2003 02:43:41 -0400" -->
<!-- isosent="20030722064341" -->
<!-- name="Paul Grant" -->
<!-- email="shade999@optonline.net" -->
<!-- subject="RE: Optimism [Was: flame wars]" -->
<!-- id="000e01c3501c$9a63e450$0264a8c0@aymanlotf" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="002101c34caf$e1f5b570$c7515651@bryan" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Paul Grant (<a href="mailto:shade999@optonline.net?Subject=RE:%20Optimism%20[Was:%20flame%20wars]"><em>shade999@optonline.net</em></a>)<br>
<strong>Date:</strong> Tue Jul 22 2003 - 00:43:41 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11827.html">Paul Grant: "RE: The establishment of a Historical Database/Discussion"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11825.html">Anders Sandberg: "&gt;Hubris"</a>
<li><strong>In reply to:</strong> <a href="11581.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11726.html">paatschb@optusnet.com.au: "Re: Optimism [Was: flame wars]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11826">[ date ]</a>
<a href="index.html#11826">[ thread ]</a>
<a href="subject.html#11826">[ subject ]</a>
<a href="author.html#11826">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: <a href="mailto:owner-extropians@extropy.org?Subject=RE:%20Optimism%20[Was:%20flame%20wars]">owner-extropians@extropy.org</a> [mailto:<a href="mailto:owner-extropians@extropy.org?Subject=RE:%20Optimism%20[Was:%20flame%20wars]">owner-extropians@extropy.org</a>]
<br>
On Behalf Of Bryan Moss
<br>
Sent: Thursday, July 17, 2003 6:07 PM
<br>
To: <a href="mailto:extropians@extropy.org?Subject=RE:%20Optimism%20[Was:%20flame%20wars]">extropians@extropy.org</a>
<br>
Subject: Re: Optimism [Was: flame wars]
<br>
<p><p><em>&gt;It's fairly easy to call them into question: the status of something 
</em><br>
<em>&gt;called &quot;intelligence&quot;
</em><br>
that can be Supersized like so many Happy Meals, the myth of substrate
<br>
independence, 
<br>
understating the complexities of system design. 
<br>
<p>There's nothing to say that u have to understand the human brain to
<br>
augment it; Case in point; car manufacturers are overlaying information
<br>
and hiliting segments of vision for workers (who are equipped with
<br>
HMDs/cameras) in an attempt to lower the training curve on complex
<br>
product assemblies (effectively boosting their intelligence).  Why mess
<br>
with the brain 
<br>
when u already have some of the largest bandwith connections to it in
<br>
the form of the senses and symbolic thinking...
<br>
<p><em>&gt; &quot;Intelligence,&quot; for example, the idea that computers are &quot;reasoning 
</em><br>
<em>&gt; machines,&quot; better than human, more rational.
</em><br>
More rational or better than human is relative to the domain that u talk
<br>
about.  Certainly humans are far more useful at this current stage.  And
<br>
certainly, irrational insofar as we all suffer from rationalizations in
<br>
an attempt to make sense out of chaotic world.  whether it is better or
<br>
worse is debateable insofar as the function tehse rationalizations
<br>
serve.
<br>
<p><em>&gt;Moore's Law, a fundamental adage of our philosophy and of computer 
</em><br>
<em>&gt;science, despite being a marketing technique of a particular company
</em><br>
that decided to reduce component size and increase speeds, design be
<br>
damned.  Tape them together and you have Supersized Intelligence:
<br>
superintelligence.
<br>
<p>Oh I don't think any computer scientist is saying that; although for
<br>
certain operations {processes}, design is not a problem, thoroughput is.
<br>
<p><em>&gt;The substrate, another part of computer age mythos: abstractionism.  Of
</em><br>
course, there's no physical theory for uploading, except perhaps, if you
<br>
might allow, this short, utterly erroneous argument: (1) at the quantum
<br>
level reality is discrete; (2) therefore, a quantum computer can
<br>
simulate any part of reality; (3) the brain probably isn't capable of
<br>
exploiting quantum mechanical effects; (4) therefore, a classical
<br>
computer can simulate a brain that is identical to and identifiable with
<br>
the original.  This, at least, is what I can salvage from my side of
<br>
those copy arguments we used to have.  (I concede.)  And finally, we
<br>
shovel all the real problems under that carpet we call &quot;software.&quot;  This
<br>
is part of that larger Myth of the Computer Age: universality.  We can
<br>
do anything in software, given enough speed.  This is not true in any
<br>
practical or useful sense, however.
<br>
<p>Personally I think FGPA's will be very useful in the future.  I was just
<br>
contemplating a day ago the flaws with current processor and motherboard
<br>
architectures.
<br>
I definately do not think you can replicate the human brain functions
<br>
identically in hardware, regardless of the speed of the processing. I
<br>
could not upload
<br>
you for instance :)  Might I might be able to replicate something thats
<br>
kind of like you (in a system) :)  I have a particularly interesting
<br>
thought experiment as it relates
<br>
to this topic :)  As this is the case (for my particular belief set),
<br>
most of my research will not be in replicating ur brain functions in
<br>
silicon, but rather, a method for 
<br>
keeping the human brain alive, for restoring neural plasticity, and of
<br>
course, some sort of neuromechanical interface to allow for different
<br>
sensors, effectors and shells
<br>
(combinations thereof).
<br>
<p><em>&gt;I say the following with complete confidence: there will be no
</em><br>
Yudkowskian Singularity, the copy is not the original, the creation of
<br>
the first assembler will not cause an immediate revolution in
<br>
manufacturing.  These are science fiction pipedreams.  They're not even
<br>
very good ones.  Further, we need to &quot;deconstruct&quot; our relation to the
<br>
computer revolution.  We're on the other side now, I mean this in
<br>
complete seriousness, the computer revolution is played out.  All that
<br>
is left is for computers to recede; not in the hip, ubiquitous
<br>
technology &quot;computer in my doorknob&quot; sense but in the &quot;everybody stopped
<br>
caring&quot; sense.  
<br>
<p>Oh I don't know about that.  I think that ur average person will hit
<br>
their saturation point shortly (if not already); but clever people will
<br>
always have a need
<br>
for processing power, given that they are the ones truly able to harness
<br>
computers to specific tasks.  I think eventually think that generic
<br>
classes
<br>
of computer searches will be implemented in hardware, with a FGPA layer
<br>
to interface for the particular data representation required to perform
<br>
that
<br>
search.. Something like that would be incredibly useful for scientific
<br>
computation, in so far as it requires a robust (probably nearly
<br>
[sub]optimal) solution be found for a 
<br>
noisy environment (fitness function) within a given time frame.
<br>
<p><em>&gt;But that's our origin and we need to pick it apart to understand where
</em><br>
we came from.  Artificial Intelligence, of the CS kind, of the kind that
<br>
assumes we can design Minds (not brains) through some sort of hokey
<br>
self-reflection, is the sort of hubris we must now only find humour in.
<br>
(Which is not to say computer simulation won't play a big role in the
<br>
brain sciences or any other science, but it's a tool now, nothing more.)
<br>
<p>I'ld agree with ur last statement, it is just a tool at this stage.  As
<br>
to designing brains through self-reflection; I should hope not :) There
<br>
are some incredibly interesting
<br>
permutations on the concept of a self-aware intelligence that should be
<br>
explored.  Why build another human brain, if you can specialize the
<br>
intellect sufficiently
<br>
to surpass our capabilities within a limited domain.  I think the
<br>
challenge in the future will not build a human brain, but sufficient
<br>
intelligence of the right type
<br>
to handle the environment the machine will be placed into.
<br>
<p><em>&gt;Even if you bracket the three &quot;ultratechnologies&quot; I mentioned only as a
</em><br>
thought exercise, it's interesting to see how the horizon changes.
<br>
Without superintelligence, without the technological Saviour-God, there
<br>
is no wall over which we cannot see.  Without uploading, we're going to
<br>
die unless we fight for it.  Curing aging is only a first (incredibly
<br>
difficult) step, the way we value our lives will have to change, the
<br>
medical practise will have to change.  Nobody wants to live to 400 and
<br>
slip in the bath, crack their head open on the faucet.
<br>
<p>Hahahaha :) if ur willing to deal with invasion of privacy issues, u
<br>
need to redesign the current &quot;ambulance&quot; technologies; something
<br>
suitable insofar
<br>
as bringing the hospital to the patient, and in a hurry. And yes, I
<br>
agree, medicine as its currently practiced (or rather medical knowledge
<br>
as its currently
<br>
pursued) is idiotic at best, inefficient at worst.
<br>
<p><em>&gt;It's an entirely different attitude towards death and we have to sell
</em><br>
it to the world.  Without drexlerian nanontechnology (and I speak more
<br>
of the supposed time frame than the technology itself) there is no
<br>
sudden &quot;fix&quot; for the poor, the starving.  We need to engineer crops,
<br>
educate people, provide clean water.  None of this is going to be easy.
<br>
We're not going to get off-world soon either, so, yes, we're stuck here
<br>
amidst the war, the famine, those evil fundamentalists.
<br>
<p>I don't think there honestly is a fix for any of those things.  Even if
<br>
you engineer crops, educate people, and provide clean water.
<br>
I think to do that u would have to exert a significant effort to change
<br>
the fundamental nature of the human experiences; something
<br>
which is simply not possible to do.  Or put another way, you'll never be
<br>
able to eliminate scarcity, and ergo, envy short of brainwashing
<br>
or reduction of intelligence (and ergo the ability to cognitively
<br>
perceive such differences).  At best u will simply push such &quot;gross&quot;
<br>
occurrences under the surface, aka political correctness.
<br>
<p><em>&gt;Designer babies?  Not likely!
</em><br>
<p>I don't about that, why not?  I think that somebody will eventually set
<br>
up a practice somewhere where u can at least screen
<br>
for the charactistics u want in ur kid.  Whether or not they'll be able
<br>
to manipulate the genes (any time soon) is another issue.  
<br>
But soon I think, a portion of medicine will either go underground, or
<br>
establish itself within a country that deliberately leaves 
<br>
its rules open to allow such basic types of research.  Where there is a
<br>
market, there is a will.
<br>
<p>omard-out
<br>
<p><p><p><p><p>BM
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11827.html">Paul Grant: "RE: The establishment of a Historical Database/Discussion"</a>
<li><strong>Previous message:</strong> <a href="11825.html">Anders Sandberg: "&gt;Hubris"</a>
<li><strong>In reply to:</strong> <a href="11581.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11726.html">paatschb@optusnet.com.au: "Re: Optimism [Was: flame wars]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11826">[ date ]</a>
<a href="index.html#11826">[ thread ]</a>
<a href="subject.html#11826">[ subject ]</a>
<a href="author.html#11826">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Jul 22 2003 - 00:52:05 MDT
</em></small></p>
</body>
</html>
