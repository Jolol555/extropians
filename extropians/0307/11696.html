<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: ExI principles: people left behind?</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: ExI principles: people left behind?">
<meta name="Date" content="2003-07-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ExI principles: people left behind?</h1>
<!-- received="Sun Jul 20 02:20:27 2003" -->
<!-- isoreceived="20030720082027" -->
<!-- sent="Sun, 20 Jul 2003 01:22:09 -0700" -->
<!-- isosent="20030720082209" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: ExI principles: people left behind?" -->
<!-- id="200307200122.09185.samantha@objectent.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Pine.LNX.4.44.0307181822210.15760-100000@server.aeiveos.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20ExI%20principles:%20people%20left%20behind?"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Jul 20 2003 - 02:22:09 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11697.html">Samantha Atkins: "Re: ExI principles: people left behind?"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11695.html">Spudboy100@aol.com: "Re: A vision"</a>
<li><strong>In reply to:</strong> <a href="11632.html">Robert J. Bradbury: "Re: ExI principles: people left behind?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11696">[ date ]</a>
<a href="index.html#11696">[ thread ]</a>
<a href="subject.html#11696">[ subject ]</a>
<a href="author.html#11696">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Friday 18 July 2003 19:55, Robert J. Bradbury wrote:
<br>
<p><em>&gt; &gt; Historical villains have killed millions of people in
</em><br>
<em>&gt; &gt; terrible causes, but the idea that it's too inconvenient to think about
</em><br>
<em>&gt; &gt; the subject, and that dropping nukes would save time and aggravation, may
</em><br>
<em>&gt; &gt; well represent a new low for the human species.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ah, but the debate must change if the &quot;killing of millions of people&quot;
</em><br>
<em>&gt; is in the name of a &quot;good&quot; cause.  I do not note in your message
</em><br>
<em>&gt; a schema for the valuation of &quot;lives&quot;.  Say even an AI life vs.
</em><br>
<em>&gt; a human life.  This is not a new debate -- it goes way back to
</em><br>
<em>&gt; the question of whether one has the right to kill (shut off, erase)
</em><br>
<em>&gt; ones copies -- (even *if* they have given you &quot;well informed&quot;
</em><br>
<em>&gt; permission to do so in advance).
</em><br>
<em>&gt;
</em><br>
<p>Some things, imho, go beyond just logic and reasoning.  Ethics is one of those 
<br>
things.  The value of human life is not something you can simply plug into a 
<br>
mathematical formula.   The question of whether it is ok to sacrifice tens of 
<br>
millions of people to our supposed brighter future without them cannot be 
<br>
settled at the level of the reasoning intellect alone.   Copies have nothing 
<br>
to do with it.
<br>
<p><p><em>&gt; And the &quot;valuation of lives&quot; goes to the crux of the matter.  Nick
</em><br>
<em>&gt; in his paper suggested there were some alternate perspectives
</em><br>
<em>&gt; of utilitarian evaluations, Anders expanded on this quite a bit in
</em><br>
<em>&gt; his comments (much to my education).
</em><br>
<em>&gt;
</em><br>
<em>&gt; But the problem is not simple and it doesn't go away (just because we
</em><br>
<em>&gt; find the discussion repulsive).
</em><br>
<em>&gt;
</em><br>
<p>The problem originally stated was that some cultures do not understand or want 
<br>
some things we consider to be of extreme value and distrust those who do not 
<br>
value them utterly.   I hardly thing it is a solution to simply exterminate 
<br>
all of these inconvenient people.   Do you?  Really?    It goes far beyond 
<br>
repulsive.  It crosses the line into that which will not be considered or 
<br>
allowed if we are talking about extropic values for humankind.  Last time I 
<br>
checked our supposed shared principles don't say extropic values for &quot;us&quot; at 
<br>
the expense of however many of &quot;them&quot; seem inconvenient or possibly a threat.  
<br>
If you believe differently then it is up to you to justify this stand.  A 
<br>
specious argument on hypothentical astronomical numbers of future beings is 
<br>
not at all sufficient has has been pointed out.
<br>
<p><em>&gt; I do agree that villains have abused their power and that millions of
</em><br>
<em>&gt; innocent people have died as a result.  I would also probably agree
</em><br>
<em>&gt; that my suggestion would also result in similar negentropic casualties.
</em><br>
<em>&gt; But the point I am trying to get at is *when* the negentropic losses
</em><br>
<em>&gt; are acceptable?  Is the saving of a single human life worth a sacrifice
</em><br>
<em>&gt; by humanity?  In medicine this is known as &quot;triage&quot; -- and it involves
</em><br>
<em>&gt; some very difficult decisions as to how one optimizes who one saves.
</em><br>
<em>&gt;
</em><br>
<p>Negentropic losses are nto acceptable when they can be avoided.   We are not 
<br>
talking about the saving of a single human life but the cold-blooded 
<br>
slaughter of tens of millions of real human beings on the basis of some 
<br>
specious hypothetical argument.  There is quite a huge difference.    
<br>
<p><em>&gt; I was trying to go beyond that.  I was trying to determine whether
</em><br>
<em>&gt; or not there is a moral framework for the net worth of human lives
</em><br>
<em>&gt; and whether that justifies a &quot;way of being&quot;?  For example, the
</em><br>
<em>&gt; Buddhist perpective on &quot;lives&quot; provides a &quot;way of being&quot; -- the
</em><br>
<em>&gt; extropic principles may not (at least in some aspects).  And perhaps
</em><br>
<em>&gt; more importantly the extropic perspective may *never* generate a
</em><br>
<em>&gt; schema that trumps the Buddhist perspective.  That is why I raised
</em><br>
<em>&gt; the question of how one achieves the shortest path to ones goals.
</em><br>
<em>&gt;
</em><br>
<p>You are correct that the extropic principles do not provide a sufficient 
<br>
ethical basis or &quot;way of being&quot;.    My goals are oriented in a maximally 
<br>
extropic future for all human beings, not just for those who happen to think 
<br>
more or less like I do.   It is not compatible with my goals to murder and do 
<br>
so in the tens of millions as this is expressly contradictory. 
<br>
<p><em>&gt; &gt; And how easy it is for people who can't distinguish word games from
</em><br>
<em>&gt; &gt; reality to arrange a few thoughts in the right order and decide to
</em><br>
<em>&gt; &gt; commit genocide.  The human mind has no safety catch.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I am not playing word games.  My comment was very serious (though
</em><br>
<em>&gt; I may currently regret posting it).  It was an effort to question
</em><br>
<em>&gt; &quot;at what rate&quot; and &quot;how&quot; do you want humanity to evolve?
</em><br>
<em>&gt;
</em><br>
<p>The &quot;evolving&quot; I want is not compatible with the regression suggested in the 
<br>
least.
<br>
<p><em>&gt; &gt; Because you genuinely seem to be serious.  I wish I could say I don't
</em><br>
<em>&gt; &gt; understand it, but I do, and I'm sad, and frightened, because you were
</em><br>
<em>&gt; &gt; someone I used to respect.  Even if you don't understand what you're
</em><br>
<em>&gt; &gt; saying, even if it has no connection to reality for you, you said it, and
</em><br>
<em>&gt; &gt; I can't make it unreal to myself.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If it is of any help, reframe it in terms of &quot;can you erase your copies&quot;?
</em><br>
<em>&gt; It seems to be a reasonable proposal that an evolving technological
</em><br>
<em>&gt; civilization that allows the erasing of copies would advance faster
</em><br>
<em>&gt; than one that does not (simply due to the expense of the memory
</em><br>
<em>&gt; requirements of preserving inactive copies -- ignoring the question
</em><br>
<em>&gt; of whether copies must be allowed some slice of the global CPU time).
</em><br>
<em>&gt;
</em><br>
<p>Specious dry intellectual games are abhorrent when you have suggested 
<br>
megadeaths as somehow possibly beneficial to our goals.
<br>
<p><em>&gt; So making the great &quot;leap&quot; that one human is pretty much like another
</em><br>
<em>&gt; human (I mean really -- if a 1 cm^3 nanocomputer can support 100,000+
</em><br>
<em>&gt; human minds our &quot;individuality&quot; is probably overrated) one begins to
</em><br>
<em>&gt; get into the question of the &quot;survival of humanity&quot;.  This isn't a
</em><br>
<em>&gt; new topic -- it has been discussed by Robin in his &quot;If Uploads Come
</em><br>
<em>&gt; First&quot; paper (<a href="http://hanson.gmu.edu/uploads.html">http://hanson.gmu.edu/uploads.html</a>).
</em><br>
<em>&gt;
</em><br>
<p>This leads straight to the Dark Side.  You can choose whether or not to go 
<br>
there.  It is a very fundamental choice.  You can't intellectualize your 
<br>
choice.  It comes from a deeper or at least different level than that in 
<br>
large part.
<br>
<p><em>&gt; All I am saying, and I am sad that it makes you &quot;sad, and frightened&quot;
</em><br>
<em>&gt; but someone has to face what I perceive as the spectre of the Pied Piper,
</em><br>
<em>&gt; is that the philosophy, belief system, what we promote, etc. may be
</em><br>
<em>&gt; very incomplete unless we deal with the fact that a society that
</em><br>
<em>&gt; allows the deletion of copies may out-evolve a society that does not.
</em><br>
<em>&gt;
</em><br>
<p>We are not talking about the deletion of copies!  And no, human beings are not 
<br>
interchangeble units with zero cost to erase a few if the appear to you to be 
<br>
superfluous!  And no, it is not at all itneresting to talk about how the copy 
<br>
question is actually the same thing.  You have a fundamental choice to make. 
<br>
What will it be?  That choice will have consequences.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11697.html">Samantha Atkins: "Re: ExI principles: people left behind?"</a>
<li><strong>Previous message:</strong> <a href="11695.html">Spudboy100@aol.com: "Re: A vision"</a>
<li><strong>In reply to:</strong> <a href="11632.html">Robert J. Bradbury: "Re: ExI principles: people left behind?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11696">[ date ]</a>
<a href="index.html#11696">[ thread ]</a>
<a href="subject.html#11696">[ subject ]</a>
<a href="author.html#11696">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Sun Jul 20 2003 - 02:32:19 MDT
</em></small></p>
</body>
</html>
