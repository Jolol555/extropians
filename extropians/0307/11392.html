<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Why Does Self-Discovery Require a Journey?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Why Does Self-Discovery Require a Journey?">
<meta name="Date" content="2003-07-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why Does Self-Discovery Require a Journey?</h1>
<!-- received="Fri Jul 11 22:29:27 2003" -->
<!-- isoreceived="20030712042927" -->
<!-- sent="Sat, 12 Jul 2003 00:27:19 -0400" -->
<!-- isosent="20030712042719" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Why Does Self-Discovery Require a Journey?" -->
<!-- id="3F0F8E27.3020606@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="5.2.1.1.2.20030711135913.01bf41c8@mail.gmu.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Why%20Does%20Self-Discovery%20Require%20a%20Journey?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Fri Jul 11 2003 - 22:27:19 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11393.html">Terry W. Colvin: "FWD (SPAM) Solve your woman problems forever"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11391.html">Paul Grant: "RE: Sol-like system discovered...SETI new directions?"</a>
<li><strong>In reply to:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11396.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<li><strong>Reply:</strong> <a href="11396.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11392">[ date ]</a>
<a href="index.html#11392">[ thread ]</a>
<a href="subject.html#11392">[ subject ]</a>
<a href="author.html#11392">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin Hanson wrote:
<br>
<p><em>&gt; On 7/11/2003, Eliezer Yudkowsky  wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt; ... many papers/books in philosophy and psychology, and fewer in 
</em><br>
<em>&gt;&gt;&gt; evolutionary psychology, on self-deception.  ...
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Keywords?  Names?  Paper titles?  Google fodder would be appreciated.  
</em><br>
<em>&gt;&gt; I expect my current knowledge to substantially exceed the state of the 
</em><br>
<em>&gt;&gt; art in philosophy, but I am interested in any bodies of experimental 
</em><br>
<em>&gt;&gt; evidence from psychology, or any work in evolutionary psychology.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Most of what academia has produced isn't yet on the web.
</em><br>
<p>Most of it isn't, but enough of it usually is to get a quick snapshot of a 
<br>
novel subfield, provided you're already familiar with most of the nearby 
<br>
fields.  To check my initial expectations about what the field would look 
<br>
like, I Googled and used:
<br>
<p><a href="http://cogprints.ecs.soton.ac.uk/archive/00000295/00/MELE.html">http://cogprints.ecs.soton.ac.uk/archive/00000295/00/MELE.html</a>
<br>
<a href="http://www.philosophy.stir.ac.uk/cnw/self-deception.htm">http://www.philosophy.stir.ac.uk/cnw/self-deception.htm</a>
<br>
<p>Note Mele's commonsense emphasis that one need not have an explicit 
<br>
cognitive representation of a self-deception goal in order to become 
<br>
self-deceived (section 3).  He lists mechanisms such as negative 
<br>
misinterpretation, positive misinterpretation, selective 
<br>
focusing/attending, and selective evidence-gathering, and concludes &quot;In 
<br>
none of the examples offered does the person hold the true belief that ~p 
<br>
and then intentionally bring it about that he or she believes that p. Yet, 
<br>
assuming that my hypothetical agents acquire relevant false beliefs in the 
<br>
ways described, these are garden-variety instances of self-deception.&quot;
<br>
<p>I am making a similar objection to your claims about what people *really 
<br>
want*.  It's a startling claim and it sets off people's cheater-detectors, 
<br>
but I don't think it's true.  The gross inconsistency between beliefs and 
<br>
actions does not indicate that &quot;what people believe they want&quot; is not 
<br>
&quot;what they really want&quot;, it means that people are grossly inconsistent in 
<br>
ways that have been subject to natural selection on heritable variations.
<br>
<p><em>&gt; In phil see 
</em><br>
<em>&gt; Mele, in psych see Paulhaus, in evol psych see Trivers (all cited in 
</em><br>
<em>&gt; <a href="http://hanson.gmu.edu/deceive.pdf">http://hanson.gmu.edu/deceive.pdf</a>).  (Some experts coming to my 
</em><br>
<em>&gt; conference are Robert Frank, Jay Hamilton, Dennis Krebs, Robert Kurzban, 
</em><br>
<em>&gt; Al Mele, Harold Sackeim, Robert Trivers, Bill von Hippel.) (I expect you 
</em><br>
<em>&gt; over-estimate your philosophy abilities, but then most people do.)
</em><br>
<p>Without an understanding of how general intelligence works and how it 
<br>
evolved, nothing in philosophy makes any sense; in particular, without a 
<br>
functional decomposition of intelligence, philosophical modeling carves 
<br>
the mind at the wrong joints and then breaks down.  And that is why I 
<br>
expect my knowledge to exceed the state of the art in philosophy.  I can 
<br>
talk about emotional reinforcement mechanisms for real experiences and 
<br>
imagined experiences; declarative beliefs with emotional valencies; 
<br>
deliberative decision-making; how past experience and emotion influences 
<br>
which subjective future experiences are visualized during deliberation; 
<br>
impulses that override deliberation; the pressure of consistency with 
<br>
abstract beliefs considered as a special case of emotional pressure... and 
<br>
so on.  But my theory of *volition* is a constructive one - it does not 
<br>
correspond to any natural category in the mind; there is no hidden 
<br>
register where you can look up what people &quot;really want&quot;.  Yet most 
<br>
theoreticians, faced with a problem like this, would start with &quot;want&quot; as 
<br>
a simple fact, and try to construct more detailed accounts of cognitive 
<br>
processes as complex facts phrased in terms of &quot;wanting&quot;, *exactly the 
<br>
wrong approach*.
<br>
<p>&quot;Studying adaptive gross inconsistencies&quot; seems like a fine way to phrase 
<br>
the problem - it encourages looking for specific cognitive mechanisms and 
<br>
specific pressures exerted at specific points in the interaction of those 
<br>
mechanisms.  It even has the nice overtone of &quot;Surprise!  Incompetence!&quot; 
<br>
that helped the field of heuristics and biases become popular.  But when 
<br>
you start telling me that people do not really want what they say they 
<br>
want, I become worried for several reasons.
<br>
<p>One, you're assuming that wanting-ness is a simple natural category, which 
<br>
distracts attention away from the task of arriving at a functional 
<br>
decomposition of decision-making into a surprisingly weird evolutionary 
<br>
layer-cake with human icing on top.
<br>
<p>Two, you're setting off people's cheater-detectors in a way that invokes 
<br>
an implicit theory of mind that I think is oversimplified, false-to-fact, 
<br>
and carves the mind at the wrong joints; just as the idea that 
<br>
self-deception starts with believing ~p and follows a deliberate plan to 
<br>
fool oneself is oversimplified, false-to-fact, and carves the mind at the 
<br>
wrong joints.
<br>
<p>Three, you're making a preemptive philosophical judgment about the nature 
<br>
of true personal identity and the construction of volition that (a) may 
<br>
ultimately be a matter for personal choice (b) has serious consequences 
<br>
(c) I strongly disagree with.
<br>
<p>Four: back when the field of game theory was getting started, people 
<br>
discovered the Prisoner's Dilemma, and then went around announcing that 
<br>
there was no possible rational reason to cooperate and that anyone who did 
<br>
so was being merely sentimental.  They congratulated themselves on being 
<br>
so tough-minded.  Later, they realized the problem was iterative and 
<br>
invented the concept of reciprocal cooperation.  But *meanwhile*, game 
<br>
theorists who had *not* heard of this result would *actually defect on the 
<br>
iterated PD*.  They would defect on the Prisoner's Dilemma!  (See, for 
<br>
example, the Flood-Dresher experiment.)  Congratulating yourself on a 
<br>
tough-minded view of human nature can render you *incompetent* on problems 
<br>
that the merest hunter-gatherer knows the solution to - it is *not*, 
<br>
historically speaking, a reliable heuristic.  Now you plan to tell people 
<br>
that nobody really cares about altruism, and that all idealism is a lie 
<br>
and a patina.  I think this is just as damaging as telling people that the 
<br>
only possible rational action is to defect on the (iterated!) Prisoner's 
<br>
Dilemma.  Of course I also think that &quot;all idealism is a lie&quot; will turn 
<br>
out to be just as *wrong* as &quot;it is rational to defect on the (iterated) 
<br>
Prisoner's Dilemma&quot; - if it were true, I would tell you to go ahead and 
<br>
report it no matter the consequences.  Why?  Because I am a true idealist. 
<br>
&nbsp;&nbsp;And so are you, and so probably are most people to greater or lesser 
<br>
degrees.
<br>
<p>Five, there's no good reason to mess with points 1-4 - they are totally 
<br>
extraneous to the real substance of your theory.  You can declare yourself 
<br>
to be studying &quot;adaptive gross inconsistencies in moral belief and real 
<br>
actions&quot;, and get the benefit of intersection with both evolutionary 
<br>
psychology and experimental psychology, without ever needing to take a 
<br>
stance about what people &quot;really&quot; &quot;want&quot;, or presuming a particular 
<br>
functional decomposition of the mechanisms involved.  Modularize away 
<br>
those contrarian points...
<br>
<p><em>&gt;&gt; Also, if you are talking about a major upheaval in the belief system 
</em><br>
<em>&gt;&gt; there is no such thing as a &quot;briefly informed&quot; choice - you have to 
</em><br>
<em>&gt;&gt; extrapolate major changes within the person's volition, including 
</em><br>
<em>&gt;&gt; reactions to many different changes and compounded choices about those 
</em><br>
<em>&gt;&gt; reactions.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I limited my claim to the sorts of things we've seen.  We've seen how 
</em><br>
<em>&gt; people behave if briefly informed.   We haven't seen your ideal of fully 
</em><br>
<em>&gt; informed post-upheaval choice.
</em><br>
<p>When have we seen how people behave if briefly informed?  How can you 
<br>
briefly inform someone of something they don't believe to be true?
<br>
<p><em>&gt;&gt; I would reject both metrics as adequate theories of volition or even 
</em><br>
<em>&gt;&gt; instantaneous want, though the informed choice metric comes closer.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The question is what you would put in their place.  There are huge and 
</em><br>
<em>&gt; long traditions in economics and philosophy, among other places, 
</em><br>
<em>&gt; discussing how to describe what people &quot;really&quot; want.  This is another 
</em><br>
<em>&gt; of those areas that you shouldn't try to reinvent before surveying what 
</em><br>
<em>&gt; has been done.
</em><br>
<p>I am mostly sympathetic to arguments of the type &quot;read the literature, 
<br>
dammit&quot;, though the amount of literature reading that is required does 
<br>
vary from person to person.  But I have to say that I was not surprised by 
<br>
my brief survey - it looks pretty much like what I expected.  Is there any 
<br>
particular area or result of which you worry I am ignorant?
<br>
<p><em>&gt;&gt; The folk picture of people struggling between their high moral 
</em><br>
<em>&gt;&gt; aspirations and their inner demons is, as far as I can tell, pretty 
</em><br>
<em>&gt;&gt; much correct.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The folk picture that most people are much more concerned about 
</em><br>
<em>&gt; appearing moral than being moral is also pretty much correct.
</em><br>
<p>I am not sure what you mean by &quot;more concerned&quot; in this context.  People 
<br>
are concerned about being moral.  People are concerned about appearing 
<br>
moral.  The mechanisms are different but intertwined.  What constitutes 
<br>
&quot;concern&quot;, and how do you determine whether &quot;being moral&quot; or &quot;appearing 
<br>
moral&quot; receives &quot;greater concern&quot;?  My guess is that whether people are 
<br>
&quot;more concerned&quot; will depend on how concern is operationally defined and 
<br>
the context in which the concern is tested... meaning that researchers, 
<br>
depending on their starting prejudices, could easily construct an 
<br>
experiment in which people are shown to be more concerned with being moral 
<br>
than appearing moral, or vice versa.  For example, if I present people 
<br>
with an explicit choice *apparent to the subject* of being moral or 
<br>
appearing moral, I would guess that they would choose being moral, as they 
<br>
would be unable to do otherwise and retain their self-respect.  On the 
<br>
other hand, the more distant the dilemma from conscious perception in 
<br>
those terms, the more I would expect evolution's puppet strings to have 
<br>
opportunities to take over.  There are different mechanisms interacting 
<br>
here, and by manipulating the context I could determine which mechanism 
<br>
would appear to win, but the most important truth is that there are 
<br>
*different* mechanisms involved!
<br>
<p><em>&gt;&gt; People die saving unrelated children.  Is that a lie?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That is a pretty rare phenomena.  It is rarer still in situations where 
</em><br>
<em>&gt; people know they will die, and know they cannot not gain social approval 
</em><br>
<em>&gt; from doing so.
</em><br>
<p>In general and speaking very broadly, the less adaptive something is, the 
<br>
rarer it will end up being, after all the selection on all the heritable 
<br>
variations has been taken into account.  But it happens; it is something 
<br>
that the human mind can really do, given its configuration.  The 
<br>
mechanisms of true altruism are, in fact, there, operating as 
<br>
independently executing adaptations, and can be exposed given the right 
<br>
context.
<br>
<p><em>&gt;&gt; My own claim is that if you asked people what they cared about, what 
</em><br>
<em>&gt;&gt; mattered most to them, what kind of person they wanted to be, they 
</em><br>
<em>&gt;&gt; would say that the altruism is the most important part of them.  Since 
</em><br>
<em>&gt;&gt; that is what they tell me, why should I - or any friend of theirs - 
</em><br>
<em>&gt;&gt; contradict them?  The deliberative system may sometimes be weak, but 
</em><br>
<em>&gt;&gt; it is ultimately in charge - or at least is the center I look to, to 
</em><br>
<em>&gt;&gt; determine how to find the &quot;person&quot; I want to &quot;help&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is the heart of our dispute.  As in discussions of whether the 
</em><br>
<em>&gt; upload, or its copy, would &quot;really be you&quot;, there is an element of 
</em><br>
<em>&gt; definition or choice in looking into a complex contradictory person and 
</em><br>
<em>&gt; saying what their &quot;real&quot; preferences are.  If you aren't going to appeal 
</em><br>
<em>&gt; to any criteria about why this is a good choice, but just declare it by 
</em><br>
<em>&gt; definition, then there isn't much more to talk about.
</em><br>
<p>The construction of volition is something I'm working on writing up, but 
<br>
it may be a while before you see anything from me on the subject.
<br>
<p>But if I had a genie built using your definition of &quot;wanting&quot;, I would 
<br>
never, ever make a wish to it.
<br>
<p>The term &quot;real preferences&quot; may mean rather different things to Friendly 
<br>
AI creators and economists, as Dan Fabulich points out.
<br>
<p><em>&gt;&gt; I wouldn't *use* the term &quot;want&quot; for a corporation.  ... Also the 
</em><br>
<em>&gt;&gt; above does not seem to be a good example of self-deception, just 
</em><br>
<em>&gt;&gt; simple deliberate lying.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Corporations, and other organizations can have behavior that is very 
</em><br>
<em>&gt; much like individual self-deception.  So its too bad that you reject 
</em><br>
<em>&gt; such examples, as they are much easier to analyze.
</em><br>
<p>Er... it looks to me like they're easy to analyze because they're simpler 
<br>
yet unrelated phenomena, i.e., deliberate deception rather than 
<br>
self-deception.  Why would anyone construe it otherwise?  Why not pick an 
<br>
uncontroversial example like only 2% of high school seniors believing they 
<br>
are below average in leadership ability?
<br>
<p>The form of your argument seems to be:  &quot;Look at this corporation engaging 
<br>
in deliberate deception.  We would say this corporation is lying about 
<br>
what it really wants, right?  The lie benefits the corporation, so your 
<br>
cheater-detectors should go off.  Now look at this human activity of 
<br>
self-deception.  This is similar, right?  And it benefits the human, 
<br>
right?  So your cheater-detectors should go off and attribute to the human 
<br>
the same kind of lying, cheating behavior that you attribute to corporate 
<br>
PR departments.&quot;  But this is not a valid analogy.  In one case we have 
<br>
human deliberation pulling the puppet strings, in the other, evolutionary 
<br>
adaptation.  Evolution doesn't want you to lie, evolution wants you to be 
<br>
honest and self-deceived.  In linguistic political organisms, there are 
<br>
*separate and distinct* selection pressures on motivations and actions, 
<br>
which may come into conflict.  You are taking human behaviors that result 
<br>
from these conflicting selection pressures, and invoking cheater-detectors 
<br>
on apparently self-beneficial outcomes to attribute selfish 
<br>
intentionality.  To this I object because it is *the wrong explanation*. 
<br>
Furthermore, I object to it as a temporary scaffolding in the explanation 
<br>
because it is an emotionally destructive thing to say, just as telling 
<br>
people that it is rational to defect in the (iterated) Prisoner's Dilemma 
<br>
is emotionally destructive, and yet appealing on account of its apparent 
<br>
tough-mindedness.
<br>
<p><em>&gt; Also closely related is the question of what a nation &quot;wants.&quot;  You see, 
</em><br>
<em>&gt; it seems that in many ways the voting/politics person within us makes 
</em><br>
<em>&gt; different choices than we do personally.   Personally you might buy 
</em><br>
<em>&gt; foreign products, or hire a foreign worker, but politically you might 
</em><br>
<em>&gt; want to prohibit them.  It is not just that people may be ignorant about 
</em><br>
<em>&gt; social processes; our political selves seem to have different 
</em><br>
<em>&gt; preferences from our non-political selves!  Politically, we talk as if 
</em><br>
<em>&gt; we are more high-minded.  So which selves should political outcomes 
</em><br>
<em>&gt; correspond to?  Should people get the products they would want as 
</em><br>
<em>&gt; ordinary people, or the products they say they want as political people?
</em><br>
<p>Why should there be a hidden register in the brain containing an answer to 
<br>
this question?  As I understand what it means to help people, it is not 
<br>
&quot;helping&quot; to fulfill temptations they are ashamed of and ignore principles 
<br>
they are proud of.  It may also not be &quot;helping&quot; people to extrapolate 
<br>
their principles farther than they did when they were choosing those 
<br>
principles.  Defining volition is an FAI-complete problem.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11393.html">Terry W. Colvin: "FWD (SPAM) Solve your woman problems forever"</a>
<li><strong>Previous message:</strong> <a href="11391.html">Paul Grant: "RE: Sol-like system discovered...SETI new directions?"</a>
<li><strong>In reply to:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11396.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<li><strong>Reply:</strong> <a href="11396.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11392">[ date ]</a>
<a href="index.html#11392">[ thread ]</a>
<a href="subject.html#11392">[ subject ]</a>
<a href="author.html#11392">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Jul 11 2003 - 22:38:30 MDT
</em></small></p>
</body>
</html>
