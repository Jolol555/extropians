<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Why Does Self-Discovery Require a Journey?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Why Does Self-Discovery Require a Journey?">
<meta name="Date" content="2003-07-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why Does Self-Discovery Require a Journey?</h1>
<!-- received="Fri Jul 11 10:53:44 2003" -->
<!-- isoreceived="20030711165344" -->
<!-- sent="Fri, 11 Jul 2003 12:51:19 -0400" -->
<!-- isosent="20030711165119" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Why Does Self-Discovery Require a Journey?" -->
<!-- id="3F0EEB07.4030109@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="5.2.1.1.2.20030711092552.01c7d9f8@mail.gmu.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Why%20Does%20Self-Discovery%20Require%20a%20Journey?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Fri Jul 11 2003 - 10:51:19 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11372.html">Hal Finney: "RE: Number of carbon atoms in the Earth's biomass"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11370.html">Extropian Agroforestry Ventures Inc.: "Re: Number of oxygen atoms in the Earth's biomass"</a>
<li><strong>In reply to:</strong> <a href="11368.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<li><strong>Reply:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11371">[ date ]</a>
<a href="index.html#11371">[ thread ]</a>
<a href="subject.html#11371">[ subject ]</a>
<a href="author.html#11371">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin Hanson wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; [FYI, there are many papers/books in philosophy and psychology, and 
</em><br>
<em>&gt; fewer evolutionary psychology, on self-deception.  And classic 
</em><br>
<em>&gt; literature has many things to say about it.  (I'm co-hosting a small 
</em><br>
<em>&gt; invitation-only interdisciplinary conference on the subject here in 
</em><br>
<em>&gt; October.)  This is exactly the sort of topic that extropians shouldn't 
</em><br>
<em>&gt; try to reinvent before surveying the existing literature.  RH]
</em><br>
<p>Keywords?  Names?  Paper titles?  Google fodder would be appreciated.  I 
<br>
expect my current knowledge to substantially exceed the state of the art 
<br>
in philosophy, but I am interested in any bodies of experimental evidence 
<br>
from psychology, or any work in evolutionary psychology.
<br>
<p>I'll toss in Latane-Darley, Zimbardo, and Milgram to get the pot started, 
<br>
though those are simple errors of moral self-image rather than complex 
<br>
self-deceptions.  Incidentally, would you say that the Milgram experiment 
<br>
reveals that people &quot;really&quot; want to go along with authority?  I wouldn't 
<br>
read it that way at all.
<br>
<p><em>&gt; There are many possible mechanisms of self-deception, one of which is as 
</em><br>
<em>&gt; you describe.
</em><br>
<p>Yes.  It was a deliberate eleemosynary oversimplification of a complex 
<br>
system.  I've managed to introspectively catch rationalization mechanisms 
<br>
in four major classes so far:
<br>
<p>A:  Deliberate rationalization.
<br>
B:  Political rationalization supported by emotional mechanisms (of the 
<br>
type I described).
<br>
C:  Emergent outcomes of the interface between the pleasure-pain 
<br>
anticipation system and deliberation, possibly subject to evolutionary 
<br>
optimization for adaptive rationalization biases.
<br>
D:  Emergent outcomes of support recruitment mechanisms, again possible 
<br>
subject to evolutionary optimization of hereditary adaptively relevant 
<br>
information.
<br>
<p>A&amp;B are well-known, C&amp;D rather less so.
<br>
<p><em>&gt; The whole system of calculating actions from goals and 
</em><br>
<em>&gt; beliefs has many entry points for motivational bias.
</em><br>
<p>Not to blame you personally, but I think the idea of &quot;motivational biases&quot; 
<br>
is one of those amazingly oversimplified ideas in the philosophy of 
<br>
cognitive psychology.  I was familiar with the concept from old papers, 
<br>
but I'm surprised it's still around today.
<br>
<p>There are emotional biases which reinforce or disinforce specific thoughts 
<br>
based on how the emotions bind to the mental imagery in question - 
<br>
thoughts which are painful or pleasurable in complex ways, causing people 
<br>
to flinch away, or flinch toward them.
<br>
<p>There are biases which affect perceived truth, acting as support or 
<br>
antisupport.
<br>
<p>Evolutionary selection pressures will act on heritable variations that 
<br>
correlate with the outcome of adaptively relevant cognitive processes in 
<br>
arbitrary other ways.
<br>
<p>The idea that people's high-level, consciously held motivations have the 
<br>
ability to manipulate their internal information is naive.  People do not 
<br>
have that degree of reflective access; they are not seed AIs.  It is an 
<br>
extreme oversimplification of what is actually going on.  In fact, it is 
<br>
simply false.  You cannot deduce or attribute internal motivations in that 
<br>
way, and the real process is not one of intelligent planning at all 
<br>
(internal or external), but rather executing adaptations.
<br>
<p><em>&gt; Some of these 
</em><br>
<em>&gt; points are focused more on beliefs, others more on goals.  The system 
</em><br>
<em>&gt; also has many rich layers of protection from situations that might to 
</em><br>
<em>&gt; remove such bias.  We are much better at spotting self-deception in 
</em><br>
<em>&gt; others than in ourselves, because we have ways of avoiding looking at 
</em><br>
<em>&gt; the relevant evidence, and rationalizing it away when others point it out.
</em><br>
<p>&quot;We&quot; have ways?  Say rather that our cognitive processes contain 
<br>
tendencies to do so, some emergent, some adaptive, some that started as 
<br>
emergent but have now been evolutionary fixed.
<br>
<p><em>&gt; There are two classic ways to determine what people &quot;really&quot; want.  One 
</em><br>
<em>&gt; is based on &quot;happiness,&quot; the other on informed choice.  In your example, 
</em><br>
<em>&gt; the happiness metric asks if people are happier when they get 
</em><br>
<em>&gt; status/power versus when they actually do good for the tribe, without 
</em><br>
<em>&gt; getting such status/power.  The informed choice metric asks whether 
</em><br>
<em>&gt; people would choose status/power or good for the tribe if they were 
</em><br>
<em>&gt; briefly and privately informed, via enough evidence to typically be 
</em><br>
<em>&gt; persuasive to a neutral observer, that this is actually what they are 
</em><br>
<em>&gt; choosing between.  (I say briefly so that they can quickly forget the 
</em><br>
<em>&gt; conversation every happened and revert to the state where they actually 
</em><br>
<em>&gt; believe they are doing good for the tribe.)
</em><br>
<p>Why do you think the informed choice metric runs this way?  I would guess 
<br>
the opposite - that most people, asked to make a deliberate choice between 
<br>
status/power and the good of the tribe, would either choose the good of 
<br>
the tribe, or feel guilty about not doing so (implying that their 
<br>
renormalized volition would move in the direction of choosing the good of 
<br>
the tribe).
<br>
<p>Also, if you are talking about a major upheaval in the belief system there 
<br>
is no such thing as a &quot;briefly informed&quot; choice - you have to extrapolate 
<br>
major changes within the person's volition, including reactions to many 
<br>
different changes and compounded choices about those reactions.  Seeing 
<br>
evolution's puppet strings for the first time would be a wrenching 
<br>
upheaval if ever there was one.
<br>
<p>I would reject both metrics as adequate theories of volition or even 
<br>
instantaneous want, though the informed choice metric comes closer.
<br>
<p><em>&gt; My reading of human behavior in most of the contexts in which 
</em><br>
<em>&gt; self-deception is an issue is that most people are happier with the 
</em><br>
<em>&gt; status/power type option, versus the doing good for the tribe type 
</em><br>
<em>&gt; option, and that this is what they usually actually choose when briefly 
</em><br>
<em>&gt; and privately informed.  I agree that most people do believe that they 
</em><br>
<em>&gt; want to do good for the tribe.  My claim is that this belief is 
</em><br>
<em>&gt; relatively isolated and ineffectual; it is allowed to influence what 
</em><br>
<em>&gt; people say and some actions that influence social perceptions, but is 
</em><br>
<em>&gt; otherwise little used.
</em><br>
<p>What is the justification for taking such a dark view of things?  Why make 
<br>
this claim?  It is the sort of thing I would be very wary of if it 
<br>
appeared in my own mind, for reasons that are probably obvious to you as 
<br>
well.  The folk picture of people struggling between their high moral 
<br>
aspirations and their inner demons is, as far as I can tell, pretty much 
<br>
correct.  High moral aspirations motivate some people strongly and some 
<br>
people weakly - there is wide variation, certainly in final outcomes, 
<br>
probably even in innate strength - but they are far from the epiphenomena 
<br>
you seem to be describing.
<br>
<p>People die saving unrelated children.  Is that a lie?  It seems to me that 
<br>
the folk psychology of what goes through a person's head in that situation 
<br>
is probably essentially correct.  In many/most cases it will have nothing 
<br>
whatsoever to do with personal reputation, regardless of what the 
<br>
evolutionary selection pressure may derive from.  Individual organisms are 
<br>
adaptation-executers, not fitness-maximizers.  Evolutionary selection 
<br>
pressures do not necessarily translate directly into cognitively 
<br>
represented goals.  For linguistic political organisms there may be 
<br>
specific selection pressures *against* translating a selection pressure 
<br>
into a cognitively represented goal.
<br>
<p>My own claim is that if you asked people what they cared about, what 
<br>
mattered most to them, what kind of person they wanted to be, they would 
<br>
say that the altruism is the most important part of them.  Since that is 
<br>
what they tell me, why should I - or any friend of theirs - contradict 
<br>
them?  The deliberative system may sometimes be weak, but it is ultimately 
<br>
in charge - or at least is the center I look to, to determine how to find 
<br>
the &quot;person&quot; I want to &quot;help&quot;.
<br>
<p>When I look at a person, I tend to see the center of that person in the 
<br>
kind of final choices that control their words, or raises their hand, and 
<br>
so on.  It's not a perfect definition, but it's where I'd start looking. 
<br>
The one who takes control of the vocal cords and says to me &quot;I want to be 
<br>
a better person&quot;; that is the volition, that is the person I am talking to 
<br>
at that moment, and if I want to know which parts of the rest of the mind 
<br>
are worth talking to, I'll begin by asking that voice.
<br>
<p><em>&gt; Consider that today most people around here would say that the think the 
</em><br>
<em>&gt; world is their tribe, but they give almost no money to help poor people 
</em><br>
<em>&gt; in Africa, even when they believe that such aid would make the world a 
</em><br>
<em>&gt; better place overall.
</em><br>
<p>Then why am I, who know more of my own motives, who see more of puppet 
<br>
strings, more effectively altruistic and not less?  Was I born with an 
<br>
unusually large helping of altruistic emotions?  Why do I need to add this 
<br>
extra postulate, when being born with an unusually large helping of 
<br>
intelligence, into an era with an unancestral knowledge of evolutionary 
<br>
psychology, seems like a quite sufficient explanation?  (Though I should 
<br>
expect that people vary more widely from me than I expect - the consensus 
<br>
bias.)  How does your view of human psychology even *allow for* genuine 
<br>
dedicated altruists?
<br>
<p>The person I am talking to is the process that says &quot;The world is my 
<br>
tribe.&quot;  The cognitive mechanisms that produced that vocal output, that 
<br>
vocal decision, are where I begin to construct the definition of volition. 
<br>
&nbsp;&nbsp;Why should I begin anywhere else?
<br>
<p>My father has a doctorate in physics and is an Orthodox Jew.  He somehow 
<br>
manages not to see any conflict between the Big Bang and Darwin, and the 
<br>
Hexameron.  Human thoughts are too complicated, too fragile, and too weak 
<br>
for us to *expect* self-consistency or draw conclusions from its lack.  My 
<br>
father is neither &quot;not really an Orthodox Jew&quot;, nor &quot;not really a 
<br>
physicist&quot;.  He is simply grossly inconsistent.
<br>
<p>(Also, as has been described on this mailing list in the past, money sent 
<br>
to Africa appears to be incrementally futile.  Pick a different example?)
<br>
<p><em>&gt; When would you say that a corporation that consistently continues to 
</em><br>
<em>&gt; pollute, even though its PR denies it, &quot;really wants&quot; to not pollute?
</em><br>
<p>I wouldn't *use* the term &quot;want&quot; for a corporation.  I consider it a term 
<br>
of art in Friendly AI with respect to constructing an interpretation of 
<br>
someone's volition, and this term is not applicable to corporations, or 
<br>
would require tremendous reworking in order to be applicable.  Also the 
<br>
above does not seem to be a good example of self-deception, just simple 
<br>
deliberate lying.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11372.html">Hal Finney: "RE: Number of carbon atoms in the Earth's biomass"</a>
<li><strong>Previous message:</strong> <a href="11370.html">Extropian Agroforestry Ventures Inc.: "Re: Number of oxygen atoms in the Earth's biomass"</a>
<li><strong>In reply to:</strong> <a href="11368.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<li><strong>Reply:</strong> <a href="11373.html">Robin Hanson: "Re: Why Does Self-Discovery Require a Journey?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11371">[ date ]</a>
<a href="index.html#11371">[ thread ]</a>
<a href="subject.html#11371">[ subject ]</a>
<a href="author.html#11371">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Jul 11 2003 - 11:05:54 MDT
</em></small></p>
</body>
</html>
