<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Fermi &quot;Paradox&quot;</title>
<meta name="Author" content="Robert J. Bradbury (bradbury@aeiveos.com)">
<meta name="Subject" content="Re: Fermi &quot;Paradox&quot;">
<meta name="Date" content="2003-07-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Fermi &quot;Paradox&quot;</h1>
<!-- received="Tue Jul 22 09:16:33 2003" -->
<!-- isoreceived="20030722151633" -->
<!-- sent="Tue, 22 Jul 2003 08:16:31 -0700 (PDT)" -->
<!-- isosent="20030722151631" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Re: Fermi &quot;Paradox&quot;" -->
<!-- id="Pine.LNX.4.44.0307220746510.17144-100000@server.aeiveos.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="20030722070357.GA20864@akira.nada.kth.se" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robert J. Bradbury (<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20Fermi%20&quot;Paradox&quot;"><em>bradbury@aeiveos.com</em></a>)<br>
<strong>Date:</strong> Tue Jul 22 2003 - 09:16:31 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11841.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11839.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<li><strong>In reply to:</strong> <a href="11828.html">Anders Sandberg: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11847.html">Kevin Freels: "Re: Fermi &quot;Paradox&quot;"</a>
<li><strong>Reply:</strong> <a href="11847.html">Kevin Freels: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11840">[ date ]</a>
<a href="index.html#11840">[ thread ]</a>
<a href="subject.html#11840">[ subject ]</a>
<a href="author.html#11840">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Tue, 22 Jul 2003, Anders Sandberg wrote:
<br>
<p><em>&gt; The problem lies in determining whether the die out account or the
</em><br>
<em>&gt; become invisible account is true.
</em><br>
<p>Perhaps neither -- you have to allow that ATC can *see* &quot;everything&quot;.
<br>
<p>As I point out in the MBrains paper -- 100 billion telescopes the
<br>
diameter of the moon are well within the reach of an ATC.
<br>
<p>Given speed-of-light delays limiting foresight are you going to
<br>
expend a lot of resources going someplace only to get there and
<br>
find it already occupied?
<br>
<p><em>&gt; Historical evidence doesn't tell us much, since the rise and fall of
</em><br>
<em>&gt; civilisations on average has not had much effect on humanity as a whole.
</em><br>
<em>&gt; It is now when civilisations become global that the risks go up for
</em><br>
<em>&gt; permanent failures.
</em><br>
<p>It is very difficult to eliminate ATC that have gotten to our level.
<br>
There are thousands of people in submarines with nuclear power as an
<br>
energy resource would likely survive a GRB -- and then there are the
<br>
people within Cheyenne Mountain and similar facilities.
<br>
<p>And then there is the rapid evolution of humanity -- a few million
<br>
years (and we know that multiple experiments were being conducted
<br>
in the primate lineage during the period).  Knock us back down to
<br>
the chimpanzee level -- reasonably good odds nature would reivent us.
<br>
<p><p><em>&gt; But it is not enough to assume that the probability
</em><br>
<em>&gt; of civilisation crashing is high; it has to be so high that it results
</em><br>
<em>&gt; in *no* expanding starfarers.
</em><br>
<p>They don't have to &quot;crash&quot; -- all advanced civilizations can simply reach
<br>
the conclusion that there is *no point* to expansion.  The reason that
<br>
humans colonize is to have more resources for replication -- once one
<br>
realizes that replication (beyond limited forms of self-replication that
<br>
which allows one to trump the galactic hazard function) is pointless
<br>
then one would logically stop doing it.
<br>
<p><em>&gt; Given the awesome multiplicative power of
</em><br>
<em>&gt; even simple self-replication, once a civilisation can start sending out
</em><br>
<em>&gt; large numbers it is very hard to get rid of it.
</em><br>
<p>It is easy to produce lots of &quot;simple&quot; self-replicators -- but it isn't
<br>
a good idea to do so.  At least some of the bacteria in my gut would
<br>
attempt to consume me if they could get around my immune system.  Better
<br>
not to give then lots of opportunities to do so.
<br>
<p>&quot;Complex&quot;, and more importantly &quot;trustable&quot;, self-replicators may be a
<br>
very difficult problem.  Do you *really* want to be standing toe-to-toe
<br>
with a copy of yourself when the resources of the universe start drying
<br>
up *knowing* that they know exactly what you know and you both know
<br>
&quot;there can be only one&quot; (to steal a line from The Highlander)...
<br>
<p><em>&gt; &quot;(//((! Have you seen the new gamma ray burster in the Milky Way?&quot;
</em><br>
<em>&gt; &quot;Yes /||\, I have. I hope there were no intelligent life around there.&quot;
</em><br>
<em>&gt; &quot;We will know when we send out or probes...&quot;
</em><br>
<p>There seems to be a reasonable argument for the &quot;galactic club&quot; enforcing
<br>
a &quot;Thou shalt not send out self-replicating probes&quot; interdiction -- because
<br>
any advanced civilization isn't going to want to deal with the problems
<br>
they create in the future.
<br>
<p><em>&gt; But in general I think we are lacking something in the philosophy of the
</em><br>
<em>&gt; Fermi paradox. We need to think better here.
</em><br>
<p>I think it relates to the transition from a &quot;randomly evolved&quot; intelligence
<br>
(i.e. mutation and &quot;natural&quot; selection) into a &quot;self-directed&quot; evolutionary
<br>
process intelligence.
<br>
<p>Question -- if you knew you were likely to survive until the &quot;end of the universe&quot;
<br>
with high probability -- would you actively seek to create future problems that
<br>
you would eventually have to deal with?
<br>
<p>I don't think I would.
<br>
<p>Robert
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11841.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<li><strong>Previous message:</strong> <a href="11839.html">Bryan Moss: "Re: Optimism [Was: flame wars]"</a>
<li><strong>In reply to:</strong> <a href="11828.html">Anders Sandberg: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11847.html">Kevin Freels: "Re: Fermi &quot;Paradox&quot;"</a>
<li><strong>Reply:</strong> <a href="11847.html">Kevin Freels: "Re: Fermi &quot;Paradox&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11840">[ date ]</a>
<a href="index.html#11840">[ thread ]</a>
<a href="subject.html#11840">[ subject ]</a>
<a href="author.html#11840">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Jul 22 2003 - 09:24:30 MDT
</em></small></p>
</body>
</html>
