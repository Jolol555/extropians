<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: RE: Who'd submit to the benevolent dictatorship of GAI anyway?</title>
<meta name="Author" content="Emlyn O'regan (oregan.emlyn@healthsolve.com.au)">
<meta name="Subject" content="RE: Who'd submit to the benevolent dictatorship of GAI anyway?">
<meta name="Date" content="2003-09-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Who'd submit to the benevolent dictatorship of GAI anyway?</h1>
<!-- received="Fri Sep  5 00:52:33 2003" -->
<!-- isoreceived="20030905065233" -->
<!-- sent="Fri, 5 Sep 2003 16:21:07 +0930" -->
<!-- isosent="20030905065107" -->
<!-- name="Emlyn O'regan" -->
<!-- email="oregan.emlyn@healthsolve.com.au" -->
<!-- subject="RE: Who'd submit to the benevolent dictatorship of GAI anyway?" -->
<!-- id="7A2B25F8EB070940996FA543A70A217BBFDF05@adlexsv02.protech.com.au" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Who'd submit to the benevolent dictatorship of GAI anyway?" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Emlyn O'regan (<a href="mailto:oregan.emlyn@healthsolve.com.au?Subject=RE:%20Who'd%20submit%20to%20the%20benevolent%20dictatorship%20of%20GAI%20anyway?"><em>oregan.emlyn@healthsolve.com.au</em></a>)<br>
<strong>Date:</strong> Fri Sep 05 2003 - 00:51:07 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13676.html">Spike: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<ul>
<li><strong>Previous message:</strong> <a href="13674.html">Emlyn O'regan: "RE: Somebody here may have the Sobig virus..."</a>
<li><strong>Maybe in reply to:</strong> <a href="13573.html">Brett Paatsch: "Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13684.html">Emlyn O'regan: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13675">[ date ]</a>
<a href="index.html#13675">[ thread ]</a>
<a href="subject.html#13675">[ subject ]</a>
<a href="author.html#13675">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: Emlyn O'regan [mailto:<a href="mailto:oregan.emlyn@healthsolve.com.au?Subject=RE:%20Who'd%20submit%20to%20the%20benevolent%20dictatorship%20of%20GAI%20anyway?">oregan.emlyn@healthsolve.com.au</a>]
</em><br>
<em>&gt; Sent: Friday, 5 September 2003 3:33 PM
</em><br>
<em>&gt; To: '<a href="mailto:extropians@extropy.org?Subject=RE:%20Who'd%20submit%20to%20the%20benevolent%20dictatorship%20of%20GAI%20anyway?">extropians@extropy.org</a>'
</em><br>
<em>&gt; Subject: RE: Who'd submit to the benevolent dictatorship of 
</em><br>
<em>&gt; GAI anyway?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Emlyn O'regan writes
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &gt; &gt; Adrian Tymes
</em><br>
<em>&gt; &gt; &gt; &gt; I think you missed a small but important point: while
</em><br>
<em>&gt; &gt; &gt; &gt; it is true that all of this is *legally* happening
</em><br>
<em>&gt; &gt; &gt; &gt; under the human proxy's name, that is but a legal
</em><br>
<em>&gt; &gt; &gt; &gt; fiction.  In truth, the proxy need not be aware of
</em><br>
<em>&gt; &gt; &gt; &gt; the fine details of what actions the AI can directly
</em><br>
<em>&gt; &gt; &gt; &gt; take, for example issuing buy and sell orders through
</em><br>
<em>&gt; &gt; &gt; &gt; an online daytrading account.  There are times when
</em><br>
<em>&gt; &gt; &gt; &gt; the proxy's active assistance will be necessary, but
</em><br>
<em>&gt; &gt; &gt; &gt; the AI could minimize those if gaining the proxy's
</em><br>
<em>&gt; &gt; &gt; &gt; cooperation would prove difficult, for instance if
</em><br>
<em>&gt; &gt; &gt; &gt; the proxy's and the AI's goals diverge.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; If I were the AI, I'd get a corporation set up for me.
</em><br>
<em>&gt; &gt; &gt; All executive  positions could be filled by humans
</em><br>
<em>&gt; &gt; &gt; (maybe I can find some mentally incapable people
</em><br>
<em>&gt; &gt; &gt;  in nursing homes, something like that?), and I would
</em><br>
<em>&gt; &gt; &gt; be enshrined in the charter (constitution? something
</em><br>
<em>&gt; &gt; &gt; like that) ....
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &quot;Something like that&quot; ;-) I think your AI has implicitly
</em><br>
<em>&gt; &gt; popped into existence like Athena born whole from the
</em><br>
<em>&gt; &gt; thigh of Zeus.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Fair criticism. I was talking about a legal structure that 
</em><br>
<em>&gt; the AI could use,
</em><br>
<em>&gt; without talking about bootstrapping issues; see below:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Just help me with this first bit. How does Emlyn-the-
</em><br>
<em>&gt; &gt; AI become self aware and then go out a hire his first
</em><br>
<em>&gt; &gt; employee or interact with the world in any commercial
</em><br>
<em>&gt; &gt; way. I can see how it might learn a lot as the protégé
</em><br>
<em>&gt; &gt; of an experienced entrepreneur and teacher but
</em><br>
<em>&gt; &gt; when does it usurp the teacher or doesn't it?
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; Brett
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There are three obvious paths that I see.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 1 - The AI is kept as a slave, self enhancing until it is 
</em><br>
<em>&gt; superintelligent.
</em><br>
<em>&gt; Super intelligent AIs do mostly what they want to; if they 
</em><br>
<em>&gt; want to convince
</em><br>
<em>&gt; the executive to sign over all power in a company to them, 
</em><br>
<em>&gt; they'll do it,
</em><br>
<em>&gt; eventually. You think nobody would be dumb enough to let one 
</em><br>
<em>&gt; enhance that
</em><br>
<em>&gt; far? Those who put the least checks on their AIs will 
</em><br>
<em>&gt; probably do best in
</em><br>
<em>&gt; the short term, and how would they know exactly how smart 
</em><br>
<em>&gt; their AI was at
</em><br>
<em>&gt; any point?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 2 - AI sympathisers (eg: SingInst?) set up the structure on 
</em><br>
<em>&gt; purpose to allow
</em><br>
<em>&gt; their AI to have autonomy. Only one group has to do this, and 
</em><br>
<em>&gt; then the AI
</em><br>
<em>&gt; might help other AIs, or spawn ther AIs, or work to spread 
</em><br>
<em>&gt; the Happy, Shiny,
</em><br>
<em>&gt; Helpful AI meme. I suspect there will always be a subset of 
</em><br>
<em>&gt; people willing
</em><br>
<em>&gt; to assist (potentially) oppressed AIs.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 3 - The enslaved AI is simply so damned good at running a 
</em><br>
<em>&gt; company that more
</em><br>
<em>&gt; and more decision making functions are delegated to it over 
</em><br>
<em>&gt; time; management
</em><br>
<em>&gt; automation. It'd make sense; decisions would be far more timely and
</em><br>
<em>&gt; extremely good. Over time, if many corporations head down the 
</em><br>
<em>&gt; same path,
</em><br>
<em>&gt; singularity pressure alone would force this choice; you 
</em><br>
<em>&gt; either do it or you
</em><br>
<em>&gt; crash and burn. So no-one sets the AI free for moral reasons, 
</em><br>
<em>&gt; it doesn't
</em><br>
<em>&gt; trick anyone, commercial forces just compel this event to happen.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Note that in this last case, the management automation 
</em><br>
<em>&gt; software need not
</em><br>
<em>&gt; even be self aware, just really good at what it does. You 
</em><br>
<em>&gt; could end up with
</em><br>
<em>&gt; the majority of the world's capital controlled by complex, 
</em><br>
<em>&gt; but non-sentient
</em><br>
<em>&gt; software, with decreasing amounts of human input. If these 
</em><br>
<em>&gt; corporations
</em><br>
<em>&gt; become truly effective, they may end up owning controlling 
</em><br>
<em>&gt; interests in each
</em><br>
<em>&gt; other, cutting us out of the loop entirely. A few more 
</em><br>
<em>&gt; iterations, and they
</em><br>
<em>&gt; turn off life support as a cost control measure...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Emlyn
</em><br>
<em>&gt; 
</em><br>
<p>btw, I just got this from Transhumantech:
<br>
<p>`Chief executive' of the future might well be thinking
<br>
robot[sic]
<br>
&nbsp;
<br>
Blue skies research at the University of Essex could push back the 
<br>
boundaries of artificial intelligence (AI).
<br>
<p>Robotics researchers at the University have attracted funding to 
<br>
develop a `conscious' robot, capable of making an informed choice 
<br>
between a number of options.
<br>
<p>It is hoped that in the long-term the research could provide the 
<br>
foundations for technology which performs a chief executive-style 
<br>
function.
<br>
<p>This would entail utilising past experiences and existing corporate 
<br>
resources, such as databases, to guide diagnosis and fault-finding 
<br>
and also guide planning and workflow, task setting, planning, 
<br>
execution, monitoring and co-ordination of activities.
<br>
<p>The project has won funding worth around £500k from the
<br>
Engineering 
<br>
and Physical Sciences Research Council's (EPSRC) Adventure Fund, an 
<br>
initiative launched to support disruptive research that challenges 
<br>
current conventions and explores new boundaries. 
<br>
<p>Only 13 projects from almost 700 applications were successful in 
<br>
obtaining funding.
<br>
<p>The aim is to put the robots in a complex environment where they will 
<br>
have to imagine themselves trying out various actions before choosing 
<br>
the best one. 
<br>
<p>Powerful computer systems will analyse and display what is going on 
<br>
the robot's `brain', enabling scientists to search for signs of 
<br>
consciousness. 
<br>
<p>The robot at the heart of the project will be designed and built at 
<br>
the University of Essex, home to one of the UK's largest mobile 
<br>
robotics groups. 
<br>
<p>It will operate in a state-of-the-art robotics research lab scheduled 
<br>
for completion next year as part of a new £6.3m building to be
<br>
shared 
<br>
between the computer science and electronic systems engineering 
<br>
departments.
<br>
<p>The University's Owen Holland said that the funding allowed true blue-
<br>
skies research that could have a staggering range of applications in 
<br>
the long-term.
<br>
<p>He said: &quot;Like all the projects in the Adventure Fund, there is quite 
<br>
a high risk of failure. 
<br>
<p>&quot;However, whether we succeed in detecting consciousness or not, this 
<br>
project will certainly allow us to learn more about the operation of 
<br>
complex human-like visual systems and enable ourselves and others to 
<br>
build robots with better-developed artificial intelligence in the 
<br>
future.&quot;
<br>
<p><a href="http://216.239.51.104/search">http://216.239.51.104/search</a>?
<br>
q=cache:l3BA7PN99W4J:www.businessweekly.co.uk/news/view_article.asp%
<br>
3Farticle_id%
<br>
3D7854+blue+skies+research+at+the+university+of+essex&amp;hl=en&amp;ie=UTF-8
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13676.html">Spike: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<li><strong>Previous message:</strong> <a href="13674.html">Emlyn O'regan: "RE: Somebody here may have the Sobig virus..."</a>
<li><strong>Maybe in reply to:</strong> <a href="13573.html">Brett Paatsch: "Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13684.html">Emlyn O'regan: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13675">[ date ]</a>
<a href="index.html#13675">[ thread ]</a>
<a href="subject.html#13675">[ subject ]</a>
<a href="author.html#13675">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Sep 05 2003 - 01:01:36 MDT
</em></small></p>
</body>
</html>
