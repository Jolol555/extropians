<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Who'd submit to the benevolent dictatorship of GAI anyway?</title>
<meta name="Author" content="Brett Paatsch (bpaatsch@bigpond.net.au)">
<meta name="Subject" content="Re: Who'd submit to the benevolent dictatorship of GAI anyway?">
<meta name="Date" content="2003-09-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Who'd submit to the benevolent dictatorship of GAI anyway?</h1>
<!-- received="Thu Sep  4 23:09:11 2003" -->
<!-- isoreceived="20030905050911" -->
<!-- sent="Fri, 05 Sep 2003 15:09:17 +1000" -->
<!-- isosent="20030905050917" -->
<!-- name="Brett Paatsch" -->
<!-- email="bpaatsch@bigpond.net.au" -->
<!-- subject="Re: Who'd submit to the benevolent dictatorship of GAI anyway?" -->
<!-- id="020301c3736b$db861bc0$11262dcb@vic.bigpond.net.au" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Pine.LNX.4.44.0309040905320.20418-100000@server.aeiveos.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brett Paatsch (<a href="mailto:bpaatsch@bigpond.net.au?Subject=Re:%20Who'd%20submit%20to%20the%20benevolent%20dictatorship%20of%20GAI%20anyway?"><em>bpaatsch@bigpond.net.au</em></a>)<br>
<strong>Date:</strong> Thu Sep 04 2003 - 23:09:17 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13663.html">Brett Paatsch: "Re: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<ul>
<li><strong>Previous message:</strong> <a href="13661.html">Emlyn O'regan: "RE: Is theft becoming impossible?"</a>
<li><strong>In reply to:</strong> <a href="13639.html">Robert J. Bradbury: "Re: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13660.html">Spike: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13662">[ date ]</a>
<a href="index.html#13662">[ thread ]</a>
<a href="subject.html#13662">[ subject ]</a>
<a href="author.html#13662">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robert J. Bradbury writes: 
<br>
&nbsp;
<br>
<em>&gt; On Fri, 5 Sep 2003, Brett Paatsch wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; [snip] But if folks will go out of their way to vote just
</em><br>
<em>&gt; &gt; to keep people they don't like out of power and if they
</em><br>
<em>&gt; &gt; are already concerned about jobs, how is it that the 
</em><br>
<em>&gt; &gt; AI with its human proxies (who'd also be massive 
</em><br>
<em>&gt; &gt; beneficiaries of its wealth creation strategies and ability
</em><br>
<em>&gt; &gt; to draw better future maps etc) would not evoke a huge
</em><br>
<em>&gt; &gt;  backlash?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Brett, it depends to some extent on whether AI and 
</em><br>
<em>&gt; nanotech coevolve. AI+Nanotech allows people to live
</em><br>
<em>&gt; essentially for &quot;free&quot; (perhaps even advanced biotech can
</em><br>
<em>&gt; pull that rabbit out of the hat).  
</em><br>
<p>Theoretically and potentially free maybe, but that is not the
<br>
only possible future some folks envision when they think of
<br>
AI and Nanotech. Eg. Terminator 3 and Michael Creighton's
<br>
Prey.  
<br>
<p><em>&gt; AIs alone --  if they are &quot;owned&quot; (now we get to start an
</em><br>
<em>&gt; AI &quot;slavery&quot; discussion) and  skilled and in demand might
</em><br>
<em>&gt; allow one to live for free as well. 
</em><br>
<p>Hmm, depends whom they are owned by doesn't it. My picture
<br>
of corporate mindsets is that they are not only concerned with
<br>
current profits but with future profits and like to think in terms
<br>
of return on investment and how much of the market share of
<br>
the market potential they may capture. A competitor corp with
<br>
an AI may be a hair raiser for a corporation that sees its potential
<br>
market growth suddenly looking to be competed away.
<br>
<p>Now take the thinking up a notch. Politicians like to give their
<br>
constituents jobs, countries that can own AI first and compete
<br>
internationally can bring more of the wealth home. AI may 
<br>
potentially create the means to allow one (or even all to live free)
<br>
but is that the potential future that is *likely* to emerge given
<br>
that some folks, individuals, groups, corporations, or governents
<br>
are likely to see their investment in these enabling technologies as
<br>
their means of ensuring a standard of living for their own
<br>
constituents.  Big tech jumps seem to start of technological arms
<br>
race. 
<br>
&nbsp;
<br>
<em>&gt; Alternatively, nanotech  alone, if there are a sufficient number
</em><br>
<em>&gt; of nanotechnologists and/or computers doing the design work
</em><br>
<em>&gt; might allow one to live for free.  So there need not be a
</em><br>
<em>&gt; &quot;huge backlash&quot;.
</em><br>
<p>Agree there need not need be. But I think its a good idea to
<br>
consider what the *likely* emergence of such tech in the hands
<br>
of some but not all is going to be politically, and economically, 
<br>
not just what it might or could be ideally. 
<br>
<p>Ideally relatively safe nuclear power have been welcomed as
<br>
a great thing too.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; I also tend to disagree that one needs human proxies to
</em><br>
<em>&gt; support most AI work.  One does need the computer
</em><br>
<em>&gt; resources and interfaces to reality but after that I think 
</em><br>
<em>&gt; humans are out of the loop. 
</em><br>
<p>Ah now were into legal issues like who can be your agent
<br>
and to whom you can't grant power of attorney. Clearly
<br>
no one yet has granted agency or power of attorney to
<br>
a non biological AI. The law isn't ready imo.
<br>
<p><em>&gt; I only need to interface my AI to my bank and/or broker 
</em><br>
<em>&gt; accounts and then after that I can ignore it except to check
</em><br>
<em>&gt; up on things from time to time.  Of course one has to trust
</em><br>
<em>&gt; the AI and the interfaces but one would hope we are
</em><br>
<em>&gt; getting better at developing such things.
</em><br>
<p>I think we are and willl get better but the issue is partly how 
<br>
and at what rate. The point above is that the people your
<br>
AI is dealing with may not be willing to accept it as your
<br>
agent or acknowledge its has power of attorney for you. 
<br>
<p>&nbsp;
<br>
<em>&gt; However there are significant risks that arise if an amoral
</em><br>
<em>&gt; AI cracks a virtual private network -- such as the Kazaa
</em><br>
<em>&gt; network and installs itself on millions of machines.  The last
</em><br>
<em>&gt; month has clear demonstrated that security holes provide
</em><br>
<em>&gt; the means for viruses and worms to capture millions of 
</em><br>
<em>&gt; machines in a brief period of time.
</em><br>
<p>Yup. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; How long before someone produces an evolving virus/worm,
</em><br>
<em>&gt; perhaps akin to the various evolving SPAM messages, that
</em><br>
<em>&gt; can defeat the anti-virus filters?  Put an amoral AI on top of
</em><br>
<em>&gt; that and you potentially have a *real* problem.  
</em><br>
<p>This is a good technical question for the AI buffs. What sort of
<br>
threat is this really. How highly should we factor this risk. It
<br>
would seem to me that a modern military that takes war as far
<br>
as have psychological warfare as a specialty and has internet
<br>
specialty teams is already moving in that  risk space to some
<br>
degree. Note it is not necessary to posit a malevolent government
<br>
to posit a government concerns with the economic and military
<br>
consequences of technolgy used against it.
<br>
<p><em>&gt; One way to look at the script-kiddies of today is
</em><br>
<em>&gt; to view them as really limited AIs.  So look at the problems 
</em><br>
<em>&gt; they cause and then imagine what happens if they transfer their
</em><br>
<em>&gt; limited intelligence into the millions of machines that are 
</em><br>
<em>&gt; vulnerable.
</em><br>
<p>Or take it up a coupla notches and don't think mischievous kiddies
<br>
but think patriotic dedicated military planners and government 
<br>
agencies concerned to forge the best possible standards of living
<br>
for their citizens. It has not escaped my attention that the vernacular
<br>
of many strategic marketers is almost the same as the vernacular of
<br>
war.
<br>
<p>Regards,
<br>
Brett
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13663.html">Brett Paatsch: "Re: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<li><strong>Previous message:</strong> <a href="13661.html">Emlyn O'regan: "RE: Is theft becoming impossible?"</a>
<li><strong>In reply to:</strong> <a href="13639.html">Robert J. Bradbury: "Re: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13660.html">Spike: "RE: Who'd submit to the benevolent dictatorship of GAI anyway?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13662">[ date ]</a>
<a href="index.html#13662">[ thread ]</a>
<a href="subject.html#13662">[ subject ]</a>
<a href="author.html#13662">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Thu Sep 04 2003 - 23:20:37 MDT
</em></small></p>
</body>
</html>
