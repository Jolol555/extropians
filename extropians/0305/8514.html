<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Status of Superrationality (was Left/Right... can't we do better than this?)</title>
<meta name="Author" content="Hal Finney (hal@finney.org)">
<meta name="Subject" content="Re: Status of Superrationality (was Left/Right... can't we do better than this?)">
<meta name="Date" content="2003-05-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Status of Superrationality (was Left/Right... can't we do better than this?)</h1>
<!-- received="Tue May 20 12:31:12 2003" -->
<!-- isoreceived="20030520183112" -->
<!-- sent="Tue, 20 May 2003 11:30:14 -0700" -->
<!-- isosent="20030520183014" -->
<!-- name="Hal Finney" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Status of Superrationality (was Left/Right... can't we do better than this?)" -->
<!-- id="200305201830.h4KIUEL13331@finney.org" -->
<!-- inreplyto="Status of Superrationality (was Left/Right... can't we do better than this?)" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Hal Finney (<a href="mailto:hal@finney.org?Subject=Re:%20Status%20of%20Superrationality%20(was%20Left/Right...%20can't%20we%20do%20better%20than%20this?)"><em>hal@finney.org</em></a>)<br>
<strong>Date:</strong> Tue May 20 2003 - 12:30:14 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8515.html">Doug Thayer: "Re: &quot;liberal media&quot;"</a>
<ul>
<li><strong>Previous message:</strong> <a href="8513.html">Dehede011@aol.com: "Re: Long term self-protection [was Re: BIAS: CNN commits fraud...]"</a>
<li><strong>Maybe in reply to:</strong> <a href="8386.html">Lee Corbin: "Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8517.html">Eliezer S. Yudkowsky: "Re: Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<li><strong>Reply:</strong> <a href="8517.html">Eliezer S. Yudkowsky: "Re: Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<li><strong>Reply:</strong> <a href="8530.html">Lee Corbin: "RE: Status of Superrationality"</a>
<li><strong>Reply:</strong> <a href="8699.html">Wei Dai: "Re: Status of Superrationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8514">[ date ]</a>
<a href="index.html#8514">[ thread ]</a>
<a href="subject.html#8514">[ subject ]</a>
<a href="author.html#8514">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
A few quick comments:
<br>
<p>First, with regard to time travel and playing against your self from
<br>
the past, it must not be the case that you remember playing against the
<br>
future version of yourself, or else you would remember how the future
<br>
you had played, which would produce a free will paradox.  Therefore you
<br>
must not remember the specifics of your past play.  There should be some
<br>
uncertainty about how your past self will behave, unless you were such
<br>
as to always play the game in a completely predictable fashion.
<br>
<p>Second, an altruist could play against a selfist if the payoffs were
<br>
set up something like this:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Selfist Cooperate              Selfist Defect
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--------------------------------------------------------
<br>
Altruist Cooperate   |  Everyone in the world     |  Everyone in the world
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|  gains $5                  |  loses $10 except selfist,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|                            |  who gains $10.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-----------------------------+---------------------------
<br>
Altruist Defect      |  Everyone in the world     |  Status quo; no gain, no
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|  gains $10 except selfist, |  loss
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|  who loses $10             |
<br>
<p>The question is whether the altruist would defect in this situation.
<br>
<p>I was trying to set up a PD scenario between two rational altruists,
<br>
but it is hard since they are both motivated the same way, to increase
<br>
the total happiness of the world.  The only thing that could lead to
<br>
a difference in payoff for a particular outcome is disagreement about
<br>
how happy it would or does make people.  For example, supposed Eliezer
<br>
believed that average happiness were what mattered, while Lee believed
<br>
that total happiness were more important.  Then an outcome which increased
<br>
the population while making them more unhappy might be rated highly by
<br>
Lee but low by Eliezer.  Or suppose that Eliezer believed that &quot;friendly&quot;
<br>
AI would lead to a utopia, while Lee believed that any such effort would
<br>
inevitably destroy the world; again, an outcome which increased the
<br>
chance of this technology would be rated differently by the two altruists.
<br>
<p>However, these hypotheticals don't really work, because rational people
<br>
can't disagree!  See our previous discussion on this issue.  So I think
<br>
that for rational altruists, all 2-person games have identical payoffs
<br>
to both individuals, making them in effect one person games.
<br>
<p>A final point; Eliezer points out that the &quot;irrational&quot; action of
<br>
cooperating leads to a greater payoff.  I believe the consensus
<br>
among game theorists is that this does not change the fact that it
<br>
is irrational.  The reasoning is similar to that in Newcomb's paradox
<br>
(take one box or two, but God has arranged that you will get more money
<br>
if you take only one box).  Taking two boxes physically entails getting
<br>
at least as much as in the first box, hence it is the rational action.
<br>
In this paradox, as well, being irrational leads to a greater outcome.
<br>
I copied out some analysis on this issue from a decision theory book at
<br>
<a href="http://www.finney.org/~hal/Newcomb.html">http://www.finney.org/~hal/Newcomb.html</a>.  The argument doesn't go over
<br>
directly to the PD case, but the flavor is the same: it is possible for
<br>
an irrational action to lead to a greater outcome.
<br>
<p>Hal
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8515.html">Doug Thayer: "Re: &quot;liberal media&quot;"</a>
<li><strong>Previous message:</strong> <a href="8513.html">Dehede011@aol.com: "Re: Long term self-protection [was Re: BIAS: CNN commits fraud...]"</a>
<li><strong>Maybe in reply to:</strong> <a href="8386.html">Lee Corbin: "Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8517.html">Eliezer S. Yudkowsky: "Re: Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<li><strong>Reply:</strong> <a href="8517.html">Eliezer S. Yudkowsky: "Re: Status of Superrationality (was Left/Right... can't we do better than this?)"</a>
<li><strong>Reply:</strong> <a href="8530.html">Lee Corbin: "RE: Status of Superrationality"</a>
<li><strong>Reply:</strong> <a href="8699.html">Wei Dai: "Re: Status of Superrationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8514">[ date ]</a>
<a href="index.html#8514">[ thread ]</a>
<a href="subject.html#8514">[ subject ]</a>
<a href="author.html#8514">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue May 20 2003 - 12:43:17 MDT
</em></small></p>
</body>
</html>
