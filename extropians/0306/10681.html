<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: RE: The Future of Secrecy</title>
<meta name="Author" content="Rafal Smigrodzki (rafal@smigrodzki.org)">
<meta name="Subject" content="RE: The Future of Secrecy">
<meta name="Date" content="2003-06-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: The Future of Secrecy</h1>
<!-- received="Fri Jun 20 15:09:46 2003" -->
<!-- isoreceived="20030620210946" -->
<!-- sent="Fri, 20 Jun 2003 17:03:58 -0700" -->
<!-- isosent="20030621000358" -->
<!-- name="Rafal Smigrodzki" -->
<!-- email="rafal@smigrodzki.org" -->
<!-- subject="RE: The Future of Secrecy" -->
<!-- id="OJEHKDIANIFPAJPDBDGLIEHFCFAA.rafal@smigrodzki.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="5.2.1.1.2.20030620151719.01d2c370@mail.gmu.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Rafal Smigrodzki (<a href="mailto:rafal@smigrodzki.org?Subject=RE:%20The%20Future%20of%20Secrecy"><em>rafal@smigrodzki.org</em></a>)<br>
<strong>Date:</strong> Fri Jun 20 2003 - 18:03:58 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10682.html">Brett Paatsch: "Harvard, MIT Team Up to Explore Genomic Frontier"</a>
<ul>
<li><strong>Previous message:</strong> <a href="10680.html">natashavita@earthlink.net: "RE: The Future of Secrecy"</a>
<li><strong>In reply to:</strong> <a href="10673.html">Robin Hanson: "RE: The Future of Secrecy"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10678.html">Ramez Naam: "RE: The Future of Secrecy"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10681">[ date ]</a>
<a href="index.html#10681">[ thread ]</a>
<a href="subject.html#10681">[ subject ]</a>
<a href="author.html#10681">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin wrote:
<br>
<p><em>&gt;
</em><br>
<em>&gt; Even when creatures share many design elements, I expect much
</em><br>
<em>&gt; larger differences in raw abilities than among humans today.  I
</em><br>
<em>&gt; expect minds to vary by many orders of magnitudes of speed, memory,
</em><br>
<em>&gt; etc, and bodies to very greatly by the environment they are most
</em><br>
<em>&gt; suited for.  And minds will vary more in how much they know about
</em><br>
<em>&gt; and have specialized software for particular topics.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Thus we cannot remotely hope for peace via similarity.  If your
</em><br>
<em>&gt; favored route to keeping the peace today is via people noticing
</em><br>
<em>&gt; how similar people are, and using political systems that ignore
</em><br>
<em>&gt; differences, you'd better accept that this approach cannot last.
</em><br>
<em>&gt; Of course we might hope for peace via rationality and self-interest.
</em><br>
<em>&gt;
</em><br>
### The idea of universality of ethics (even if it means paring it down to
<br>
the most limited set of rules), as well as the concept of reciprocity among
<br>
moral agents equally endowed with basic rights, have been the bedrock of
<br>
most ethical philosophizing since the very beginning (with the exception of
<br>
aberrations as environmentalism and some flavors of animal rights
<br>
movements). It was tenable as long as all sentients were reasonably similar
<br>
but as you point out, the appearance of radically different structures will
<br>
put these ideas to the test. The concept of the Friendly AI is skirting the
<br>
problem, assuming that the FAI will never become an independent moral actor
<br>
(as long as the supergoal of Friendliness guides its behavior), although it
<br>
will be an independent moral philosopher. The problems posed by the
<br>
coexistence of radically enhanced uploads and unchanged humans will have an
<br>
even higher level of complexity. The den Otters of this world see it as a
<br>
harbinger of a brutal struggle, with the strong destroying the weak. After
<br>
all, rationality and self interest could prompt some of the top-level
<br>
cooperators (capable of verifying each other's reliability in cooperation)
<br>
to decide that minds below a certain level will not be afforded any rights
<br>
(not even self-ownership, or autonomy). Today, many of us tend to treat a
<br>
person's behavior towards beings weaker than him as a litmus test for future
<br>
cooperation - somebody who kicks his dog might kick us if given more power.
<br>
This rewards benevolent behavior towards entities which differ from us. Yet,
<br>
the cooperators capable of directly verifying reciprocal honesty would not
<br>
need to rely on such proxy measures - and maybe, as den Otter imagines,
<br>
would stomp on things lower down on the ladder of complexity. Is this a real
<br>
danger?
<br>
<p>Rafal
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10682.html">Brett Paatsch: "Harvard, MIT Team Up to Explore Genomic Frontier"</a>
<li><strong>Previous message:</strong> <a href="10680.html">natashavita@earthlink.net: "RE: The Future of Secrecy"</a>
<li><strong>In reply to:</strong> <a href="10673.html">Robin Hanson: "RE: The Future of Secrecy"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10678.html">Ramez Naam: "RE: The Future of Secrecy"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10681">[ date ]</a>
<a href="index.html#10681">[ thread ]</a>
<a href="subject.html#10681">[ subject ]</a>
<a href="author.html#10681">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Fri Jun 20 2003 - 15:19:42 MDT
</em></small></p>
</body>
</html>
