<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: greatest threats to survival (was: why believe the truth?)</title>
<meta name="Author" content="Anders Sandberg (asa@nada.kth.se)">
<meta name="Subject" content="Re: greatest threats to survival (was: why believe the truth?)">
<meta name="Date" content="2003-06-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: greatest threats to survival (was: why believe the truth?)</h1>
<!-- received="Thu Jun 19 08:31:32 2003" -->
<!-- isoreceived="20030619143132" -->
<!-- sent="Thu, 19 Jun 2003 16:35:20 +0200" -->
<!-- isosent="20030619143520" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: greatest threats to survival (was: why believe the truth?)" -->
<!-- id="20030619143520.GA22064@akira.nada.kth.se" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="OJEHKDIANIFPAJPDBDGLEEFKCFAA.rafal@smigrodzki.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Anders Sandberg (<a href="mailto:asa@nada.kth.se?Subject=Re:%20greatest%20threats%20to%20survival%20(was:%20why%20believe%20the%20truth?)"><em>asa@nada.kth.se</em></a>)<br>
<strong>Date:</strong> Thu Jun 19 2003 - 08:35:20 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10605.html">Dehede011@aol.com: "Re: Gatto? (was Re: Offlist   Re: List Moderator Suggestions)"</a>
<ul>
<li><strong>Previous message:</strong> <a href="10603.html">Brett Paatsch: "Gatto? (was Re: Offlist   Re: List Moderator Suggestions)"</a>
<li><strong>In reply to:</strong> <a href="10569.html">Rafal Smigrodzki: "RE: greatest threats to survival (was: why believe the truth?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10606.html">Rafal Smigrodzki: "military identity"</a>
<li><strong>Reply:</strong> <a href="10606.html">Rafal Smigrodzki: "military identity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10604">[ date ]</a>
<a href="index.html#10604">[ thread ]</a>
<a href="subject.html#10604">[ subject ]</a>
<a href="author.html#10604">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, Jun 18, 2003 at 07:23:15PM -0700, Rafal Smigrodzki wrote:
<br>
<em>&gt; &gt;
</em><br>
<em>&gt; ### I understand that Bayesian networks can be used to approximate the
</em><br>
<em>&gt; behavior of both low-level motor/sensory neural networks, and high-level
</em><br>
<em>&gt; semantic networks. 
</em><br>
<p>This is roughly the theme of my thesis. I don't think the brain
<br>
actually is a Bayesian neural network (slightly different from
<br>
the Bayesian networks usually discussed) but I think the idea
<br>
that it does approximate statistical inference seems to be very
<br>
fruitful. 
<br>
<p><em>&gt; Ben Goertzel is working on a system using probabilistic
</em><br>
<em>&gt; inference on &quot;atoms&quot; (simple nodes) and &quot;maps&quot;(mapping of
</em><br>
<em>&gt; ensemble of atoms) to achieve AGI. He believes that 3 to 5
</em><br>
<em>&gt; years might be sufficient to build a system capable of
</em><br>
<em>&gt; supervised learning with real-world input (e.g. scientific
</em><br>
<em>&gt; journals). This is a bit like evolution but more amenable to
</em><br>
<em>&gt; oversight.
</em><br>
<p>I think the key here is oversight, not perfect control. My 
<br>
problem with many AI proposals is that they are based on 
<br>
absolutist visions of strict logic, planned safety and other 
<br>
top-down concepts. While much neural network and evolution work 
<br>
is far too undirected and hopes for a &quot;then a miracle happens&quot; 
<br>
self-organized breakthrough when some unknown condition is met. 
<br>
Neither works well on its own; top-down design is good for 
<br>
creating overall architectures, but learning and concept 
<br>
formation is very much bottom-up. 
<br>
<p>This is why I think we need multiple approaches both in designing 
<br>
and rearing AI, and in preventing different failure modes. 
<br>
<p><em>&gt; &gt;&gt; Human-level computing power is going to be available to
</em><br>
<em>&gt; &gt;&gt; SingInst in about 15 years, so we can expect the recursive
</em><br>
<em>&gt; &gt;&gt; self-enhancement of the FAI to take off around that time.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I'm not convinced of this.  You're basing this on Moravec's
</em><br>
<em>&gt; &gt; extrapolation of computing power necessary to replace the retina to
</em><br>
<em>&gt; &gt; the whole brain?  I think that's a pretty rough model. The retina
</em><br>
<em>&gt; &gt; lacks much of the complexity of the cortex.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ### The estimate of the number of synapses and their firing rates is taken
</em><br>
<em>&gt; directly from histological and neurophysiological analysis of
</em><br>
<em>&gt; the cortex. The equivalence coefficient between computing power
</em><br>
<em>&gt; needed to emulate the retina and the number of retinal synaptic
</em><br>
<em>&gt; events is also a direct observation (subject to uncertainties
</em><br>
<em>&gt; of whether the retinal emulator is really emulating the
</em><br>
<em>&gt; retina). The main leap of faith is applying the FLOP/synapse
</em><br>
<em>&gt; equivalence coefficient from the retina to the cortex, but then
</em><br>
<em>&gt; the increased complexity of the cortex is accounted for by the
</em><br>
<em>&gt; enumeration of synapses. We have no reason to believe that the
</em><br>
<em>&gt; cortical synapses are more computationally efficient that the
</em><br>
<em>&gt; retinal ones (they have similar structures, similar
</em><br>
<em>&gt; evolutionary pressures for optimization). In fact, since
</em><br>
<em>&gt; retinas have been around much longer than the prefrontal
</em><br>
<em>&gt; cortex, the former might better optimized than the latter.
</em><br>
<p>The Moravec calculation is very rough, but many other 
<br>
calculations do tend to cluster a few orders of magnitude away. 
<br>
It doesn't matter much, since given the assumption of exponential 
<br>
computer power growth will easily fix that. 
<br>
<p>It is a much more serious issue whether self-enhancing AI is 
<br>
possible (a very interesting theoretical issue at the very least, 
<br>
and quite likely of practical relevance). 
<br>
<p>Also, we might want to examine the behavior of Moore's law and 
<br>
the computational architectures needed for AI. They might not go 
<br>
in the same direction, or computer power increases might peter 
<br>
out before they reach the right level.
<br>
<p>We have some plans at my research group for a project that would
<br>
result in a neural network with mouse cortex computational power. 
<br>
Very cool, but we still don't have any (clear) idea of how to
<br>
divide the network into parts and link them to get mousy 
<br>
intelligence. It is not unlikely that we will still not know it 
<br>
when we have far greater computing power. 
<br>
<p><em>&gt; In any case, while I am not a totally gung-ho near-term
</em><br>
<em>&gt; Singularity apostle, I do think the UFAI should figure very
</em><br>
<em>&gt; high on Brett's and most of other people's lists of future
</em><br>
<em>&gt; problems.
</em><br>
<p>I think people overestimate the dangers of superintelligence and 
<br>
underestimate the dangers of subintelligence. 
<br>
<p>Imagine software that can read scientific text, parse it and
<br>
produce stuff based on it. Already that little system would
<br>
revolutionize how much science is done - and flood the journals
<br>
by semi-automatically written papers on all subjects. Add the
<br>
ability to run simulations, and at least some disciplines might
<br>
get clogged up by academic goo - not using these papermats would
<br>
make your impact rating go down compared to those who do, useful 
<br>
papers would be hard to find amid the piles of autogenerated 
<br>
papers copying from each other and so on. 
<br>
<p>In the long run people would manage. Peer review would change 
<br>
(automated reviewers as a first step?), imact ratings will be 
<br>
viewed differently and people will find ways of using this kind 
<br>
of AI to read literature, research and write more efficiently. 
<br>
But the transient can be rather bad, and could mess up an 
<br>
academic discipline a lot. Now imagine the same applied to 
<br>
secretaries, call centers and spam. 
<br>
<p>This little example is hardly a world-ender. But it shows that 
<br>
even a fairly low level of intelligence when automated can have 
<br>
tremendous effects. It is a bit like replicating technology such 
<br>
as computer viruses; it can quickly grow in power even if it is 
<br>
basically a simple program with little smarts. Don't worry about 
<br>
the world being taken over by Tetragrammaton 2.3, worry about the 
<br>
Tamagochi Rebellion.
<br>
<p><p><pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<a href="mailto:asa@nada.kth.se?Subject=Re:%20greatest%20threats%20to%20survival%20(was:%20why%20believe%20the%20truth?)">asa@nada.kth.se</a>                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10605.html">Dehede011@aol.com: "Re: Gatto? (was Re: Offlist   Re: List Moderator Suggestions)"</a>
<li><strong>Previous message:</strong> <a href="10603.html">Brett Paatsch: "Gatto? (was Re: Offlist   Re: List Moderator Suggestions)"</a>
<li><strong>In reply to:</strong> <a href="10569.html">Rafal Smigrodzki: "RE: greatest threats to survival (was: why believe the truth?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10606.html">Rafal Smigrodzki: "military identity"</a>
<li><strong>Reply:</strong> <a href="10606.html">Rafal Smigrodzki: "military identity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10604">[ date ]</a>
<a href="index.html#10604">[ thread ]</a>
<a href="subject.html#10604">[ subject ]</a>
<a href="author.html#10604">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Thu Jun 19 2003 - 08:41:49 MDT
</em></small></p>
</body>
</html>
