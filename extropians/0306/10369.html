<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Why believe the truth?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Why believe the truth?">
<meta name="Date" content="2003-06-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why believe the truth?</h1>
<!-- received="Mon Jun 16 21:27:48 2003" -->
<!-- isoreceived="20030617032748" -->
<!-- sent="Mon, 16 Jun 2003 23:27:22 -0400" -->
<!-- isosent="20030617032722" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Why believe the truth?" -->
<!-- id="3EEE8A9A.6090800@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="5.2.1.1.2.20030616210435.01bdc598@mail.gmu.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Why%20believe%20the%20truth?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Jun 16 2003 - 21:27:22 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10370.html">Hal Finney: "Re: Why believe the truth?"</a>
<ul>
<li><strong>Previous message:</strong> <a href="10368.html">Emlyn O'regan: "RE: Why believe the truth?"</a>
<li><strong>In reply to:</strong> <a href="10362.html">Robin Hanson: "Re: Why believe the truth?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10377.html">Robin Hanson: "Re: Why believe the truth?"</a>
<li><strong>Reply:</strong> <a href="10377.html">Robin Hanson: "Re: Why believe the truth?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10369">[ date ]</a>
<a href="index.html#10369">[ thread ]</a>
<a href="subject.html#10369">[ subject ]</a>
<a href="author.html#10369">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin Hanson wrote:
<br>
<em>&gt; On 6/16/2003, Eliezer S. Yudkowsky  wrote:
</em><br>
<em>&gt;&gt; ...
</em><br>
<em>&gt;&gt; It's one thing to admit the philosophical possibility that there are 
</em><br>
<em>&gt;&gt; hypothetical scenarios where the &quot;right&quot; thing to do is believe 
</em><br>
<em>&gt;&gt; falsely, just as it is possible to construct thought experiments where 
</em><br>
<em>&gt;&gt; the right thing to do is commit suicide or overwrite your own goal 
</em><br>
<em>&gt;&gt; system.  ....  The rule &quot;Just Be Rational&quot; is more reliable than you 
</em><br>
<em>&gt;&gt; are.  Sticking to the truth is a very simple procedure, and it is more 
</em><br>
<em>&gt;&gt; reliable than any amount of complex verbal philosophization that tries 
</em><br>
<em>&gt;&gt; to calculate the utility of truth in some specific instance.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It would be nice if what you said were true, but alas I think it is 
</em><br>
<em>&gt; not.  We actually usually follow the rule &quot;Just be Natural&quot;.  Evolution 
</em><br>
<em>&gt; has equipped us with vast and complex habits of thought, which people 
</em><br>
<em>&gt; mostly just use without understanding them.  This isn't a particularly 
</em><br>
<em>&gt; dangerous strategy for the usual evolutionary reasons: your ancestors 
</em><br>
<em>&gt; did pretty well following these habits, so you probably will too.
</em><br>
<p>That works to the extent that:
<br>
<p>1)  Your sole and only goal is to reproduce statistically more frequently 
<br>
than your contemporaries, above all other considerations including 
<br>
individual survival.
<br>
2)  You are in the ancestral environment.
<br>
3)  You are playing the ancestral game.  If you live forever, for example, 
<br>
than developing your personal potential to the fullest may call for quite 
<br>
different rules than if you are only granted 40 years or so.
<br>
<p>Even if we consider only personal survival, what are, on the average, the 
<br>
greatest probable threats to the survival of any given human living today?
<br>
<p>1)  Existential risks of transhuman technologies.
<br>
2)  Answering &quot;no&quot; to an FAI who asks &quot;Do you want to live forever?&quot;
<br>
<p>All of a sudden, engaging in group self-deception does not look quite as 
<br>
clever.  Why not?  Because listed above are two major risks, completely 
<br>
unexpected, completely unancestral, emerging from left field.  You and I 
<br>
know that *specific* information.  But the only heuristic that could 
<br>
prepare someone ignorant of that specific information is:  &quot;Just Be 
<br>
Rational, Or The Unknown Variables Will Devour Your Soul.&quot;  The more 
<br>
complex things become, the more nonancestral they become, the more all the 
<br>
evolved *distortions* of reasoning become anti-useful instead of useful. 
<br>
The distorting information that evolution imposes is very specific, very 
<br>
adapted, very special-purpose.
<br>
<p>Anyone who anticipates living forever should, I think, Just Be Rational 
<br>
because you are making decisions for the long term.
<br>
<p>Anyone trying to solve a complex nonancestral problem should Just Be Rational.
<br>
<p>Anyone trying for any goal aside from reproduction, especially any 
<br>
altruistic goal, should Just Be Rational.
<br>
<p>Anyone with ambitions more complicated than pumping out babies and then 
<br>
dying should Just Be Rational.
<br>
<p>Probably anyone in a First World country should Just Be Rational.  (I 
<br>
don't know enough about Third World countries to say.)
<br>
<p>Anyone with a significant chance of seeing a Singularity in their lifetime 
<br>
should Just Be Rational.
<br>
<p>And of course, anyone who wants to retain their self-respect should Just 
<br>
Be Rational.
<br>
<p><em>&gt; ...They are natural.  They are safe strategies...
</em><br>
<p>The two are not synonymous at all.  What's the third greatest threat after 
<br>
the above two, in the First World?  Heart disease.  What is the cause of 
<br>
heart disease?  Taste buds containing obsolete statistical information 
<br>
about &quot;the correlation between taste and the satisfaction of nutritional 
<br>
demand for environmentally available foods&quot;.
<br>
<p><em>&gt; You might tell your girlfriend that she is average among the girlfriends 
</em><br>
<em>&gt; you have had, and that you think you are likely to stay with her for the 
</em><br>
<em>&gt; average time.  You might admit you are an average lover and driver, that 
</em><br>
<em>&gt; the products you sell are average, and that your in-group is no more 
</em><br>
<em>&gt; morally justified than any other group.  You might rarely disagree, and 
</em><br>
<em>&gt; accept that others are right as often as you.  You might admit that you 
</em><br>
<em>&gt; care almost nothing about poor people in Africa.
</em><br>
<p>If you plan on living forever and growing up, then admitting to such 
<br>
problems is the first step toward actually doing something about them.
<br>
<p>It is rather like the argument for believing in an afterlife because it 
<br>
comforts you for the fear of death.  It sounds very clever, but y'know, 
<br>
that sort of clever-sounding trick rarely if ever works in real life.  It 
<br>
happens that we have the specific knowledge of how this trick fails.  We 
<br>
know that, poof, all of a sudden, out of the left field, comes the 
<br>
possibility of immortality... and suddenly, believing in an afterlife is 
<br>
not &quot;comforting&quot;; it is deadly.  It can kill you.  The net yield of all 
<br>
the decisions ever made to believe in an afterlife may turn out to be 
<br>
steeply negative, even if we concede that its average value in earlier 
<br>
times was positive, which, incidentally, I do not concede.  We have that 
<br>
specific knowledge... but suppose we didn't?  It is very specialized 
<br>
knowledge, after all.  You have to be able to read far ahead to see the 
<br>
*specific* way in which this clever-sounding choice ends up killing you. 
<br>
The *general* heuristic which would save us from this mistake:  Don't try 
<br>
to be clever about your beliefs; just be rational.
<br>
<p>Even if you should successfully sum up all the risk factors for whether or 
<br>
not it is wise to deceive yourself in order to keep a girlfriend (editor's 
<br>
comment: if you do this, *something* is wrong with your life)... that's 
<br>
you, Robin Hanson, summing up all those risk factors.  Look at all the 
<br>
knowledge you needed to do that.  Look at where you got that knowledge 
<br>
from.  You had to know what the bias was, where it came from, how it 
<br>
worked, its evolutionary origin and cognitive mode of action, game theory, 
<br>
Bayesian reasoning, evolutionary psychology... by the time you could make 
<br>
an informed decision about it, you no longer had the option of deceiving 
<br>
yourself; you knew too much.  Even if we suppose that it might *turn out* 
<br>
to make sense to deceive yourself *in that instance*... how's J. Layman 
<br>
Boyfriend supposed to compute that answer?  If he is ignorant enough to 
<br>
still have the opportunity of self-deception, how can he possibly know 
<br>
enough to figure out whether self-deception is safe?
<br>
<p>What makes you think that you and I now finally know enough to see all the 
<br>
threats to which ignorance gives rise?  You won't ever see the bullet that 
<br>
kills you.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10370.html">Hal Finney: "Re: Why believe the truth?"</a>
<li><strong>Previous message:</strong> <a href="10368.html">Emlyn O'regan: "RE: Why believe the truth?"</a>
<li><strong>In reply to:</strong> <a href="10362.html">Robin Hanson: "Re: Why believe the truth?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10377.html">Robin Hanson: "Re: Why believe the truth?"</a>
<li><strong>Reply:</strong> <a href="10377.html">Robin Hanson: "Re: Why believe the truth?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10369">[ date ]</a>
<a href="index.html#10369">[ thread ]</a>
<a href="subject.html#10369">[ subject ]</a>
<a href="author.html#10369">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Mon Jun 16 2003 - 21:37:30 MDT
</em></small></p>
</body>
</html>
