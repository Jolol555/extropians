<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: greatest threats to survival (was: why believe the truth?)</title>
<meta name="Author" content="Charles Hixson (charleshixsn@earthlink.net)">
<meta name="Subject" content="Re: greatest threats to survival (was: why believe the truth?)">
<meta name="Date" content="2003-06-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: greatest threats to survival (was: why believe the truth?)</h1>
<!-- received="Tue Jun 17 11:55:53 2003" -->
<!-- isoreceived="20030617175553" -->
<!-- sent="Tue, 17 Jun 2003 10:55:50 -0700" -->
<!-- isosent="20030617175550" -->
<!-- name="Charles Hixson" -->
<!-- email="charleshixsn@earthlink.net" -->
<!-- subject="Re: greatest threats to survival (was: why believe the truth?)" -->
<!-- id="3EEF5626.8040003@earthlink.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="002d01c334e7$f8df9d80$3c178ec6@brett" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Charles Hixson (<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20greatest%20threats%20to%20survival%20(was:%20why%20believe%20the%20truth?)"><em>charleshixsn@earthlink.net</em></a>)<br>
<strong>Date:</strong> Tue Jun 17 2003 - 11:55:50 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10437.html">Kevin Freels: "Re: greatest threats to survival (was: why believe the truth?)"</a>
<ul>
<li><strong>Previous message:</strong> <a href="10435.html">Charles Hixson: "Re: irritable evolution syndrome"</a>
<li><strong>In reply to:</strong> <a href="10428.html">Brett Paatsch: "Re: greatest threats to survival (was: why believe the truth?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10572.html">Rafal Smigrodzki: "RE: greatest threats to survival (was: why believe the truth?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10436">[ date ]</a>
<a href="index.html#10436">[ thread ]</a>
<a href="subject.html#10436">[ subject ]</a>
<a href="author.html#10436">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Brett Paatsch wrote:
<br>
<p><em>&gt;Rafal Smigrodzki wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;### UFAI.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;    
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;Un-friendly AI ?  That *is* interesting.
</em><br>
<em>&gt;
</em><br>
<em>&gt;....
</em><br>
<em>&gt;
</em><br>
<em>&gt;Not being an AI enthusiast of the pedigree of certain others
</em><br>
<em>&gt;on this list I wonder:
</em><br>
<em>&gt;
</em><br>
<em>&gt;1) What is the probability of General AI in the next 20 years
</em><br>
<em>&gt;of *either* friendly or unfriendly variety? (I'm thinking about the
</em><br>
<em>&gt;massive parallelism of brains and that maybe a subjective is 
</em><br>
<em>&gt;a necessary pre-requisite for &quot;I&quot; and might be not so trivial to
</em><br>
<em>&gt;engineer.) 
</em><br>
<em>&gt;...
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
Actually, a UFAI would not necessarily need to be a general 
<br>
intelligence.  One can conceive of an appliance that delegates, say, 
<br>
long term planning to an external source, and is merely the total 
<br>
manager of manufacturing, distribution, etc. for a major economy (or 
<br>
even a relatively minor economy).  This external source of long term 
<br>
planning would be a center of vast power, and thus of viscious political 
<br>
fights which might well erupt into such things as, say, murder.  Once 
<br>
the most ruthless entity had secured control, it would first take steps 
<br>
to secure it's position.  This might well lead to it making more enemies 
<br>
in the process.  To improve it's standing, it might seek to secure 
<br>
resources from weaker neighbors.  Etc.
<br>
<p>One could easily extend this scenario until the controller became more 
<br>
paranoid than Stalin, and more ruthless.  He would, of course, take 
<br>
steps to secure himself against any foreign enemies... and then to 
<br>
destroy them.  Etc.
<br>
<p>It's an old pattern in humanity, but if the power of the dictator was 
<br>
derived from his control over the machine, and the machine was 
<br>
self-maintaining (and able to manage local matters without needing 
<br>
external direction), then it could be taken to a whole new level of 
<br>
dystopianism.  The only salvation for humanity might be that dictators 
<br>
need people to push around.  But what orders would he leave with the 
<br>
machine for when he finally died?
<br>
<p>A general intelligence UFAI could be as bad, but I doubt that it could 
<br>
be much worse.  Concentrations of power are becoming deadly menaces to 
<br>
the survival of humanity.  Largely because they *DO* tend to attract 
<br>
lunatics...and not all lunatics gibber at you.  You don't necessarily 
<br>
know them in advance.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10437.html">Kevin Freels: "Re: greatest threats to survival (was: why believe the truth?)"</a>
<li><strong>Previous message:</strong> <a href="10435.html">Charles Hixson: "Re: irritable evolution syndrome"</a>
<li><strong>In reply to:</strong> <a href="10428.html">Brett Paatsch: "Re: greatest threats to survival (was: why believe the truth?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10572.html">Rafal Smigrodzki: "RE: greatest threats to survival (was: why believe the truth?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10436">[ date ]</a>
<a href="index.html#10436">[ thread ]</a>
<a href="subject.html#10436">[ subject ]</a>
<a href="author.html#10436">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Jun 17 2003 - 12:05:53 MDT
</em></small></p>
</body>
</html>
