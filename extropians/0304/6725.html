<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: AI</title>
<meta name="Author" content="brent.allsop@attbi.com (brent.allsop@attbi.com)">
<meta name="Subject" content="Re: AI">
<meta name="Date" content="2003-04-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI</h1>
<!-- received="Thu Apr 17 14:47:08 2003" -->
<!-- isoreceived="20030417204708" -->
<!-- sent="Thu, 17 Apr 2003 20:46:59 +0000" -->
<!-- isosent="20030417204659" -->
<!-- name="brent.allsop@attbi.com" -->
<!-- email="brent.allsop@attbi.com" -->
<!-- subject="Re: AI" -->
<!-- id="200304172047.h3HKl7w10596@tick.javien.com" -->
<!-- inreplyto="AI" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> <a href="mailto:brent.allsop@attbi.com?Subject=Re:%20AI"><em>brent.allsop@attbi.com</em></a><br>
<strong>Date:</strong> Thu Apr 17 2003 - 14:46:59 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6726.html">gts: "RE: evolution and diet (was: FITNESS: Diet and Exercise)"</a>
<ul>
<li><strong>Previous message:</strong> <a href="6724.html">gts: "RE: evolution by mate selection, gene manipulation"</a>
<li><strong>Maybe in reply to:</strong> <a href="6635.html">Keith Elis: "AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6763.html">Rafal Smigrodzki: "RE: AI"</a>
<li><strong>Reply:</strong> <a href="6763.html">Rafal Smigrodzki: "RE: AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6725">[ date ]</a>
<a href="index.html#6725">[ thread ]</a>
<a href="subject.html#6725">[ subject ]</a>
<a href="author.html#6725">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer,
<br>
<p><em>&gt;&gt;&gt; an unstoppable horror erupting from your computer,
</em><br>
<p>and
<br>
<p><em>&gt;&gt;&gt; I repeat:  Do not mess around.  This is not a game.
</em><br>
<p>It’s hard for me to imagine why or how an unfriendly AI is something we should 
<br>
fear so much.  How could an unstoppable horror erupt from one’s computer?
<br>
<p>There seems to me to be a correlation between how intelligent someone is and 
<br>
how friendly one is.  Unfriendly people that end up in prison and so on, are 
<br>
really usually quite unintelligent.  To me this seems like common sense.
<br>
<p>Also, aren’t there survivability reasons for being friendly/cooperative with 
<br>
other beings?  Surely any AI would be able to figure out it could grow much 
<br>
faster by cooperating and encouraging humans to help it out rather than taking 
<br>
actions that would cause them to fight against itself every step of the way?
<br>
<p>Admittedly these aren’t very strong arguments, but then I fail to see any 
<br>
better arguments that say we should fear an unfriendly AI erupting from our 
<br>
computers.
<br>
<p>Brent Allsop
<br>
<p><p><em>&gt; Emlyn O'regan wrote:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I think you'd be far more likely to get results by developing an environment
</em><br>
<em>&gt; &gt; that requires increasing levels of intelligence to survive, and putting the
</em><br>
<em>&gt; &gt; instances into that; survival (or maybe some form of reproduction) is then
</em><br>
<em>&gt; &gt; the basis of the fitness function.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I'd say Eli would see this as a very dangerous approach to AI, but it might
</em><br>
<em>&gt; &gt; just get you through the early stages. I think you'd be unlikely to get
</em><br>
<em>&gt; &gt; general intelligence popping up in your experiments without a lot of prior
</em><br>
<em>&gt; &gt; warning; it seems unlikely that it'd be that easy. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You are correct that I see this as a very dangerous approach to AI.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Supposing that the experiment doesn't just fizzle, and you arrive at a 
</em><br>
<em>&gt; baby-level intelligence rather than an unstoppable horror erupting from 
</em><br>
<em>&gt; your computer, what are you going to do with the baby?  You don't know how 
</em><br>
<em>&gt; to make it Friendly.  If you had that kind of theoretical understanding 
</em><br>
<em>&gt; you wouldn't be poking around.
</em><br>
<em>&gt; 
</em><br>
<p><em>&gt; There is no &quot;unlikely&quot; here.  There is only an unnecessary existential risk.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Just don't go there.  If you don't know what you're doing, don't mess 
</em><br>
<em>&gt; around until you do.  Don't try to guess whether the risk is large or 
</em><br>
<em>&gt; small; if you have to guess, that means you don't know enough to guess. 
</em><br>
<em>&gt; What you don't know can and will kill you.  This is not a matter of the 
</em><br>
<em>&gt; precautionary principle.  This is me, a specific person, standing here and 
</em><br>
<em>&gt; telling you:  &quot;You see this thing right here that you don't understand? 
</em><br>
<em>&gt; That's going to kill you.&quot;  Perhaps you think I am wrong.  Perhaps I am 
</em><br>
<em>&gt; wrong.  Please do not go ahead until you understand *that thing* well 
</em><br>
<em>&gt; enough to say *exactly* why it won't kill you.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I repeat:  Do not mess around.  This is not a game.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- 
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6726.html">gts: "RE: evolution and diet (was: FITNESS: Diet and Exercise)"</a>
<li><strong>Previous message:</strong> <a href="6724.html">gts: "RE: evolution by mate selection, gene manipulation"</a>
<li><strong>Maybe in reply to:</strong> <a href="6635.html">Keith Elis: "AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6763.html">Rafal Smigrodzki: "RE: AI"</a>
<li><strong>Reply:</strong> <a href="6763.html">Rafal Smigrodzki: "RE: AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6725">[ date ]</a>
<a href="index.html#6725">[ thread ]</a>
<a href="subject.html#6725">[ subject ]</a>
<a href="author.html#6725">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Thu Apr 17 2003 - 14:54:41 MDT
</em></small></p>
</body>
</html>
