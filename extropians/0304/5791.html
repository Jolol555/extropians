<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: RE: Duplicates are Selves</title>
<meta name="Author" content="Harvey Newstrom (mail@HarveyNewstrom.com)">
<meta name="Subject" content="RE: Duplicates are Selves">
<meta name="Date" content="2003-04-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Duplicates are Selves</h1>
<!-- received="Sat Apr  5 19:01:09 2003" -->
<!-- isoreceived="20030406020109" -->
<!-- sent="Sat, 5 Apr 2003 21:00:44 -0500" -->
<!-- isosent="20030406020044" -->
<!-- name="Harvey Newstrom" -->
<!-- email="mail@HarveyNewstrom.com" -->
<!-- subject="RE: Duplicates are Selves" -->
<!-- id="000301c2fbe0$560f13f0$6401a8c0@wustpaxpp0439" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="Pine.LNX.4.44.0304051220280.27828-100000@server.aeiveos.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Harvey Newstrom (<a href="mailto:mail@HarveyNewstrom.com?Subject=RE:%20Duplicates%20are%20Selves"><em>mail@HarveyNewstrom.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 05 2003 - 19:00:44 MST
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5792.html">Harvey Newstrom: "RE: Duplicates are Selves"</a>
<ul>
<li><strong>Previous message:</strong> <a href="5790.html">Harvey Newstrom: "RE: Duplicates are Selves"</a>
<li><strong>In reply to:</strong> <a href="5781.html">Robert J. Bradbury: "RE: Duplicates are Selves"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5796.html">spike66: "thanks for the memories"</a>
<li><strong>Reply:</strong> <a href="5796.html">spike66: "thanks for the memories"</a>
<li><strong>Reply:</strong> <a href="5801.html">Damien Broderick: "RE: Duplicates are Selves"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5791">[ date ]</a>
<a href="index.html#5791">[ thread ]</a>
<a href="subject.html#5791">[ subject ]</a>
<a href="author.html#5791">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robert J. Bradbury wrote,
<br>
<em>&gt; (Oh Harvey -- you raise a host of complex issues which is why
</em><br>
<em>&gt; I suppose I hang out on this list).  Its going to be a toss-up
</em><br>
<em>&gt; today whether you or Anders get the prize for creating the most
</em><br>
<em>&gt; worthwhile stuff to talk about (though he was delivering
</em><br>
<em>&gt; abstracts so its not clearly an original work product).
</em><br>
<p>Wow!  I am honored to be compared to the Jupiter brain known as Anders,
<br>
although I fear he may be insulted.  I only hope that you do not find us so
<br>
comparable that you begin to suspect that one can replace the other, given
<br>
the current discussions....  :-)
<br>
<p>You are also in the running to get the prize for creating the most
<br>
worthwhile stuff to talk about!  (I forgot to ask what the prize was.  I
<br>
hope it is a pre-paid teleportation ticket of the kind you are describing.)
<br>
Read further to see where you have triggered me to clarify my position
<br>
versus destructive copies.  Your version of the process may resolve my
<br>
objections!
<br>
<p><em>&gt; First,
</em><br>
<em>&gt; &gt; What happens to one copy may not happen to the other copy.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Oh but you can't assume this.  If I can make 1000 copies of RJB
</em><br>
<em>&gt; I think I might be quite tempted to produce a collective mind
</em><br>
<em>&gt; (it is essential to beat the hazard function -- repeat after me
</em><br>
<em>&gt; &quot;distributed replicated intelligence&quot;).  The logical step beyond
</em><br>
<em>&gt; that is a highly interconnected &quot;distributed replicated intelligence&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Once one can do this all of the information and experiences
</em><br>
<em>&gt; become &quot;shared&quot;.
</em><br>
<p>Wow.  This is an intermediate copy/transfer scenario.  If the two brains
<br>
could really work in conjunction to control both bodies with one mind, it
<br>
would raise some new possibilities.  It might be possible to withdraw all
<br>
processing of the single mind into one or the other of the bodies.  That is,
<br>
the mind would move back and forth between the bodies.  This would be an
<br>
excellent way to transfer instead of copying a mind form one to the other.
<br>
Instead of having two complete independent individuals, where one gets
<br>
killed, we could have one neuron at a time transfer function to the other
<br>
brain and then shutdown.  Although I would need a lot more details on how
<br>
this connected brains would work as a single mind, such a thing would
<br>
probably eliminate any objection to the original being destroyed.
<br>
<p><em>&gt; &gt; As such, they each have a different point-of-view.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Only limited by the degree to which they are restricting input.
</em><br>
<em>&gt; An &quot;individual&quot; can break itself off from the &quot;collective&quot; but
</em><br>
<em>&gt; as soon as it does that it is dooming itself to mortality.
</em><br>
<em>&gt; No way out of this box (at least that I've seen yet).
</em><br>
<p>I was not considering a connected brain.  I was talking about the copies
<br>
being identical yet distinct beings.  Connecting them as you suggest brings
<br>
up a whole new range of possibilities.
<br>
<p><em>&gt; &gt; That point-of-view never is modified to achieve
</em><br>
<em>&gt; immortality.  It is only the
</em><br>
<em>&gt; &gt; newly created point-of-view that experiences immortality.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This seems to assume there is never a collective intelligence
</em><br>
<em>&gt; that does not need to be copied/teleported to achieve &quot;immortality&quot;.
</em><br>
<p>I was indeed assuming that.  I was imagining two distinct copies without a
<br>
shared mind.  Therefore, my objection can really be seen as objecting to two
<br>
minds, where one mind is destroyed.  If there is a single mind, I don't care
<br>
if there are two bodies and one is destroyed.  This is indeed an important
<br>
distinction to my position.  If we can duplicate bodies, retain a single
<br>
mind, and transfer the one mind between the two bodies, I would have no
<br>
objection to what happens to any body.  As long as the single mind
<br>
continues, I would be happy.  (Now we need to research and carefully define
<br>
how to count minds, and what to count as part of the same single mind....)
<br>
<p><em>&gt; &gt; It may &quot;remember&quot; being mortal in that we have programmed it with a
</em><br>
<em>&gt; &gt; copy of all the memories from the original, but it never actually
</em><br>
<em>&gt; &gt; experienced them.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Oh, now I think you are treading on very thin ice -- attempting to
</em><br>
<em>&gt; differentiate &quot;memories&quot; from &quot;experiences&quot;.  If the molecular
</em><br>
<em>&gt; reassembly is &quot;identical&quot; how can these be differentiated (other
</em><br>
<em>&gt; than in the mind if one happens to know one is a replicant?).
</em><br>
<em>&gt;
</em><br>
<em>&gt; An experience *is* a memory I don't see one escaping from that easily.
</em><br>
<p>People can &quot;remember&quot; false memories of alien abduction and sexual
<br>
molestation that they never really experienced.  When we get to the point of
<br>
rewriting memories into our brains, I am making the distinction between real
<br>
experiences that actually happened and current memory of the events which
<br>
may or may not match reality.  (Semantics again, I think....)
<br>
<p><em>&gt; &gt; One is mortal and is never saved.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If one does not form a distributed replicated intelligence one is
</em><br>
<em>&gt; mortal.  End of discussion.
</em><br>
<p>I agree here!  My objection to the destructive copy was the lack of a
<br>
distributed intelligence.  An exact copy of my intelligence is not the same
<br>
as connecting/distributing my intelligence between the bodies.
<br>
<p>I think that you have addressed Eliezer's distinction between /copying/ a
<br>
mind into a new body and /moving/ a mind into a new body.  Your process of
<br>
distribution seems to allow for the actual moving of a mind from one place
<br>
to another instead of just copying it.
<br>
<p><pre>
--
Harvey Newstrom, CISSP, IAM, GSEC
&lt;www.HarveyNewstrom.com&gt;
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5792.html">Harvey Newstrom: "RE: Duplicates are Selves"</a>
<li><strong>Previous message:</strong> <a href="5790.html">Harvey Newstrom: "RE: Duplicates are Selves"</a>
<li><strong>In reply to:</strong> <a href="5781.html">Robert J. Bradbury: "RE: Duplicates are Selves"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5796.html">spike66: "thanks for the memories"</a>
<li><strong>Reply:</strong> <a href="5796.html">spike66: "thanks for the memories"</a>
<li><strong>Reply:</strong> <a href="5801.html">Damien Broderick: "RE: Duplicates are Selves"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5791">[ date ]</a>
<a href="index.html#5791">[ thread ]</a>
<a href="subject.html#5791">[ subject ]</a>
<a href="author.html#5791">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Sat Apr 05 2003 - 19:12:57 MST
</em></small></p>
</body>
</html>
