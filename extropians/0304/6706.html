<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: AI</title>
<meta name="Author" content="Charles Hixson (charleshixsn@earthlink.net)">
<meta name="Subject" content="Re: AI">
<meta name="Date" content="2003-04-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI</h1>
<!-- received="Thu Apr 17 09:54:24 2003" -->
<!-- isoreceived="20030417155424" -->
<!-- sent="Thu, 17 Apr 2003 08:54:22 -0700" -->
<!-- isosent="20030417155422" -->
<!-- name="Charles Hixson" -->
<!-- email="charleshixsn@earthlink.net" -->
<!-- subject="Re: AI" -->
<!-- id="3E9ECE2E.2050600@earthlink.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="3E9E8264.2020308@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Charles Hixson (<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20AI"><em>charleshixsn@earthlink.net</em></a>)<br>
<strong>Date:</strong> Thu Apr 17 2003 - 09:54:22 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6707.html">Charles Hixson: "Re: 'Almost all of the media of the world in English' (was: Arab World Stunne..."</a>
<ul>
<li><strong>Previous message:</strong> <a href="6705.html">Dehede011@aol.com: "Re: GOV: US Reputation (RE: Arab World Stunned by Baghdad's Fall)"</a>
<li><strong>In reply to:</strong> <a href="6694.html">Eliezer S. Yudkowsky: "Re: AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6689.html">Samantha Atkins: "Re: AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6706">[ date ]</a>
<a href="index.html#6706">[ thread ]</a>
<a href="subject.html#6706">[ subject ]</a>
<a href="author.html#6706">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer S. Yudkowsky wrote:
<br>
<p><em>&gt; Emlyn O'regan wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; I think you'd be far more likely to get results by developing an 
</em><br>
<em>&gt;&gt; environment
</em><br>
<em>&gt;&gt; that requires increasing levels of intelligence to survive, and 
</em><br>
<em>&gt;&gt; putting the
</em><br>
<em>&gt;&gt; instances into that; survival (or maybe some form of reproduction) is 
</em><br>
<em>&gt;&gt; then
</em><br>
<em>&gt;&gt; the basis of the fitness function.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; I'd say Eli would see this as a very dangerous approach to AI, but it 
</em><br>
<em>&gt;&gt; might
</em><br>
<em>&gt;&gt; just get you through the early stages. I think you'd be unlikely to get
</em><br>
<em>&gt;&gt; general intelligence popping up in your experiments without a lot of 
</em><br>
<em>&gt;&gt; prior
</em><br>
<em>&gt;&gt; warning; it seems unlikely that it'd be that easy. 
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; You are correct that I see this as a very dangerous approach to AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Supposing that the experiment doesn't just fizzle, and you arrive at a 
</em><br>
<em>&gt; baby-level intelligence rather than an unstoppable horror erupting 
</em><br>
<em>&gt; from your computer, what are you going to do with the baby?  You don't 
</em><br>
<em>&gt; know how to make it Friendly.  If you had that kind of theoretical 
</em><br>
<em>&gt; understanding you wouldn't be poking around.
</em><br>
<em>&gt;
</em><br>
<em>&gt; There is no &quot;unlikely&quot; here.  There is only an unnecessary existential 
</em><br>
<em>&gt; risk.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Just don't go there.  If you don't know what you're doing, don't mess 
</em><br>
<em>&gt; around until you do.  Don't try to guess whether the risk is large or 
</em><br>
<em>&gt; small; if you have to guess, that means you don't know enough to 
</em><br>
<em>&gt; guess. What you don't know can and will kill you.  This is not a 
</em><br>
<em>&gt; matter of the precautionary principle.  This is me, a specific person, 
</em><br>
<em>&gt; standing here and telling you:  &quot;You see this thing right here that 
</em><br>
<em>&gt; you don't understand? That's going to kill you.&quot;  Perhaps you think I 
</em><br>
<em>&gt; am wrong.  Perhaps I am wrong.  Please do not go ahead until you 
</em><br>
<em>&gt; understand *that thing* well enough to say *exactly* why it won't kill 
</em><br>
<em>&gt; you.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I repeat:  Do not mess around.  This is not a game.
</em><br>
<em>&gt;
</em><br>
The question might be &quot;what is the baby trying to optomize?&quot;  Genetic 
<br>
programs don't just work at random, they've also got some selection 
<br>
mechanism.  This selection mechanism is what will be establishing all of 
<br>
the &quot;instincts&quot; of the resultant program.  I can imagine an approach 
<br>
like this that could lead to a Friendly AI, but I don't think I could 
<br>
design it.
<br>
<p>OTOH, some similar mechanism will probably be needed to allow the AI to 
<br>
adapt to unforseen situations.  And unless you are very clever indeed, 
<br>
your AI won't have any knowledge of what it means to be someone else as 
<br>
an intrinsic part of it's thought processes.  So the selection mechanism 
<br>
wouldn't be able to choose based on a consideration of whether or not it 
<br>
was harming other sentients.  (It probably wouldn't even know what a 
<br>
sentient was.)
<br>
<p>So what you need to do is have the genetic algorithm be a sort of a 
<br>
&quot;brain-storming&quot; module, that throws up all sorts of approaches which 
<br>
are judged by other parts of the mind.  And generally discarded.  It 
<br>
would then evolve a set of &quot;useful algorithms&quot;, and when faced with a 
<br>
novel problem consider the various approaches suggested (by the genetic 
<br>
blackbox), and then evaluate the projected results of applying the 
<br>
suggestion.  Then it would decide which way to go.  Here the &quot;genetic 
<br>
blackbox&quot; would be basically a way of generating possibly useful 
<br>
approaches.  Each suggestion checked would be evaluated against a 
<br>
problem and scored (increment or decrement value of the approach).  The 
<br>
lease valuable approaches would be discarded, a couple of new approaches 
<br>
would be generated.  And the selection would be at random based on 
<br>
value.  (You don't get distinct generations with this approach, but over 
<br>
time you get an equivalent effect).
<br>
<p>This could well be a very useful *component* of the seed.
<br>
<p>Another important part would be what are the nucleotides that the 
<br>
genetic program is combining.  I would suggest that they include most of 
<br>
Knuth's fundamental algorithms, though designing an API that would allow 
<br>
the genetic program to combine them could be a challenge.  Still, you 
<br>
have containers with access and deletion methods.  You've got 
<br>
arithmetic.  You've got set operations (expanded to work on all of the 
<br>
containers)... there's a lot to work with.  But I think that until the 
<br>
program starts tinkering in an understanding way with it's own 
<br>
internals, the fundamental algorithms should probably be considered 
<br>
immutable.  These are the components you build with, not the pieces you 
<br>
are designing.  Program instructions need to be available as sequencing 
<br>
operations, etc., but they are at too low a level for even the genetic 
<br>
component to design.  (Besides, we've generally got nearly optimum 
<br>
algorithms in these areas, so extensive improvement is probably 
<br>
impossible...better to put the creative energy into places that aren't 
<br>
optimized.)
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6707.html">Charles Hixson: "Re: 'Almost all of the media of the world in English' (was: Arab World Stunne..."</a>
<li><strong>Previous message:</strong> <a href="6705.html">Dehede011@aol.com: "Re: GOV: US Reputation (RE: Arab World Stunned by Baghdad's Fall)"</a>
<li><strong>In reply to:</strong> <a href="6694.html">Eliezer S. Yudkowsky: "Re: AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6689.html">Samantha Atkins: "Re: AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6706">[ date ]</a>
<a href="index.html#6706">[ thread ]</a>
<a href="subject.html#6706">[ subject ]</a>
<a href="author.html#6706">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Thu Apr 17 2003 - 10:01:28 MDT
</em></small></p>
</body>
</html>
