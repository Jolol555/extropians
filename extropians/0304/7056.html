<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: PHIL: Good question</title>
<meta name="Author" content="Adrian Tymes (wingcat@pacbell.net)">
<meta name="Subject" content="Re: PHIL: Good question">
<meta name="Date" content="2003-04-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: PHIL: Good question</h1>
<!-- received="Tue Apr 22 20:17:50 2003" -->
<!-- isoreceived="20030423021750" -->
<!-- sent="Tue, 22 Apr 2003 19:17:39 -0700 (PDT)" -->
<!-- isosent="20030423021739" -->
<!-- name="Adrian Tymes" -->
<!-- email="wingcat@pacbell.net" -->
<!-- subject="Re: PHIL: Good question" -->
<!-- id="20030423021739.36938.qmail@web80106.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="000201c30938$d92c8d20$6ca6fea9@netcom.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Adrian Tymes (<a href="mailto:wingcat@pacbell.net?Subject=Re:%20PHIL:%20Good%20question"><em>wingcat@pacbell.net</em></a>)<br>
<strong>Date:</strong> Tue Apr 22 2003 - 20:17:39 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7057.html">Eliezer S. Yudkowsky: "Re: PHIL: Good question"</a>
<ul>
<li><strong>Previous message:</strong> <a href="7055.html">Jef Allbright: "Re: Fiction Books"</a>
<li><strong>In reply to:</strong> <a href="7053.html">Keith Elis: "PHIL: Good question"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7057.html">Eliezer S. Yudkowsky: "Re: PHIL: Good question"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7056">[ date ]</a>
<a href="index.html#7056">[ thread ]</a>
<a href="subject.html#7056">[ subject ]</a>
<a href="author.html#7056">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Keith Elis &lt;<a href="mailto:hagbard@ix.netcom.com?Subject=Re:%20PHIL:%20Good%20question">hagbard@ix.netcom.com</a>&gt; wrote:
<br>
<em>&gt; In the end, the best response I could muster to this
</em><br>
<em>&gt; question was to
</em><br>
<em>&gt; bring it back to the perennial issue of starting
</em><br>
<em>&gt; points and assumptions.
</em><br>
<em>&gt; If one values rational thinking alone, then perhaps
</em><br>
<em>&gt; another's
</em><br>
<em>&gt; transhumanist thinking does differ in certain
</em><br>
<em>&gt; respects. Only very rare
</em><br>
<em>&gt; people can truthfully say they value rational
</em><br>
<em>&gt; thinking and nothing else.
</em><br>
<em>&gt; When other values are present, one's thinking may
</em><br>
<em>&gt; very well vary from
</em><br>
<em>&gt; the rational baseline. But this answer doesn't seem
</em><br>
<em>&gt; good enough to me.
</em><br>
<p>Start with this as a base.  Add in differing ways of
<br>
finding out information, such that the data that the
<br>
transhumanist uses to make decisions is different from
<br>
the data that most people use.  The data is still
<br>
valid
<br>
and correct; it is just that most people are
<br>
socialized to turn blind eyes to the realities of the
<br>
ongoing improvements we are now experiencing, instead
<br>
making the assumption that life in the future will be
<br>
almost identical to life today.  From some points of
<br>
view, it will be; from others, it won't.  Also, for
<br>
the
<br>
more Luddist people, add in evidence that - since it
<br>
shocks and scares no one - rarely makes it into the
<br>
media, that the majority of new technology ventures
<br>
can
<br>
and do safely achieve something like the improvements
<br>
they are designed for.
<br>
<p>Different values.  Different data.  Same rationality.
<br>
Different conclusions.  And, to be frank,
<br>
transhumanist
<br>
values are steadily growing more mainstream; it may
<br>
well already be the case that the average rationalist
<br>
and the average transhumanist *don't* disagree on some
<br>
key issues, like whether it is possible and desirable
<br>
for people to live longer, better lives (by almost any
<br>
measure of &quot;better&quot;) than their ancestors.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7057.html">Eliezer S. Yudkowsky: "Re: PHIL: Good question"</a>
<li><strong>Previous message:</strong> <a href="7055.html">Jef Allbright: "Re: Fiction Books"</a>
<li><strong>In reply to:</strong> <a href="7053.html">Keith Elis: "PHIL: Good question"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7057.html">Eliezer S. Yudkowsky: "Re: PHIL: Good question"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7056">[ date ]</a>
<a href="index.html#7056">[ thread ]</a>
<a href="subject.html#7056">[ subject ]</a>
<a href="author.html#7056">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Apr 22 2003 - 20:29:51 MDT
</em></small></p>
</body>
</html>
