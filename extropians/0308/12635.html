<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: RE: To thine ownself be true?</title>
<meta name="Author" content="Paul Grant (shade999@optonline.net)">
<meta name="Subject" content="RE: To thine ownself be true?">
<meta name="Date" content="2003-08-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: To thine ownself be true?</h1>
<!-- received="Thu Aug  7 08:45:05 2003" -->
<!-- isoreceived="20030807144505" -->
<!-- sent="Tue, 05 Aug 2003 23:21:18 -0400" -->
<!-- isosent="20030806032118" -->
<!-- name="Paul Grant" -->
<!-- email="shade999@optonline.net" -->
<!-- subject="RE: To thine ownself be true?" -->
<!-- id="000e01c35bc9$d0c632b0$0264a8c0@aymanlotf" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="016b01c35b7e$7eb1e320$11262dcb@vic.bigpond.net.au" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Paul Grant (<a href="mailto:shade999@optonline.net?Subject=RE:%20To%20thine%20ownself%20be%20true?"><em>shade999@optonline.net</em></a>)<br>
<strong>Date:</strong> Tue Aug 05 2003 - 21:21:18 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12636.html">John B: "Re: Fermi &quot;Paradox&quot;"</a>
<ul>
<li><strong>Previous message:</strong> <a href="12634.html">John K Clark: "Re: Arnold will run!"</a>
<li><strong>In reply to:</strong> <a href="12521.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12648.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<li><strong>Reply:</strong> <a href="12648.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12635">[ date ]</a>
<a href="index.html#12635">[ thread ]</a>
<a href="subject.html#12635">[ subject ]</a>
<a href="author.html#12635">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
-----Original Message-----
<br>
From: <a href="mailto:owner-extropians@extropy.org?Subject=RE:%20To%20thine%20ownself%20be%20true?">owner-extropians@extropy.org</a> [mailto:<a href="mailto:owner-extropians@extropy.org?Subject=RE:%20To%20thine%20ownself%20be%20true?">owner-extropians@extropy.org</a>]
<br>
On Behalf Of Brett Paatsch
<br>
Sent: Tuesday, August 05, 2003 2:22 PM
<br>
To: <a href="mailto:extropians@extropy.org?Subject=RE:%20To%20thine%20ownself%20be%20true?">extropians@extropy.org</a>
<br>
Subject: Re: To thine ownself be true?
<br>
<p><p><p>Paul Grant &lt;<a href="mailto:shade999@optonline.net?Subject=RE:%20To%20thine%20ownself%20be%20true?">shade999@optonline.net</a>&gt; writes:
<br>
<p><em>&gt; &lt;brett&gt; There are some classes of pre-emptive
</em><br>
<em>&gt; action made on the basis of genuinely held, earnestly
</em><br>
<em>&gt; reasoned (note I am not touching *belief* here) views 
</em><br>
<em>&gt; that would require action in my view. 
</em><br>
<p><em>&gt; &lt;me&gt; trying to justify a pre-emptive measure on the
</em><br>
<em>&gt; notion that is &quot;genuinely held&quot; or &quot;earnestly reasoned&quot;
</em><br>
<em>&gt; is a rationalization in my opinion, generally to excuse
</em><br>
<em>&gt; the type of behavior you are engaging in...
</em><br>
<p>&lt;brett&gt;By including the word 'generally' above aren't you in 
<br>
fact conceding my point? I.E. in *some* specific
<br>
circumstances pre-emptive action *is* morally justified?
<br>
<p>&lt;me&gt; reread what i wrote; I clearly state it is a rationalization,
<br>
and then apply generally by way of a cause.  I am simply stating
<br>
that there may be other reasons to rationalize other than seeking
<br>
an excuse for preemptive action...
<br>
<p><em>&gt;  the limit on this line of reasoning though, is in the
</em><br>
<em>&gt; duration of the act
</em><br>
<em>&gt; .... for instance, say you were prescient, and saw a man
</em><br>
<em>&gt; who was going to mug you (with a knife) 10 minutes 
</em><br>
<em>&gt; from now, and hit him over a head; then you would be
</em><br>
<em>&gt; acting morally (given ur prescience).  Lets say you are
</em><br>
<em>&gt; not prescient, and you hit  him over the head on the 
</em><br>
<em>&gt; possibility that he might mug you; than you are acting
</em><br>
<em>&gt; immorally. 
</em><br>
<p>&lt;brett&gt; In the real world, where our moral judgement is supposed 
<br>
to assist us, (or at least that is my contention) we are 
<br>
*never* fully prescient and so there is always *some* 
<br>
chance the suspected or likely mugger may not in fact
<br>
mug us. 
<br>
<p>&lt;me&gt; perhaps; in real life, I generally prepare for the attack,
<br>
rather than instigate a pre-emptive attack.
<br>
<p>&lt;brett&gt; Assuming one values oneself, how can we do
<br>
otherwise than weigh up the chances as best we can?
<br>
My answer - we can't. Therefore the point becomes 
<br>
how best we can. 
<br>
<p>&lt;me&gt; learn to recognize (and avoid) abuse and abusive
<br>
behaviors..  that includes learning not to abuse others 
<br>
in an attempt to prevent said abuse.
<br>
<p>&lt;brett&gt; At this point I think its worth distinguishing between 
<br>
a moral code, which may be a preconsidered 
<br>
framework that one uses to help reach a particular 
<br>
moral judgement and moral judgements per se. 
<br>
<p>&lt;brett&gt; There are *no* moral codes that provide definitive
<br>
answers to all the moral dilemmas that arise just as
<br>
there are no maps on a scale of 1:1, therefore whenever
<br>
a particular moral judgement is required there is no
<br>
dodging that the subjective individual must make it
<br>
which or without the benefit of a more or less 
<br>
sophisticated moral code. 
<br>
<p>&lt;me&gt; I see things in black and white;  I don't have
<br>
a particularly sophisticated moral code; just a 
<br>
sophisticated world-view.  The rules themselves are 
<br>
quite easy.  I might add that you can generate a complex
<br>
world view from an array of black/white values... and
<br>
if it is a matter of black and white values, then my moral
<br>
code does have a 1-to-1 correspondence.
<br>
<p><em>&gt; Lets say you are not prescient, and he is mugging
</em><br>
<em>&gt; someone else (as it is apparent to you from your
</em><br>
<em>&gt; vantage point), and you intervene by hitting him
</em><br>
<em>&gt; over the head... Then you're actions may or may
</em><br>
<em>&gt; not be immoral, on the basis that he may not be
</em><br>
<em>&gt; the one doing the mugging, but rather, may be the
</em><br>
<em>&gt; muggee. 
</em><br>
<p>&lt;brett&gt; Actually I'd say in the circumstances you describe 
<br>
the person *has* acted morally, but with poor 
<br>
judgement, so poor in fact that they may be found
<br>
to have acted illegally. 
<br>
<p>&lt;me&gt; you would; I would not; the reason being that the
<br>
proper action is to act to seperate them, without harming
<br>
one party of another precisely because you are ill-informed.
<br>
You should have a duty (under your moral code) to negotiate
<br>
in good faith, and having said that, you have an obligation to
<br>
do due diligence in an attempt to (as completely as possible)
<br>
understand the situation.  Properly exercised restraint is a 
<br>
remarkeably under-appreciated quality.
<br>
<p><em>&gt; The point being that you have to consider the
</em><br>
<em>&gt; granularity of the event, the knowledge
</em><br>
<em>&gt; you had as an autonomous agent, the environment 
</em><br>
<em>&gt; you're in, and the action chosen, and the outcome of
</em><br>
<em>&gt; that action... 
</em><br>
<p>&lt;brett&gt; Sure. But the &quot;you&quot; in this case is a subjective individual 
<br>
using their own judgement, when such judgement may 
<br>
or may not be particularly good. So it also behooves us to 
<br>
consider the granularity of the *moral code* that is taken 
<br>
by many of us into situations where it can guide particular 
<br>
moral judgements. 
<br>
<p>&lt;me&gt; judgement and morality are entertwined, no?
<br>
you can't have a good moral code if you're judgement
<br>
is consistently unable to judge according to that moral 
<br>
code..  As to granularity of a moral code, I think it is sufficient
<br>
to establish a clearly understood (objective) test is in order 
<br>
to determine that level of granularity by which any particular
<br>
moral code can be applied to...
<br>
<p><p>&lt;brett&gt;If one is running around in 2003 holding that the 10 
<br>
commandments are all the moral code that is needed 
<br>
one is going to come up against some particularly 
<br>
curly challenges in interpreting how to operationalise
<br>
the directive that though shalt not kill. 
<br>
<p>&lt;brett&gt;Even this simple edict is subject to interpretation. Life in 
<br>
2003 is known to take place on more than the organismic level. 
<br>
Cells are alive. And human cancer cells are human life. 
<br>
<p>&lt;me&gt; sure if you don't consider that human cancer cells replicate 
<br>
through meisos rather than fertilization.  of course (and this would 
<br>
be VERY interesting); what would happen if a cancer colony was 
<br>
able to generate say sperm.... would it be considered life...
<br>
intriguing thought.
<br>
<p>&lt;brett&gt;Clearly it is absurb to argue that a cancer cell or a 
<br>
multiples of them are of moral weight with a person
<br>
dying of cancer. Yet this is not much of an exaggeration
<br>
beyond the proposition that say all embryos are a form of
<br>
human life when by human life what is obviously meant
<br>
is personhood.
<br>
<p>&lt;me&gt; I say tear it out of the womb and see if it survives 
<br>
unaided.  if it does, boom, human being.  if it doesn't,
<br>
well then, at best it was an incomplete human being who
<br>
died.  There is no inherent reason to relegate women
<br>
to the equivalent of biological life carriers.
<br>
<p>&lt;brett&gt;
<br>
Before laws can be set that codify legally what may and
<br>
may not be done it is prudent to have a moral disucssion
<br>
where the words we use do not obfuscate the reals 
<br>
issues at hand. Issues such as how does a civil society
<br>
weight the rights or potential persons (embryos, fetus etc
<br>
at different stages). When we do not decide or address
<br>
these questions public policy continues to be made on
<br>
the basis of outdated moral and legal codes. And persons
<br>
suffer needlessly.  
<br>
<p>&lt;me&gt; Oh I would agree :) regarding a code of laws being
<br>
unduly influenced by any one particular moral code.  Personally,
<br>
I don't think laws should attempt to legislate morality.  It is
<br>
up to people to do that.
<br>
<p>&lt;snipped stuff on legal code &gt;
<br>
<p><em>&gt; Of course you could always say (arbitrarily) that I was reacting to 
</em><br>
<em>&gt; the best of my abilities to the best of my knowledge ergo my action 
</em><br>
<em>&gt; was moral by my system of morals/ethics.... But I tend to think of 
</em><br>
<em>&gt; that as a cop-out.
</em><br>
<p>&lt;brett&gt; Really? I think the key word here is 'tend'. How could you
<br>
put a moral obligation on someone to act better than the
<br>
best of their abilities and knowledge?  
<br>
<p>&lt;me&gt; I don't in real life; I hold everybody to the same standard 
<br>
that I hold myself to.
<br>
<p>&lt;brett&gt; Do you think there is a moral sphere separate from the 
<br>
legal sphere? Some apparently don't. I think the legal sphere 
<br>
is smaller than the morals sphere.
<br>
<p>&lt;me&gt; I think the two are completely seperate systems; that is not
<br>
to say a legal code cannot borrow from an established moral code
<br>
(or vice versa in cases where moral codes are not derived from
<br>
an unchangeable word of god).
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; In relation to your secondary point (stated in this letter); I 
</em><br>
<em>&gt; &gt; really don't think morality has anything necessarily to do with 
</em><br>
<em>&gt; &gt; self-delusion, or the acknowledgement thereof. Or rather, there is 
</em><br>
<em>&gt; &gt; no truth that states necessarily you  have to be honest, ergo an act
</em><br>
<p><em>&gt; &gt; of dishonesty (as it relates to self-delusion) does not violate any
</em><br>
<em>&gt; &gt; particularly great truth.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; First the status of morality and the rationality of
</em><br>
<em>&gt; ethics is pretty widely regarded at least so far as I am 
</em><br>
<em>&gt; aware in philosophical circles as being almost a matter 
</em><br>
<em>&gt; of opinion.
</em><br>
<em>&gt; (eg. Bertrand Russell. History of Western Philosophy).
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &lt;me&gt; I'm sure it is; until you run into an event that requires faith 
</em><br>
<em>&gt; or belief outside of rationality.
</em><br>
<p>&lt;brett&gt; Actually I think BR would hold the line even in the face of your
<br>
example. 
<br>
But BR overlooked a few things as Godel pointed out. Maybe he abandoned 
<br>
the search for a rational ethics too early. 
<br>
<p>&lt;me&gt; I never read BR so I can't really comment on his particular
<br>
philosophical bent.
<br>
my circuit on philosophy keeps getting delayed; I can't stand wading
<br>
through stuff
<br>
thats no relevant (given my stripped down operating assumptions).  I
<br>
think someday
<br>
I'll get bored enough to get to the juicy parts [probably in some
<br>
condensed
<br>
version of all the philosophies].
<br>
<p><em>&gt; Ergo if I'm marooned on a desert island for 60 years,
</em><br>
<em>&gt; does it really make a damned difference if I hallucinate marilyn 
</em><br>
<em>&gt; monroe on the island with me in order to remain sane?
</em><br>
<p>&lt;brett&gt; Legally no. Morally? Depends. By the code I've been arguing it
<br>
*would* make a difference if there was some net difference in 
<br>
utility to you. ie. If you really *could* make the decision to 
<br>
hallucinate to preserve your sanity (or not) then I'd argue the 
<br>
moral choice is the one that you *think* will result in the best 
<br>
outcome for you. 
<br>
<p>&lt;me&gt; ergo my confusion since I thought you stated that self-delusion was
<br>
immoral.
<br>
and yes, you can make a decision to hallucinate... same as you can wake
<br>
up (out of the
<br>
equivalent of a dream) when you are rescued.
<br>
<p>&lt;brett&gt;
<br>
Whether it would in fact yeild the best outcome for you is not the point
<br>
as the 
<br>
facts of the outcome are not knowable to you at the time you decide. 
<br>
<p>&lt;me&gt; I would say that they are; I would say that the only reason to
<br>
willing
<br>
self-delude yourself via fantasy or whatever is specifically because you
<br>
have examined the outcomes and decided that reality sucked and you could
<br>
do better. I would say that you would end up having to constantly
<br>
(subconsciously)
<br>
moniter reality to decide when you would come out of ur protective
<br>
insanity.
<br>
<p>&lt;brett&gt; Now thats the moral code. The reason for the moral code is
<br>
that usually judgements will be required in real life which one 
<br>
cannot anticipate and the better, the more sophisticated your 
<br>
moral code the better, (the more enlightened) your judgement 
<br>
of your own best interests will be. 
<br>
<p>&lt;me&gt; again I balk at the requirement for a sophisticated moral code;
<br>
you can have an incredibly simple moral code; but apply it through
<br>
the use of a sophisticated world view (ergo ur judgement). 
<br>
<p>&lt;brett&gt; In this particular case I don't think there is much latitude for
<br>
immoral action as you really would be alone on the desert island in the
<br>
situation you stipulate. Of course the situation you stipulate could not
<br>
arise. One would never know one was going to be marooned for sixty years
<br>
AND CHOOSE to hallucinate. Hallucinations for the most part are going to
<br>
be dysfunctional even on the island. 
<br>
<p>&lt;me&gt; .. for the most part? and I do dispute ur choosing to hallucinate;
<br>
ever hear
<br>
of self-hypnosis?  If you can get urself into a deep enough trance, you
<br>
can suggest
<br>
post-hypnotic suggestions that trigger when you wake... including the
<br>
post hypnotic
<br>
suggestion to renew itself until you are rescued.  And you can cause
<br>
hallucinations
<br>
in a deep enough trance btw.  And thats not even calling upon the
<br>
experience
<br>
of mystics, or people who have sufficiently advanced manipulation
<br>
techniques...
<br>
<p><em>&gt;  I tend towards a function and dysfunctional definition of sanity; if 
</em><br>
<em>&gt; its dysfunctional, then you are not being ethical.
</em><br>
<p>&lt;brett&gt; This seems to be confounding sanity with ethics. 
<br>
<p>Not really :)
<br>
<p>&lt;brett&gt; Which is problematic if the insane cannot make 
<br>
sound judgements in their own interests by virtue of being insane.
<br>
<p>&lt;me&gt; ergo my distinction between function and dysfunctional insanity.
<br>
<p><em>&gt;  if its functional, you are being ethical.
</em><br>
<em>&gt; and since functionality is related to the environment you are 
</em><br>
<em>&gt; operating in, ergo my comment about self-delusion not really having 
</em><br>
<em>&gt; anything to do with morality.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I definately think everyone is engaged in it to some degree 
</em><br>
<em>&gt; (self-delusion), and to the extent that it helps you, its ethical
</em><br>
<p>&lt;brett&gt; So do I. The human condition is mortal. It would hardly 
<br>
behoove us to dwell on it excessively and abandon hope 
<br>
when there was none. Perhaps the illusion of a life after 
<br>
death only becomes dysfunctional when it gets in the way 
<br>
of the realisation of longer life in practice.  
<br>
<p>&lt;brett&gt; In the vast majority of cases self-delusion *is* going to be 
<br>
harmful. In those circumstances where it is not harmful to 
<br>
anyone including the person who is self-deluded then I'd
<br>
agree it not immoral.  
<br>
<p>&lt;me&gt; ok well then we've settled that line of logic :)
<br>
&nbsp;
<br>
<em>&gt; &lt;brett&gt; I find this conclusion (Bertrand Russell's)
</em><br>
<em>&gt; powerful, dangerous and deeply unsatisfying so I am
</em><br>
<em>&gt; keen to have at it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;me&gt; I was just telling my little sister yesterday about one of the 
</em><br>
<em>&gt; classical issues in my life (at one point during my younger years); at
</em><br>
<p><em>&gt; what point does being too intelligent start to harm you (the classic 
</em><br>
<em>&gt; form being, if you could trade intelligence for gauranteed happiness, 
</em><br>
<em>&gt; would you do it)... most intelligent people say no; I think the really
</em><br>
<p><em>&gt; intelligent people though, when they consider it, say yes.
</em><br>
<p>&lt;brett&gt; I think this is pure speculation. Would a less intelligent 
<br>
you be you? 
<br>
<p>&lt;me&gt; does it make a difference if you are gauranteed to be happy?
<br>
<p>&lt;brett&gt; If you think so there may be possibilites for you 
<br>
to chart a life for yourself that involves more happiness
<br>
and less intellect. But personally I don't think so. How do 
<br>
you aim at happiness without identifying something that
<br>
will make you happy. Happiness is not itself a thing that
<br>
can be persued. 
<br>
<p>&lt;me&gt; ergo my point :) if you can't gaurantee happiness by
<br>
method of intelligence, and some mythical blue genie (whom
<br>
to the best of your abilities to discern is capable of granting) 
<br>
is willing to gaurantee ur happiness at the cost of your
<br>
intelligence than any sane, rational person of sufficient 
<br>
intellect would not think twice.  This assumes that everyone
<br>
wants to be happy[maiximized utility table]... which I don't 
<br>
think is an unreasonable...
<br>
<p><em>&gt; This is of
</em><br>
<em>&gt; course, assumes that people intuitively seek to maximize
</em><br>
<em>&gt; their utilities, and said maximization of utility defines a 
</em><br>
<em>&gt; state of happiness [which is, I think, reasonable]... 
</em><br>
<p>&lt;brett&gt; I don't I think its premature at best and problematic at
<br>
worst. One cannot be happy without a cause. Happiness
<br>
per se is not persuable. Pleasure is. Lesser levels of 
<br>
sentience are. But I doubt these are what appeal to you
<br>
as an alternative. 
<br>
<p>&lt;me&gt; take a look at a little kid sometime :)
<br>
<p>&lt;snip happiness is a sideeffect&gt;
<br>
&nbsp;
<br>
<em>&gt; Any moral system you build on that
</em><br>
<em>&gt; premise is doomed to fail because it does not take into account 
</em><br>
<em>&gt; actions by that subpopulation of people (antisocial individuals who 
</em><br>
<em>&gt; are operating on a different ethical system).  I would state that ur 
</em><br>
<em>&gt; assumption that there is a propensity to reason is a reasonable one in
</em><br>
<p><em>&gt; that it is necessary for the ability to recognize other autonomous 
</em><br>
<em>&gt; agents actions for what they are; expressions of their own 
</em><br>
<em>&gt; moral/ethical systems..
</em><br>
<p>&lt;brett&gt; Ah I think you missed my point. The potential to persuade 
<br>
using the sociability aspect *is* far stronger when individuals are
<br>
powerless 
<br>
and my point is that the all those who are mortal are now becoming
<br>
*aware* 
<br>
that they possess a poor form of wealth and power if it can't extend
<br>
their life 
<br>
and health. 
<br>
<p>&lt;me&gt; ... and these are the only people you're interested in approaching?
<br>
<p>&lt;brett&gt; There is an opportunity there to get them to revisit the social
<br>
compact. 
<br>
But these cagey old survivers will not fall for bs. When arguments are
<br>
put to them 
<br>
that are not in their interest they will not buy into them.
<br>
<p>&lt;me&gt; its been my experience that people who are very wealthy generally
<br>
don't
<br>
give a shit about social compact.  They got (and preserve) their wealth
<br>
at the
<br>
cost of other individuals...  I would agree that you need to put it in
<br>
terms
<br>
that involve greed.
<br>
<p>&lt;brett&gt; So in my view a moral argument cannot be put to a rich or
<br>
powerful individual 
<br>
unless it is couched in terms of offering *something* for them. We live
<br>
in an 
<br>
historic period. In this  period it might be possible to promote a
<br>
policy of more 
<br>
life for all or more life for none. 
<br>
<p>&lt;me&gt; good luck getting the rich to give a shit about the poor (past the
<br>
ones
<br>
making off with their valuables)....
<br>
<p>&lt;brett&gt; The alternative may be cabals of the powerful working to 
<br>
'immortalise' themselves. Such a scenario may restart 
<br>
&quot;history&quot; whose demise was greatly exaggerated.  
<br>
<p>&lt;me&gt; probably :) I hope to be part of a successful cabal :)
<br>
but only if quality of life is high...
<br>
<p><em>&gt; &lt;brett&gt; Further those
</em><br>
<em>&gt; who do not know endeavour to understand themselves,
</em><br>
<em>&gt; what manner of creature they are, are not going to be
</em><br>
<em>&gt; in a position to know what the most optimal compromises
</em><br>
<em>&gt; for them are when compromises need to be made.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I've met several people who are extremely intuitively, but unable
</em><br>
<p><em>&gt; to verbalize (form coherent sentences) expressing their 
</em><br>
<em>&gt; viewpoints...they just know what is right for them, and what is not...
</em><br>
<p><em>&gt; how does your system encompass them?
</em><br>
&nbsp;
<br>
&lt;brett&gt; They learn to reason and they learn to use language to persuade.
<br>
<p>They learn to understand what they want. This gives them the 
<br>
best chance to make their way and improve their situation as they go. 
<br>
It does not guarantee them success. 
<br>
<p>&lt;omd&gt; and if the overall performance of this new system ends up being
<br>
worse than their intuitive model? what then?
<br>
<p>&lt;brett&gt; The universe in which hard work  gurantees success is not this
<br>
one in my view. 
<br>
<p>&lt;omd&gt; work smarter, not harder has always been my motto...
<br>
<p><em>&gt; &lt;brett&gt; A person
</em><br>
<em>&gt; that deludes themselves that they are a different sort of
</em><br>
<em>&gt; creature with different sets of drivers and needs than 
</em><br>
<em>&gt; they actually have is precluded from sitting down at table 
</em><br>
<em>&gt; to negotiate for their own best interests because they do not 
</em><br>
<em>&gt; know their own best interests. A person that deludes
</em><br>
<em>&gt; themselves willingly can hardly be a person that others 
</em><br>
<em>&gt; would want to engage in a moral compacts with. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; according to you :) to me its fine :) In fact, i rather like 
</em><br>
<em>&gt; space cadets :)
</em><br>
<p><em>&gt; It not the space cadets that you have to worry about.
</em><br>
<em>&gt; Its the wizened old cynics and manipulators that figure
</em><br>
<em>&gt; that life is a bitch and that they are not going to join the
</em><br>
<em>&gt; ideological idiocy of submission. These guys have the 
</em><br>
<em>&gt; power to fuck up all your plans and irronically shortchange
</em><br>
<em>&gt; themselves in their cynicism too. They are not greedy
</em><br>
<em>&gt; enough for life (according to this theory). There is a fatal
</em><br>
<em>&gt; foolishness in their cynicism. They may be happy to have
</em><br>
<em>&gt; ten more years of power in the forms that they have 
</em><br>
<em>&gt; become accustomed too. They may rate their progress
</em><br>
<em>&gt; not against what it possible but against how big a differenc
</em><br>
<em>&gt; there is between them and the common man.
</em><br>
<p>&lt;me&gt; that is common btw; in people from all walks of life
<br>
(competition versus a neighbor) versus global competition...
<br>
it seems (given the broadness) that it is inherent to peoples
<br>
point of views... besides the trick to manipulations is to learn
<br>
how to do it urself.
<br>
&nbsp;
<br>
<em>&gt; The logical consequence of this line of thinking unchecked
</em><br>
<em>&gt; is the formation of power cabals and starker separations between the 
</em><br>
<em>&gt; haves and the have nots (in which ironically even the haves will have 
</em><br>
<em>&gt; less than they may have had).
</em><br>
<p>&lt;me&gt; that assumes there is no such thing as a stead accretion of
<br>
knowledge
<br>
in the hands of a few.  there is no reason to limit it to the life of
<br>
any one
<br>
person (or collection); you can consider your lineage for instance.
<br>
<p>&lt;snip of antisocial/sociopathic stuff&gt;
<br>
&nbsp;
<br>
<em>&gt; &gt; [Brett]
</em><br>
<em>&gt; &gt; This is where I think it becomes important
</em><br>
<em>&gt; &gt; to acknowledge to oneself that one can be rational and
</em><br>
<em>&gt; &gt; that one is by nature social. If one does not acknowledge
</em><br>
<em>&gt; &gt; that one is social one is not (by my reckoning) being true
</em><br>
<em>&gt; &gt; to oneself and one does not have the sort of maturity 
</em><br>
<em>&gt; &gt; that will enable one to be on good terms with oneself
</em><br>
<em>&gt; &gt; and to form real compacts that have a chance of being
</em><br>
<em>&gt; &gt; honored with others. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; Ooooh I don't know about that :)  You seem to take
</em><br>
<em>&gt; &gt; that people are by nature, social creatures.  I don't
</em><br>
<em>&gt; &gt; necessarily think thats the case. Or to qualify, people
</em><br>
<em>&gt; &gt; are social by a matter of degree.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Sure but there is a baseline.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; go tell that to the unibomber.
</em><br>
<p>&lt;brett&gt; I would have been happy to point out to the unibomber that
<br>
he was born social, so much so that he couldn't raise his head to feed.
<br>
<p>&lt;me&gt; granted :) but that doesn't really nullify the fact that he did
<br>
become
<br>
extremely antisocial afterwards...
<br>
<p>&lt;brett&gt; Then I'd ask him where his sociability ended. It could be an
<br>
insightful conversation. 
<br>
<p>&lt;me&gt; probably when he realized it was a losing game for his utility
<br>
tables...
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; Some are quite capable
</em><br>
<em>&gt; &gt; of going it alone while others would die if seperated
</em><br>
<em>&gt; &gt; from the herd.
</em><br>
<p>&lt;brett&gt; None are capable of going it alone yet. But here is the point in
<br>
the future we may re-engineer ourselves to such an extent that some may
<br>
indeed feel capable of going it alone. And these indivduals will not
<br>
necessarily be able to be reasoned with with the same starting premises.
<br>
These individuals may become meglomanical persuing as the culmination of
<br>
their individuality dominance over all else. Because, if you have no
<br>
empathy - why the hell not?
<br>
<p>&lt;me&gt; why not indeed?
<br>
&nbsp;
<br>
<em>&gt; &lt;brett&gt; Only after some initial basic social assistance has
</em><br>
<em>&gt; been rendered.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; We're dealing with [dynamic] adults here, no?
</em><br>
<em>&gt; You don't intend to limit your morality to only those who
</em><br>
<em>&gt; are currently social? 
</em><br>
<p><em>&gt; Nor do I intend to convert the bad eggs
</em><br>
<em>&gt; to altruism. I see it as far more useful to persuade the good
</em><br>
<em>&gt; eggs that if they do not want war with the bad eggs they had
</em><br>
<em>&gt; better acknowledge that principle 101 for the bad egg is 
</em><br>
<em>&gt; likely to be what is in this for me. If there is not an answer to
</em><br>
<em>&gt; that question then conflict will come about.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Many infants get suboptimal social assistance and the
</em><br>
<em>&gt; outcomes are often dysfunctional people. But they are not 
</em><br>
<em>&gt; dysfunctional  by choice. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; but they're still dysfunctional, at least, according to what 
</em><br>
<em>&gt; currently  passes for a majority of society.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yeah. And society pays the price. A more enlightened society might see
</em><br>
<p><em>&gt; better economies in avoiding the dysfunctional early socialisation.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; So i question ur assumption that everyone
</em><br>
<em>&gt; &gt; is social.... Its obviously a core belief in ur system, and certes,
</em><br>
<em>&gt; &gt; generally speaking, it is the case that most people are social.
</em><br>
<em>&gt;
</em><br>
<p>&lt;brett&gt; Everyone is social to a degree. Am I really saying that everyone
<br>
<p>is reachable through their residual sociability. I doubt it. 
<br>
I think nature throws up dysfunctional types of all forms and 
<br>
some genuine sociopaths can probably only be dealt with as amoral 
<br>
threats. 
<br>
<p>&lt;me&gt; watch some interviews with a sociopath :)  they're really quite
<br>
fascinating...  anyways, there's no reason to render a sociopath a
<br>
threat;
<br>
in fact, I'ld say they can be harnassed to detect flaws in current
<br>
modes.
<br>
&nbsp;
<br>
<em>&gt; &gt; But not all.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Not all to the same degree. But there is no person alive at 
</em><br>
<em>&gt; present (to the best of my knowledge) with the power to stay alive 
</em><br>
<em>&gt; without cooperating with others.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; but you acknowledge that it is a possibility?
</em><br>
<p>&lt;brett&gt; Yes. Imo that is a possibility. For me the interest in morality
<br>
is linked 
<br>
to an interest in politics and in the means by which the possibility may
<br>
<p>more become a probability in my life time. Hey I am social, but I am 
<br>
also rational, and I am in this for me :-) 
<br>
<p>&lt;me&gt; I suggest you pick up a microscope and a centrifuge then :)
<br>
&nbsp;
<br>
<em>&gt; &lt;brett&gt; It is not necessary that social be about niceness
</em><br>
<em>&gt; it is better, more funcitonal, if it is about an enlightened
</em><br>
<em>&gt;  understanding of frailty and the benefits of cooperation.
</em><br>
<em>&gt;  I would argue that tyrants that aim for the short glorious
</em><br>
<em>&gt;  life of Archilles in 2003 are short changing themselves.
</em><br>
<em>&gt;  They are sub-optimally selfish. With a tweak of their 
</em><br>
<em>&gt; value  systems they may be able to satisfy more of their 
</em><br>
<em>&gt; needs and desires by  cooperating. But many of them
</em><br>
<em>&gt;  would have to re-learn and I'd expect few of them to
</em><br>
<em>&gt;  change what has worked for them if they could not be
</em><br>
<em>&gt; presented with a compelling argument. If there is no 
</em><br>
<em>&gt; compelling argument that can be made to their self 
</em><br>
<em>&gt; interest then I would say that no real moral argument
</em><br>
<em>&gt;  is being put to them at all.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; ....except to say that they have presumeably
</em><br>
<em>&gt; successfuly satisfied their own utility tables....
</em><br>
<p>&lt;brett&gt; No they optimised. But I'd argue they have sold themselves
<br>
short. 
<br>
They could and may in may cases yet achieve more.
<br>
<p>&lt;me&gt; perhaps, but they certainly won't be listening... if they're
<br>
satisfied,
<br>
why change the status quo?
<br>
<p>----------------------------------- SNIP, wait for part 2 :) damn this
<br>
is long :) --------------
<br>
<p><em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; If there was a creature that by nature was not social in any sense I
</em><br>
<p><em>&gt; &gt; would grant by my notion of morality that that creature would have 
</em><br>
<em>&gt; &gt; no duties to others and that that creature would not be acting 
</em><br>
<em>&gt; &gt; immorally in anything it did to others.  If one is sure that one is 
</em><br>
<em>&gt; &gt; being threatened by a genuine sociopath by my moral reckoning
</em><br>
<em>&gt; &gt; one would not only be permitted to act in ones defence
</em><br>
<em>&gt; &gt; one would be morally obliged. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; see now I wouldn't go that far; just because ur being threatened by 
</em><br>
<em>&gt; &gt; a sociopath does not necessarily mean they will carry out that act;
</em><br>
<p><em>&gt; &gt; there's a whole subset of sociopaths that lead &quot;normal&quot; lives 
</em><br>
<em>&gt; &gt; without going through the murder sprees that characterize their (by 
</em><br>
<em>&gt; &gt; our definitions) less-successful brethern.  I think thats more of a 
</em><br>
<em>&gt; &gt; policy issue (to be decided upon by each individual)....
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; That is exactly right. In the end the individual must decide 
</em><br>
<em>&gt; moral policy for themselves. The intelligent individual will take into
</em><br>
<p><em>&gt; account existing social mores and laws but in the end they will not 
</em><br>
<em>&gt; shirk the responsibility of the moral decision. They cannot. To shirk 
</em><br>
<em>&gt; is to allow defaults to go  into play.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; yes but ur system implies a judging of that moral code (at the 
</em><br>
<em>&gt; end of the day) by other members of that society... so individual 
</em><br>
<em>&gt; morality is irrelevant if the rest of the group does not consent to 
</em><br>
<em>&gt; that action as being moral...
</em><br>
<p>No because we *are* social we learn at least some moral
<br>
codes as we becomes socialised. We maybe go through
<br>
something like Kohlbergs levels of moral reasoning. 
<br>
We learn terms like utlilitarianism and consequentialism
<br>
and from this social stock of idea on moral codes we
<br>
fashion our own. We don't invent from scratch. 
<br>
I'm suggesting we van bet better moral codes into the
<br>
ground water. These won;t remove from individuals the
<br>
need to make moral judgements but they will increase 
<br>
the likelihood that reason and enlightenment are brought
<br>
to the process of agreement making and law making.
<br>
<p><em>&gt; &lt;me&gt;my overall point is that saying you're action
</em><br>
<em>&gt; (by your own moral standard) is moral is trivially 
</em><br>
<em>&gt; easy to do; convincing
</em><br>
<em>&gt; others is far more difficult.
</em><br>
<p>Absolutely. I am in my view doing a pretty poor and
<br>
very longwinded effort at that here. But perhaps in 
<br>
working it through like this I will be able to distill it
<br>
into something shorter and more convincing because
<br>
it will appeal to people as a sort of empowering 
<br>
knowledge. Like probability theory, or tit for tat. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; In practise I would have some residual doubts about
</em><br>
<em>&gt; &gt; the completeness of the sociopathy of even a creature
</em><br>
<em>&gt; &gt; such as Hitler so I would not feel completely free to exterminate 
</em><br>
<em>&gt; &gt; him with extreme prejudice unless I had made a good faith reckoning 
</em><br>
<em>&gt; &gt; as to the nature of him as a threat to what I value. Then having 
</em><br>
<em>&gt; &gt; made a best a rational determination of the nature of the threat
</em><br>
<em>&gt; &gt; as I could given the time and context I would feel free
</em><br>
<em>&gt; &gt; to exterminate him with exteme prejudice and I 
</em><br>
<em>&gt; &gt; would expect to feel no guilt but only some misgivings
</em><br>
<em>&gt; &gt; that had I more time I might have judged better. ie.
</em><br>
<em>&gt; &gt; My concept of morality is I think in that sense
</em><br>
<em>&gt; &gt; practical. And it is extensible. If others share it,
</em><br>
<em>&gt; &gt; if they act rationally and in accordance with their selfish
</em><br>
<em>&gt; &gt;  best interests as they perceive it I can (in the context) 
</em><br>
<em>&gt; &gt; of this moral system have not fault them morally.  
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; now don't u see a contradiction therein? What if
</em><br>
<em>&gt; &gt; the sociopath, or even loony person (to broaden the set), is merely 
</em><br>
<em>&gt; &gt; acting to fulfill his own utility (ergo munching on ur spleen or the
</em><br>
<p><em>&gt; &gt; like)?  I mean, just because someone else is &quot;selfishly&quot; (is their 
</em><br>
<em>&gt; &gt; any other way?!) pursuing there own interests, doesn't necessarily 
</em><br>
<em>&gt; &gt; mean ur own moral code should approve their own...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; No my moral code would tell me if this person
</em><br>
<em>&gt; is reasonable I can point out that their aspiration to munch on my 
</em><br>
<em>&gt; spleen is well recognized by me and that that is not a circumstance  
</em><br>
<em>&gt; that I can permit to prevail. Either we  reason out a conclusion 
</em><br>
<em>&gt; together or we fight to the death  now. I then invite them to do their
</em><br>
<p><em>&gt; calculations of cooperation vs competition and consider how the
</em><br>
<em>&gt;  agreement if it is to be cooperation will be effectively 
</em><br>
<em>&gt; honored. If at any stage I feel that my appeals to their
</em><br>
<em>&gt;  reasoning is hopeless then I fall back on trying to kill 
</em><br>
<em>&gt; them before they kill me. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; what, you offer them half ur spleen? you're moral
</em><br>
<em>&gt; code has just failed to offer a suitable compromise to
</em><br>
<em>&gt; another rational autonomous agent... whereas his 
</em><br>
<em>&gt; morality disregards yours, yours fails to achieve its
</em><br>
<em>&gt;  basic premise... that of being attractive to others
</em><br>
<em>&gt;  rational beings...
</em><br>
<p>No I offer them the viewpoint that getting my spleen
<br>
will come at great risk to them and provide them 
<br>
little nourishment. I suggest that they are better of 
<br>
regsrding me as a resource and seeking to cooperate
<br>
with me.  I am pretty resourceful and persuasive.
<br>
In many cases I'd expect to pull it off because I would
<br>
really find ways to cooperate. But in some cases
<br>
the universe is a bitch. If the other guy seems me
<br>
as food and I can't persuade him otherwise his 
<br>
circumstances and mine may genuinely be that 
<br>
desperate. Then, one of us will die and one of us
<br>
will eat.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Paul]
</em><br>
<em>&gt; &gt; &gt; Pretty much the only time u can consider something
</em><br>
<em>&gt; &gt; &gt; moral or immoral is after the event has occurred,
</em><br>
<em>&gt; &gt; &gt; and then, only for urself.  Morality has absolutely
</em><br>
<em>&gt; &gt; &gt; no import in a pre-emptive doctrine.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]I don't agree. By my reckoning of morality, when individuals 
</em><br>
<em>&gt; &gt; agree to cooperate with each other for their mutual advantage 
</em><br>
<em>&gt; &gt; (perhaps at some cost to them on other dimensions were they 
</em><br>
<em>&gt; &gt; reckoning their best interests separately) there is a moral bond 
</em><br>
<em>&gt; &gt; between them.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; according to ur definition of morality :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Yes. According to a system I'm offering up
</em><br>
<em>&gt; for consideration because I think there is some 
</em><br>
<em>&gt; consistency and utility in it and because if I am right
</em><br>
<em>&gt;  and it is teachable I will benefit by shifting the 
</em><br>
<em>&gt; cooperate (or) compete decision more towards
</em><br>
<em>&gt;  cooperation (just as if I had taught the principle 
</em><br>
<em>&gt; of tit for tat). 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; .. but is it the optimal solution?
</em><br>
<p>The optimal solution for me, for the other of for 
<br>
both of us? It is in my view more likely to be the
<br>
optimal solution in more circumstances because it
<br>
is the more rationally approached solution and 
<br>
by being rationally approached we can consider
<br>
each others real needs and measure each others
<br>
real willingness to compromise AND at the
<br>
end of the day we can always fall back on the
<br>
option to compete. Come that unfortunate outcome.
<br>
I would compete *very* hard. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Paul]
</em><br>
<em>&gt; &gt; &gt; Anyone that believes to the contrary has not
</em><br>
<em>&gt; &gt; &gt; rationally examined the situation.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Depends what you mean by belief. Belief
</em><br>
<em>&gt;  is a problem word for me because a lot of people
</em><br>
<em>&gt; who are doing more than mere believing use the
</em><br>
<em>&gt; word belief to indicate a sort of less than certain
</em><br>
<em>&gt;  knowledge. The problem is that some people 
</em><br>
<em>&gt; that use the word belief may have done no 
</em><br>
<em>&gt; personal processing on the issue at hand at all but 
</em><br>
<em>&gt; may have simply adopted wholesale something that
</em><br>
<em>&gt;  they were indoctrinated with.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; the latter part of that paragraph is what
</em><br>
<em>&gt; I'm implying; that any rational person who has 
</em><br>
<em>&gt; (without resort to emotion, or any rationalization
</em><br>
<em>&gt;  or justification) examined the concept of acting
</em><br>
<em>&gt;  pre-emptively (sans sufficient proof or knowledge
</em><br>
<em>&gt;  of the current environment) is reasoning falsely.
</em><br>
<p>Pre-emption is slippery. Consider the word 
<br>
pretext. Give a politician a pretext and they are no
<br>
longer arguing pre-emption they are arguing reasonable
<br>
and measured response. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; If you are implying that my proposed moral
</em><br>
<em>&gt; system is flawed or inconsistent or unclear then, yes,
</em><br>
<em>&gt;  I am willing to accept that that  could be in fact a valid
</em><br>
<em>&gt;  criticism but I'd ask you to point out where  because 
</em><br>
<em>&gt; as I've said trying to find means of increasing cooperation
</em><br>
<em>&gt; and putting morality and ethics on a more rational footing
</em><br>
<em>&gt;  is a  worthwhile task.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; three points really;
</em><br>
<em>&gt; a) it doesn't make a difference how you arrive at an API,
</em><br>
<em>&gt;  it is only important to establish one (rational or otherwise).
</em><br>
<em>&gt;
</em><br>
<em>&gt;  There is no reason that an emotional or intuitive based
</em><br>
<em>&gt; person cannot maximize their own utility while being 
</em><br>
<em>&gt; consistent from an external point of view of their behaviors.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ergo, consistency is key {even more so than cooperation, becaue if you
</em><br>
<p><em>&gt; really want somebodies cooperation, you will invariably have that 
</em><br>
<em>&gt; already incorporated in ur utility  table [by virtue of it being a 
</em><br>
<em>&gt; necessity to fulfill some other  greater utility] and ergo you will 
</em><br>
<em>&gt; have something to offer in trade}.
</em><br>
<p>I think it does matter that its rational not emotional or faith or
<br>
belief based because reasoning facilitates coomunication and
<br>
understanding between sovereign agents far more 
<br>
effectively. Reason has as its tool language. I am not pooh poohing
<br>
emotion. Emotion is what makes life worth living by emotions cannot be
<br>
conveyed in the same way as 
<br>
reasons. Nor are they are reviewable and reliable in making judgements.
<br>
In science we do well to acknowledge that out emotions can mislead us. I
<br>
think we do well also to acknowledge this in the formulation of
<br>
contracts and laws. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; b) it should successfully deal with all types of people; that  
</em><br>
<em>&gt; includes people  who want to munch on ur spleen, and  people who are 
</em><br>
<em>&gt; complete loners[antisocial], and even those  that aren't rational 
</em><br>
<em>&gt; [non-functionally insane]
</em><br>
<p>It does those who finally want to munch on my spleen I regard as forces
<br>
of nature like sharks or lions. I don't regard their desire to eat me as
<br>
immoral but I definately regard my desire to avoid being eaten as just
<br>
and I feel fully free to exterminate such with extreme prejudice.
<br>
<p>There are no *complete loners* that I am aware of. Yet the time of the
<br>
complete loner is likely to be in the future and these guys cou;ld be
<br>
very dangerous. For now dysfunctional loners that poss a threat, when
<br>
they poss a threat are fair game for 
<br>
taking action against. 
<br>
<p>There are patterns in most forms of insanity. I'd take my 
<br>
understanding of the particular person and their alledged ailment into
<br>
account and go from there. The code doesn't prescibe a 
<br>
solution to all it only provides a (better I hope) framework. 
<br>
Individual judgements still need to be made.
<br>
&nbsp;
<br>
<em>&gt; c) the API should be predicteable...having a code of laws  where 
</em><br>
<em>&gt; no-one can predict whether or not they are in compliance is pointless.
</em><br>
<p><em>&gt; It doesn't  make a difference whether or not they agree with the 
</em><br>
<em>&gt; fundamental reasonings, they should be able to follow the statements
</em><br>
<em>&gt; out to their (hopefully logical) consequences or in barring
</em><br>
<em>&gt;  that, have a simple intuitive model to guide them.
</em><br>
<em>&gt; 
</em><br>
<p>I think my systme is more predictable than others. Those 
<br>
thatt present rationally are quickly processes rationally for cooperate
<br>
options and compete threats. Those that don't operate in a rational
<br>
paradign still fall into patterns. Animals are not rational, inanimate
<br>
objects are not rational, if a person behaves in an irrational way they
<br>
can often make themselves grist for my mill or the mill of others that
<br>
do act rationally and with an eye for the political. 
<br>
<p><em>&gt; &gt; [brett]To be frank, I am doubtful that the word belief can be 
</em><br>
<em>&gt; &gt; validly coupled (except as crude linguistic shorthand for &quot;this is 
</em><br>
<em>&gt; &gt; my operating hypothesis&quot;) with a rational examination of  any 
</em><br>
<em>&gt; &gt; situation. Belief is often used by fairly rational people in just 
</em><br>
<em>&gt; &gt; this short hand manner.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; belief =&gt; a statement a rational agent holds true.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Many use it like this. I don't like it because I spend a lot 
</em><br>
<em>&gt; of time considering the politics of language and communication.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I don't; I use a word sans negative or positive connotations. 
</em><br>
<em>&gt; Descriptive, accurate and precise. The sentence is where I pass 
</em><br>
<em>&gt; judgement on the thought, not the word.
</em><br>
<p>I accept that that is often true. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I think that if an extrope is debating with a flat earther in
</em><br>
<p><em>&gt; front of an open minded audience and the audience is only partly 
</em><br>
<em>&gt; paying attention and they hear the extrope talking of beliefs on the 
</em><br>
<em>&gt; one hand and the flat earther talking of beliefs on the other the 
</em><br>
<em>&gt; audience may be seduced into thinking one belief may be just as good 
</em><br>
<em>&gt; as the other. I think it is in our interests to get some probability
</em><br>
<em>&gt; and quantifiability into the discussion. Belief is language which 
</em><br>
<em>&gt; serves the preservation of the status quo. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I agree; if you are ambigious on how I am using a word, just ask 
</em><br>
<em>&gt; for clarification.. vice versa on my end, assumed, of course.
</em><br>
<em>&gt; 
</em><br>
You miss the political point. The audience is the voting public. It is
<br>
up to extropians to convince them of our relatively non-conservative
<br>
agendas or tohave to wear the policies that are put in place. 
<br>
<p>It is for us to be smart in our communications or wear the consequences
<br>
ofnot being. When we use the word belief we weaken our cases where they
<br>
should be strongest -we usually have reasoned and we unlike our
<br>
opponents (should be) open to the superior 
<br>
argument.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Brett] By the code of morality I have tried to
</em><br>
<em>&gt; &gt; describe, belief qua belief is immoral. This is because when one is 
</em><br>
<em>&gt; &gt; believing one is not reasoning and when one is not reasoning to the 
</em><br>
<em>&gt; &gt; route of ones selfish best interest one is  groping with a less than
</em><br>
<p><em>&gt; &gt; optimal method.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; depends on how u define it :)
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Yes. And I don't think extropes generally define it as
</em><br>
<em>&gt; &gt; I do, but my point is that people who hear belief being used may be 
</em><br>
<em>&gt; &gt; people we are trying to persuade and it behooves us to use the most 
</em><br>
<em>&gt; &gt; persuasive language.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; disagree.  more important than persuading other
</em><br>
<em>&gt; people is establishing a way of communicating clearly
</em><br>
<em>&gt; and unambigiously, preferably with some training
</em><br>
<em>&gt; into how to accurately convey your thought processes
</em><br>
<em>&gt; to another, and how to detect (and request clarification) when others 
</em><br>
<em>&gt; are using a word to convey a different semantic construct.
</em><br>
<p>Often the extropic message is a most persuasiveluy put
<br>
when it is put in terms of clear and unambiguous 
<br>
communication. 
<br>
<p>I have personally seen huge decisons on national policy &quot;justified&quot; by
<br>
political leaders not on the basis of the evidence but on the basis of
<br>
belief.  
<br>
<p><em>&gt; Ergo I never argue persuasively, only defensively :)
</em><br>
<em>&gt; Lawyers argue persuasively, and just about everybody
</em><br>
<em>&gt; I know (excluding lawyers) hates dealing with them
</em><br>
<em>&gt; [ergo a necessary evil]....
</em><br>
<p>Very much so. Fact is the legislation that exists in our countries is
<br>
established in a particular way. There is no point wishing it were
<br>
otherwise, it is as it is. Therefore I'd rather be an effective lobbyist
<br>
for the policies and laws I want to see enacted (or not enacted) then
<br>
not be.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; Belief is a poor word for conveying significant amounts
</em><br>
<em>&gt; &gt; of intellectual exercise.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; And certes, just because
</em><br>
<em>&gt; &gt; you believe something doesn't necessarily make it false
</em><br>
<em>&gt; &gt; (or ill-advised); classic example, I believe the sun will rise
</em><br>
<em>&gt; &gt; tomorrow morning...  Of course the veracity of that statement will 
</em><br>
<em>&gt; &gt; require observation tomorrow morning; but the belief is both
</em><br>
advisable
<br>
<em>&gt; 
</em><br>
<em>&gt; &gt; and statistically speaking, fairly certain...  In other words, 
</em><br>
<em>&gt; &gt; belief
</em><br>
<em>&gt; &gt; and logic are not necessarily at odds; it depends on how you define
</em><br>
<em>&gt; &gt; it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; My point is that when you speak in a political forum you
</em><br>
<em>&gt; do your own thought process which is based on considerably 
</em><br>
<em>&gt; more than mere indoctrination by another (I hope) a disservice 
</em><br>
<em>&gt; when you use the word belief instead of another word. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I see; you're making a broader point than are discussion :)
</em><br>
<p>Yes. Sorry I get evangelical sometimes. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt;(This is because not everyone who hears you use the word
</em><br>
<em>&gt; belief knows that you will have done more processing. 
</em><br>
<em>&gt; It seems to me that many extropes fail to realise that the audience, 
</em><br>
<em>&gt; the rest of the world doesn't give away free credibility points 
</em><br>
<em>&gt; for one wacky belief over another.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; for me, personally, in day-to-day interactions, people always 
</em><br>
<em>&gt; quickly realize that any thought I express has been well-thought out. 
</em><br>
<em>&gt; I have not, of course, attempted to communicate in a traditional 
</em><br>
<em>&gt; public forum {press, tv, etc} other than internet-based forums 
</em><br>
<em>&gt; (list-servs and usenet).  Incidentally, mostly because I'm not really 
</em><br>
<em>&gt; trying to persuade  anybody of anything outside of my scope of 
</em><br>
<em>&gt; interaction.  I'm primarily interested in getting my viewpoints out, 
</em><br>
<em>&gt; to confirm whether or not there are any flaws in my thinking that I 
</em><br>
<em>&gt; have missed, or to flesh out an idea by gathering other people's 
</em><br>
<em>&gt; inputs on the subject, generally through anecdotal experiences... The 
</em><br>
<em>&gt; scientifically-based stuff I get through journals and books.
</em><br>
<p>Perhaps you are still relatively young and have yet to grow your
<br>
political teeth. This is fair enough. If you come to see the connection
<br>
between the stuff we aspire to and the legislations that goes through
<br>
nation 
<br>
parliament on stem cells and nanotechnology and intellectual property
<br>
you may see things differently. I do not mean to be patronising. 
<br>
Actually I'd like to be empowering. Many young extropes could be potent
<br>
political forces for change in their own individual right if only they
<br>
perceived the need and put some time into acquiring the skills.
<br>
<p><em>&gt; &gt; [brett]My contention is that as soon as one becomes
</em><br>
<em>&gt; &gt; a &quot;believer&quot; one has ceased to hold to the principle
</em><br>
<em>&gt; &gt; of to thine own self be true - unless one is incapable
</em><br>
<em>&gt; &gt; of reasoning - (or one must reach a tentative
</em><br>
<em>&gt; &gt; conclusion based on the imperative to live and
</em><br>
<em>&gt; &gt; act in real time).
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; hahahaha :) re - ur last qualification :)
</em><br>
<em>&gt; &gt; well since we're all stuck in this current universe... :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Yes, but again I'd go back to pan critical rationalism.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Without ever getting absolute certainty there are techniques
</em><br>
<em>&gt; which we can learn which give us a much higher probability of 
</em><br>
<em>&gt; getting a correct (a useful) answer.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; until you discover that extreme you didn't consider.. I'm an 
</em><br>
<em>&gt; engineer (mentality-wise), so for the most part, I always have to  
</em><br>
<em>&gt; build/plan for the worst case scenario.. Theoretically, that means I 
</em><br>
<em>&gt; have a smaller margin for error before I'm willing to sweep it under 
</em><br>
<em>&gt; the rug as not worth planning for.
</em><br>
<p>Soory don't follow. Sounds right but don;t see the 
<br>
relevance.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; &gt; Generally speaking, I have no use for morality;
</em><br>
<em>&gt; &gt; &gt; just ethics [standard api, consistently adhered to, logically 
</em><br>
<em>&gt; &gt; &gt; derived, based on reality]....
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]I'm reading api as 'application programming interface'.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; yuppers.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]&quot;Generally speaking&quot; I suspect you are unlikely to enjoy 
</em><br>
<em>&gt; &gt; discussing morality and/or ethics much further with me ;-)
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; it doesn't really bother me, if thats what u're asking :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I was asking. I don't enjoy boring people, I just risk it ;-)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; thats fair :) generally the conversation ends up dying out when 
</em><br>
<em>&gt; nobody bothers responding :)
</em><br>
<p>I expect that will be after this post and thats fair enough. It has been
<br>
good to try and write down some stuff and try and get some 
<br>
ideas straight. Or straighter. 
<br>
&nbsp;
<br>
<em>&gt; &gt; but I've pretty much made up my ethical system, at least
</em><br>
<em>&gt; &gt; in terms of the larger ruleset (meta-rules)...
</em><br>
<em>&gt; &gt; some of the smaller &quot;behaviors&quot; are data-driven
</em><br>
<em>&gt; &gt; (tit-for-tat, etc) :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; As indeed in practice most of us have. If I am right and a 
</em><br>
<em>&gt; better more universal ethical system can be derived  I would expect 
</em><br>
<em>&gt; that in most peoples cases there would be  very little observable  
</em><br>
<em>&gt; differences in how they'd behave. But then on the other hand when one 
</em><br>
<em>&gt; starts to routinely reason as oppose to believing one is  in a 
</em><br>
<em>&gt; position to converse mind to mind with other reasoning beings.
</em><br>
<em>&gt; Beliefs can very easily become entrenched positions. 
</em><br>
<em>&gt; I think to reason when reason is  available is more 
</em><br>
<em>&gt; social and because I think humans are social (their
</em><br>
<em>&gt;  interests are best served by cooperation) to  reason is
</em><br>
<em>&gt;  moral to believe is not.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I agree with everything but ur last statement :)
</em><br>
<em>&gt; as I said, give me an simple, robust API anyday. 
</em><br>
<em>&gt;  It doesn't matter to me if there is a one-to-one mapping
</em><br>
<em>&gt;  between it and some derived, generic ethical system,
</em><br>
<em>&gt;  or there is a many-to-one mapping.  I generally prefer
</em><br>
<em>&gt;  rationally based systems in that the API happens
</em><br>
<em>&gt; to conform to reality [generally the other requirement,
</em><br>
<em>&gt; don't want to end up getting killed or maimed for my API]...
</em><br>
<p>To use you terminology I'm more concerned with the 
<br>
consequences of trying to push forward with a suboptimal
<br>
API.
<br>
<p><em>&gt; I dunno, overall, I have some fairly big problems with
</em><br>
<em>&gt; your API.
</em><br>
<p>I can tell. But thanks for persisting its helped me clarify
<br>
my thoughts. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; I think more than anything else though, its that social
</em><br>
<em>&gt; requirment thing... :)  Then again, I've been described
</em><br>
<em>&gt;  by several people in my life as a human computer...
</em><br>
<p>:-)  I agree the social bit is the weaker bit. 
<br>
<p>Regards,
<br>
Brett 
<br>
<p>{PS: No reply expected - frankly it would scare
<br>
me to have to revisit this thread at this length again
<br>
soon - I need to break it out, seriously edit and
<br>
see what happens next}
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12636.html">John B: "Re: Fermi &quot;Paradox&quot;"</a>
<li><strong>Previous message:</strong> <a href="12634.html">John K Clark: "Re: Arnold will run!"</a>
<li><strong>In reply to:</strong> <a href="12521.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12648.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<li><strong>Reply:</strong> <a href="12648.html">Brett Paatsch: "Re: To thine ownself be true?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12635">[ date ]</a>
<a href="index.html#12635">[ thread ]</a>
<a href="subject.html#12635">[ subject ]</a>
<a href="author.html#12635">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Thu Aug 07 2003 - 08:55:51 MDT
</em></small></p>
</body>
</html>
