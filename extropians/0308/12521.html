<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: To thine ownself be true?</title>
<meta name="Author" content="Brett Paatsch (bpaatsch@bigpond.net.au)">
<meta name="Subject" content="Re: To thine ownself be true?">
<meta name="Date" content="2003-08-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: To thine ownself be true?</h1>
<!-- received="Tue Aug  5 12:57:07 2003" -->
<!-- isoreceived="20030805185707" -->
<!-- sent="Wed, 06 Aug 2003 04:22:14 +1000" -->
<!-- isosent="20030805182214" -->
<!-- name="Brett Paatsch" -->
<!-- email="bpaatsch@bigpond.net.au" -->
<!-- subject="Re: To thine ownself be true?" -->
<!-- id="016b01c35b7e$7eb1e320$11262dcb@vic.bigpond.net.au" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="000601c35b1e$7ed0b760$0264a8c0@aymanlotf" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brett Paatsch (<a href="mailto:bpaatsch@bigpond.net.au?Subject=Re:%20To%20thine%20ownself%20be%20true?"><em>bpaatsch@bigpond.net.au</em></a>)<br>
<strong>Date:</strong> Tue Aug 05 2003 - 12:22:14 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12522.html">Mike Lorrey: "Orlowski: Your hate piece on Robin Hanson"</a>
<ul>
<li><strong>Previous message:</strong> <a href="12520.html">Natasha Vita-More: "Re: FWD (forteana) Meet the 'transhumanists' behind the Pentagon terror  casino"</a>
<li><strong>In reply to:</strong> <a href="12476.html">Paul Grant: "RE: To thine ownself be true?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12635.html">Paul Grant: "RE: To thine ownself be true?"</a>
<li><strong>Reply:</strong> <a href="12635.html">Paul Grant: "RE: To thine ownself be true?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12521">[ date ]</a>
<a href="index.html#12521">[ thread ]</a>
<a href="subject.html#12521">[ subject ]</a>
<a href="author.html#12521">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Paul Grant &lt;<a href="mailto:shade999@optonline.net?Subject=Re:%20To%20thine%20ownself%20be%20true?">shade999@optonline.net</a>&gt; writes:
<br>
<p><em>&gt; &lt;brett&gt; There are some classes of pre-emptive
</em><br>
<em>&gt; action made on the basis of genuinely held, earnestly 
</em><br>
<em>&gt; reasoned (note I am not touching *belief* here) views 
</em><br>
<em>&gt; that would require action in my view. 
</em><br>
<p><em>&gt; &lt;me&gt; trying to justify a pre-emptive measure on the
</em><br>
<em>&gt; notion that is &quot;genuinely held&quot; or &quot;earnestly reasoned&quot;
</em><br>
<em>&gt; is a rationalization in my opinion, generally to excuse 
</em><br>
<em>&gt; the type of behavior you are engaging in...
</em><br>
<p>By including the word 'generally' above aren't you in 
<br>
fact conceding my point? I.E. in *some* specific
<br>
circumstances pre-emptive action *is* morally justified?
<br>
<p><em>&gt;  the limit on this line of reasoning though, is in the 
</em><br>
<em>&gt; duration of the act
</em><br>
<em>&gt; .... for instance, say you were prescient, and saw a man
</em><br>
<em>&gt; who was going to mug you (with a knife) 10 minutes 
</em><br>
<em>&gt; from now, and hit him over a head; then you would be
</em><br>
<em>&gt; acting morally (given ur prescience).  Lets say you are
</em><br>
<em>&gt; not prescient, and you hit  him over the head on the 
</em><br>
<em>&gt; possibility that he might mug you; than you are acting
</em><br>
<em>&gt; immorally. 
</em><br>
<p>In the real world, where our moral judgement is supposed 
<br>
to assist us, (or at least that is my contention) we are 
<br>
*never* fully prescient and so there is always *some* 
<br>
chance the suspected or likely mugger may not in fact
<br>
mug us. Assuming one values oneself, how can we do
<br>
otherwise than weigh up the chances as best we can?
<br>
My answer - we can't. Therefore the point becomes 
<br>
how best we can. 
<br>
<p>At this point I think its worth distinguishing between 
<br>
a moral code, which may be a preconsidered 
<br>
framework that one uses to help reach a particular 
<br>
moral judgement and moral judgements per se. 
<br>
<p>There are *no* moral codes that provide definitive
<br>
answers to all the moral dilemmas that arise just as
<br>
there are no maps on a scale of 1:1, therefore whenever
<br>
a particular moral judgement is required there is no
<br>
dodging that the subjective individual must make it
<br>
which or without the benefit of a more or less 
<br>
sophisticated moral code. 
<br>
<p><em>&gt; Lets say you are not prescient, and he is mugging
</em><br>
<em>&gt; someone else (as it is apparent to you from your 
</em><br>
<em>&gt; vantage point), and you intervene by hitting him
</em><br>
<em>&gt; over the head... Then you're actions may or may
</em><br>
<em>&gt; not be immoral, on the basis that he may not be
</em><br>
<em>&gt; the one doing the mugging, but rather, may be the
</em><br>
<em>&gt; muggee. 
</em><br>
<p>Actually I'd say in the circumstances you describe 
<br>
the person *has* acted morally, but with poor 
<br>
judgement, so poor in fact that they may be found
<br>
to have acted illegally. 
<br>
<p><em>&gt; The point being that you have to consider the 
</em><br>
<em>&gt; granularity of the event, the knowledge
</em><br>
<em>&gt; you had as an autonomous agent, the environment 
</em><br>
<em>&gt; you're in, and the action chosen, and the outcome of
</em><br>
<em>&gt; that action... 
</em><br>
<p>Sure. But the &quot;you&quot; in this case is a subjective individual
<br>
using their own judgement, when such judgement may 
<br>
or may not be particularly good. So it also behooves us to 
<br>
consider the granularity of the *moral code* that is taken 
<br>
by many of us into situations where it can guide particular
<br>
moral judgements. 
<br>
<p>If one is running around in 2003 holding that the 10 
<br>
commandments are all the moral code that is needed 
<br>
one is going to come up against some particularly 
<br>
curly challenges in interpreting how to operationalise
<br>
the directive that though shalt not kill. Even this simple
<br>
edict is subject to interpretation. Life in 2003 is known
<br>
to take place on more than the organismic level. Cells
<br>
are alive. And human cancer cells are human life. 
<br>
Clearly it is absurb to argue that a cancer cell or a 
<br>
multiples of them are of moral weight with a person
<br>
dying of cancer. Yet this is not much of an exaggeration
<br>
beyond the proposition that say all embryos are a form of
<br>
human life when by human life what is obviously meant
<br>
is personhood.
<br>
<p>Before laws can be set that codify legally what may and
<br>
may not be done it is prudent to have a moral disucssion
<br>
where the words we use do not obfuscate the reals 
<br>
issues at hand. Issues such as how does a civil society
<br>
weight the rights or potential persons (embryos, fetus etc
<br>
at different stages). When we do not decide or address
<br>
these questions public policy continues to be made on
<br>
the basis of outdated moral and legal codes. And persons
<br>
suffer needlessly.  
<br>
<p>&lt;snipped stuff on legal code &gt;
<br>
<p><em>&gt; Of course you could always say (arbitrarily) that I was
</em><br>
<em>&gt; reacting to the best of my abilities to the best of my 
</em><br>
<em>&gt; knowledge ergo my action was moral by my system of 
</em><br>
<em>&gt; morals/ethics.... But I tend to think of that as a cop-out.
</em><br>
<p>Really? I think the key word here is 'tend'. How could you
<br>
put a moral obligation on someone to act better than the
<br>
best of their abilities and knowledge?  
<br>
<p>Do you think there is a moral sphere separate from the 
<br>
legal sphere? Some apparently don't. I think the legal sphere
<br>
is smaller than the morals sphere.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; In relation to your secondary point (stated in this letter);
</em><br>
<em>&gt; &gt; I really don't think morality has anything necessarily to
</em><br>
<em>&gt; &gt; do with self-delusion, or the acknowledgement thereof.
</em><br>
<em>&gt; &gt; Or rather, there is no truth that states necessarily you
</em><br>
<em>&gt; &gt;  have to be honest, ergo an act of dishonesty (as it
</em><br>
<em>&gt; &gt; relates to self-delusion) does not violate any 
</em><br>
<em>&gt; &gt; particularly great truth.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; First the status of morality and the rationality of 
</em><br>
<em>&gt; ethics is pretty widely regarded at least so far as I am 
</em><br>
<em>&gt; aware in philosophical circles as being almost a matter 
</em><br>
<em>&gt; of opinion.
</em><br>
<em>&gt; (eg. Bertrand Russell. History of Western Philosophy).
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &lt;me&gt; I'm sure it is; until you run into an event that
</em><br>
<em>&gt; requires faith or belief outside of rationality. 
</em><br>
<p>Actually I think BR would hold the line even in the face of
<br>
your example. But BR overlooked a few things as Godel
<br>
pointed out. Maybe he abandoned the search for a rational
<br>
ethics too early. 
<br>
<p><em>&gt; Ergo if I'm marooned on a desert island for 60 years,
</em><br>
<em>&gt; does it really make a damned difference if I hallucinate
</em><br>
<em>&gt; marilyn monroe on the island with me in order to
</em><br>
<em>&gt; remain sane? 
</em><br>
<p>Legally no. Morally? Depends. By the code I've been arguing it
<br>
*would* make a difference if there was some net difference in 
<br>
utility to you. ie. If you really *could* make the decision to 
<br>
hallucinate to preserve your sanity (or not) then I'd argue the
<br>
moral choice is the one that you *think* will result in the best
<br>
outcome for you. 
<br>
<p>Whether it would in fact yeild the best outcome for you is not
<br>
the point as the facts of the outcome are not knowable to you
<br>
at the time you decide. 
<br>
<p>Now thats the moral code. The reason for the moral code is
<br>
that usually judgements will be required in real life which one 
<br>
cannot anticipate and the better, the more sophisticated your
<br>
moral code the better, (the more enlightened) your judgement
<br>
of your own best interests will be. 
<br>
<p>In this particular case I don't think there is much latitude for
<br>
immoral action as you really would be alone on the desert
<br>
island in the situation you stipulate. Of course the situation
<br>
you stipulate could not arise. One would never know one
<br>
was going to be marooned for sixty years AND CHOOSE
<br>
to hallucinate. Hallucinations for the most part are going
<br>
to be dysfunctional even on the island. 
<br>
<p><em>&gt;  I tend towards a function and dysfunctional definition of
</em><br>
<em>&gt; sanity; if its dysfunctional, then you are not being ethical.
</em><br>
<p>This seems to be confounding sanity with ethics. Which is 
<br>
problematic if the insane cannot make sound judgements
<br>
in their own interests by virtue of being insane.
<br>
<p><em>&gt;  if its functional, you are being ethical.
</em><br>
<em>&gt; and since functionality is related to the environment you are
</em><br>
<em>&gt; operating in, ergo my comment about self-delusion not really
</em><br>
<em>&gt; having anything to do with morality. 
</em><br>
<em>&gt;
</em><br>
<em>&gt; I definately think everyone is engaged in it to some degree
</em><br>
<em>&gt; (self-delusion), and to the extent that it helps you, its ethical
</em><br>
<p>So do I. The human condition is mortal. It would hardly 
<br>
behoove us to dwell on it excessively and abandon hope when
<br>
there was none. Perhaps the illusion of a life after death only
<br>
becomes dysfunctional when it gets in the way of the realisation
<br>
of longer life in practice.  
<br>
<p>In the vast majority of cases self-delusion *is* going to be 
<br>
harmful. In those circumstances where it is not harmful to 
<br>
anyone including the person who is self-deluded then I'd
<br>
agree it not immoral.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I find this conclusion (Bertrand Russell's) 
</em><br>
<em>&gt; powerful, dangerous and deeply unsatisfying so I am
</em><br>
<em>&gt; keen to have at it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;me&gt; I was just telling my little sister yesterday about one
</em><br>
<em>&gt; of the classical issues in my life (at one point during
</em><br>
<em>&gt; my younger years); at what point does being too intelligent
</em><br>
<em>&gt; start to harm you (the classic form being, if you could trade
</em><br>
<em>&gt; intelligence for gauranteed happiness, would you do it)...
</em><br>
<em>&gt; most intelligent people say no; I think the really intelligent
</em><br>
<em>&gt; people though, when they consider it, say yes. 
</em><br>
<p>I think this is pure speculation. Would a less intelligent you
<br>
be you? If you think so there may be possibilites for you 
<br>
to chart a life for yourself that involves more happiness
<br>
and less intellect. But personally I don't think so. How do 
<br>
you aim at happiness without identifying something that
<br>
will make you happy. Happiness is not itself a thing that
<br>
can be persued. 
<br>
<p>Happiness is not a object its a consequence. Doing things
<br>
makes us happy. Actually drugs and stimulation to neural
<br>
centres probaly make us happy in a sort too. But these 
<br>
seem to involve short term happiness (pleasure) for long
<br>
term happiness. (I think I'm picking up Bishop Berkley here
<br>
but could be mistaken).
<br>
<p><em>&gt; This is of 
</em><br>
<em>&gt; course, assumes that people intuitively seek to maximize
</em><br>
<em>&gt; their utilities, and said maximization of utility defines a 
</em><br>
<em>&gt; state of happiness [which is, I think, reasonable]... 
</em><br>
<p>I don't I think its premature at best and problematic at
<br>
worst. One cannot be happy without a cause. Happiness
<br>
per se is not persuable. Pleasure is. Lesser levels of 
<br>
sentience are. But I doubt these are what appeal to you
<br>
as an alternative. 
<br>
<p><em>&gt; Ergo self-delusion
</em><br>
<em>&gt; is only dangerous if you can't discard the delusion when
</em><br>
<em>&gt; it becomes detrimental to your pursuit of happiness.
</em><br>
<p>Can you think of a form of happiness that you could choose
<br>
to pursue where happiness qua happiness was not the goal?
<br>
<p>I think you will find that happiness is a side effect. It cannot
<br>
be approached directedly at though it were a destination.
<br>
It arises as a result of achieving or doing other things. Things
<br>
which are in accordance with our nature as rational social
<br>
beings.
<br>
&nbsp;
<br>
<em>&gt; &lt;brett&gt; Ok. Now here's my point. Unless a moral code
</em><br>
<em>&gt; can  arise form a set of universals such as a propensity to
</em><br>
<em>&gt; reason and a predispositon to sociability then there is
</em><br>
<em>&gt; not likely to be much genuine agreement between 
</em><br>
<em>&gt; subjective individuals on moral codes. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt;Oh I'll *agree* that it is absolutely necessary
</em><br>
<em>&gt; to have something to that effect; I think the inclusion of
</em><br>
<em>&gt; a predisposition to sociability is where your moral system
</em><br>
<em>&gt; will fail, as in a fair amount of people are not (at some point
</em><br>
<em>&gt; in their lives) sociable.... 
</em><br>
<p>I agree its the weak point. 
<br>
<p><em>&gt; Any moral system you build on that
</em><br>
<em>&gt; premise is doomed to fail because it does not take into account
</em><br>
<em>&gt; actions by that subpopulation of people (antisocial individuals
</em><br>
<em>&gt; who are operating on a different ethical system).  I would
</em><br>
<em>&gt; state that ur assumption that there is a propensity to
</em><br>
<em>&gt; reason is a reasonable one in that it is necessary for
</em><br>
<em>&gt; the ability to recognize other autonomous agents actions
</em><br>
<em>&gt; for what they are; expressions of their own moral/ethical
</em><br>
<em>&gt; systems..
</em><br>
<p>Ah I think you missed my point. The potential to persuade 
<br>
using the sociability aspect *is* far stronger when individuals
<br>
are powerless and my point is that the all those who are mortal
<br>
are now becoming *aware* that they possess a poor form of
<br>
wealth and power if it can't extend their life and health. There
<br>
is an opportunity there to get them to revisit the social compact.
<br>
But these cagey old survivers will not fall for bs. When arguments
<br>
are put to them that are not in their interest they will not buy into
<br>
them.
<br>
<p>So in my view a moral argument cannot be put to a rich or
<br>
powerful individual unless it is couched in terms of offering
<br>
*something* for them. We live in an historic period. In this 
<br>
period it might be possible to promote a policy of more life
<br>
for all or more life for none. 
<br>
<p>The alternative may be cabals of the powerful working to 
<br>
'immortalise' themselves. Such a scenario may restart 
<br>
&quot;history&quot; whose demise was greatly exaggerated.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Further those
</em><br>
<em>&gt; who do not know endeavour to understand themselves,
</em><br>
<em>&gt; what manner of creature they are, are not going to be
</em><br>
<em>&gt; in a position to know what the most optimal compromises
</em><br>
<em>&gt; for them are when compromises need to be made. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I've met several people who are extremely intuitively,
</em><br>
<em>&gt; but unable to verbalize (form coherent sentences) expressing
</em><br>
<em>&gt; their viewpoints...they just know what is right for them, and
</em><br>
<em>&gt; what is not... how does your system encompass them?
</em><br>
&nbsp;
<br>
They learn to reason and they learn to use language to persuade.
<br>
They learn to understand what they want. This gives them the
<br>
best chance to make their way and improve their situation as
<br>
they go. It does not guarantee them success. The universe in
<br>
which hard work gurantees success is not this one in my view. 
<br>
<p><em>&gt; &lt;brett&gt; A person
</em><br>
<em>&gt; that deludes themselves that they are a different sort of 
</em><br>
<em>&gt; creature with different sets of drivers and needs than 
</em><br>
<em>&gt; they actually have is precluded from sitting down at table 
</em><br>
<em>&gt; to negotiate for their own best interests because they do not 
</em><br>
<em>&gt; know their own best interests. A person that deludes
</em><br>
<em>&gt; themselves willingly can hardly be a person that others 
</em><br>
<em>&gt; would want to engage in a moral compacts with. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; according to you :) to me its fine :) In fact, i rather
</em><br>
<em>&gt; like space cadets :)  
</em><br>
<p><em>&gt; It not the space cadets that you have to worry about.
</em><br>
<em>&gt; Its the wizened old cynics and manipulators that figure 
</em><br>
<em>&gt; that life is a bitch and that they are not going to join the
</em><br>
<em>&gt; ideological idiocy of submission. These guys have the 
</em><br>
<em>&gt; power to fuck up all your plans and irronically shortchange
</em><br>
<em>&gt; themselves in their cynicism too. They are not greedy
</em><br>
<em>&gt; enough for life (according to this theory). There is a fatal
</em><br>
<em>&gt; foolishness in their cynicism. They may be happy to have
</em><br>
<em>&gt; ten more years of power in the forms that they have 
</em><br>
<em>&gt; become accustomed too. They may rate their progress
</em><br>
<em>&gt; not against what it possible but against how big a differenc
</em><br>
<em>&gt; there is between them and the common man.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The logical consequence of this line of thinking unchecked
</em><br>
<em>&gt; is the formation of power cabals and starker separations
</em><br>
<em>&gt; between the haves and the have nots (in which ironically
</em><br>
<em>&gt; even the haves will have less than they may have had).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I should give you a friendly warning at this point;
</em><br>
<em>&gt; I am generally where people's morals systems (day-2-day)
</em><br>
<em>&gt; break; they invariable adopt (when dealing with me) mine
</em><br>
<em>&gt; as it is impossible to force me to adopt theirs, and generally
</em><br>
<em>&gt; speaking, I am a fairly productive person (and very difficult
</em><br>
<em>&gt; to avoid if your moral system ends up conflicting with mine).
</em><br>
<em>&gt; I say this of course, in a friendly manner, because it will
</em><br>
<em>&gt; give you an insight to my fundamental objection to your
</em><br>
<em>&gt; system....that it, it is not sufficiently broad enough to 
</em><br>
<em>&gt; encompass all useful people (non-functional insanity excluded).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Within the context of the time available I think 
</em><br>
<em>&gt; individuals ought to use pan critical rationalism in 
</em><br>
<em>&gt; their approach to understanding their own nature and 
</em><br>
<em>&gt; then pursuing the optimal outcome for them in accordance 
</em><br>
<em>&gt; with their nature. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt;....which may end up not being rational (to outside
</em><br>
<em>&gt; examination)....
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; This optimal outcome will necessarily 
</em><br>
<em>&gt; involve compromise because others whose cooperation 
</em><br>
<em>&gt; is needed will not if they are enlightened and empowered 
</em><br>
<em>&gt; (and likely to be good allies as a consequence) strike 
</em><br>
<em>&gt; bad bargains.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I would agree with this sentence :) compromise
</em><br>
<em>&gt; is often called for amongst people if they hope to culture
</em><br>
<em>&gt; friendships that will be substantial in trade.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; Or to put it more bluntly, sometimes self-delusion
</em><br>
<em>&gt; &gt; is the ticket :) Ever wonder why (evolutionary-speaking)
</em><br>
<em>&gt; &gt; we have emotions?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I reckon to the extent one is self deluded one will be 
</em><br>
<em>&gt; screwed at the negotiating table because perceptive others 
</em><br>
<em>&gt; will recognize you as having a lower sentience quotient and 
</em><br>
<em>&gt; the only one to blame for this if you are self deluding will 
</em><br>
<em>&gt; be yourself.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; depends on how intelligent they are.  some forms of 
</em><br>
<em>&gt; self-delusion are bad, some are good.  some are bad generally,
</em><br>
<em>&gt; but useful in achieving short-term goals...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; fundamentally though, I think you're exclusion of
</em><br>
<em>&gt; people who are self-deluded though, would end up eliminating
</em><br>
<em>&gt; all of humanity... and ergo ur proposed moral system would
</em><br>
<em>&gt; fail in that it would not encompass anyone... and if there
</em><br>
<em>&gt; was a completely rational person (at some point), than they 
</em><br>
<em>&gt; would probably end up suicidal..  Of course this is conjecture
</em><br>
<em>&gt; on my part (assuming everyone is self-delusional to a degree)
</em><br>
<em>&gt; but I think it is bourne out by the nature of being human.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; Now against this point it might be argued that there
</em><br>
<em>&gt; &gt; are no circumstances where dishonesty with oneself is
</em><br>
<em>&gt; &gt; a moral matter. I conceed that this is the traditional view but my 
</em><br>
<em>&gt; &gt; contention is that that traditional view is wrong, flawed, and lacking
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; in utility.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; Fair enough, I'll bite :)
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; I am arguing that only those that can commit themselves
</em><br>
<em>&gt; &gt; to hold themselves to a rational moral code are in a
</em><br>
<em>&gt; &gt; position to have the sort of maturity that is required to 
</em><br>
<em>&gt; &gt; forge the sort of compacts that will best serve the 
</em><br>
<em>&gt; &gt; strongest forms of cooperatives and the most extropic
</em><br>
<em>&gt; &gt; societies.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; substitute &quot;ethics&quot; in for &quot;morality&quot; and I'd agree;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; So far I've been using morality and ethics without
</em><br>
<em>&gt; distinguishing them particularly. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; yeah I noticed :) I was trying to disinguish the two 
</em><br>
<em>&gt; for the purposes of this dialogue :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; morality to be is something generally provided for people
</em><br>
<em>&gt; &gt; by external sources (rather than derived by said people);
</em><br>
<em>&gt; &gt; it also deals heavily with intention.  Now, I *really* don't care what
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; people's intentions are, just their actions.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Of course you do. A person that you know was intending
</em><br>
<em>&gt; to steal from you yesterday but did not for lack of an 
</em><br>
<em>&gt; opportunity is likely to be filed as such and regarded as
</em><br>
<em>&gt; such. If not you'd be suckered far more often than the 
</em><br>
<em>&gt; norm.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; &quot;an honest man is just a thief without opportunity&quot; :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Intention are more of a heuristic to decide whether or
</em><br>
<em>&gt; &gt; not someone's future actions will be favorable.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; They certainly are that. And a persons future actions
</em><br>
<em>&gt; , their motives, their reputation are surely part of practical 
</em><br>
<em>&gt; moral deliberations on your part. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; nope.  I deal on a tit-for-tat basis.  Either people adhere
</em><br>
<em>&gt; to a basic set of standards, or they disappear from any sort of
</em><br>
<em>&gt; significant interactions (if I itch, I scratch).  There's generally
</em><br>
<em>&gt; a ramp-up period of re-training.  They are free to interact with
</em><br>
<em>&gt; others, however they wish. I do not interfere unless called upon
</em><br>
<em>&gt; by another (involved) party.  I am *always* fair.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; This discussion could all
</em><br>
<em>&gt; &gt; be simplified by people adopting a non-intention based
</em><br>
<em>&gt; &gt; system, where people are judged by their actions, and 
</em><br>
<em>&gt; &gt; statements made by said people are evaluated in that 
</em><br>
<em>&gt; &gt; context (as actions).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I am trying to establish the validity of the statement to 
</em><br>
<em>&gt; thine ownself be true. You, I think, are trying to make me
</em><br>
<em>&gt; make the case or to refute it.  I am not interested in a simple moral
</em><br>
<em>&gt; system 
</em><br>
<em>&gt; I am interested in a rational, teachable and extensible one. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; Its rational, teachable and extensible.  In fact, its more
</em><br>
<em>&gt; teachable
</em><br>
<em>&gt; than a complicated one....  There are no gray areas.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt;If I can teach a moral system that has high 
</em><br>
<em>&gt; utility to those I teach it too, like teaching the principle of tit 
</em><br>
<em>&gt; for tat, then I can be confident that the world will be that much more
</em><br>
<em>&gt; pleasant and predictable for me as a result.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; evaluate my suggestion within the context of whether or not such 
</em><br>
<em>&gt; a system would be fit ur standards and offer high utility... I would
</em><br>
<em>&gt; suggest, humbly, that it does...
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; I do not imagine that any of us ultimately succeeds in avoiding self 
</em><br>
<em>&gt; &gt; delusion. But if the charge of hyper-rationality is ever a valid 
</em><br>
<em>&gt; &gt; criticism I do not think it can be so on matters of morality where the
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; individuals concerned acknowledge that their take on the universe is 
</em><br>
<em>&gt; &gt; inherently subjective and inherently selfish.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; I think there are degrees of self-delusion; I think
</em><br>
<em>&gt; &gt; more important than self-delusion is the end effect that
</em><br>
<em>&gt; &gt; self-delusion has on the person as a total system.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; In almost all negotiations, and most moral matters 
</em><br>
<em>&gt; between persons involve a quid quo pro, the best possible 
</em><br>
<em>&gt; outcome for the individuals involved depends on them 
</em><br>
<em>&gt; recognizing the best possible outcome for them (without 
</em><br>
<em>&gt; their being deluded as to what they want or need) and 
</em><br>
<em>&gt; then most closely approximating it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I think perhaps, we mean two things by being deluded..
</em><br>
<em>&gt; You are referring to a final state of utility reached
</em><br>
<em>&gt; by a rational deduction of what your particular utility table
</em><br>
<em>&gt; is... I am referring to it as a person who has already determined
</em><br>
<em>&gt; their utility table, but reached it through a non-rational pathway.
</em><br>
<em>&gt; Ergo for you, someone who is self-deluding themselves is incapable
</em><br>
<em>&gt; of understanding what their true utility tables are... whereas for me,
</em><br>
<em>&gt; a person who is self-deluding themselves is a person who is mapping
</em><br>
<em>&gt; their stimuli (internal &amp; external) to alter an unpleasant situation to
</em><br>
<em>&gt; a state of utility...where said mapping may not be based either on
</em><br>
<em>&gt; a rational inference chain (thinking), or even by rational examination
</em><br>
<em>&gt; of ones self... What do you think? Can you clarify exactly what you
</em><br>
<em>&gt; mean by self-delusion?
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; It is my contention that if we cannot find a harmony of
</em><br>
<em>&gt; &gt; selfish interests we will not find anything but the illusion
</em><br>
<em>&gt; &gt; of harmony at all. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; in other words, someplace where everyones needs
</em><br>
<em>&gt; &gt; are met...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Absolutely not. That is pure fantasy land. The best we can
</em><br>
<em>&gt; hope to achieve is a reasonable compromise where all sit
</em><br>
<em>&gt; down in good faith and recognizing that all are compromising 
</em><br>
<em>&gt; but all are gaining in the aggregate all act in accordance with 
</em><br>
<em>&gt; the agreement.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; in other words, someplace where everyones needs
</em><br>
<em>&gt; are met...to the best of the collectives ability?
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; And in order for their to be a harmony of selfish interests
</em><br>
<em>&gt; &gt; their must be real recognition of the nature of oneself 
</em><br>
<em>&gt; &gt; and ones needs. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; or a mapping of sensory input to available physical stimulus.
</em><br>
<em>&gt; &gt; thats another possibility, sans recognition of one's own selfish
</em><br>
<em>&gt; &gt; interests.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I wouldn't limit one's self understanding and ones understanding
</em><br>
<em>&gt;  of ones needs and desires to the mere physical. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I certainly wouldn't extend it to the metaphysical :) Brain
</em><br>
<em>&gt; processing
</em><br>
<em>&gt; is a physical process.  Its influenced directly by physical processes..
</em><br>
<em>&gt; Including meta-thoughts (working on ur concepts directly with a higher
</em><br>
<em>&gt; level grammer).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I think there are social needs in most people that are very deep
</em><br>
<em>&gt; seeded 
</em><br>
<em>&gt; and go beyond the need for physical contact.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I wasn't referring to that :) I was referring to altering the
</em><br>
<em>&gt; reality you're
</em><br>
<em>&gt; living in (cognitively) by biofeedback, but on an subconscious level.
</em><br>
<em>&gt; Something
</em><br>
<em>&gt; akin to the Siberian train conductors lowering their metabolism, based
</em><br>
<em>&gt; on when
</em><br>
<em>&gt; the train was going to pull into the station [arrive].. but more
</em><br>
<em>&gt; sophisticated..
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Same goes for empaths (people with highly developed
</em><br>
<em>&gt; &gt; abilities to sense what others are feeling off of physical
</em><br>
<em>&gt; &gt; [body, speech] cues).  They intuitively understand people
</em><br>
<em>&gt; &gt; and respond sans a specific rational understanding of those
</em><br>
<em>&gt; &gt; people.  There's no reason (any empaths out there?) to
</em><br>
<em>&gt; &gt; think that emotion-intuition is not being applied to 
</em><br>
<em>&gt; &gt; themselves (the equivalent of reflection).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I am not sure what your point is here. Sociopaths are also
</em><br>
<em>&gt; good readers of patterns. They just don't empathise. But
</em><br>
<em>&gt; I would argue that sociopathy is dysfunction. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; Depends on whether or not sociopaths can manage to
</em><br>
<em>&gt; contain their more destructive impulses (or rather, get away
</em><br>
<em>&gt; with it).  There's a subpopulation of sociopaths who are 
</em><br>
<em>&gt; quite successful, who manage to sustain their needs by
</em><br>
<em>&gt; twisting the letter of the law to suit their need.  Its not
</em><br>
<em>&gt; necessarily a dysfunction. + on top of it, it depends on whether
</em><br>
<em>&gt; or not a sociopath is bothered by prison.  Who knows?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; And real  sociopaths would possible grin at me 
</em><br>
<em>&gt; and say who needs that sentimental bullshit anyway. 
</em><br>
<em>&gt; And I'd say you do here's why ..etc.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I think I can say very fairly that sociopaths do not
</em><br>
<em>&gt; think like normal people; especially (or rather, primarily)
</em><br>
<em>&gt; when it comes to their utility tables...  There's no basis
</em><br>
<em>&gt; for comparison :) Ergo why I brought them into the
</em><br>
<em>&gt; conversation...
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; [Brett]
</em><br>
<em>&gt; &gt; This is where I think it becomes important
</em><br>
<em>&gt; &gt; to acknowledge to oneself that one can be rational and
</em><br>
<em>&gt; &gt; that one is by nature social. If one does not acknowledge 
</em><br>
<em>&gt; &gt; that one is social one is not (by my reckoning) being true
</em><br>
<em>&gt; &gt; to oneself and one does not have the sort of maturity 
</em><br>
<em>&gt; &gt; that will enable one to be on good terms with oneself
</em><br>
<em>&gt; &gt; and to form real compacts that have a chance of being
</em><br>
<em>&gt; &gt; honored with others. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; Ooooh I don't know about that :)  You seem to take
</em><br>
<em>&gt; &gt; that people are by nature, social creatures.  I don't 
</em><br>
<em>&gt; &gt; necessarily think thats the case. Or to qualify, people
</em><br>
<em>&gt; &gt; are social by a matter of degree.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Sure but there is a baseline. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; go tell that to the unibomber.
</em><br>
<p>I would have been happy to point out to the unibomber that
<br>
he was born social, so much so that he couldn't raise his head
<br>
to feed.
<br>
<p>Then I'd ask him where his sociability ended. It could be an
<br>
insightful conversation. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; Some are quite capable
</em><br>
<em>&gt; &gt; of going it alone while others would die if seperated
</em><br>
<em>&gt; &gt; from the herd.
</em><br>
<p>None are capable of going it alone yet. But here is the point
<br>
in the future we may re-engineer ourselves to such an extent
<br>
that some may indeed feel capable of going it alone. And these
<br>
indivduals will not necessarily be able to be reasoned with 
<br>
with the same starting premises. These individuals may become
<br>
meglomanical persuing as the culmination of their individuality
<br>
dominance over all else. Because, if you have no empathy 
<br>
- why the hell not?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Only after some initial basic social assistance has 
</em><br>
<em>&gt; been rendered.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; We're dealing with [dynamic] adults here, no? 
</em><br>
<em>&gt; You don't intend to limit your morality to only those who
</em><br>
<em>&gt; are currently social? Nor do I intend to convert the bad eggs
</em><br>
<em>&gt; to altruism. I see it as far more useful to persuade the good
</em><br>
<em>&gt; eggs that if they do not want war with the bad eggs they had
</em><br>
<em>&gt; better acknowledge that principle 101 for the bad egg is 
</em><br>
<em>&gt; likely to be what is in this for me. If there is not an answer to
</em><br>
<em>&gt; that question then conflict will come about.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Many infants get suboptimal social assistance and the 
</em><br>
<em>&gt; outcomes are often dysfunctional people. But they are not 
</em><br>
<em>&gt; dysfunctional  by choice. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; but they're still dysfunctional, at least, according to what
</em><br>
<em>&gt; currently  passes for a majority of society.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yeah. And society pays the price. A more enlightened society
</em><br>
<em>&gt; might see better economies in avoiding the dysfunctional early
</em><br>
<em>&gt; socialisation.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; So i question ur assumption that everyone
</em><br>
<em>&gt; &gt; is social.... Its obviously a core belief in ur system, and certes, 
</em><br>
<em>&gt; &gt; generally speaking, it is the case that most people are social.
</em><br>
<em>&gt;
</em><br>
Everyone is social to a degree. Am I really saying that everyone 
<br>
is reachable through their residual sociability. I doubt it. I think
<br>
nature throws up dysfunctional types of all forms and some
<br>
genuine sociopaths can probably only be dealt with as amoral
<br>
threats. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Belief has nothing to do with it. I have learned and
</em><br>
<em>&gt; observed human infants I know that physiologically they 
</em><br>
<em>&gt; cannot survive without assistance - that they wish to survive
</em><br>
<em>&gt; - that they suckle if they can and cry if they can't is not a 
</em><br>
<em>&gt; matter of mere belief.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I'll agree with ur assessment on babies... now whats
</em><br>
<em>&gt; the relevance to your moral system?
</em><br>
<p>Babies will go with the flow and be sociable until their selfish
<br>
desires are frustrated. Then they have to learn to compromise
<br>
or they engage the world with power plays and as babies they
<br>
loss. But some learn enough from the lesson to grow older and
<br>
play better and win for a time. But in the end in 2003 the 
<br>
default prognosis is that all of us are dead. The premium is
<br>
on cooperation. To get people to cooperate you have to respect
<br>
their rational desire to look after their own interests. You have
<br>
to offer them deals that really are win win, or you have to expect
<br>
that their will be conflict and they have no moral obligation to 
<br>
buckle under and surrender their resources and power.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; But not all.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Not all to the same degree. But there is no person
</em><br>
<em>&gt; alive at present (to the best of my knowledge) with the power
</em><br>
<em>&gt; to stay alive without cooperating with others. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; but you acknowledge that it is a possibility?
</em><br>
<p>Yes. Imo that is a possibility. For me the interest in morality
<br>
is linked to an interest in politics and in the means by which the
<br>
possibility may more become a probability in my life time. 
<br>
Hey I am social, but I am also rational, and I am in this for
<br>
me :-) 
<br>
&nbsp;
<br>
<em>&gt; &lt;brett&gt; It is not necessary that social be about niceness 
</em><br>
<em>&gt; it is better, more funcitonal, if it is about an enlightened
</em><br>
<em>&gt;  understanding of frailty and the benefits of cooperation.
</em><br>
<em>&gt;  I would argue that tyrants that aim for the short glorious
</em><br>
<em>&gt;  life of Archilles in 2003 are short changing themselves.
</em><br>
<em>&gt;  They are sub-optimally selfish. With a tweak of their 
</em><br>
<em>&gt; value  systems they may be able to satisfy more of their 
</em><br>
<em>&gt; needs and desires by  cooperating. But many of them
</em><br>
<em>&gt;  would have to re-learn and I'd expect few of them to
</em><br>
<em>&gt;  change what has worked for them if they could not be
</em><br>
<em>&gt; presented with a compelling argument. If there is no 
</em><br>
<em>&gt; compelling argument that can be made to their self 
</em><br>
<em>&gt; interest then I would say that no real moral argument
</em><br>
<em>&gt;  is being put to them at all.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; ....except to say that they have presumeably 
</em><br>
<em>&gt; successfuly satisfied their own utility tables....
</em><br>
<p>No they optimised. But I'd argue they have sold themselves
<br>
short. They could and may in may cases yet achieve more.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt; If there was a creature that by nature was not social in
</em><br>
<em>&gt; &gt; any sense I would grant by my notion of morality that
</em><br>
<em>&gt; &gt; that creature would have no duties to others and that
</em><br>
<em>&gt; &gt; that creature would not be acting immorally in anything
</em><br>
<em>&gt; &gt; it did to others.  If one is sure that one is being
</em><br>
<em>&gt; &gt; threatened by a genuine sociopath by my moral reckoning
</em><br>
<em>&gt; &gt; one would not only be permitted to act in ones defence
</em><br>
<em>&gt; &gt; one would be morally obliged. 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; see now I wouldn't go that far; just because ur being
</em><br>
<em>&gt; &gt; threatened by a sociopath does not necessarily mean they
</em><br>
<em>&gt; &gt; will carry out that act;  there's a whole subset of sociopaths
</em><br>
<em>&gt; &gt; that lead &quot;normal&quot; lives without going through the murder
</em><br>
<em>&gt; &gt; sprees that characterize their (by our definitions) 
</em><br>
<em>&gt; &gt; less-successful brethern.  I think thats more of a policy issue
</em><br>
<em>&gt; &gt; (to be decided upon by each individual)....
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; That is exactly right. In the end the individual must
</em><br>
<em>&gt; decide moral policy for themselves. The intelligent individual
</em><br>
<em>&gt; will take into account existing social mores and laws but in
</em><br>
<em>&gt; the end they will not shirk the responsibility of the moral 
</em><br>
<em>&gt; decision. They cannot. To shirk is to allow defaults to go
</em><br>
<em>&gt;  into play.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; yes but ur system implies a judging of that moral code
</em><br>
<em>&gt; (at the end of the day) by other members of that society...
</em><br>
<em>&gt; so individual morality is irrelevant if the rest of the group
</em><br>
<em>&gt; does not consent to that action as being moral...
</em><br>
<p>No because we *are* social we learn at least some moral
<br>
codes as we becomes socialised. We maybe go through
<br>
something like Kohlbergs levels of moral reasoning. 
<br>
We learn terms like utlilitarianism and consequentialism
<br>
and from this social stock of idea on moral codes we
<br>
fashion our own. We don't invent from scratch. 
<br>
I'm suggesting we van bet better moral codes into the
<br>
ground water. These won;t remove from individuals the
<br>
need to make moral judgements but they will increase 
<br>
the likelihood that reason and enlightenment are brought
<br>
to the process of agreement making and law making.
<br>
<p><em>&gt; &lt;me&gt;my overall point is that saying you're action 
</em><br>
<em>&gt; (by your own moral standard) is moral is trivially 
</em><br>
<em>&gt; easy to do; convincing
</em><br>
<em>&gt; others is far more difficult.
</em><br>
<p>Absolutely. I am in my view doing a pretty poor and
<br>
very longwinded effort at that here. But perhaps in 
<br>
working it through like this I will be able to distill it
<br>
into something shorter and more convincing because
<br>
it will appeal to people as a sort of empowering 
<br>
knowledge. Like probability theory, or tit for tat. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [brett]
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; In practise I would have some residual doubts about
</em><br>
<em>&gt; &gt; the completeness of the sociopathy of even a creature
</em><br>
<em>&gt; &gt; such as Hitler so I would not feel completely free to
</em><br>
<em>&gt; &gt; exterminate him with extreme prejudice unless I had
</em><br>
<em>&gt; &gt; made a good faith reckoning as to the nature of him 
</em><br>
<em>&gt; &gt; as a threat to what I value. Then having made a 
</em><br>
<em>&gt; &gt; best a rational determination of the nature of the threat
</em><br>
<em>&gt; &gt; as I could given the time and context I would feel free
</em><br>
<em>&gt; &gt; to exterminate him with exteme prejudice and I 
</em><br>
<em>&gt; &gt; would expect to feel no guilt but only some misgivings
</em><br>
<em>&gt; &gt; that had I more time I might have judged better. ie.
</em><br>
<em>&gt; &gt; My concept of morality is I think in that sense
</em><br>
<em>&gt; &gt; practical. And it is extensible. If others share it,
</em><br>
<em>&gt; &gt; if they act rationally and in accordance with their selfish
</em><br>
<em>&gt; &gt;  best interests as they perceive it I can (in the context) 
</em><br>
<em>&gt; &gt; of this moral system have not fault them morally.  
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; now don't u see a contradiction therein? What if
</em><br>
<em>&gt; &gt; the sociopath, or even loony person (to broaden the set),
</em><br>
<em>&gt; &gt; is merely acting to fulfill his own utility (ergo munching
</em><br>
<em>&gt; &gt; on ur spleen or the like)?  I mean, just because someone
</em><br>
<em>&gt; &gt; else is &quot;selfishly&quot; (is their any other way?!) pursuing
</em><br>
<em>&gt; &gt; there own interests, doesn't necessarily mean ur own
</em><br>
<em>&gt; &gt; moral code should approve their own...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; No my moral code would tell me if this person
</em><br>
<em>&gt; is reasonable I can point out that their aspiration to munch
</em><br>
<em>&gt; on my spleen is well recognized by me and that that is not
</em><br>
<em>&gt; a circumstance  that I can permit to prevail. Either we
</em><br>
<em>&gt;  reason out a conclusion together or we fight to the death
</em><br>
<em>&gt;  now. I then invite them to do their calculations of 
</em><br>
<em>&gt; cooperation vs competition and consider how the
</em><br>
<em>&gt;  agreement if it is to be cooperation will be effectively 
</em><br>
<em>&gt; honored. If at any stage I feel that my appeals to their
</em><br>
<em>&gt;  reasoning is hopeless then I fall back on trying to kill 
</em><br>
<em>&gt; them before they kill me. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; what, you offer them half ur spleen? you're moral
</em><br>
<em>&gt; code has just failed to offer a suitable compromise to 
</em><br>
<em>&gt; another rational autonomous agent... whereas his 
</em><br>
<em>&gt; morality disregards yours, yours fails to achieve its
</em><br>
<em>&gt;  basic premise... that of being attractive to others
</em><br>
<em>&gt;  rational beings...
</em><br>
<p>No I offer them the viewpoint that getting my spleen
<br>
will come at great risk to them and provide them 
<br>
little nourishment. I suggest that they are better of 
<br>
regsrding me as a resource and seeking to cooperate
<br>
with me.  I am pretty resourceful and persuasive.
<br>
In many cases I'd expect to pull it off because I would
<br>
really find ways to cooperate. But in some cases
<br>
the universe is a bitch. If the other guy seems me
<br>
as food and I can't persuade him otherwise his 
<br>
circumstances and mine may genuinely be that 
<br>
desperate. Then, one of us will die and one of us
<br>
will eat.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Paul]
</em><br>
<em>&gt; &gt; &gt; Pretty much the only time u can consider something
</em><br>
<em>&gt; &gt; &gt; moral or immoral is after the event has occurred, 
</em><br>
<em>&gt; &gt; &gt; and then, only for urself.  Morality has absolutely
</em><br>
<em>&gt; &gt; &gt; no import in a pre-emptive doctrine.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]I don't agree. By my reckoning of morality, when
</em><br>
<em>&gt; &gt; individuals agree to cooperate with each other for their
</em><br>
<em>&gt; &gt; mutual advantage (perhaps at some cost to them on
</em><br>
<em>&gt; &gt; other dimensions were they reckoning their best
</em><br>
<em>&gt; &gt; interests separately) there is a moral bond between
</em><br>
<em>&gt; &gt; them.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; according to ur definition of morality :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Yes. According to a system I'm offering up 
</em><br>
<em>&gt; for consideration because I think there is some 
</em><br>
<em>&gt; consistency and utility in it and because if I am right
</em><br>
<em>&gt;  and it is teachable I will benefit by shifting the 
</em><br>
<em>&gt; cooperate (or) compete decision more towards
</em><br>
<em>&gt;  cooperation (just as if I had taught the principle 
</em><br>
<em>&gt; of tit for tat). 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; .. but is it the optimal solution?
</em><br>
<p>The optimal solution for me, for the other of for 
<br>
both of us? It is in my view more likely to be the
<br>
optimal solution in more circumstances because it
<br>
is the more rationally approached solution and 
<br>
by being rationally approached we can consider
<br>
each others real needs and measure each others
<br>
real willingness to compromise AND at the
<br>
end of the day we can always fall back on the
<br>
option to compete. Come that unfortunate outcome.
<br>
I would compete *very* hard. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Paul]
</em><br>
<em>&gt; &gt; &gt; Anyone that believes to the contrary has not
</em><br>
<em>&gt; &gt; &gt; rationally examined the situation.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Depends what you mean by belief. Belief
</em><br>
<em>&gt;  is a problem word for me because a lot of people
</em><br>
<em>&gt; who are doing more than mere believing use the 
</em><br>
<em>&gt; word belief to indicate a sort of less than certain
</em><br>
<em>&gt;  knowledge. The problem is that some people 
</em><br>
<em>&gt; that use the word belief may have done no 
</em><br>
<em>&gt; personal processing on the issue at hand at all but 
</em><br>
<em>&gt; may have simply adopted wholesale something that
</em><br>
<em>&gt;  they were indoctrinated with.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; the latter part of that paragraph is what 
</em><br>
<em>&gt; I'm implying; that any rational person who has 
</em><br>
<em>&gt; (without resort to emotion, or any rationalization
</em><br>
<em>&gt;  or justification) examined the concept of acting
</em><br>
<em>&gt;  pre-emptively (sans sufficient proof or knowledge
</em><br>
<em>&gt;  of the current environment) is reasoning falsely.
</em><br>
<p>Pre-emption is slippery. Consider the word 
<br>
pretext. Give a politician a pretext and they are no
<br>
longer arguing pre-emption they are arguing reasonable
<br>
and measured response. 
<br>
<p><em>&gt;  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; If you are implying that my proposed moral 
</em><br>
<em>&gt; system is flawed or inconsistent or unclear then, yes,
</em><br>
<em>&gt;  I am willing to accept that that  could be in fact a valid
</em><br>
<em>&gt;  criticism but I'd ask you to point out where  because 
</em><br>
<em>&gt; as I've said trying to find means of increasing cooperation
</em><br>
<em>&gt; and putting morality and ethics on a more rational footing
</em><br>
<em>&gt;  is a  worthwhile task.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; three points really; 
</em><br>
<em>&gt; a) it doesn't make a difference how you arrive at an API,
</em><br>
<em>&gt;  it is only important to establish one (rational or otherwise).
</em><br>
<em>&gt;
</em><br>
<em>&gt;  There is no reason that an emotional or intuitive based 
</em><br>
<em>&gt; person cannot maximize their own utility while being 
</em><br>
<em>&gt; consistent from an external point of view of their behaviors.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ergo, consistency is key {even more so than cooperation,
</em><br>
<em>&gt; becaue if you really want somebodies cooperation, you 
</em><br>
<em>&gt; will invariably have that already incorporated in ur utility
</em><br>
<em>&gt;  table [by virtue of it being a necessity to fulfill some other
</em><br>
<em>&gt;  greater utility] and ergo you will have something to offer in
</em><br>
<em>&gt; trade}.
</em><br>
<p>I think it does matter that its rational not emotional or faith
<br>
or belief based because reasoning facilitates coomunication
<br>
and understanding between sovereign agents far more 
<br>
effectively. Reason has as its tool language. I am not pooh
<br>
poohing emotion. Emotion is what makes life worth living
<br>
by emotions cannot be conveyed in the same way as 
<br>
reasons. Nor are they are reviewable and reliable in making
<br>
judgements. In science we do well to acknowledge that out
<br>
emotions can mislead us. I think we do well also to acknowledge
<br>
this in the formulation of contracts and laws. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; b) it should successfully deal with all types of people; that
</em><br>
<em>&gt;  includes people  who want to munch on ur spleen, and
</em><br>
<em>&gt;  people who are complete loners[antisocial], and even those
</em><br>
<em>&gt;  that aren't rational [non-functionally insane]
</em><br>
<p>It does those who finally want to munch on my spleen I regard
<br>
as forces of nature like sharks or lions. I don't regard their desire
<br>
to eat me as immoral but I definately regard my desire to avoid
<br>
being eaten as just and I feel fully free to exterminate such with
<br>
extreme prejudice.
<br>
<p>There are no *complete loners* that I am aware of. Yet the time
<br>
of the complete loner is likely to be in the future and these guys
<br>
cou;ld be very dangerous. For now dysfunctional loners that
<br>
poss a threat, when they poss a threat are fair game for 
<br>
taking action against. 
<br>
<p>There are patterns in most forms of insanity. I'd take my 
<br>
understanding of the particular person and their alledged ailment
<br>
into account and go from there. The code doesn't prescibe a 
<br>
solution to all it only provides a (better I hope) framework. 
<br>
Individual judgements still need to be made.
<br>
&nbsp;
<br>
<em>&gt; c) the API should be predicteable...having a code of laws
</em><br>
<em>&gt;  where no-one can predict whether or not they are in 
</em><br>
<em>&gt; compliance is pointless.  It doesn't  make a difference 
</em><br>
<em>&gt; whether or not they agree with the fundamental 
</em><br>
<em>&gt; reasonings, they should be able to follow the statements 
</em><br>
<em>&gt; out to their (hopefully logical) consequences or in barring
</em><br>
<em>&gt;  that, have a simple intuitive model to guide them.
</em><br>
<em>&gt; 
</em><br>
<p>I think my systme is more predictable than others. Those 
<br>
thatt present rationally are quickly processes rationally for
<br>
cooperate options and compete threats. Those that don't
<br>
operate in a rational paradign still fall into patterns. Animals
<br>
are not rational, inanimate objects are not rational, if a person
<br>
behaves in an irrational way they can often make themselves
<br>
grist for my mill or the mill of others that do act rationally
<br>
and with an eye for the political. 
<br>
<p><em>&gt; &gt; [brett]To be frank, I am doubtful that the word belief can
</em><br>
<em>&gt; &gt; be validly coupled (except as crude linguistic
</em><br>
<em>&gt; &gt; shorthand for &quot;this is my operating hypothesis&quot;) with
</em><br>
<em>&gt; &gt; a rational examination of  any situation. Belief is often
</em><br>
<em>&gt; &gt; used by fairly rational people in just this short hand
</em><br>
<em>&gt; &gt; manner.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; belief =&gt; a statement a rational agent holds true.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Many use it like this. I don't like it because I spend a lot
</em><br>
<em>&gt; of time considering the politics of language and communication.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I don't; I use a word sans negative or positive connotations.
</em><br>
<em>&gt; Descriptive, accurate and precise. The sentence is where I pass
</em><br>
<em>&gt; judgement on the thought, not the word.
</em><br>
<p>I accept that that is often true. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I think that if an extrope is debating with a flat earther in
</em><br>
<em>&gt;  front of an open minded audience and the audience is only partly 
</em><br>
<em>&gt; paying attention and they hear the extrope talking of beliefs on the 
</em><br>
<em>&gt; one hand and the flat earther talking of beliefs on the other the 
</em><br>
<em>&gt; audience may be seduced into thinking one belief may be just as 
</em><br>
<em>&gt; good as the other. I think it is in our interests to get some
</em><br>
<em>&gt; probability 
</em><br>
<em>&gt; and quantifiability into the discussion. Belief is language which 
</em><br>
<em>&gt; serves the preservation of the status quo. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I agree; if you are ambigious on how I am using a word,
</em><br>
<em>&gt; just ask for clarification.. vice versa on my end, assumed, of course.
</em><br>
<em>&gt; 
</em><br>
You miss the political point. The audience is the voting public. It is
<br>
up to extropians to convince them of our relatively non-conservative
<br>
agendas or tohave to wear the policies that are put in place. 
<br>
<p>It is for us to be smart in our communications or wear the
<br>
consequences ofnot being. When we use the word belief we weaken
<br>
our cases where they should be strongest -we usually have reasoned
<br>
and we unlike our opponents (should be) open to the superior 
<br>
argument.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; [Brett] By the code of morality I have tried to
</em><br>
<em>&gt; &gt; describe, belief qua belief is immoral. This is because
</em><br>
<em>&gt; &gt; when one is believing one is not reasoning and when
</em><br>
<em>&gt; &gt; one is not reasoning to the route of ones selfish best interest
</em><br>
<em>&gt; &gt; one is  groping with a less than optimal method.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt;
</em><br>
<em>&gt; &gt; depends on how u define it :) 
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Yes. And I don't think extropes generally define it as
</em><br>
<em>&gt; &gt; I do, but my point is that people who hear belief being
</em><br>
<em>&gt; &gt; used may be people we are trying to persuade and it
</em><br>
<em>&gt; &gt; behooves us to use the most persuasive language.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; disagree.  more important than persuading other
</em><br>
<em>&gt; people is establishing a way of communicating clearly
</em><br>
<em>&gt; and unambigiously, preferably with some training
</em><br>
<em>&gt; into how to accurately convey your thought processes
</em><br>
<em>&gt; to another, and how to detect (and request clarification)
</em><br>
<em>&gt; when others are using a word to convey a different
</em><br>
<em>&gt; semantic construct.  
</em><br>
<p>Often the extropic message is a most persuasiveluy put
<br>
when it is put in terms of clear and unambiguous 
<br>
communication. 
<br>
<p>I have personally seen huge decisons on national policy
<br>
&quot;justified&quot; by political leaders not on the basis of the
<br>
evidence but on the basis of belief.  
<br>
<p><em>&gt; Ergo I never argue persuasively, only defensively :)
</em><br>
<em>&gt; Lawyers argue persuasively, and just about everybody
</em><br>
<em>&gt; I know (excluding lawyers) hates dealing with them 
</em><br>
<em>&gt; [ergo a necessary evil]....
</em><br>
<p>Very much so. Fact is the legislation that exists in our
<br>
countries is established in a particular way. There is no
<br>
point wishing it were otherwise, it is as it is. Therefore
<br>
I'd rather be an effective lobbyist for the policies and
<br>
laws I want to see enacted (or not enacted) then not
<br>
be.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; Belief is a poor word for conveying significant amounts
</em><br>
<em>&gt; &gt; of intellectual exercise.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; And certes, just because
</em><br>
<em>&gt; &gt; you believe something doesn't necessarily make it false
</em><br>
<em>&gt; &gt; (or ill-advised); classic example, I believe the sun will rise 
</em><br>
<em>&gt; &gt; tomorrow morning...  Of course the veracity of that statement will 
</em><br>
<em>&gt; &gt; require observation tomorrow morning; but the belief is both advisable
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; and statistically speaking, fairly certain...  In other words, belief 
</em><br>
<em>&gt; &gt; and logic are not necessarily at odds; it depends on how you define
</em><br>
<em>&gt; &gt; it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; My point is that when you speak in a political forum you 
</em><br>
<em>&gt; do your own thought process which is based on considerably 
</em><br>
<em>&gt; more than mere indoctrination by another (I hope) a disservice 
</em><br>
<em>&gt; when you use the word belief instead of another word. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I see; you're making a broader point than are discussion :)
</em><br>
<p>Yes. Sorry I get evangelical sometimes. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt;(This is because not everyone who hears you use the word 
</em><br>
<em>&gt; belief knows that you will have done more processing. 
</em><br>
<em>&gt; It seems to me that many extropes fail to realise that the audience, 
</em><br>
<em>&gt; the rest of the world doesn't give away free credibility points 
</em><br>
<em>&gt; for one wacky belief over another.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; for me, personally, in day-to-day interactions, people always
</em><br>
<em>&gt; quickly realize that any thought I express has been well-thought out.
</em><br>
<em>&gt; I have not, of course, attempted to communicate in a traditional public
</em><br>
<em>&gt; forum {press, tv, etc} other than internet-based forums (list-servs and 
</em><br>
<em>&gt; usenet).  Incidentally, mostly because I'm not really trying to persuade
</em><br>
<em>&gt;  anybody of anything outside of my scope of interaction.  I'm primarily
</em><br>
<em>&gt; interested in getting my viewpoints out, to confirm whether or not there
</em><br>
<em>&gt; are any flaws in my thinking that I have missed, or to flesh out an idea
</em><br>
<em>&gt; by gathering other people's inputs on the subject, generally through 
</em><br>
<em>&gt; anecdotal experiences... The scientifically-based stuff I get through
</em><br>
<em>&gt; journals and books.
</em><br>
<p>Perhaps you are still relatively young and have yet to grow your political
<br>
teeth. This is fair enough. If you come to see the connection between
<br>
the stuff we aspire to and the legislations that goes through nation 
<br>
parliament on stem cells and nanotechnology and intellectual property
<br>
you may see things differently. I do not mean to be patronising. 
<br>
Actually I'd like to be empowering. Many young extropes could be
<br>
potent political forces for change in their own individual right if only
<br>
they perceived the need and put some time into acquiring the skills.
<br>
<p><em>&gt; &gt; [brett]My contention is that as soon as one becomes
</em><br>
<em>&gt; &gt; a &quot;believer&quot; one has ceased to hold to the principle
</em><br>
<em>&gt; &gt; of to thine own self be true - unless one is incapable
</em><br>
<em>&gt; &gt; of reasoning - (or one must reach a tentative
</em><br>
<em>&gt; &gt; conclusion based on the imperative to live and
</em><br>
<em>&gt; &gt; act in real time). 
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; hahahaha :) re - ur last qualification :)
</em><br>
<em>&gt; &gt; well since we're all stuck in this current universe... :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Yes, but again I'd go back to pan critical rationalism.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; Without ever getting absolute certainty there are techniques 
</em><br>
<em>&gt; which we can learn which give us a much higher probability of 
</em><br>
<em>&gt; getting a correct (a useful) answer.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; until you discover that extreme you didn't consider..
</em><br>
<em>&gt; I'm an engineer (mentality-wise), so for the most part, I 
</em><br>
<em>&gt; always have to  build/plan for the worst case scenario..
</em><br>
<em>&gt; Theoretically, that means I have a smaller margin for error
</em><br>
<em>&gt; before I'm willing to sweep it under the rug as not worth
</em><br>
<em>&gt; planning for.
</em><br>
<p>Soory don't follow. Sounds right but don;t see the 
<br>
relevance.
<br>
<p><em>&gt;  
</em><br>
<em>&gt; &gt; &gt; Generally speaking, I have no use for morality;
</em><br>
<em>&gt; &gt; &gt; just ethics [standard api, consistently adhered to,
</em><br>
<em>&gt; &gt; &gt; logically derived, based on reality]....
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]I'm reading api as 'application programming interface'.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; yuppers.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; [brett]&quot;Generally speaking&quot; I suspect you are unlikely to
</em><br>
<em>&gt; &gt; enjoy discussing morality and/or ethics much further
</em><br>
<em>&gt; &gt; with me ;-)
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; &lt;me&gt; it doesn't really bother me, if thats what u're asking :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; I was asking. I don't enjoy boring people, I just risk it ;-)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; thats fair :) generally the conversation ends up dying out when
</em><br>
<em>&gt; nobody bothers responding :)
</em><br>
<p>I expect that will be after this post and thats fair enough. It has
<br>
been good to try and write down some stuff and try and get some 
<br>
ideas straight. Or straighter. 
<br>
&nbsp;
<br>
<em>&gt; &gt; but I've pretty much made up my ethical system, at least
</em><br>
<em>&gt; &gt; in terms of the larger ruleset (meta-rules)...
</em><br>
<em>&gt; &gt; some of the smaller &quot;behaviors&quot; are data-driven  
</em><br>
<em>&gt; &gt; (tit-for-tat, etc) :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;brett&gt; As indeed in practice most of us have. If I am right
</em><br>
<em>&gt; and a better more universal ethical system can be derived
</em><br>
<em>&gt;  I would expect that in most peoples cases there would be
</em><br>
<em>&gt;  very little observable  differences in how they'd behave. 
</em><br>
<em>&gt; But then on the other hand when one starts to routinely 
</em><br>
<em>&gt; reason as oppose to believing one is  in a position to 
</em><br>
<em>&gt; converse mind to mind with other reasoning beings.
</em><br>
<em>&gt; Beliefs can very easily become entrenched positions. 
</em><br>
<em>&gt; I think to reason when reason is  available is more 
</em><br>
<em>&gt; social and because I think humans are social (their
</em><br>
<em>&gt;  interests are best served by cooperation) to  reason is
</em><br>
<em>&gt;  moral to believe is not.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;me&gt; I agree with everything but ur last statement :) 
</em><br>
<em>&gt; as I said, give me an simple, robust API anyday. 
</em><br>
<em>&gt;  It doesn't matter to me if there is a one-to-one mapping
</em><br>
<em>&gt;  between it and some derived, generic ethical system,
</em><br>
<em>&gt;  or there is a many-to-one mapping.  I generally prefer
</em><br>
<em>&gt;  rationally based systems in that the API happens
</em><br>
<em>&gt; to conform to reality [generally the other requirement,
</em><br>
<em>&gt; don't want to end up getting killed or maimed for my API]...
</em><br>
<p>To use you terminology I'm more concerned with the 
<br>
consequences of trying to push forward with a suboptimal
<br>
API.
<br>
<p><em>&gt; I dunno, overall, I have some fairly big problems with 
</em><br>
<em>&gt; your API.
</em><br>
<p>I can tell. But thanks for persisting its helped me clarify
<br>
my thoughts. 
<br>
<p><em>&gt; 
</em><br>
<em>&gt; I think more than anything else though, its that social 
</em><br>
<em>&gt; requirment thing... :)  Then again, I've been described
</em><br>
<em>&gt;  by several people in my life as a human computer...
</em><br>
<p>:-)  I agree the social bit is the weaker bit. 
<br>
<p>Regards,
<br>
Brett 
<br>
<p>{PS: No reply expected - frankly it would scare
<br>
me to have to revisit this thread at this length again
<br>
soon - I need to break it out, seriously edit and
<br>
see what happens next}
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12522.html">Mike Lorrey: "Orlowski: Your hate piece on Robin Hanson"</a>
<li><strong>Previous message:</strong> <a href="12520.html">Natasha Vita-More: "Re: FWD (forteana) Meet the 'transhumanists' behind the Pentagon terror  casino"</a>
<li><strong>In reply to:</strong> <a href="12476.html">Paul Grant: "RE: To thine ownself be true?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12635.html">Paul Grant: "RE: To thine ownself be true?"</a>
<li><strong>Reply:</strong> <a href="12635.html">Paul Grant: "RE: To thine ownself be true?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12521">[ date ]</a>
<a href="index.html#12521">[ thread ]</a>
<a href="subject.html#12521">[ subject ]</a>
<a href="author.html#12521">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Aug 05 2003 - 13:05:45 MDT
</em></small></p>
</body>
</html>
