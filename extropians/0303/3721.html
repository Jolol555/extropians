<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: Why will we reach the singularity?</title>
<meta name="Author" content="Robert J. Bradbury (bradbury@aeiveos.com)">
<meta name="Subject" content="Re: Why will we reach the singularity?">
<meta name="Date" content="2003-03-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why will we reach the singularity?</h1>
<!-- received="Sat Mar  1 14:26:12 2003" -->
<!-- isoreceived="20030301212612" -->
<!-- sent="Sat, 1 Mar 2003 13:26:10 -0800 (PST)" -->
<!-- isosent="20030301212610" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Re: Why will we reach the singularity?" -->
<!-- id="Pine.LNX.4.44.0303011108430.9244-100000@server.aeiveos.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="5.1.0.14.2.20030301102327.00ab8ec0@pop.skynet.be" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robert J. Bradbury (<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20Why%20will%20we%20reach%20the%20singularity?"><em>bradbury@aeiveos.com</em></a>)<br>
<strong>Date:</strong> Sat Mar 01 2003 - 14:26:10 MST
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3722.html">Dehede011@aol.com: "Re: Communism-Capitalism 500yrs"</a>
<ul>
<li><strong>Previous message:</strong> <a href="3720.html">Artillo5@cs.com: "Re: IRAQ: Fire the script writer, please"</a>
<li><strong>In reply to:</strong> <a href="3710.html">Joao Magalhaes: "Why will we reach the singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3724.html">Reason: "RE: Why will we reach the singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3721">[ date ]</a>
<a href="index.html#3721">[ thread ]</a>
<a href="subject.html#3721">[ subject ]</a>
<a href="author.html#3721">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Joao, now this is indeed an interesting question and I will offer
<br>
my comments not having reviewed the other comments.
<br>
<p><em>&gt; I've been wondering on why are transhumanists so confident that we will
</em><br>
<em>&gt; reach the singularity.
</em><br>
<p>The question of the &quot;singularity&quot; (and how it is perceived) is tied up
<br>
in the &quot;soft&quot; vs. &quot;hard&quot; takeoff scenarios.  My personal opinion is
<br>
that the &quot;inertia&quot; of humanity will tend to bias development towards
<br>
the &quot;soft&quot; side of things (i.e. a slow ramp-up to the singularity).
<br>
<p><em>&gt; In truth, I'm disappointed with what's being done and I want to know
</em><br>
<em>&gt; why are transhumanists so confident we will reach the singularity.
</em><br>
<p>Some of the rest of us who have spent a great deal of their personal
<br>
resources are disappointed as well *but* there are some interesting
<br>
developments that offset this (the Ellison Medical Foundation comes
<br>
to mind).
<br>
<p>In truth, a real &quot;singularity&quot; must require one of two things:
<br>
(a) a majority of humans must accept that they have to increase
<br>
&nbsp;&nbsp;&nbsp;&nbsp;the rate of their self-evolution and act accordingly; or
<br>
(b) that an independent self-evolving unconstrained AI is developed.
<br>
<p>I don't view (b) as a good alternative for humanity unless Eliezer's
<br>
efforts at a &quot;friendly&quot; AI are successful.
<br>
<p>We have made progress in astrophysics but it is a very slow journey.
<br>
<p><em>&gt; It's true breakthroughs have been made in
</em><br>
<em>&gt; biology and medicine, such as the Human Genome Project, but, shit, we
</em><br>
<em>&gt; haven't even cured AIDS, how can we expect to cure aging anytime soon?
</em><br>
<p>Two *very* different problems (I must stress this).  HIV is a problem
<br>
involving a virus with a genome replication mechanism designed to be
<br>
sloppy.  Aging is a problem with a genome replication mechanism
<br>
designed to be increasingly accurate (as the longevity of the
<br>
species increases).  That is not to say that accurate genome replication
<br>
prevents aging (there are a host of other problems one has to solve
<br>
to prevent aging) -- but that innacurate genome replication cannot
<br>
but contribute to aging (obviously if one has evolved a genetic
<br>
program with &quot;minimal&quot; aging and it becomes corrupted so that it
<br>
is no longer that program the impact is most likely to be detrimental.)
<br>
<p><em>&gt; Also, I'm disappointed with the way science is made in the academia with
</em><br>
<em>&gt; personal egos rising above finding the mechanisms of aging. If we want to
</em><br>
<em>&gt; cure aging, we need to work together, but not many do that.
</em><br>
<p>Not completely true.  Since I'm not in &quot;academia&quot; I can function somewhat
<br>
independently of that framework.  That has allowed me positions on both
<br>
the AGE and ExI boards of directors.  So I can exert some influence
<br>
and have done so when the opportunity has been available.  Aubrey
<br>
de Grey is doing similar functions with regards to the 10th IABG
<br>
Congress.
<br>
<p>But my observations (of a decade or so of being involved in aging
<br>
research) are that it is very much related to a lack of interest
<br>
(belief) that the problem can be solved and therefore a lack of
<br>
funding and/or qualified scientists going into the area (these
<br>
are obviously related).
<br>
<p><em>&gt; In the end, I would say that the basis for the singularity is Moore's law,
</em><br>
<em>&gt; for it allows not only faster computers but also developments in DNA
</em><br>
<em>&gt; sequencing and a host of other possibilities.
</em><br>
<p>Yes, obviously so.
<br>
<p><em>&gt; Yet I'm sure there are physical limits for Moore's law. When will we
</em><br>
<em>&gt; reach them? Can you be sure Moore's law will continue for long enough
</em><br>
<em>&gt; to develop a smarter-than-man artificial intelligence?
</em><br>
<p>The hard limits were discussed in quite great detail in Drexler's
<br>
Nanosystems { Sections 12.8 and 12.9 (and all of the discussion
<br>
leading up to that) }.
<br>
<p>You can get 10^21 OPS, roughly 6 times greater than our best estimate
<br>
of a brain at 10^15 OPS, but multiplied by the fact that the
<br>
nanocomputer probably occupies a volume of ~1 cm^3 compared to the
<br>
brain's &gt; 1000 cm^3 (so propagation delays are significantly less
<br>
and &quot;intelligence&quot; may be significantly greater).
<br>
<p>Or in other words -- a nanocomputer is potentially a *lot* smarter
<br>
than humans (on the order of millions to billions of times).
<br>
<p>When we will reach these limits depends on to a large extent on economic
<br>
factors.  I have received information that the U.S. investment in
<br>
venture capital declined from $90 billion to $19 billion between
<br>
2000 and 2002.  So if you want to evaluate technology and business
<br>
development, one has to factor economics into the process.  But I
<br>
think it is safe to assume that we *will* push this envelope
<br>
(i.e. to the limits of Moore's Law) within this century, perhaps
<br>
within the next few decades.
<br>
<p>(This is, in part, Ray Kurzweil's message, but I am adapting it a bit to
<br>
allow for my own perspectives.)
<br>
<p><em>&gt; When I found transhumanism, already several years ago, I thought it set an
</em><br>
<em>&gt; optimistic but plausible scenario. Now, I'm starting to wonder if we're not
</em><br>
<em>&gt; just another cult willing to sacrifice reality towards a fairer image of
</em><br>
<em>&gt; the world.
</em><br>
<p>We are *definitely* in the &quot;optmistic/plausible&quot; scenario.
<br>
I and others have been, over the last decade, been willing to put
<br>
&quot;money on the line&quot;.  There is clearly viewable progress
<br>
(where in the mid-90's there were essentially two significant
<br>
companies involved in aging research, now there are more than
<br>
a dozen).  I see progress in other transhumanistic perspectives
<br>
as well (see recent NY Times articles on the installation of solar
<br>
power systems at the Whitehouse).
<br>
<p>Joao, do not lose hope -- it is just that progress sometimes takes
<br>
much longer than we would like (or expect).
<br>
<p>*But* please do not count the singularity out.  It depends in large
<br>
part how we develop its foundations.
<br>
<p>Robert
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3722.html">Dehede011@aol.com: "Re: Communism-Capitalism 500yrs"</a>
<li><strong>Previous message:</strong> <a href="3720.html">Artillo5@cs.com: "Re: IRAQ: Fire the script writer, please"</a>
<li><strong>In reply to:</strong> <a href="3710.html">Joao Magalhaes: "Why will we reach the singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3724.html">Reason: "RE: Why will we reach the singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3721">[ date ]</a>
<a href="index.html#3721">[ thread ]</a>
<a href="subject.html#3721">[ subject ]</a>
<a href="author.html#3721">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Sat Mar 01 2003 - 14:31:07 MST
</em></small></p>
</body>
</html>
