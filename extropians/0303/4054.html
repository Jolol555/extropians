<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)</title>
<meta name="Author" content="Michael M. Butler (mmb@spies.com)">
<meta name="Subject" content="AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)">
<meta name="Date" content="2003-03-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)</h1>
<!-- received="Sun Mar  9 15:35:55 2003" -->
<!-- isoreceived="20030309223555" -->
<!-- sent="Sun, 09 Mar 2003 14:35:46 -0800" -->
<!-- isosent="20030309223546" -->
<!-- name="Michael M. Butler" -->
<!-- email="mmb@spies.com" -->
<!-- subject="AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)" -->
<!-- id="oprlsg1w1smkbtpc@spies.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20030309210359.65556.qmail@web80103.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael M. Butler (<a href="mailto:mmb@spies.com?Subject=Re:%20AI%20Risks,%20was%20Re:%20Rulers%20and%20Famine%20in%20Poor%20Countries%20(was%20Obesity)"><em>mmb@spies.com</em></a>)<br>
<strong>Date:</strong> Sun Mar 09 2003 - 15:35:46 MST
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4055.html">Rafal Smigrodzki: "Re: funding and advocacy for anti-aging research"</a>
<ul>
<li><strong>Previous message:</strong> <a href="4053.html">Rafal Smigrodzki: "Re: Do patents really foster innovation?"</a>
<li><strong>In reply to:</strong> <a href="4051.html">Adrian Tymes: "Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4073.html">Adrian Tymes: "Re: AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<li><strong>Reply:</strong> <a href="4073.html">Adrian Tymes: "Re: AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4054">[ date ]</a>
<a href="index.html#4054">[ thread ]</a>
<a href="subject.html#4054">[ subject ]</a>
<a href="author.html#4054">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Adrian Tymes &lt;<a href="mailto:wingcat@pacbell.net?Subject=Re:%20AI%20Risks,%20was%20Re:%20Rulers%20and%20Famine%20in%20Poor%20Countries%20(was%20Obesity)">wingcat@pacbell.net</a>&gt; wrote:
<br>
<em>&gt; --- &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20AI%20Risks,%20was%20Re:%20Rulers%20and%20Famine%20in%20Poor%20Countries%20(was%20Obesity)">sentience@pobox.com</a>&gt;
</em><br>
<em>&gt; wrote:
</em><br>
<em>&gt;&gt; Robert J. Bradbury wrote:
</em><br>
...
<br>
<em>&gt;&gt; &gt; while I'm concerned
</em><br>
<em>&gt;&gt; &gt; that before then we might get a rogue AI
</em><br>
...
<br>
<em>&gt;&gt; I finally did work out
</em><br>
<em>&gt;&gt; the theory that describes what it is going from point A to point B
</em><br>
<em>&gt;&gt; when a moral human builds a moral AI, and it turns out that if you
</em><br>
<em>&gt;&gt; build an AI and you don't know exactly what the hell you're doing, you 
</em><br>
<em>&gt;&gt; die. Period.  No exceptions.
</em><br>
<em>&gt;
</em><br>
<em>&gt; You have a *chance* of dying.  You could, totally by
</em><br>
<em>&gt; accident, wind up doing the right thing anyway.  This
</em><br>
<em>&gt; is not the same thing as guaranteed death.
</em><br>
<p>And the combinatorics could wind up resulting in a likelihood smaller than 
<br>
the quantity 1 over the number of seconds that have elapsed since the Big 
<br>
Bang. That's not the same as guaranteed death, but it's the way to bet if 
<br>
those are the odds. So are odds of 1 in 100.
<br>
<p>Adrian, just for my couriosity's sake, how do you figure
<br>
the odds? I'm not just asking that question rhetorically.
<br>
<p>Against that, I think a case can be made that, for issues as hairy as this, 
<br>
Bayes isn't applicable in a vacuum; we don't get to refine our estimates
<br>
over multiple trials that include catastrophe--maybe the human race does 
<br>
(if
<br>
we luck out), maybe not, but probably not we here assembled. Conflict 
<br>
levels
<br>
of 11 (that's 10^11 casualties--hundreds of millions dead) /or more/ also 
<br>
surely change the weight.
<br>
<p><em>&gt;
</em><br>
<em>&gt;&gt; Do you have any ideas for dealing with this besides
</em><br>
<em>&gt;&gt; building FAI first? Because as far as I can tell, humanity is in
</em><br>
<em>&gt;&gt; serious, serious trouble.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes.  Build an AI that you can trust, even if it
</em><br>
<em>&gt; quickly goes beyond your control.
</em><br>
...
<br>
<em>&gt; perspective), but if you can trust someone else to be
</em><br>
<em>&gt; gifted with the capabilities that an AI would have...
</em><br>
<p>I agree with what you're saying but (and perhaps this is also what you're 
<br>
saying) the only way I can see to apply the level of trust I give to a 
<br>
person is to guarantee the physical limitations and the
<br>
developmental psychological ground of an actual human.
<br>
<p>I wonder how likely this is, given the fraction of people with technical 
<br>
chops that would dismiss this out of hand as [quasi]paranoid.
<br>
We internet-enable hot tubs, for goodness' sake. So the first aspect 
<br>
(physical limitations) is likely to be ignored in some way by even the 
<br>
&quot;embodied consciousness&quot; folks.
<br>
<p>MMB
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4055.html">Rafal Smigrodzki: "Re: funding and advocacy for anti-aging research"</a>
<li><strong>Previous message:</strong> <a href="4053.html">Rafal Smigrodzki: "Re: Do patents really foster innovation?"</a>
<li><strong>In reply to:</strong> <a href="4051.html">Adrian Tymes: "Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4073.html">Adrian Tymes: "Re: AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<li><strong>Reply:</strong> <a href="4073.html">Adrian Tymes: "Re: AI Risks, was Re: Rulers and Famine in Poor Countries (was Obesity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4054">[ date ]</a>
<a href="index.html#4054">[ thread ]</a>
<a href="subject.html#4054">[ subject ]</a>
<a href="author.html#4054">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Sun Mar 09 2003 - 15:40:55 MST
</em></small></p>
</body>
</html>
