<!-- received="Thu Jan  7 06:37:07 1999 MDT" -->
<!-- sent="07 Jan 1999 14:36:28 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Paths to Uploading" -->
<!-- id="b49k8yz6w83.fsf@void.nada.kth.se" -->
<!-- inreplyto="Wed, 6 Jan 1999 19:33:50 -0000" -->
<!-- version=1.10, linesinbody=110 -->
<html><head><title>extropians: Re: Paths to Uploading</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: Paths to Uploading</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>07 Jan 1999 14:36:28 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#188">[ date ]</a><a href="index.html#188">[ thread ]</a><a href="subject.html#188">[ subject ]</a><a href="author.html#188">[ author ]</a>
<!-- next="start" -->
<li><a href="0189.html">[ Next ]</a><a href="0187.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0163.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Bryan Moss" &lt;bryan.moss@dial.pipex.com&gt; writes:

<p>
<a href="0163.html#0188qlink1">&gt; &gt;&gt; Why do we have such small brains? To me it suggests that the level of</a><br>
<i>&gt; &gt;&gt; complexity achievable is *very* close to the achieved level.</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt;I have the impression that you are not seriously proposing any upper</i><br>
<i>&gt; &gt;limit on intelligence.</i><br>
<i>&gt; </i><br>
<i>&gt; Friends and family might argue that I've never proposed anything serious in</i><br>
<i>&gt; my life, but I'm in two minds about this. There's a beautiful coherent and</i><br>
<i>&gt; hopefully quite brilliant concept in the making but I can't get my brain</i><br>
<i>&gt; around it at the moment. </i><br>

<p>
It would be wonderfully ironic if there was some law that there is an
upper limit to intelligence, and all intelligences are too weak to
truly understand or prove the law.  :-)

<p>
(seriously, limits and hindrances like this may correspond to the
"toposophical barriers" discussed in Lem's Golem XIV. I think they may
exist, but they are not necessarily impermeable)

<p>
<i>&gt; Later in your post you mention a Theory of</i><br>
<a href="0163.html#0188qlink2">&gt; Complexity, that's where I'm going with this, only I'm shying away from</a><br>
<i>&gt; using the term 'complexity' because I'm worried I might abuse it.</i><br>

<p>
Don't worry, everybody is abusing the poor term. :-)

<p>
<a href="0163.html#0188qlink3">&gt; Let's say there is a parameter of the universe called 'complexity' and it</a><br>
<i>&gt; defines how easy it is to make a complex structure of any kind. Now if this</i><br>
<i>&gt; parameter is set to low (complex structures are unlikely) life would not</i><br>
<i>&gt; have evolved. If this parameter is set too high (complex structures are</i><br>
<i>&gt; highly likely) and complex structures formed very easily then the</i><br>
<i>&gt; generalisations (systems like DNA, protein, intelligence, etc) that we call</i><br>
<i>&gt; 'life' would not have evolved. </i><br>

<p>
This assumes that the complexity parameter affects all levels. It
sounds a bit like the "border of chaos" idea: "interesting systems"
(i.e life) are possible only in the zone between too much order (low
complexity in your terminology) and too much chaos (high complexity in
your terminology). In the chaotic domain patterns are not stable
because new patterns continually form, and in the ordered domain new
patterns have a hard time emerging or surving.

<p>
<a name="0209qlink1">Note that your complexity parameter is system dependent: some systems
(like gases) have low complexity, you can't build anything interesting
from them, others are too complex (turbulent plasmas?). And
metasystems formed from other systems (like molecules of atoms or
clumps of matter from molecules) can have quite different
complexity. The *BIG* questions are if there is some kind of "master
complexity parameter" that affects all or most levels of the universe,
or if it is just physics that allows different systems and their
complexity parameters could be calculated (somehow) from</a> the
interactions.

<p>
<a href="0163.html#0188qlink4">&gt; Now - and this is where it gets</a><br>
<i>&gt; really sketchy - I'm imagine something similar for 'intelligence' but I have</i><br>
<i>&gt; absolutely no idea how to explain it at the moment. Fundamentally I don't</i><br>
<i>&gt; think it's wrong to suggest that there might be an upper limit to</i><br>
<i>&gt; intelligence, the way I imagine it is a graph with 'generalisation' and</i><br>
<i>&gt; 'specialisation' plotted against each other and diagonal line travelling</i><br>
<i>&gt; between them.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;     Generalisation</i><br>
<i>&gt;           |\</i><br>
<i>&gt;           |  \</i><br>
<i>&gt;           |    o We are close to here</i><br>
<i>&gt;           |      \</i><br>
<i>&gt;           |        \</i><br>
<i>&gt;           ------------ Specialisation</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; And this all corresponds to the limited complexity of the system.</i><br>

<p>
<a name="0209qlink3">Suppose you have a limited amount of mental resources to put into
learning and applying your knowledge. Should you specialize or
generalize? The answer depends on your environment and goals - on a
primordial African savannah being a generalist when it comes to
survival is essential, in a pampered western world you get richly
rewarded for specializing narrowly (at least I, as a graduate student,
gets rewarded for it). We might have biases left by evolution, which
has of course set some basic level of ability and interest suitable
for our evolutionary past.</a>

<p>
<a href="0163.html#0188qlink5">&gt; [I hate having to explain fragments of ideas that are probably just ill</a><br>
<i>&gt; logic on my part.]</i><br>

<p>
Know the feeling. 

<p>
<a href="0163.html#0188qlink6">&gt; &gt;Neurotech is going to be the controversial thing. What does "human"</a><br>
<i>&gt; &gt;mean when you can alter it? Not just enhance memory or change sexual</i><br>
<i>&gt; &gt;preferences, but add *new* structures to the brain like the ability to</i><br>
<i>&gt; &gt;do something like episodic memory for muscle movements? Lots of issues</i><br>
<i>&gt; &gt;here, and biotech will contribute with problems.</i><br>
<i>&gt; </i><br>
<a name="0209qlink4"><i>&gt; I'd be interested to hear what you thought of Dyson's 'radiotelepathy' in</i><br>
<i>&gt; _Imagined Worlds_.</a></i><br>

<p>
<a name="0209qlink5">Yes, he has an interesting point and I think something like that may
become very useful if it can be built. We are already getting there
with mobile phones. At the same time, when I read it I felt that good
old Dyson is getting old - he never even mentioned nanotechnology, and
seemed somehow stuck in a Stapledon world. Very odd.</a>

<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0189.html">[ Next ]</a><a href="0187.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0163.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
</body></html>
