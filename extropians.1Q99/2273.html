<!-- received="Wed Feb 24 14:48:14 1999 MDT" -->
<!-- sent="Wed, 24 Feb 1999 20:34:53 +0000" -->
<!-- name="Nick Bostrom" -->
<!-- email="bostrom@ndirect.co.uk" -->
<!-- subject="RE: FAQ Additions (Posthuman mind control)" -->
<!-- id="199902242037.UAA15452@sioux.hosts.netdirect.net.uk" -->
<!-- inreplyto="003401be6003$1a090640$352501c0@mfg130" -->
<!-- version=1.10, linesinbody=48 -->
<html><head><title>extropians: RE: FAQ Additions (Posthuman mind control)</title>
<meta name=author content="Nick Bostrom">
<link rel=author rev=made href="mailto:bostrom@ndirect.co.uk" title ="Nick Bostrom">
</head><body>
<h1>RE: FAQ Additions (Posthuman mind control)</h1>
Nick Bostrom (<i>bostrom@ndirect.co.uk</i>)<br>
<i>Wed, 24 Feb 1999 20:34:53 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2273">[ date ]</a><a href="index.html#2273">[ thread ]</a><a href="subject.html#2273">[ subject ]</a><a href="author.html#2273">[ author ]</a>
<!-- next="start" -->
<li><a href="2274.html">[ Next ]</a><a href="2272.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2250.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2286.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
Billy Brown wrote:

<p>
<a href="2250.html#2273qlink1">&gt; If you are going to create an actual person (as opposed to an animal, or a</a><br>
<i>&gt; special-purpose device), you have a moral obligation to give them the</i><br>
<i>&gt; ability to reason, to learn, and to grow.  Any sentient being should be</i><br>
<i>&gt; capable of asking questions, seeking the answers, and applying those answers</i><br>
<i>&gt; to their own thoughts and actions.</i><br>

<p>
<a name="2286qlink1">Does this mean you think that no animals are sentient? Sounds 
implausible to me.</a>

<p>
<a href="2250.html#2273qlink2">&gt; This standard still gives wide latitude in the choice of personality,</a><br>
<i>&gt; intelligence level, ease of self-modification, etc.  However, it would</i><br>
<i>&gt; forbid any truly permanent form of mind control.  To enforce a fixed moral</i><br>
<i>&gt; code you must create a mind that is incapable of thinking about morality, or</i><br>
<i>&gt; (more likely) that is capable of thinking about it but can never change its</i><br>
<i>&gt; mind.</i><br>

<p>
<a name="2286qlink2">No, at least that is not what I am proposing. Let it be able to think 
about morality. Let it also be able to change its fundamental values. 
If I am right then that won't matter, because it will not *want* to 
change them. (I'm almost tempted to defin a "fundamental value" as: a 
preference that you would not want to change.) What I am suggeting is 
that any SI we build has repect for human rights as a fundamental 
value. As long</a> aswe make sure it has that value, then we need have 
nothing to fear. It will go about its business and perhaps transform 
itself into a power beyond all human understanding, but it would not 
harm us humans, because it would not want to harm us. Maybe speaking 
of an "inviolable moral code as a core element of its programming" 
conjures up the wrong conotations -- as if it were some form of 
coercion going on. I see it simply as selecting one type of value 
(human-friendly) rather than another (indifferent or hostile).

<p>
The value-selection process might not be that explicit. Maybe as 
Moravec thinks, the SI will grow out of robot factories. Since robot 
factories that produce nice robots will tend to proliferate more than 
ones that produce nasty ones, natural selection could favour 
human-friendly values. The nasty ones, no one would want to buy. 
Except if you had malicious intents or didn't care about the risks a 
badly programmed robot would pose to other humans. And that is what 
should be prohibited, especially with top-range superintelligent 
robots, since they could cause so disproportionally much harm.

<p>
Nick Bostrom
<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a>      n.bostrom@lse.ac.uk
Department of Philosophy, Logic and Scientific Method
London School of Economics
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2274.html">[ Next ]</a><a href="2272.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2250.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2286.html">Billy Brown</a>
</ul>
</body></html>
