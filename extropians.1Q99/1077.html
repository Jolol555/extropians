<!-- received="Fri Jan 22 08:05:18 1999 MDT" -->
<!-- sent="Fri, 22 Jan 1999 09:04:59 -0600" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="RE: Nanotech Arms Race" -->
<!-- id="000301be4618$96e43450$352501c0@mfg130" -->
<!-- inreplyto="36A7A7E5.CB108193@together.net" -->
<!-- version=1.10, linesinbody=81 -->
<html><head><title>extropians: RE: Nanotech Arms Race</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>RE: Nanotech Arms Race</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Fri, 22 Jan 1999 09:04:59 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1077">[ date ]</a><a href="index.html#1077">[ thread ]</a><a href="subject.html#1077">[ subject ]</a><a href="author.html#1077">[ author ]</a>
<!-- next="start" -->
<li><a href="1078.html">[ Next ]</a><a href="1076.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1060.html">Michael S. Lorrey</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="1113qlink1">Michael S. Lorrey wrote:
<br>
<a href="1060.html#1077qlink1">&gt; You own implicit assumption which I find weak is that there needs to be an</a><br>
AI to
<br>
<a href="1060.html#1077qlink2">&gt; run this system. The thing with nanotech is that you can give the little</a><br>
buggers
<br>
<a href="1060.html#1077qlink3">&gt; simple instructions to fulfill, and when done, die. You also assume that</a><br>
if
<br>
<a href="1060.html#1077qlink4">&gt; there were an AI, that it would, could, or couldn't be restricted from,</a><br>
<i>&gt; developing enough independence to prevent the mad plot to blast</a> the</i><br>
planet.
<br>
<a href="1060.html#1077qlink5">&gt; Computers are, despite their power, amazingly stupid devices when they</a><br>
don't
<br>
<a href="1060.html#1077qlink6">&gt; have good software. Even the smartest ones can easily be programmed to</a><br>
take no
<br>
<a href="1060.html#1077qlink7">&gt; initiative (or, rather, just don't program it to take initiative).</a><br>

<p>
Let's stick with the same example: "Computer, go gather two million comets
from the Oort cloud, make a giant projectile out of them, and smash it into
the Earth."  What does the computer have to do to carry out that order?

<p>
Well, first it has to figure out how to do the job.  That means inventing a
whole range of spacecraft, construction robots (nanoscale or otherwise),
power systems, giant propulsion systems, etc.  Then it has to co-ordinate
all the work - so we add in a system-spanning communication system, all
kinds of sensors, and a huge computer network.  Oh, lets not forget - it has
to program all those robotic gadgets, plus the computers that will
coordinate their work.

<p>
Then it builds the initial seed and sends it on its way - oh, wait, we also
need to invent an Earth-based launch system and figure out where to aim it
(better build some astronomy gear).  When the seed finally arrives on site
it starts building - and unexpected things happen (the unexpected *always*
happens on construction projects).  So the software running the project
needs to be smart enough to adapt to unforeseen problems, inventing
solutions along the way to its goal.

<p>
<a name="1113qlink2">Add it all up, and you have a system that has all the intelligence of a
human engineering &amp; construction team.  It can do pretty much anything a
human could, but millions of times faster.  It doesn't really matter how it
works internally - it could be an algorithmic AI, a giant neural net, an
ecosphere of evolving programs, or a mixlplic of quasitronic gimrods.  From
the outside, the effect is the same as having a lobotomized SI.

</a>
<p>
I make no assumptions about the nature of the AI - I just pointed out that
if it already does everything a sentient can do *except* take action of its
own volition, it won't be long before someone adds that last missing piece
to their copy of the program.  I do think that you would have to invent a
fully sentient AI before you could figure out how to make one that can act
sentient without having a sense of self, but that isn't central to the
argument.

<p>
<a name="1113qlink3"><a href="1060.html#1077qlink8">&gt; A missing factor in these blast calculations is seismic. Get enough</a><br>
impacts
<br>
<a href="1060.html#1077qlink9">&gt; going at once and the shock waves will turn the entire lithosphere (the</a><br>
crust)
<br>
<a href="1060.html#1077qlink10">&gt; of the planet to lava. Diamonds burn just fine at such temperatures.... We</a><br>
know
<br>
<i>&gt; that this is an effective strategy because the Alvarez asteroid which</i><br>
killed the
<br>
<a href="1060.html#1077qlink11">&gt; dinos created a shock wave that went around the planet and focused in the</a><br>
middle
<br>
<a href="1060.html#1077qlink12">&gt; of the Indian Ocean (where the island which is now India was at the time)</a><br>
and
<br>
<a href="1060.html#1077qlink13">&gt; turned the area which is now the Deccan plateau to lava.....</a><br>
<i>&gt;</i><br>
<i>&gt; I would say that 20 asteroids or comets about 20 miles in diameter</i><br>
impacting at
<br>
<a href="1060.html#1077qlink14">&gt; once in a dodecahedral pattern would do the trick....</a><br>

<p>
Sorry, no.  That's a fantasy.  It takes around 10^18 calories to melt one
cubic kilometer of rock.  Your asteroids carry about 10^21 cal apiece, so
the whole flock could melt 20,000 cubic km - which is less than their own
combined volume of 81,000 cubic km, and insignificant on the scale</a> of a
planet.  In practice most of the energy gets dispersed over a large area in
the form of flash, shock wave, flying debris, and so on, so the actual
melting effect is even smaller.

<p>
Billy Brown, MCSE+I
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1078.html">[ Next ]</a><a href="1076.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1060.html">Michael S. Lorrey</a>
<!-- nextthread="start" -->
</ul>
</body></html>
