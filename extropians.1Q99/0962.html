<!-- received="Tue Jan 19 13:02:31 1999 MDT" -->
<!-- sent="Tue, 19 Jan 1999 14:52:45 -0500" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="retroman@together.net" -->
<!-- subject="Re: A moral zero-point?" -->
<!-- id="36A4E28D.24B7ADC0@together.net" -->
<!-- inreplyto="A moral zero-point?" -->
<!-- version=1.10, linesinbody=21 -->
<html><head><title>extropians: Re: A moral zero-point?</title>
<meta name=author content="Michael S. Lorrey">
<link rel=author rev=made href="mailto:retroman@together.net" title ="Michael S. Lorrey">
</head><body>
<h1>Re: A moral zero-point?</h1>
Michael S. Lorrey (<i>retroman@together.net</i>)<br>
<i>Tue, 19 Jan 1999 14:52:45 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#962">[ date ]</a><a href="index.html#962">[ thread ]</a><a href="subject.html#962">[ subject ]</a><a href="author.html#962">[ author ]</a>
<!-- next="start" -->
<li><a href="0963.html">[ Next ]</a><a href="0961.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0884.html">joe dees</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
joe dees wrote:

<p>
<a name="0976qlink1"><a href="0884.html#0962qlink1">&gt; At Mon, 18 Jan 1999 10:48:12 -0500, you wrote:</a><br>
<i>&gt; &gt;This is what I dispute. While most, or all ethical systems do not agree</a> on everything, there are plenty of commonalities among most of them, especially the most successful of them, to imply that there is an inherent objective truth to the shared heuristics, at least as far as the human species is concerned. There may also be a subset of this set which may be objective truth for all thinking beings.</i><br>
<i>&gt; &gt;</i><br>
<i>&gt;</i><br>
<i>&gt; If by "zero-point" you mean cases or classes where all ethical systems would agree, the most likely candidates are the ancient prohibitions against murder, theft, rape, cheating and lying; yet even in these, exceptions can be found, which may be exceptions in some systems but not in others.  Can you furnish an example of such a "zero-point"?</i><br>

<p>
First of all I don't require that ALL ethical systems share identical heuristics, for the plain fact that some ethical/moral systems are demonstrated to be more successful than others, because they are more 'fit' due to their closer dovetailing with optimal objective morality.

<p>
I would also say that there are two types of morals or ethics in any system, proscriptive and prescriptive, which often condition or impose exceptions on the other.  While theft is discouraged, compassion for and sharing resources with those in need is encouraged, for example (or while murder, rape, assault, and battery is discouraged, defending yourself and others from such assaults is encouraged).

<p>
This is why ethics or morals are a system of inter-related heuristics, rather than just a few simple rules that are black and white and not related to each other (even though some moral systems try to be that simple). Simplicity does aid in propagation and popular compliance, to a point, but there is a limit to how simple or complex a system can go and remain functional, adaptable, and stable over a long term.

<p>
Just because a moral or ethical system is very inter-relational does not make it subjective, it is just complex and abstracted.<a name="1007qlink4"> The Golden Rule, which semantically is very simple and easy to remember and propagate, can only be seen as a generalization over a complex amount of subjective considerations and thus has considerable amount of paradox built into it (i.e. if I'm a masochist, should I hurt others because that is how I want to be treated?) as
has been described on this list in other recent posts, but it is extremely adaptable due to its vagueness as well, thus having long term viability. However, it does accurately define two seemingly objective morals/ethics: being true to the self and being true to others,</a> placing both on an equal/commutative moral or ethical footing. One could argue that putting the second on equal footing with the first tends to serve only to optimize the first, and is
not a sucessful goal in and of itself, which is why systems which emphasize others over the self in any and all situations tend to not be as successful as ones oriented toward the self, but putting the interests of others on a similar footing being only because it is directly beneficial to the self (as Anders has talked about his models which compare cooperators versus individuals practicing "might is right").

<p>
Mike Lorrey
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0963.html">[ Next ]</a><a href="0961.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0884.html">joe dees</a>
<!-- nextthread="start" -->
</ul>
</body></html>
