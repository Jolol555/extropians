<!-- received="Mon Mar 29 10:39:53 1999 MDT" -->
<!-- sent="Mon, 29 Mar 1999 10:39:05 -0600" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="RE: Yudkowsky's AI (again)" -->
<!-- id="001601be7a02$b1445000$352501c0@mfg130" -->
<!-- inreplyto="199903280050.AAA06305@sioux.hosts.netdirect.net.uk" -->
<!-- version=1.10, linesinbody=50 -->
<html><head><title>extropians: RE: Yudkowsky's AI (again)</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>RE: Yudkowsky's AI (again)</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Mon, 29 Mar 1999 10:39:05 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3791">[ date ]</a><a href="index.html#3791">[ thread ]</a><a href="subject.html#3791">[ subject ]</a><a href="author.html#3791">[ author ]</a>
<!-- next="start" -->
<li><a href="3792.html">[ Next ]</a><a href="3790.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3685.html">Nick Bostrom</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Nick Bostrom wrote:
<br>
<i>&gt; Billy Brown wrote:</i><br>
<a href="3685.html#3791qlink1">&gt; &gt;I won't pretend to know what it will actually do at that point,</a><br>
<i>&gt; &gt; but I can't see it being concerned about something as prosaic as its</i><br>
<i>&gt; &gt; supply of atoms.</i><br>
<i>&gt;</i><br>
<i>&gt; Why not? If it is better off (however slightly) with these atoms than</i><br>
<i>&gt; without them, then in this scenario could all be dead, unless we have</i><br>
<i>&gt; been wise enough to make sure that the power is ethical..</i><br>

<p>
Note: I assume here that we're talking about strong SI and some variant of
the rapid self-enhancement scenario.

<p>
Well, first off, I think an SI is going to invent its own ethics long before
it really deserves that label.  IMO, everything any human has ever thought
of on the topic is going to seem intuitively obvious to such an entity.
Now, whether its morals will agree with ours is still an open question
(although I side with Eliezer in expecting that the SI is more likely to be
correct than we are).

<p>
But that aside, atoms are mostly useful for bulky, clumsy, primitive
applications like nanotechnology and electronic computers.  An SI with
moderately advanced nanotech can convert a few cubic meters of mass into a
computer in hours or less, and would probably do so.  However, the delays
involved in manipulating bulk matter on any larger scale are going to seem
agonizingly long once it ports itself to that first machine.  How willing
are you to wait several days to complete the project if your consciousness
runs 10^12 times faster than that of a human?

<p>
IMHO, what happens next depends on the ultimate nature of physics.  I see
two important cases:

<p>
<a name="3854qlink1">If it is possible to migrate to some kind of custom-engineered reality, the
SI will do so before it has existed long enough to bother with changing any
significant portion of the Earth (moving atoms is so *slow*, after all).
There is a very small chance that this could have side effects that would
destroy Earth, but it seems unlikely - if such a project is not possible at
low energy levels, the SI will probably have to migrate to some location
where high energy densities can be achieved.

<p>
If such projects are not possible, the SI will probably migrate to whatever
part of the universe is best suited for its projects.  Since all of the
options that have been suggested require exotic physical conditions (i.e.
the surface of a neutron star), I conclude that there is little chance it
would want to stay here.  So, once again the odds are in our favor.</a>

<p>
Billy Brown, MCSE+I
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3792.html">[ Next ]</a><a href="3790.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3685.html">Nick Bostrom</a>
<!-- nextthread="start" -->
</ul>
</body></html>
