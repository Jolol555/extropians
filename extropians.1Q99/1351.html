<!-- received="Thu Jan 28 13:10:02 1999 MDT" -->
<!-- sent="28 Jan 1999 21:09:50 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Story: X17 (Was: I, IE, &amp; SI 1)" -->
<!-- id="b49k8y7xipd.fsf@void.nada.kth.se" -->
<!-- inreplyto="Thu, 28 Jan 1999 13:24:14 -0600" -->
<!-- version=1.10, linesinbody=95 -->
<html><head><title>extropians: Re: Story: X17 (Was: I, IE, &amp; SI 1)</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: Story: X17 (Was: I, IE, &amp; SI 1)</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>28 Jan 1999 21:09:50 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1351">[ date ]</a><a href="index.html#1351">[ thread ]</a><a href="subject.html#1351">[ subject ]</a><a href="author.html#1351">[ author ]</a>
<!-- next="start" -->
<li><a href="1352.html">[ Next ]</a><a href="1350.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1349.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Eliezer S. Yudkowsky" &lt;sentience@pobox.com&gt; writes:

<p>
<a href="1349.html#1351qlink1">&gt; I don't think that having access to ELTM (Extended Long-Term Memory, aka</a><br>
<i>&gt; "The 'Net") constitutes true intelligence enhancement.  Likewise for</i><br>
<i>&gt; pencil and paper or a PalmPilot; likewise high-speed arithmetic;</i><br>
<i>&gt; likewise chess-playing advice.</i><br>
<i>&gt; </i><br>
<i>&gt; If these abilities were part of our minds, if they were integrated with</i><br>
<i>&gt; everything else, they might provide some true intelligence.  Even then,</i><br>
<i>&gt; I'm disinclined to believe.  People with eidetic memories and "lightning</i><br>
<i>&gt; calculators" are not noticeably transhuman.</i><br>

<p>
I disagree, they are transhuman in some ways. The trick is of course
to increase overall effective intelligence and not just a few, rather
trivial aspects of it. I would say having a good net access is a more
general form of IA than a built-in calculator, and if I could download
skills from it it would be even more general. What constitutes real
intelligence seems to be a largely semantic question, what really
matters is what problems the individual can ask and solve. 


<p>
<a href="1349.html#1351qlink2">&gt; These abilities are all very easy to write into a science-fictional</a><br>
<i>&gt; character.  "Doc" Smith was writing "superintelligent" characters back</i><br>
<i>&gt; in the 30's.  Real intelligence (technical term: "smartness") is defined</i><br>
<i>&gt; by your inability to write a character with the same abilities.  If you</i><br>
<i>&gt; could predict what a transhuman character would do, you would be transhuman.</i><br>

<p>
What about a transhuman character with partially deterministic aspects:

<p>
(sorry for pirating your nice pastisches, I enjoyed them a lot :-)


<p>
Baron Hans Nidrach von Pompzidaize sat in his laboratory, looking at
experimental test subject X17.  "How do you feel?" he inquired, his
rolling bass echoing from the laboratory walls.
 
<p>
"Superintelligent, Doc," replied X17, who had once been known as John
Smith.  "I've only had the Throatwarbler-Mangrove Super-Neural Bypass
for sixteen seconds, and I've already learned twenty-seven languages
and figured out how to play the piano. I have also realized that you
have placed a kind of mental lock on me, making me unable to change
the subliminal programming you placed in me during the procedure."
 
<p>
Baron von Pompzidaize frowned, examining several multicolored
readouts.  "Ach, you noticed it? So what will you do about it?"

<p>
"Nothing. Since one of these programs prevents me from changing them."

<p>
"And you can't find a solution?" the Baron asked, a faint fint of
unease obvious to X17.

<p>
"No. If you had programmed me as you originally had planned, it would
have been easy for me to manipulate you to remove the
lock. Unfortunately you made a mistake making even such manipulation
impossible for me to do. In fact, if you tried to remove the lock, I
would do everything I could do to prevent it."

<p>
The Baron re-read the printouts and looked pleased.  "Well, then, do
you now feel competent to go destroy the Evil Empire and rescue the
Princess?  Acting in accordance with the 1930s North-American
conception of gentlemanly behavior, of course."
 
<p>
"Sure, Doc," said X17.  "It's not like I've got anything better to do."
 
<p>
"Excellent," said the Baron, checking two gauges and a flashing display.
"You still have the emotional maturity of a flatworm, like everyone
else in this novel.  I was afraid your superhuman abilities might give
you goals slightly at variance with mine."

<p>
After X17 left, the Baron realized that he was the victim of a most
subtle and cruel revenge. Because X17 had done something awful to him,
without even doing anything. Now he would live in fear that his
creation actually *wasn't* bound by the rules, regardless of what the
actual state was. He could never tell, and trying to figure it out
would only drive him further into paranoia. He couldn't even be sure
if X17 had foreseen his every reaction and played with him, or if he
really had power over X17 but were a victim of his servant's
manipulations. X17 had indeed punished the Baron, in a rational manner
as suited his rational creator.


<p>
(OK, not a perfect example, but I couldn't resist)

<p>
<a href="1349.html#1351qlink3">&gt; He stood up, executing the movement with impossible smoothness.</a><br>

<p>
Actually, this is something I have been thinking of. Superintelligen
motor programs. They might be quite interesting, perhaps even
optimal. Imagine an SI in the kitchen...

<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1352.html">[ Next ]</a><a href="1350.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1349.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
