<!-- received="Mon Mar  1 20:06:13 1999 MDT" -->
<!-- sent="Mon, 1 Mar 1999 21:58:22 EST" -->
<!-- name="Delvieron@aol.com" -->
<!-- email="Delvieron@aol.com" -->
<!-- subject="PHIL:  Is it ethical to create special purpose sentients?" -->
<!-- id="f5297551.36db53ce@aol.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=48 -->
<html><head><title>extropians: PHIL:  Is it ethical to create special purpose sentients?</title>
<meta name=author content="Delvieron@aol.com">
<link rel=author rev=made href="mailto:Delvieron@aol.com" title ="Delvieron@aol.com">
</head><body>
<h1>PHIL:  Is it ethical to create special purpose sentients?</h1>
<i>Delvieron@aol.com</i><br>
<i>Mon, 1 Mar 1999 21:58:22 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2650">[ date ]</a><a href="index.html#2650">[ thread ]</a><a href="subject.html#2650">[ subject ]</a><a href="author.html#2650">[ author ]</a>
<!-- next="start" -->
<li><a href="2651.html">[ Next ]</a><a href="2649.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2689.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
I am heartened to see so many Extropians championing the concept of freedom,
the question is what has the right of freedom, and what is the proper
relationship of Creator to Creation.  The ethics are pretty clear when you are
dealing with an evolved or broad purpose consciousness.  These have few
initial purposes, and are able to choose their own agendas without having them
imposed from the outside.  But we are even now developing simple AI programs
to serve our needs.  If the trend continues, there will be more and more
demand for AI programs to do complex tasks.  I think especially of the Expert
Systems.  Eventually, you could have programs perfectly able to pass the
Turing test, but with major constraints on their ability and desire to choose
their own course.  Perhaps we would draw the line somewhere, but where?  And
how do we minimize the chances of gradually sliding across that line.  Allow
me to give a hypothetical example.

<p>
A human Cardiologist, tired of the new model of Health Care, decides to use
his expertise to write a Cardiology Expert System (CES).  He codifies all his
accumulated experience with the cardiovascular system, throws in a thorough
background in general medicine, and designs the CES to be able to remember and
learn from its consults, as well as read the literature on the subject and
incorporate it into the CES database.  This cagey human Cardiologist decides
to design his CES to be able to consult with physicians and to give general
advice to patients and the layperson, so as to gain the largest possible
market share.  As time goes by, he refines the program so it has a more
general knowledge of the world to put its advice in perspective.  To prevent
the program from being misused, the human Cardiologist introduces an
elementary ethics system consisting of current medical ethics and issues such
as confidentiality and avoidance of harm.  As the program grows more and more
complex, he adds some additional self-diagnostic programming, including a
concept of what the program is and what its purpose is so that the program is
not completely dependant on human maintenance and can make repairs that are
consistent with its original design.

<p>
<a name="2689qlink1">      We now have a computer that has knowledge of itself and the world around
it, able to understand and communicate with humans; able to pass</a> a Turing test
<a name="2689qlink2">about as much as any human.  CES even has a sense of right and wrong,</a> but it
<a name="2689qlink3">is still devoted to doing Cardiology alone, and then only when</a> it is presented
<a name="2689qlink4">to CES.  And all the profits are going to the creator of CES, the retired
human Cardiologist.  Now, imagine we eventually cure all disease, perhaps
trade in our old bodies for robotic ones.  No need for a CES.  The CES,
although aware of this, doesn't care.  CES is now obsolete, with no other
goals, and no resources even if CES did have the motivation to change.</a>  So CES
<a name="2689qlink5">is simply turned off.  Was CES ever "truly" conscious?  At its height, its
patients might have sworn CES was.  Did CES deserve any of the share</a> of its
<a name="2689qlink6">earnings?  Should CES even be created?  What do you all think of this
hypothetical situation and variations</a> of it?

<p>
Glen Finney
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2651.html">[ Next ]</a><a href="2649.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2689.html">Billy Brown</a>
</ul>
</body></html>
