<!-- received="Tue Jan 12 21:54:15 1999 MDT" -->
<!-- sent="Tue, 12 Jan 1999 22:53:12 -0600" -->
<!-- name="Scott Badger" -->
<!-- email="wbadger@psyberlink.net" -->
<!-- subject="Re: Subjective Morality" -->
<!-- id="00b601be3eb0$b9f41560$ae9112cf@wbadger" -->
<!-- inreplyto="Subjective Morality" -->
<!-- version=1.10, linesinbody=100 -->
<html><head><title>extropians: Re: Subjective Morality</title>
<meta name=author content="Scott Badger">
<link rel=author rev=made href="mailto:wbadger@psyberlink.net" title ="Scott Badger">
</head><body>
<h1>Re: Subjective Morality</h1>
Scott Badger (<i>wbadger@psyberlink.net</i>)<br>
<i>Tue, 12 Jan 1999 22:53:12 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#555">[ date ]</a><a href="index.html#555">[ thread ]</a><a href="subject.html#555">[ subject ]</a><a href="author.html#555">[ author ]</a>
<!-- next="start" -->
<li><a href="0556.html">[ Next ]</a><a href="0554.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0544.html">Lee Daniel Crocker</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Thank you for your thoughtful, patient, and articulate response 
Lee.  I'm having a difficult time with this concept and I appreciate 
your efforts to enlighten.

<p>
Lee Daniel Croker wrote:


<p>
<a href="0544.html#0555qlink1">&gt;&gt; How did you determine that is your best course?  What exactly </a><br>
<i>&gt;&gt; is wrong with a rational, functional, utilitarian morality?</i><br>
<i>&gt;</i><br>
<i>&gt;"Rational", "functional", and "utilitarian" are value judgments</i><br>
<i>&gt;as well, so there might be something very "wrong" with them, or</i><br>
<i>&gt;there might not be.  Or there might be no way to judge.</i><br>


<p>
Probably the latter.

<p>
<a href="0544.html#0555qlink2">&gt;Our epistemologies have improved over the years to the point</a><br>
<i>&gt;where many of us are quite willing to express confidence in and</i><br>
<i>&gt;make a personal /commitment/ to the "reality" of propositions</i><br>
<i>&gt;about the world.  I plant crops, confident the Sun will rise</i><br>
<i>&gt;tomorrow to nourish them; I treat my infection with antibiotics</i><br>
<i>&gt;rather than leeches; I refrain from filling my gas tank with</i><br>
<i>&gt;milk, confident that my understanding of combustion justifies</i><br>
<i>&gt;that decision.  We further have confidence that any two</i><br>
<i>&gt;sufficiently intelligent beings will reach the same conclusions</i><br>
<i>&gt;about nature; we call this "objective reality".</i><br>
<i>&gt;</i><br>
<i>&gt;Is there any reason to suspect that our moral philosophies will</i><br>
<i>&gt;not also continue to improve as our natural philosophies have?</i><br>
<i>&gt;Is there some barrier that will prevent future intelligences</i><br>
<i>&gt;from having as much confidence in their choice of action as I</i><br>
<i>&gt;have now in my descriptions of nature?  Is there some reason</i><br>
<i>&gt;that two intelligences /cannot/ of necessity reach the same</i><br>
<i>&gt;moral conclusion about the same circumstances?  Might it not</i><br>
<i>&gt;be the case that our moral epistemologies will evolve to the</i><br>
<i>&gt;point where I can bet my life that any other intelligent being</i><br>
<i>&gt;will reach the same moral conclusion as I, just as I would bet</i><br>
<i>&gt;it on eir reaching the same physical conclusion as I?  I would</i><br>
<i>&gt;call that state of affairs "objective morality".</i><br>


<p>
It sounds like you're saying that if enough people agree on a 
moral system, it can be considered to be an objective reality.  
If everyone on Earth agreed that the Sun was warm, I would 
withhold judgement until unbiased instrumentation repeatedly 
confirmed the hypothesis.  I would then have high confidence,
as I assume you would.  The same goes for the rest of objective
reality.  How are morals to be measured?  Is broad consensus 
across species really an acceptable criterion?  What if the 10,000th
species we run into disagrees?  Do we simply conclude that they're
"unevolved"?

<p>
<a href="0544.html#0555qlink3">&gt;Objective reality is a powerful concept that allows humans to</a><br>
<i>&gt;do miraculous things, like building bridges that don't collapse</i><br>
<i>&gt;and cars that run.  I do not yet have confidence that there</i><br>
<i>&gt;exists an objective morality, but the potential it would hold</i><br>
<i>&gt;for allowing us to do even more miraculous things demands that</i><br>
<i>&gt;I seek it, for the same reason I must seek objective reality.</i><br>
<i>&gt;Just because I can't see it is no reason to abandon the search.</i><br>


<p>
Please explain.  What leads you to believe that an "objective" 
morality is more powerful than a non-objective (perhaps rational, 
functional, utilitarian) morality?  What advantage does objectivity 
offer?  Is it not more parsimonious to hypothesize that moral 
systems are a function of evolution and culture?  Would you 
suggest that moral systems exist without sentience?  Are they 
objective in that sense?  If the existence of a moral system 
relies upon our contemplations of it, how can it be objective?  
I suspect that the laws of natural selection are at work wherever 
sentience arises, but the cultural differences will most likely 
result in differing moral systems from species to species.

<p>
Here's a question.  Would you expect an SI from Earth to have
the "exact" same moral system as an SI from Vega?

<p>
<a href="0544.html#0555qlink4">&gt;Until then, I also see value in behaving /as if/ there is such</a><br>
<i>&gt;a thing, and making a personal commitment to behaving in a</i><br>
<i>&gt;manner consistent with my current best guess as to what it is,</i><br>
<i>&gt;because I have no better moral epistemology to use...yet.</i><br>


<p>
My guess is that your moral system and mine are highly 
congruent.  I also suspect that alien intelligences have 
constructed similar moral systems to ours.  None of that, 
in my mind, necessarily lends credence to the notion of an 
objective morality.

<p>
But perhaps our definitions are misconstrued.  I suspect that 
moral systems between highly evolved intelligences will be 
highly congruent due to the laws of natural selection and the 
laws of social psychology.  If this is the case, does that make 
it objective?

<p>
Scott Badger
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0556.html">[ Next ]</a><a href="0554.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0544.html">Lee Daniel Crocker</a>
<!-- nextthread="start" -->
</ul>
</body></html>
