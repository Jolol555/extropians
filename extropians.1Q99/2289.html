<!-- received="Wed Feb 24 16:51:12 1999 MDT" -->
<!-- sent="Thu, 25 Feb 1999 00:46:41 +0100" -->
<!-- name="den Otter" -->
<!-- email="neosapient@geocities.com" -->
<!-- subject="Re: FAQ Additions (Posthuman mind control)" -->
<!-- id="199902242351.PAA24633@geocities.com" -->
<!-- inreplyto="FAQ Additions (Posthuman mind control)" -->
<!-- version=1.10, linesinbody=45 -->
<html><head><title>extropians: Re: FAQ Additions (Posthuman mind control)</title>
<meta name=author content="den Otter">
<link rel=author rev=made href="mailto:neosapient@geocities.com" title ="den Otter">
</head><body>
<h1>Re: FAQ Additions (Posthuman mind control)</h1>
den Otter (<i>neosapient@geocities.com</i>)<br>
<i>Thu, 25 Feb 1999 00:46:41 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2289">[ date ]</a><a href="index.html#2289">[ thread ]</a><a href="subject.html#2289">[ subject ]</a><a href="author.html#2289">[ author ]</a>
<!-- next="start" -->
<li><a href="2290.html">[ Next ]</a><a href="2288.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2274.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->



<hr>
<br>
<a name="3593qlink1"><a href="1669.html#2289qlink1">&gt; From: Eliezer S. Yudkowsky &lt;sentience@pobox.com&gt;</a><br>

<p>
<a href="2274.html#2289qlink2">&gt; den Otter wrote:</a><br>
<i>&gt; &gt; </i><br>
<i>&gt; &gt; Morals are subjective, but the most practical (=rational) course of action</i><br>
<i>&gt; &gt; would be not to create AIs with SI potential and work on uploading instead.</i><br>
</a><i>&gt; &gt; Again, our prime directive should _always_ be survival. Survival is the</i><br>
<i>&gt; &gt; prerequisite for _all_ other actions. Any philosophy that does not value</i><br>
<i>&gt; &gt; personal survival [in an optimal state] above everything else is by definition</i><br>
<i>&gt; &gt; irrational. Thus follows that transhumanism (with an immortalist element)</i><br>
<i>&gt; &gt; is the best philosophy currently available to us.</i><br>
<i>&gt; </i><br>
<i>&gt; den Otter, according to your philosophy, Newton should have forgotten</i><br>
<i>&gt; about all that silly "physics" stuff and pursued alchemy or theology,</i><br>
<i>&gt; which (at the time) were widely considered the most plausible courses to</i><br>
<i>&gt; immortality. </i><br>

<p>
Well, first of all this philosophy is meant for the present and
future, and not the (distant) past. People simply didn't have the 
means back then to make truly rational choices and more importantly,
to save themselves. It would only be frustrating to be an atheistic
immortalist back then, though had it been more widespread
we'd probably be well past the Singularity by now. Had Newton
followed my philosphy, he would probably still have done good
scientific work, only aimed at life extension instead of "general"
physics. But this is irrelevant, as the philosophy is for the 20th
century and up.

<p>
Anyway, you seem to disagree that survival is the prerequisite
for all other actions, and thus a rational prime directive, or is
it something else? Any goal, no matter how grand it is, is
useless [to you] once you're dead. You won't be watching from
afar and enjoying your work, as many seem to (subconsciously)
think.

<p>
<a href="2274.html#2289qlink3">&gt; By your standards Gilgamesh behaved more ethically than</a><br>
<i>&gt; Socrates. </i><br>

<p>
A somewhat strange comparison, IMO. What do you exactly
mean here? 
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2290.html">[ Next ]</a><a href="2288.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2274.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
