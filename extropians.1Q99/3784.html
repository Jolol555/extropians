<!-- received="Mon Mar 29 09:17:00 1999 MDT" -->
<!-- sent="Mon, 29 Mar 1999 17:16:25 +0000" -->
<!-- name="Nick Bostrom" -->
<!-- email="bostrom@ndirect.co.uk" -->
<!-- subject="Re: reasoning under computational limitations" -->
<!-- id="199903291616.RAA30419@sioux.hosts.netdirect.net.uk" -->
<!-- inreplyto="36FE95A8.86238637@pobox.com" -->
<!-- version=1.10, linesinbody=117 -->
<html><head><title>extropians: Re: reasoning under computational limitations</title>
<meta name=author content="Nick Bostrom">
<link rel=author rev=made href="mailto:bostrom@ndirect.co.uk" title ="Nick Bostrom">
</head><body>
<h1>Re: reasoning under computational limitations</h1>
Nick Bostrom (<i>bostrom@ndirect.co.uk</i>)<br>
<i>Mon, 29 Mar 1999 17:16:25 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3784">[ date ]</a><a href="index.html#3784">[ thread ]</a><a href="subject.html#3784">[ subject ]</a><a href="author.html#3784">[ author ]</a>
<!-- next="start" -->
<li><a href="3785.html">[ Next ]</a><a href="3783.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3722.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3799.html">Lee Daniel Crocker</a>
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky wrote:

<p>
<a href="3722.html#3784qlink1">&gt; Nick Bostrom wrote:</a><br>
<i>&gt; &gt; </i><br>
<i>&gt; &gt; Eliezer S. Yudkowsky wrote:</i><br>
<i>&gt; &gt; </i><br>
<i>&gt; &gt; &gt; Of course.  There are eleven people with the correct digit and nine</i><br>
<i>&gt; &gt; &gt; people with nine different incorrect digits.  Ergo, your digit is</i><br>
<i>&gt; &gt; &gt; probably the right one.</i><br>
<i>&gt; &gt; </i><br>
<i>&gt; &gt; Are you aware that this is the same reasoning that gives rise to the</i><br>
<i>&gt; &gt; Doomsday argument? Do you accept that argument? If not, why?</i><br>
<i>&gt; </i><br>
<i>&gt; What are we talking about, here?  The idea that we probably live in the</i><br>
<i>&gt; time with the largest population, ergo there are no galactic civilizations?</i><br>

<p>
Very roughly, yes.

<p>
<a href="3722.html#3784qlink2">&gt; Nope.  Argument falls apart if the population keeps growing infinitely. </a><br>

<p>
You are right that the infinite case is problematic. However, 
problematic is not the same as wrong; and anyway it does not settle 
the finite case.

<p>
Let's look at the infinite case however. Try the following variant of 
Wei's example: There is a countable infinity of people with various 
even numbers; and in addition there are either (A) ten people with 
number 3 and one person with number 5; or (B) one person with number 
3 and ten people with number 5. Suppose that you find that you have 
number 3. It would seem reasonable for you to think that given this, 
A is more likely than B. And yet this is an example where there is an 
infinite population and where the argument consequently "breaks down" 
-- the conditional probability of you having number 3 is zero (or 
infinitessimal) on both A and B.

 
<p>
<a href="3722.html#3784qlink3">&gt; I mean, what you're saying is that if I don't know whether I'm in an</a><br>
<i>&gt; environment where everyone has different numbers or everyone has the</i><br>
<i>&gt; same number, no matter which number I get, I should predict that</i><br>
<i>&gt; everyone has the same number.</i><br>

<p>
No, that depends on what the background information is.

<p>
Suppose you have two hypotheses each with 50% prior probability: (H1) 
There is a number n (0&lt;=n&lt;=9) such that everybody have the number n; 
(H2) For each number n (0&lt;=n&lt;=9), one tenth of all people have number 
n. Then finding that you have, say, number 7 doesn't give you any 
reason to prefer H1 to H2.

<p>
But suppose that instead of H1 you had (H1*): Everybody has number 7. 
And suppose that the prior probability of H1* is 50% and that the 
prior probability of H2 is also 50%. Then, finding that you have 
number 7 does indeed give you reason to think that H1* is true.


<p>
<a href="3722.html#3784qlink4">&gt; The Doomsday argument doesn't look very predictive.  I mean, every</a><br>
<i>&gt; single generation except ours that tried to use it would be wrong,</i><br>
<i>&gt; right?</i><br>

<p>
No, it doesn't say that our generation will be the last. It says that 
we have underestimated the risk that there won't be very many 
generations after ours. So we don't yet know whether our grandparents 
(or their grandparent) would have been wrong if they had applied the 
DA. But if the first few humans had applied it, then, yes, they would 
have been misled.

<p>
<a href="3722.html#3784qlink5">&gt;  And we have no reason to think that we'll be different, right? </a><br>
<i>&gt; According to the "predict the present given the past" clause, this</i><br>
<i>&gt; heuristic is no good.</i><br>

<p>
This is a common objection, but it is incorrect. The DA is a 
probabilistic argument, and as such it can and will give misleading 
results if applied in untypical circumstances. The first few humans 
were in untypical circumstances and therefore it is not surprising 
that they would have been misled. But try this exercise: Suppose 
everybody that will ever have lived applied the DA. Will that lead to 
a greater or a smaller fraction being right than if nobody applies 
it? We can demand of a probabilistic principle that it never misleads 
us; only that following it we will be right more often than not.


<p>
<a href="3722.html#3784qlink6">&gt; Actually, I don't know if I accept the Doomsday argument.  Maybe when I</a><br>
<i>&gt; decide, I'll add another adjective to Yudkowsky's Modified Anthropic</i><br>
<i>&gt; Occam's Razor.</i><br>

<p>
A suicidal twist of Occam's razor?

<p>
<a href="3722.html#3784qlink7">&gt; But if I did accept the Doomsday argument, given the number of times I</a><br>
<i>&gt; have to use the Anthropic principle to explain my own existence - once</i><br>
<i>&gt; for the noncomputable qualia, and another time for being a Specialist,</i><br>
<i>&gt; and another time for having the chance to do something fun and</i><br>
<i>&gt; important, e.g. Singularity - I'd have to assume I was a computer</i><br>
<i>&gt; simulation, right?</i><br>

<p>
Not necessarily. Only if you assume (1) that there are many more 
observers in computer simulation than in flesh; and (2) that people 
in computer simulations are in the same reference class as people in 
flesh


<p>
<i>&gt;  I mean, I'm something out of science fiction, so I'd</i><br>
<a href="3722.html#3784qlink8">&gt; have to assume I was *actual* science fiction.  There are more books</a><br>
<i>&gt; than people, right?  This set of assumptions explains all the facts at a</i><br>
<i>&gt; much higher relative probability, right?</i><br>


<p>
Fictional people in books are not in the reference class. They don't 
really observe or find themselves as anything. People in computer 
simulations are a different matter; they might be in the reference 
class.


<p>
Nick Bostrom
<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a>      n.bostrom@lse.ac.uk
Department of Philosophy, Logic and Scientific Method
London School of Economics
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3785.html">[ Next ]</a><a href="3783.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3722.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3799.html">Lee Daniel Crocker</a>
</ul>
</body></html>
