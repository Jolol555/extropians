<!-- received="Sun Feb 21 15:04:23 1999 MDT" -->
<!-- sent="Sun, 21 Feb 1999 16:08:51 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: FAQ Additions" -->
<!-- id="36D083F1.A1BB78CE@pobox.com" -->
<!-- inreplyto="FAQ Additions" -->
<!-- version=1.10, linesinbody=42 -->
<html><head><title>extropians: Re: FAQ Additions</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: FAQ Additions</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 21 Feb 1999 16:08:51 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2148">[ date ]</a><a href="index.html#2148">[ thread ]</a><a href="subject.html#2148">[ subject ]</a><a href="author.html#2148">[ author ]</a>
<!-- next="start" -->
<li><a href="2149.html">[ Next ]</a><a href="2147.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2136.html">Nick Bostrom</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2152.html">Nick Bostrom</a>
</ul>
<!-- body="start" -->

<p>
<a name="2152qlink1">Nick Bostrom wrote:
<br>
<i>&gt; </i><br>
<a href="2136.html#2148qlink1">&gt; That looks like the kind of comment for which CritLink would be</a><br>
<i>&gt; ideal.</i><br>

<p>
I CritLink'd it, but bear in mind that I didn't see any reference from
your page to the CritLink version.</a>

<p>
<a name="2152qlink2">I would also suggest that, after the CritLink version has been around
for a while, you take any comments that the reader deserves to hear and
incorporate them into the body of the FAQ.</a>

<p>
<a href="2136.html#2148qlink2">&gt; Actually, in his latest book "Robot", Moravec explicitly proposes</a><br>
<i>&gt; that laws require that robots be built "securely nice in the first</i><br>
<i>&gt; place". "Every neuance of their motivation is a design choice. They</i><br>
<i>&gt; can be constructed to enjoy the role of servant to humankind." And it</i><br>
<i>&gt; is a "matter of life and death to humans" that they "do not have a</i><br>
<i>&gt; right to vote on the laws that govern and tax them." (pp139-40). In</i><br>
<i>&gt; the long run, Moravec looks forward to advanced robots superseding</i><br>
<i>&gt; humans and taking over the universe, but we both can and should</i><br>
<i>&gt; ensure a comfortable retirement for humanity by programming in</i><br>
<i>&gt; suitable "internal laws" in our mind children.</i><br>

<p>
Well, I suppose that shows the need for programmatic humility in such
discussions.  "Every nuance of their motivation is a design choice." 
Probably didn't occur to him at all that Interim goals could and would
come into existence on their own.  Probably wouldn't have taken any
precautions.  I wonder what would have happened when conflicts arose?

<p>
My statement was based on Moravec's review of _Engines of Creation_ in
_Technology Review_ (1986):

<p>
<a name="2158qlink1">"Why should machines millions of times more intelligent, fecund, and
<a name="2170qlink2">industrious than ourselves exist only to support our ponderous,</a> antique
bodies and dim-witted minds in luxury?"</a>
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2149.html">[ Next ]</a><a href="2147.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2136.html">Nick Bostrom</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2152.html">Nick Bostrom</a>
</ul>
</body></html>
