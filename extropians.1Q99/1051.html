<!-- received="Thu Jan 21 06:38:42 1999 MDT" -->
<!-- sent="Thu, 21 Jan 1999 07:38:24 -0600" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="RE: Nanotech Arms Race" -->
<!-- id="000d01be4543$543753b0$352501c0@mfg130" -->
<!-- inreplyto="36A66DFC.E765D132@clemmensen.shirenet.com" -->
<!-- version=1.10, linesinbody=40 -->
<html><head><title>extropians: RE: Nanotech Arms Race</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>RE: Nanotech Arms Race</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Thu, 21 Jan 1999 07:38:24 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1051">[ date ]</a><a href="index.html#1051">[ thread ]</a><a href="subject.html#1051">[ subject ]</a><a href="author.html#1051">[ author ]</a>
<!-- next="start" -->
<li><a href="1052.html">[ Next ]</a><a href="1050.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1033.html">Dan Clemmensen</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1052.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
<a name="1060qlink1">Dan Clemmensen wrote of assorted ways to depopulate Earth using nanotech.
I'll reply to his suggestions in another post - I've got a related point to
make here:

<p>
I believe I have detected an interesting implicit assumption in your
scenarios, which is common to nanotech doomsday theories but is not at all
realistic.  You seem to assume that your nanotech is controlled by a
computer system that can obey commands like "Go grab 2x10^6 comets from the
Oort cloud, merge them to make a giant projectile, and then smash it into
the Earth."  The computer obligingly does so, with no muss or fuss.

<p>
Now, the AI that runs that computer can already do everything an SI could.</a>
It can do millions of man-years worth of engineering, programming, and R&amp;D
in a few weeks (or less).  It can supervise giant construction projects,
deal with unexpected physical obstacles, and generally do anything a human
would do in its place.  The only thing it lacks is self-will.

<p>
<a name="1069qlink1">Do I really need to point out how unlikely that is?  To get this genie
machine you have to figure out how to make a fully sentient AI, then come up
with a way to lobotomize it (presumably by tinkering with its goal system).
Even if that happened, it won't be a week before someone decides to free
one.</a>

<p>
Even if the AI can't be made sentient for some reason, this is still an
instant-SI scenario.  "Upload me" isn't any harder a command than the comet
project, after all.  There are several other easy paths to SI as well - you
could build a neural interface and integrate your own mind with the genie
machine's design ability, for example.

<p>
If you want to talk about nanotech sans SI, that necessarily means there
aren't any genie machines.  That in turn means that many types of
construction still involve large numbers of people and a lot of money - your
nanofab simply builds whatever designs you can buy for it.  The resulting
world is very different than our own, and it is more unstable, but it isn't
nearly as bad as the one you fear.

<p>
Billy Brown, MCSE+I
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1052.html">[ Next ]</a><a href="1050.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1033.html">Dan Clemmensen</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1052.html">Billy Brown</a>
</ul>
</body></html>
