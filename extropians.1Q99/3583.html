<!-- received="Thu Mar 25 13:15:28 1999 MDT" -->
<!-- sent="Thu, 25 Mar 1999 14:20:31 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Yudkowsky's AI (again)" -->
<!-- id="36FA9A87.A1BC15ED@pobox.com" -->
<!-- inreplyto="Yudkowsky's AI (again)" -->
<!-- version=1.10, linesinbody=43 -->
<html><head><title>extropians: Re: Yudkowsky's AI (again)</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Yudkowsky's AI (again)</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Thu, 25 Mar 1999 14:20:31 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3583">[ date ]</a><a href="index.html#3583">[ thread ]</a><a href="subject.html#3583">[ subject ]</a><a href="author.html#3583">[ author ]</a>
<!-- next="start" -->
<li><a href="3584.html">[ Next ]</a><a href="3582.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3579.html">Michael S. Lorrey</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3588.html">Lee Daniel Crocker</a>
</ul>
<!-- body="start" -->

<p>
"Michael S. Lorrey" wrote to den Otter:
<br>
<i>&gt; </i><br>
<a href="3579.html#3583qlink1">&gt; Since</a><br>
<i>&gt; you are talking about guarding against even ONE Power getting there before you,</i><br>
<i>&gt; then no one will ever upload. Someone has to be first, if it is done at all. A</i><br>
<i>&gt; number of someones for the test phase of the technology, then those that can</i><br>
<i>&gt; afford the cost, then as those individuals have an impact on the economy, others</i><br>
<i>&gt; can be bootstrapped.</i><br>
<i>&gt; </i><br>
<i>&gt; It is all a matter of trust. Who do you trust?</i><br>

<p>
Let me put it this way:  If den Otter thinks I'm going to trust a HUMAN,
he's nuts.  I know how the human motivational system works, and I know
how Elisson's (of _Coding_) motivational system works.  Who do I trust? 
Damn straight.

<p>
If I wanted to safeguard my self-interests, or more likely was
honor-bound to safeguard someone else's, you'd better believe that I
wouldn't trust *any* mind unless I could see the source code.  I would
trust Elisson over *me*.  Not from an abstract standpoint; *personally*.
 den Otter's blind trust of his own mind is based simply on ignorance of
his own cognitive architecture.

<p>
<a name="3588qlink1">As for anyone else trusting den Otter, whose personal philosophy
apparently states "The hell with any poor fools who get in my way," who
wants to climb into the Singularity on a heap of backstabbed bodies, the
Sun will freeze over first.  Supposing that humans were somehow uploaded
manually, I'd imagine that the HUGE ORGANIZATION that first had the
power to do it would be *far* more likely to choose good 'ol altruistic
other's-goals-respecting Lee Daniel Crocker.</a>  If, somehow, den Otter
managed to amass enough personal wealth to go it alone, which I must say
seems a probability on the order of a hen laying a square egg, someone
would get scared and nuke his laboratories.

<p>
You know something?  Altruism really is the best strategy, even from a
selfish perspective.
<pre>
-- 
        sentience@pobox.com          Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/singul_arity.html">http://pobox.com/~sentience/singul_arity.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3584.html">[ Next ]</a><a href="3582.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3579.html">Michael S. Lorrey</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3588.html">Lee Daniel Crocker</a>
</ul>
</body></html>
