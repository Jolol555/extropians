<!-- received="Wed Jan  6 09:41:03 1999 MDT" -->
<!-- sent="06 Jan 1999 17:40:58 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Paths to Uploading" -->
<!-- id="b4990fgbbhh.fsf@void.nada.kth.se" -->
<!-- inreplyto="Wed, 6 Jan 1999 09:29:29 -0600" -->
<!-- version=1.10, linesinbody=63 -->
<html><head><title>extropians: Re: Paths to Uploading</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: Paths to Uploading</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>06 Jan 1999 17:40:58 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#152">[ date ]</a><a href="index.html#152">[ thread ]</a><a href="subject.html#152">[ subject ]</a><a href="author.html#152">[ author ]</a>
<!-- next="start" -->
<li><a href="0153.html">[ Next ]</a><a href="0151.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0149.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0161.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
<a name="0157qlink1">"Billy Brown" &lt;bbrown@conemsco.com&gt; writes:

<p>
<a href="0149.html#0152qlink1">&gt; I say 'it', because I expect human-equivalent hardware to arrive several</a><br>
</a><i>&gt; years before human-equivalent AI.  That means the first self-enhancing AI</i><br>
<i>&gt; that doesn't bottleneck will have the hardware to go from transhuman to SI</i><br>
<i>&gt; in a matter of days, at most.  At that point humans are far to slow to</i><br>
<i>&gt; interfere with it - it can invent general-purpose assemblers, use someone's</i><br>
<i>&gt; automated lab equipment to build one, and migrate itself to rapid</i><br>
<i>&gt; infrastructure in a matter of hours.  A few hours after that we've got a</i><br>
<i>&gt; full-grown Power on our hands.</i><br>

<p>
<a name="0161qlink2"><a name="0160qlink1">OK, this is the standard SI apotheosis scenario. But note that it is
based on a lot of unsaid assumptions: that it is just hardware
resources that distinguish a human level AI from an SI (i.e, the
software development is fairly trivial for the AI and can be done</a> very
<a name="0160qlink2">fast, and adding more processor power will make the AI *smarter*),</a>
</a>
<a name="0161qlink3"><a name="0160qlink3">that this process has a time constant shorter than days (why just this
figure? why not milliseconds or centuries?),</a> that there will be no
</a>
<a name="0161qlink4"><a name="0160qlink4">systems able to interfere with it - note that one of your original
assumptions was the existence of human-level AI;</a> if AI can get faster
(not even smarter) by adding more processor power, "tame" AI could
keep the growing AI under</a> control - that this SI is able to invent
<a name="0161qlink5"><a name="0160qlink5">anything it needs to (where does it get the skills?)</a> and will have
</a>
<a name="0161qlink6"><a name="0160qlink6">easy access to somebody's automated lab equipment (how many labs have
their equipment online, accessible through the Net?</a> why are you
<a name="0160qlink7">assuming the AI is able to hack any system,</a> especially given the
<a name="0160qlink8">presence of other AI?).</a> And finally, we have the assumption that the
</a>
<a name="0161qlink7"><a name="0160qlink9">SI will be able to outwit any human in all respects - which is based
on the idea that intelligence is completely general and the same kind
of mind that can design a better AI can fool a human into (say)
connecting an experimental computer to the net or disable other
security features.</a></a>

<p>
<a name="0161qlink1"><a name="0160qlink10">As you can tell, I don't quite buy this scenario. To me, it sounds
more like a Hollywood meme.</a></a> 

<p>
<a href="0149.html#0152qlink2">&gt; &gt; Wearables and information services will be starting this process</a><br>
<i>&gt; &gt; within a decade, I'm fairly sure. Add agile manufacturing, and you can</i><br>
<i>&gt; &gt; get nanotech-like surprises in production even before nanotech</i><br>
<i>&gt; &gt; (imagine if the effects of microfactories spreading and cutting out</i><br>
<i>&gt; &gt; the middleman between sales and raw materials, as well as</i><br>
<i>&gt; &gt; transportation: micro outlet stores in every mall).</i><br>
<i>&gt; </i><br>
<i>&gt; Don't forget the biotech revolution.  Exponential advance gives us a</i><br>
<i>&gt; revolution in pharmacology in the coming decade, and cyberpunk-style body</i><br>
<i>&gt; modification in the decade after that.  The economic effect is not as</i><br>
<i>&gt; pronounced, but the social effects would be huge.</i><br>

<p>
The biotech effects will be slowed by a very thick systems of
regulations and controls (not all bad, mind you): just because your
sub-AIs invent anti-Alzheimer and anti-cancer drugs each minute
doesn't mean your pharmaceutical corporation can sell them
immediately, they have to go through a few years (more likely a
decade) of testing before approval. It might be easier with body
modification, actually.


<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0153.html">[ Next ]</a><a href="0151.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0149.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0161.html">Billy Brown</a>
</ul>
</body></html>
