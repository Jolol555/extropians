<!-- received="Tue Jan  5 15:47:43 1999 MDT" -->
<!-- sent="05 Jan 1999 23:47:40 +0100" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Paths to Uploading" -->
<!-- id="b49ogod2v77.fsf@void.nada.kth.se" -->
<!-- inreplyto="Tue, 5 Jan 1999 20:21:22 -0000" -->
<!-- version=1.10, linesinbody=80 -->
<html><head><title>extropians: Re: Paths to Uploading</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: Paths to Uploading</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>05 Jan 1999 23:47:40 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#118">[ date ]</a><a href="index.html#118">[ thread ]</a><a href="subject.html#118">[ subject ]</a><a href="author.html#118">[ author ]</a>
<!-- next="start" -->
<li><a href="0119.html">[ Next ]</a><a href="0117.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0110.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Bryan Moss" &lt;bryan.moss@dial.pipex.com&gt; writes:

<p>
<a href="0110.html#0118qlink1">&gt; If you make a high-level abstraction (that is, a piece of code that</a><br>
<i>&gt; recreates the exact input and output) of a neuron do you preserve subjective</i><br>
<i>&gt; experience? If you make a high-level abstraction of the entire brain do you</i><br>
<i>&gt; preserve subjective experience? What is identity? How much is different?</i><br>
<i>&gt; Even if you do think uploading is possible you're still faced with hundreds</i><br>
<i>&gt; of currently unanswerable questions.</i><br>

<p>
Exactly. But the experiments leading up to uploading and uploading
itself will answer many of these questions.<a name="0163qlink1"> The final answer will of
course be when you upload yourself and a certain digital mind begins
</a>
to experience whatever it experiences.

<p>
<a href="0110.html#0118qlink2">&gt; &gt; A claim like 'no mind can be smarter than a bright human' makes about as</a><br>
<i>&gt; &gt; much sense as 'any mass of gold more than ten miles in diameter will</i><br>
<i>&gt; &gt; spontaneously combust'.  Neither claim can actually be tested, but it</i><br>
<i>&gt; &gt; would be amazing if either one were true.</i><br>
<i>&gt; </i><br>
<a name="0163qlink2"><i>&gt; Why do we have such small brains? To me it suggests that the level of</i><br>
<i>&gt; complexity achievable is *very* close to the achieved level.</i><br>

<p>
I have the impression that you are not seriously proposing any upper
limit on intelligence,</a> but anyway: the brain is definitely not small,
rather it is as large as it can be given<a name="0163qlink3"> our current biology. It
consumes a significant percentage of our energy; most likely it is
close to the maximum possible size given a hunter-gatherer diet (one
factor affecting its evolutionary growth may have been more food
availability). In addition we have all sorts of purely mechanical
</a>
problems with our large brains.

<p>
But large brains are not impossible, just look at the blue whale
(whose cerebellum, interestingly enough, appears to be human sized
while the rest of the brain is huge). Lots of neurons isn't the same
thing as intelligence.

<p>
<a href="0110.html#0118qlink3">&gt; Since we're talking about plausible future scenarios it might be fun, being</a><br>
<i>&gt; in the midst of millennium fever, to come up with some. No dates or</i><br>
<i>&gt; predictions, just how you think the next few major technologies will</i><br>
<i>&gt; pan-out. How about it? (And fifty years from now, when we're all six</i><br>
<i>&gt; centimetres tall and living in habitat domes on the moon, we can have a good</i><br>
<i>&gt; laugh at them.)</i><br>

<p>
My guess is that the Big Things the next 50 years will be
nanotechnology / biotechnology (both areas will likely merge rather
than remain distinct), the understanding of the brain and the
resulting neurotechnologies, and finally the Theory of
Complexity. No. 1 feels fairly straighforward, the other are a bit
more risky speculation.

<p>
Nanotech would simply emerge and cause a lot of revolutionizing
changes; it is too broad, too useful, too normal in some sense (making
and manipulating things isn't something utterly *new*). Expect
quarrels over the applications and fears once the nanosystems start to
become truly powerful, but in the end it is the same question as has
plagued the last two centuries: how to distribute the wealth and means
of production, and to what ends.

<p>
<a name="0163qlink4"><a name="0127qlink1">Neurotech is going to be the controversial thing. What does "human"
mean when you can alter it? Not just enhance memory or change sexual
preferences, but add *new* structures to the brain like the ability to
do something like episodic memory for muscle movements? Lots of issues
here, and biotech will contribute with problems.</a></a> 

<p>
Complexity is the subtlest part. If my guess/feeling is right Kaufmann
and the others are right and there are "laws of complex systems". It
will be an invisible revolution, first in the sciences, then in
technology (such as the above areas) and slowly also in human
thinking. Remember that the Newtonian view took several centuries to
spread, and that most people still don't have digested evolution,
quantum mechanics and Godel. Complexity would likely be even more
profound.


<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0119.html">[ Next ]</a><a href="0117.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0110.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
</body></html>
