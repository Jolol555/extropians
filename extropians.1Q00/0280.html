<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: SOC: Opposition to Transhumanism</TITLE>
<META NAME="Author" CONTENT="Anders Sandberg (asa@nada.kth.se)">
<META NAME="Subject" CONTENT="Re: SOC: Opposition to Transhumanism">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: SOC: Opposition to Transhumanism</H1>
<!-- received="Thu Jan  6 13:30:16 2000" -->
<!-- isoreceived="20000106203016" -->
<!-- sent="06 Jan 2000 21:29:59 +0100" -->
<!-- isosent="20000106202959" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: SOC: Opposition to Transhumanism" -->
<!-- id="b49ln639c54.fsf@sans04.nada.kth.se" -->
<!-- inreplyto="Wed, 05 Jan 2000 23:10:57 +0100&quot;" -->
<STRONG>From:</STRONG> Anders Sandberg (<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20SOC:%20Opposition%20to%20Transhumanism&In-Reply-To=&lt;b49ln639c54.fsf@sans04.nada.kth.se&gt;"><EM>asa@nada.kth.se</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Jan 06 2000 - 13:29:59 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="0281.html">hal@finney.org: "Re: EURISKO homepage"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0279.html">Eliezer S. Yudkowsky: "Re: SOC: Opposition to Transhumanism"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#280">[ date ]</A>
<A HREF="index.html#280">[ thread ]</A>
<A HREF="subject.html#280">[ subject ]</A>
<A HREF="author.html#280">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&quot;D.den Otter&quot; &lt;<A HREF="mailto:neosapient@geocities.com?Subject=Re:%20SOC:%20Opposition%20to%20Transhumanism&In-Reply-To=&lt;b49ln639c54.fsf@sans04.nada.kth.se&gt;">neosapient@geocities.com</A>&gt; writes:
<BR>
<P><EM>&gt; &gt; &gt; &gt; You can be opposed against transhumanism and the things we hold dear
</EM><BR>
<EM>&gt; &gt; &gt; &gt; without being fanatic about them.
</EM><BR>
<EM>&gt; &gt; &gt; 
</EM><BR>
<EM>&gt; &gt; &gt; ...but not without being stupid.
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; Not at all. I can imagine intelligent and well-educated non-stupid
</EM><BR>
<EM>&gt; &gt; people opposing transhumanism too, based on their values and knowledge
</EM><BR>
<EM>&gt; &gt; of how the world functions. 
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; In other words, these otherwise intelligent people have some blind
</EM><BR>
<EM>&gt; spots of ignorance which cause them to act contrary to their own 
</EM><BR>
<EM>&gt; enlightened self-interest (which is what transhumanism is all about).
</EM><BR>
<P>Not necessarily. First, they might have a different knowledge-base
<BR>
from us - it could even be wider - which leads to a different
<BR>
conclusion. Second, their notion of englightened self-interest might
<BR>
be fundamentally different from the one you are using. Not everyone is
<BR>
an objectivist, to the surprise of the objectivists :-)
<BR>
<P><EM>&gt; &gt; They are in many ways more troublesome
</EM><BR>
<EM>&gt; &gt; than fanatics.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Yes, they can be very annoying indeed, but at least they don't go 
</EM><BR>
<EM>&gt; around blowing stuff up...
</EM><BR>
<P>People who blow things up tend to become disliked and feared by the
<BR>
large majority of people, who actually considers it a sign of
<BR>
dangerous fanaticism or mental illness. Reasonable people with values
<BR>
many people subscribe to, on the other hand, can influence them greatly.  
<BR>
<P>&nbsp;
<BR>
<EM>&gt; &gt; For example, imagine a sociologist who has studied the incidence of
</EM><BR>
<EM>&gt; &gt; burnout in our society who comes into contact with transhumanist
</EM><BR>
<EM>&gt; &gt; thinking. He will point out that the psychological effects of the
</EM><BR>
<EM>&gt; &gt; tremendous changes and speed-ups we are proposing will lead to burnout
</EM><BR>
<EM>&gt; &gt; and psychological distress on a massive scale, maybe so much that
</EM><BR>
<EM>&gt; &gt; society will desintegrate. The transhumanists will of course claim
</EM><BR>
<EM>&gt; &gt; that this will be fixed by technology , the adoption of transhumanist
</EM><BR>
<EM>&gt; &gt; thinking and self-help as well as reconfigurations of human
</EM><BR>
<EM>&gt; &gt; psychology. But the sociologist, drawing on his knowledge base in
</EM><BR>
<EM>&gt; &gt; social psychology and history, will regard this hypothesis as highly
</EM><BR>
<EM>&gt; &gt; unlikely to occur, in fact less likely than the hypothesis that this
</EM><BR>
<EM>&gt; &gt; is just transhumanists defending their own worldview (you can do a
</EM><BR>
<EM>&gt; &gt; completely correct Bayesian analysis of this situation and come to
</EM><BR>
<EM>&gt; &gt; this conclusion - given the priors of the sociologist). We of course
</EM><BR>
<EM>&gt; &gt; have slightly different information, and regard the first possibility
</EM><BR>
<EM>&gt; &gt; as more likely (even if we should always ask ourselves how much is due
</EM><BR>
<EM>&gt; &gt; to possibility two). So in the end he will disagree with us and if he
</EM><BR>
<EM>&gt; &gt; considers us dangerous, try to move against us.
</EM><BR>
<EM>&gt; &gt; 
</EM><BR>
<EM>&gt; &gt; In the above example both sides could try sharing their analysis and
</EM><BR>
<EM>&gt; &gt; facts, trying to make an analysis together both could agree on.  
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; The man in the above example clearly lacks some crucial data.
</EM><BR>
<EM>&gt; He is a specialist, and has trouble with looking beyond his own
</EM><BR>
<EM>&gt; narrow field of interest. He can't see the big picture, lacks 
</EM><BR>
<EM>&gt; vision. A very common problem (even on this list).
</EM><BR>
<P>How did you reach that conclusion? Note that in the above example it
<BR>
is not said that he lacks cruicial data (of course, he might lack
<BR>
them) but rather that given his prior knowledge his estimation of thje
<BR>
likeliehood of various effects differs from our estimation. While lack
<BR>
of information is an important factor in disagreements, it is not the
<BR>
only possible reason. Different priors and valuations can also make
<BR>
entirely rational agents disagree.
<BR>
<P><EM>&gt; Anyway, your 
</EM><BR>
<EM>&gt; example only seems to confirm that all opposition to transhumanism(*) 
</EM><BR>
<EM>&gt; is either based on incomplete information (or even disinformation) 
</EM><BR>
<EM>&gt; or on the failure of the subject to process correct and complete 
</EM><BR>
<EM>&gt; information logically. Therefore, this kind of criticism is of
</EM><BR>
<EM>&gt; little practical value (and it certainly isn't &quot;intelligent&quot;).
</EM><BR>
<EM>&gt; I've yet to see relevant, intelligent opposition to core 
</EM><BR>
<EM>&gt; transhumanist ideas.
</EM><BR>
<P>As I said above, you can get entirely different results if your value
<BR>
set is different. A buddhist considering the physical world a
<BR>
pointless illusion best escaped from would not subscribe to the same
<BR>
behavior as you even when entirely rational and given the same
<BR>
data. Even a small difference in valuations, say in the relative value
<BR>
of freedom versus security, can lead to drastically different views. 
<BR>
<P>Saying that all opponents to transhumanism are either misinformed or
<BR>
illogical is a great way of isolating oneself into an ideological air
<BR>
castle isolated from reality. I have seen people taking this view in
<BR>
defending everything from communism to objectivism, and the results
<BR>
have always been bad.
<BR>
<P><EM>&gt; &gt; But
</EM><BR>
<EM>&gt; &gt; even worse is if the basic values differ - a person valuing the
</EM><BR>
<EM>&gt; &gt; eternal and unchanging would be opposed to us in principle, 
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; Ah, but since the natural state of things (the world, the universe) is
</EM><BR>
<EM>&gt; far from eternal and unchanging, that person would still need transhuman
</EM><BR>
<EM>&gt; technologies to realize his dream. What sweet irony...
</EM><BR>
<P>That person would not accept your view that the universe is changing -
<BR>
the underlying essence for example might be eternal and unchanging and
<BR>
the apparent change an illusion. A philosophical view a great deal of
<BR>
people have taken, however much we might disagree with them. It cannot
<BR>
even be refuted, which makes it silly from a popperian empiricist
<BR>
view, but these people do not even feel they have to subscribe to that
<BR>
view. People with a different ontology and epistemology can be awfully
<BR>
hard to convince that you are right...
<BR>
<P><PRE>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20SOC:%20Opposition%20to%20Transhumanism&In-Reply-To=&lt;b49ln639c54.fsf@sans04.nada.kth.se&gt;">asa@nada.kth.se</A>                            <A HREF="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</A>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0281.html">hal@finney.org: "Re: EURISKO homepage"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0279.html">Eliezer S. Yudkowsky: "Re: SOC: Opposition to Transhumanism"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#280">[ date ]</A>
<A HREF="index.html#280">[ thread ]</A>
<A HREF="subject.html#280">[ subject ]</A>
<A HREF="author.html#280">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:02:06 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
