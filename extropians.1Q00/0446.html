<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: &gt;H Re: transhuman-digest V1 #562</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: &gt;H Re: transhuman-digest V1 #562">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: &gt;H Re: transhuman-digest V1 #562</H1>
<!-- received="Sun Jan  9 10:06:28 2000" -->
<!-- isoreceived="20000109170628" -->
<!-- sent="Sun, 09 Jan 2000 11:07:09 -0600" -->
<!-- isosent="20000109170709" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: &gt;H Re: transhuman-digest V1 #562" -->
<!-- id="3878C03A.CC6D0568@pobox.com" -->
<!-- inreplyto="3878A83B.58D9@geocities.com" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20&gt;H%20Re:%20transhuman-digest%20V1%20#562&In-Reply-To=&lt;3878C03A.CC6D0568@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Sun Jan 09 2000 - 10:07:09 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="0447.html">Robert Wasley: "Re: Creating new states"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0445.html">D.den Otter: "Re: International Third Position (was Re: SOC Opponents ofTranshumanism)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0442.html">D.den Otter: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0455.html">Bryan Moss: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0455.html">Bryan Moss: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#446">[ date ]</A>
<A HREF="index.html#446">[ thread ]</A>
<A HREF="subject.html#446">[ subject ]</A>
<A HREF="author.html#446">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&quot;D.den Otter&quot; wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; How can you be so sure that this won't be the case? In the
</EM><BR>
<EM>&gt; absence of hard data either way, we must assume a 50% chance
</EM><BR>
<EM>&gt; of AIs causing our extinction.
</EM><BR>
<P>That's good enough for me!  What changed your mind?
<BR>
<P><EM>&gt; Oh golly, we've just been
</EM><BR>
<EM>&gt; reduced to a second-rate life form. We no longer control
</EM><BR>
<EM>&gt; our planet. We're at the mercy of hyperintelligent machines.
</EM><BR>
<EM>&gt; Yeah, that's something to be excited about...
</EM><BR>
<P>Sooner or later, we're gonna either toast the planet, or come up against
<BR>
something smarter than we are.  You know that.  We've agreed on that. 
<BR>
Your sole point of disagreement is that you believe that you'll be
<BR>
better off if *you're* the first Power.  But Otter, that's silly.  If
<BR>
transforming me into a Power might obliterate my tendency to care about
<BR>
the welfare of others, it has an equal chance of obliterating my
<BR>
tendency to care about myself.  If someone else, on becoming a Power,
<BR>
might destroy you; then you yourself, on becoming a Power, might
<BR>
overwrite yourself with some type of optimized being or mechanism.  You
<BR>
probably wouldn't care enough to preserve any kind of informational or
<BR>
even computational continuity.  Both of these theories - unaltruism and
<BR>
unselfishness - are equally plausible, and learning that either one was
<BR>
the case would greatly increase the probability of the other.
<BR>
<P>So, given that there's also a 50% chance that the Powers are nice guys,
<BR>
or that no objective morality exists and Powers are freely programmable;
<BR>
and given also that if the Powers *aren't* nice guys, then being the
<BR>
Power-seed probably doesn't help; and given that your chance of winning
<BR>
a competition to personally become the Power-seed is far more tenuous
<BR>
than the chance of cooperatively writing an AI; and given that if we
<BR>
*don't* create Powers, we're gonna get wiped out by a nanowar; and given
<BR>
the fact that uploading is advanced drextech that comes after the
<BR>
creation of nanoweapons, while AI can be run on IBM's Blue Gene; and
<BR>
given your admitted 50% chance that the Other Side of Dawn is a really
<BR>
nice place to live, and that everyone can become Powers -
<BR>
<P>In what sense is AI *not* something to be excited about?
<BR>
<PRE>
-- 
               <A HREF="mailto:sentience@pobox.com?Subject=Re:%20&gt;H%20Re:%20transhuman-digest%20V1%20#562&In-Reply-To=&lt;3878C03A.CC6D0568@pobox.com&gt;">sentience@pobox.com</A>      Eliezer S. Yudkowsky
                  <A HREF="http://pobox.com/~sentience/beyond.html">http://pobox.com/~sentience/beyond.html</A>
Typing in Dvorak         Programming with Patterns  Writing in Gender-neutral
Voting for Libertarians  Heading for Singularity    There Is A Better Way
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0447.html">Robert Wasley: "Re: Creating new states"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0445.html">D.den Otter: "Re: International Third Position (was Re: SOC Opponents ofTranshumanism)"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0442.html">D.den Otter: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0455.html">Bryan Moss: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0455.html">Bryan Moss: "Re: &gt;H Re: transhuman-digest V1 #562"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#446">[ date ]</A>
<A HREF="index.html#446">[ thread ]</A>
<A HREF="subject.html#446">[ subject ]</A>
<A HREF="author.html#446">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:02:10 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
