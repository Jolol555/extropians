<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Otter vs. Yudkowsky</TITLE>
<META NAME="Author" CONTENT="Eliezer S. Yudkowsky (sentience@pobox.com)">
<META NAME="Subject" CONTENT="Re: Otter vs. Yudkowsky">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Otter vs. Yudkowsky</H1>
<!-- received="Tue Mar 14 00:32:08 2000" -->
<!-- isoreceived="20000314073208" -->
<!-- sent="Tue, 14 Mar 2000 01:26:34 -0600" -->
<!-- isosent="20000314072634" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Otter vs. Yudkowsky" -->
<!-- id="38CDE95E.12BAF519@pobox.com" -->
<!-- inreplyto="3.0.6.32.20000313194432.007b5a60@pop.gmx.net" -->
<STRONG>From:</STRONG> Eliezer S. Yudkowsky (<A HREF="mailto:sentience@pobox.com?Subject=Re:%20Otter%20vs.%20Yudkowsky&In-Reply-To=&lt;38CDE95E.12BAF519@pobox.com&gt;"><EM>sentience@pobox.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Tue Mar 14 2000 - 00:26:34 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="4838.html">hal@finney.org: "Re: Luddites are everywhere!"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4836.html">Anton Sherwood: "Re: Sticks and Stones and Bullets, Oh, My!"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4816.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="4867.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4867.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4837">[ date ]</A>
<A HREF="index.html#4837">[ thread ]</A>
<A HREF="subject.html#4837">[ subject ]</A>
<A HREF="author.html#4837">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
sayke wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;         do terms like &quot;dumb&quot; kinda lose meaning in the absence of personal
</EM><BR>
<EM>&gt; control? i think so.
</EM><BR>
<P>Oh, bull.  You have no personal control over your quarks, your neurons,
<BR>
or your environment.  There is not one tool you can use which has a 100%
<BR>
chance of working.  You are at the mercy of the random factors and the
<BR>
hidden variables.  &quot;Maintaining control&quot; consists of using the tool with
<BR>
the highest probability of working.
<BR>
<P><EM>&gt;         how kind of the sysop. theocracy might sound nifty, but i don't think it
</EM><BR>
<EM>&gt; would be stable, let alone doable, from a monkey point of view.
</EM><BR>
<P>How fortunate that the Sysop is not a monkey.
<BR>
<P><EM>&gt;         an omniscient ai is pretty much inscrutable, right? i don't know how we
</EM><BR>
<EM>&gt; can evaluate the inscrutable's chances of becoming what we would call
</EM><BR>
<EM>&gt; &quot;corrupt&quot;. i think the least inscrutable thing about an omniscient
</EM><BR>
<EM>&gt; intelligence would be its need for resources. other then that... i dunno.
</EM><BR>
<P>Yes, its need for resources in order to make humans happy.  Munching on
<BR>
the humans to get the resources to make the humans happy is not valid
<BR>
logic even for SHRDLU.  Inscrutability is one thing, stupidity another.
<BR>
<P><EM>&gt;         i fail to see how it could not get tangled up... even in a case like &quot;in
</EM><BR>
<EM>&gt; order to maximize greeness, the resources over there should be used in this
</EM><BR>
<EM>&gt; manner&quot; (which has no self-subject implied) a distenction must be made
</EM><BR>
<EM>&gt; between resources more directly controlled (what i would call &quot;my stuff&quot;)
</EM><BR>
<EM>&gt; and resources more indirectly controlled (what i would call &quot;other stuff&quot;),
</EM><BR>
<EM>&gt; etc... and as soon as that distenction is made, degrees of
</EM><BR>
<EM>&gt; ownership/beingness/whatever is implied, and from there promptly gets mixed
</EM><BR>
<EM>&gt; up in the goal system...
</EM><BR>
<P>Wrong.
<BR>
<P>What else can I say?  You, as a human, have whole symphonies of
<BR>
emotional tones that automatically bind to a cognitive structure with
<BR>
implications of ownership.  Seeds don't.  End of story.
<BR>
<P><EM>&gt;         necessary? in the sense that such an arrangement will increase my odds of
</EM><BR>
<EM>&gt; survival, etc? i doubt it, if only because the odds against my survival
</EM><BR>
<EM>&gt; must be dire indeed (understatement) to justify the massive amount of work
</EM><BR>
<EM>&gt; that would be required to make a sysop; effort that could rather be
</EM><BR>
<EM>&gt; invested towards, say, getting off this planet; where getting off the
</EM><BR>
<EM>&gt; planet would be a better stopgap anyway.
</EM><BR>
<P>Getting off the planet will protect you from China.  It will not protect
<BR>
you from me.  And you can't get off the planet before I get access to a
<BR>
nanocomputer, anyway.
<BR>
<P><EM>&gt;         unless, of course, you come up with a well thought out essay on the order
</EM><BR>
<EM>&gt; of &quot;coding a transhuman ai&quot; discussing the creation of a specialized sysop
</EM><BR>
<EM>&gt; ai.
</EM><BR>
<P>If the problem is solvable, it should be comparatively trivial. 
<BR>
Extremely hard, you understand, but not within an order of magnitude of
<BR>
the problem of intelligence itself.
<BR>
<P><EM>&gt;         i trend towards advocating a very dumb sysop, if it can be called that...
</EM><BR>
<EM>&gt; a &quot;simple&quot; upload manager...
</EM><BR>
<P>Probably not technologically possible.  Even a mind as relatively
<BR>
&quot;simple&quot; as Eurisko was held together mostly by the fact of self-modification.
<BR>
<P><EM>&gt; &gt;You and a thousand other Mind-wannabes wish to
</EM><BR>
<EM>&gt; &gt;ensure your safety and survival.  One course of action is to upload,
</EM><BR>
<EM>&gt; &gt;grow on independent hardware, and then fight it out in space.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;         or just run the fuck away, and hopefully not fight it out for a very, very
</EM><BR>
<EM>&gt; long time, if ever. dibs on alpha centauri... ;)
</EM><BR>
<P>One of the things Otter and I agree on is that you can't run away from a
<BR>
Power.  Nano, yes.  Not a Power.  Andromeda wouldn't be far enough.  The
<BR>
only defense against a malevolent Power is to be a Power yourself. 
<BR>
Otter got that part.  The part Otter doesn't seem to get is that if a
<BR>
thousand people want to be Powers, then synchronization is probably
<BR>
physically impossible and fighting it out means your chance of winning
<BR>
is 0.1%; the only solution with a non-negligible probability of working
<BR>
is creating a trusted Sysop Mind.  Maybe it only has a 30% chance of
<BR>
working, but that's better than 0.1%.
<BR>
<P>Of course, if you're totally attached to your carnevale instincts and
<BR>
you insist on regarding the Mind as a competing &quot;agent&quot; instead of an
<BR>
awesomely powerful tool with a 30% chance of working - an essentially
<BR>
subjective distinction - then you might refuse to hand things over to
<BR>
Big Brother; this does, however, consist of sacrificing yourself and
<BR>
your whole planet to satisfy a factually incorrect instinct.
<BR>
<P><EM>&gt;         or we all will go Elsewhere... or we will all stalemate... or we will all
</EM><BR>
<EM>&gt; borgify... or we will all decide to commit suicide... or (insert
</EM><BR>
<EM>&gt; possibilities here that only a Power could think of).
</EM><BR>
<P>Great.  In that case, the Sysop can set you free with a clear conscience.
<BR>
<P><EM>&gt; &gt;No.  You cannot have a thousand times as much fun with a thousand times
</EM><BR>
<EM>&gt; &gt;as much mass.
</EM><BR>
<EM>&gt; 
</EM><BR>
<EM>&gt;         i don't see how we can know that. what if, just for example, we need the
</EM><BR>
<EM>&gt; entire solar system to make a very special kind of black hole? geez...
</EM><BR>
<P>Then we'll all cooperate.
<BR>
<P><EM>&gt;         mutually assured destruction seems more clever then a sysop.
</EM><BR>
<P>It won't work for nano and it sure won't work for Minds.
<BR>
<P><EM>&gt;         what if the objective goal is to attain as much &quot;individuality&quot; (whatever
</EM><BR>
<P>Then we'll all do it together, inevitably.  No problem.
<BR>
<P><EM>&gt;         what if i want to *be* said Pact?
</EM><BR>
<P>I don't trust you.  I can't see your source code, and if I could, I
<BR>
almost certainly wouldn't trust it.  den Otter doesn't trust you either.
<BR>
&nbsp;You're an agent, not a tool.
<BR>
<PRE>
-- 
       <A HREF="mailto:sentience@pobox.com?Subject=Re:%20Otter%20vs.%20Yudkowsky&In-Reply-To=&lt;38CDE95E.12BAF519@pobox.com&gt;">sentience@pobox.com</A>      Eliezer S. Yudkowsky
          <A HREF="http://pobox.com/~sentience/beyond.html">http://pobox.com/~sentience/beyond.html</A>
                 Member, Extropy Institute
           Senior Associate, Foresight Institute
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="4838.html">hal@finney.org: "Re: Luddites are everywhere!"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="4836.html">Anton Sherwood: "Re: Sticks and Stones and Bullets, Oh, My!"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="4816.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="4867.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="4867.html">sayke: "Re: Otter vs. Yudkowsky"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#4837">[ date ]</A>
<A HREF="index.html#4837">[ thread ]</A>
<A HREF="subject.html#4837">[ subject ]</A>
<A HREF="author.html#4837">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:05:07 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
