<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: electronic intelligence and ethics</TITLE>
<META NAME="Author" CONTENT="Anders Sandberg (asa@nada.kth.se)">
<META NAME="Subject" CONTENT="Re: electronic intelligence and ethics">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: electronic intelligence and ethics</H1>
<!-- received="Wed Feb 23 11:32:05 2000" -->
<!-- isoreceived="20000223183205" -->
<!-- sent="23 Feb 2000 19:32:01 +0100" -->
<!-- isosent="20000223183201" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: electronic intelligence and ethics" -->
<!-- id="b49ya8b3h3y.fsf@sans04.nada.kth.se" -->
<!-- inreplyto="Tue, 22 Feb 2000 13:16:23 PST&quot;" -->
<STRONG>From:</STRONG> Anders Sandberg (<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20electronic%20intelligence%20and%20ethics&In-Reply-To=&lt;b49ya8b3h3y.fsf@sans04.nada.kth.se&gt;"><EM>asa@nada.kth.se</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Feb 23 2000 - 11:32:01 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3422.html">Zero Powers: "Re: what it's like to be uploaded"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3420.html">QueeneMUSE@aol.com: "Re: rehabilitation versus punishment in a future society...."</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3440.html">Ziana Astralos: "Re: electronic intelligence and ethics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3421">[ date ]</A>
<A HREF="index.html#3421">[ thread ]</A>
<A HREF="subject.html#3421">[ subject ]</A>
<A HREF="author.html#3421">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
&quot;Zero Powers&quot; &lt;<A HREF="mailto:zero_powers@hotmail.com?Subject=Re:%20electronic%20intelligence%20and%20ethics&In-Reply-To=&lt;b49ya8b3h3y.fsf@sans04.nada.kth.se&gt;">zero_powers@hotmail.com</A>&gt; writes:
<BR>
<P><EM>&gt; Following up on QueeneMuse's interesting question about what the uploading 
</EM><BR>
<EM>&gt; experience will be like, one of the things I wonder about is what sort of 
</EM><BR>
<EM>&gt; life we (plain, trans-, or post-)humans will be allowed by the electronic 
</EM><BR>
<EM>&gt; intelligences (I prefer the term EI to AI) once they take over.
</EM><BR>
<P>Aren't you a bit determinist here? It almost sounds like the future
<BR>
was pre-planned...
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the new 5-year plan, our glorious chairman has decided AI
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will be achieved in 2024 [wild applause] A self-augmenting AI
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;system will be operational in 2025! [wild applause] And
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exactly 32 hours after that the Singularity will be reached
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[wild applause, the speaker tries to be heard] ...as predicted
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;by the Maxist-Yudkowist Dialectic!  [standing ovations and
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spontaneous singing from the assembled transhumans]
<BR>
<P>The development of AI and the further interactions between
<BR>
human-derived and non-human intelligence are complex issues, and just
<BR>
saying that they will take over is to oversimplify things. For
<BR>
example, Hans Moravec sketches a scenario in _Robot_ where the
<BR>
super-AI corporations of the future will provide the humans with a
<BR>
pleasant lifestyle by having them as stock owners. If that scenario
<BR>
will come to pass or not depends a lot on exactly how hard AI is going
<BR>
to be to achieve relative other technologies and the changes in
<BR>
society, how the economy will interact with the AI possibilities and
<BR>
the results of individual actions.
<BR>
<P><EM>&gt; But what else (if anything) will motivate them?  Will there be any &quot;good&quot; 
</EM><BR>
<EM>&gt; for them other than information?  Any &quot;evil&quot; other than ignorance?  Will 
</EM><BR>
<EM>&gt; they care at all about such trivialities as emotion, fairness, compassion 
</EM><BR>
<EM>&gt; and pain?  Whether or not I want to survive the ascendancy of strong EI will 
</EM><BR>
<EM>&gt; depend largely upon this question.  Unfortunately I'll never know the 
</EM><BR>
<EM>&gt; answers unless and until I survive to that time.  Or unless I am persuaded 
</EM><BR>
<EM>&gt; by the musings of this list.  I can't wait to hear your thoughts.
</EM><BR>
<P>We could likely create AIs with all sorts of motivations, ranging from
<BR>
the arbitrary (&quot;Green is an axiomatic good - strive to maximize
<BR>
greenness&quot;) over the useful (&quot;To serve humans is the greatest joy&quot;) to
<BR>
the frustrating (&quot;Discover the meaning of it all&quot;). But only some
<BR>
motivational systems are likely robust and flexible enough to work in
<BR>
the world at large, and once AIs start to change themselves and their
<BR>
offspring, we will likely see a kind of evolution take place.
<BR>
<P>My guess is that the basics will be fairly similar to most other life:
<BR>
preserve your own (and possibly your offspring's) existence, use
<BR>
efficient means to achieve your goals (rationality, bounded by
<BR>
available intelligence and the environment). Other than that I think
<BR>
there is room for enormous variety, likely much more than the one seen
<BR>
among humans. Also, I consider human-AI symbiosis a likely path, so
<BR>
there might be entities around that contain mixtures of synthetic and
<BR>
human-derived motivations.
<BR>
<P><PRE>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<A HREF="mailto:asa@nada.kth.se?Subject=Re:%20electronic%20intelligence%20and%20ethics&In-Reply-To=&lt;b49ya8b3h3y.fsf@sans04.nada.kth.se&gt;">asa@nada.kth.se</A>                            <A HREF="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</A>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3422.html">Zero Powers: "Re: what it's like to be uploaded"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3420.html">QueeneMUSE@aol.com: "Re: rehabilitation versus punishment in a future society...."</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3440.html">Ziana Astralos: "Re: electronic intelligence and ethics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3421">[ date ]</A>
<A HREF="index.html#3421">[ thread ]</A>
<A HREF="subject.html#3421">[ subject ]</A>
<A HREF="author.html#3421">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:04:06 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
