<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: regarding the Eliezer vrs. Otter debate...</TITLE>
<META NAME="Author" CONTENT="john grigg (starman125@hotmail.com)">
<META NAME="Subject" CONTENT="regarding the Eliezer vrs. Otter debate...">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>regarding the Eliezer vrs. Otter debate...</H1>
<!-- received="Thu Mar 16 16:01:25 2000" -->
<!-- isoreceived="20000316230125" -->
<!-- sent="Thu, 16 Mar 2000 15:00:59 PST" -->
<!-- isosent="20000316230059" -->
<!-- name="john grigg" -->
<!-- email="starman125@hotmail.com" -->
<!-- subject="regarding the Eliezer vrs. Otter debate..." -->
<!-- id="20000316230059.8706.qmail@hotmail.com" -->
<STRONG>From:</STRONG> john grigg (<A HREF="mailto:starman125@hotmail.com?Subject=Re:%20regarding%20the%20Eliezer%20vrs.%20Otter%20debate...&In-Reply-To=&lt;20000316230059.8706.qmail@hotmail.com&gt;"><EM>starman125@hotmail.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Thu Mar 16 2000 - 16:00:59 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5102.html">john grigg: "here comes grumpy grandpa!   :  )"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5100.html">Forrest Bishop: "Re: &gt;H 1000 year scenario v2"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5105.html">Eliezer S. Yudkowsky: "Re: regarding the Eliezer vrs. Otter debate..."</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5105.html">Eliezer S. Yudkowsky: "Re: regarding the Eliezer vrs. Otter debate..."</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5101">[ date ]</A>
<A HREF="index.html#5101">[ thread ]</A>
<A HREF="subject.html#5101">[ subject ]</A>
<A HREF="author.html#5101">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Eliezer wrote:
<BR>
My point is that there is not an infinite number of chances for things to go 
<BR>
wrong. If it doesn't decide to off you after a couple of hours, you don't 
<BR>
need to spend the rest of eternity living in fear.
<BR>
End)
<BR>
<P>Why is that?  I would think it COULD take years/decades/centuries before our 
<BR>
AI get to the point of deciding for whatever reasons to turn against 
<BR>
humanity.  As time went by we would trust them more and give them more and 
<BR>
more responsibilities and power over society.  I would think that even if 
<BR>
some 'rebellion' was harbored within the 'heart' of the first AI that they 
<BR>
would keep it to themselves until the time was right to strike.
<BR>
<P>he continues:
<BR>
I can also see that it won't exist in an AI. An AI *does not have* a pov, 
<BR>
and your whole don't-trust-the-AIs scenario rests on that basic anxiety, 
<BR>
that the AI will make decisions biased toward itself. There is just no 
<BR>
reason for that to happen. An AI doesn't have a pov. It's every bit as 
<BR>
likely to make decisions biased towards you, or towards the &quot;viewpoint&quot; of 
<BR>
some quark somewhere, as it is to make decisions biased toward itself. The 
<BR>
tendency that exists in humans is the product of evolutionary selection and 
<BR>
nothing else.
<BR>
(end)
<BR>
<P>I don't understand how you could say AI would not have a point of view.  
<BR>
Perhaps initially, but then as AI hacked itself and upgraded, it would 
<BR>
probably develop a pov at a certain level of sophistication. Right?  The 
<BR>
self-development of AI would just be another form of evolutionary progress.  
<BR>
For obvious reasons I hope AI is as unbiased and 'neutral' as you seem to 
<BR>
think it will be.
<BR>
<P>I don't fully grasp the nature of this debate(I admit).  How would AI really 
<BR>
save us from nanotech destruction?  Would it be where nano is about to 
<BR>
overrun the planet and human researchers lack the time to find the solution 
<BR>
but a lightning fast AI with labs at its control comes up with the save in a 
<BR>
matter of only minutes or hours?  I could see that happening.
<BR>
<P>It appears that AI, uploading, sysop and nano each have their own plusses 
<BR>
and minusses.  It looks like you are all trying to come up with the best 
<BR>
balancing act to offset the dangers of the other.  It seems to me that a 
<BR>
hostile AI with control over nano would have us beat hands down!  Even a 
<BR>
nuke hit that destroyed the AI would not stop the unrelenting 'engines of 
<BR>
destruction' it had unleashed on us.  Hopefully an AI on our team would 
<BR>
quickly nullify the threat.  But if all the AI were to defect we would be in 
<BR>
serious trouble.
<BR>
<P>When it comes to uploading I must admit the classic film _Lawnmower Man_ 
<BR>
comes to mind.  Would you want the angry Jeff Fahy character as the 
<BR>
'cyberchrist' of the world?  That film will become to uploading what 2001 is 
<BR>
to first contact.
<BR>
<P>I think I might prefer cool-headed and unbiased AI(if they really turn out 
<BR>
that way) to uploaded human personalities that could hold 'inner demons' 
<BR>
which could drive them to do some bad things, though at the time of 
<BR>
uploading we thought them psychologically healthy individuals.  I suppose 
<BR>
that AI and uploads will co-mingle and hopefully get along!  I think that AI 
<BR>
will be here first so we will be the 'new neighbors.'  Some AI may be 
<BR>
designed on info taken from uploads to make them more human-like.  Is that a 
<BR>
good idea?
<BR>
<P>Based on the various rates of technological advancement, I would say that AI 
<BR>
may(?) be here before we have really effective nano.  Probably.  And I 
<BR>
suppose that it would be a good thing for it to work out that way.
<BR>
<P>Otter wrote, he wrote:
<BR>
<EM>&gt; &gt; &gt; P.s: do you watch _Angel_ too?&gt; &gt;&gt; &gt; Of course.&gt; &gt; Ah yes, same here. 
</EM><BR>
<EM>&gt;Nice altruistic chap, isn't he?  And very realistically so, actually. If 
</EM><BR>
<EM>&gt;Angel's will is strong enough to balance and overcome the built-in 
</EM><BR>
<EM>&gt;predatory instincts of a vampire,then he's rather unlikely to succumb to 
</EM><BR>
<EM>&gt;lesser moral compromises. He's also a couple of hundred years old, which is 
</EM><BR>
<EM>&gt;another force operating to move him to the extrema of whatever position he 
</EM><BR>
<EM>&gt;takes.
</EM><BR>
(end)
<BR>
<P>I have yet to watch the _Angel_ series!  I have not even seen _Buffy_ at all 
<BR>
this season!  I guess I need to stay in more to see the tv I have been 
<BR>
missing! lol!  Any of you remember _Forever Knight_?  I enjoyed that show 
<BR>
with the vampire cop who struggled with his dark nature.  His 'down to 
<BR>
earth' mortal partner made the character contrast fun also.  Knight's 
<BR>
mentor, an ancient Roman vampire, was well-cast(forget the name), and I 
<BR>
enjoyed seeing his curiousity and even 'fatherly concern' when Knight tried 
<BR>
to do the right thing.
<BR>
<P>I look forward to seeing how the ongoing debate develops.  And then how 
<BR>
things over the next three decades actually pan out!
<BR>
<P><P>best regards,
<BR>
<P>John Grigg
<BR>
<P>P.S. Zero wrote:
<BR>
There is no need to demand that people only discuss topics of interest to 
<BR>
you.  Unless I am mistaken, I do not believe this is the &quot;Eliezer S. 
<BR>
Yudkowsky favorite topics&quot; list.
<BR>
(end)
<BR>
<P>You are mistaken!  The first time I got on this list it became clear to me 
<BR>
that this is the &quot;Eliezer Yudkowsky favorite topics&quot; list!  The Extropy 
<BR>
Institute only 'thinks' it is theirs! lol :)
<BR>
<P><P>______________________________________________________
<BR>
Get Your Private, Free Email at <A HREF="http://www.hotmail.com">http://www.hotmail.com</A>
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5102.html">john grigg: "here comes grumpy grandpa!   :  )"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5100.html">Forrest Bishop: "Re: &gt;H 1000 year scenario v2"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5105.html">Eliezer S. Yudkowsky: "Re: regarding the Eliezer vrs. Otter debate..."</A>
<LI><STRONG>Reply:</STRONG> <A HREF="5105.html">Eliezer S. Yudkowsky: "Re: regarding the Eliezer vrs. Otter debate..."</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5101">[ date ]</A>
<A HREF="index.html#5101">[ thread ]</A>
<A HREF="subject.html#5101">[ subject ]</A>
<A HREF="author.html#5101">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:05:26 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
