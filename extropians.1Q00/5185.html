<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Why the future won't accommodate everyone!</TITLE>
<META NAME="Author" CONTENT="Michael S. Lorrey (mike@datamann.com)">
<META NAME="Subject" CONTENT="Re: Why the future won't accommodate everyone!">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Why the future won't accommodate everyone!</H1>
<!-- received="Fri Mar 17 11:26:14 2000" -->
<!-- isoreceived="20000317182614" -->
<!-- sent="Fri, 17 Mar 2000 13:23:35 -0500" -->
<!-- isosent="20000317182335" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="mike@datamann.com" -->
<!-- subject="Re: Why the future won't accommodate everyone!" -->
<!-- id="38D27827.9DC58D79@datamann.com" -->
<!-- inreplyto="000401bf9030$23031de0$1b6945c2@oemcomputer" -->
<STRONG>From:</STRONG> Michael S. Lorrey (<A HREF="mailto:mike@datamann.com?Subject=Re:%20Why%20the%20future%20won't%20accommodate%20everyone!&In-Reply-To=&lt;38D27827.9DC58D79@datamann.com&gt;"><EM>mike@datamann.com</EM></A>)<BR>
<STRONG>Date:</STRONG> Fri Mar 17 2000 - 11:23:35 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="5186.html">Robert J. Bradbury: "Re: stunning multimedia site"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5184.html">Robert J. Bradbury: "Re: THERMODYNAMICS [Re: Technology: Inverted energy source..]"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5178.html">Sarah Marr: "RE: Why the future won't accommodate everyone!"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5273.html">Brian Atkins: "Re: Why the future needs everyone!"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5185">[ date ]</A>
<A HREF="index.html#5185">[ thread ]</A>
<A HREF="subject.html#5185">[ subject ]</A>
<A HREF="author.html#5185">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Sarah Marr wrote:
<BR>
<P><EM>&gt; Mike Lorrey wrote, in reply to my post:
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt; They own it [stock] whether they know it or not...
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Perhaps, but I don't think that indirect ownership acts to effect the
</EM><BR>
<EM>&gt; suggested benefits of the original post; i.e. it doesn't provide freedom
</EM><BR>
<EM>&gt; from governmental interference.
</EM><BR>
<P>True, however I think that as more people start to become more informed and
<BR>
independent minded that they will start to understand that what is going on is
<BR>
other people are making stock market profits on their money. The promise of
<BR>
reduced risk by the separation of the person from the actual ownership of stock
<BR>
is a false one, because if the true stock holder goes belly up, the government
<BR>
bails them out, and we are the one's who pay the tab anyways. Granted trained
<BR>
individuals using expert methods, including the Black Sholes equation, can
<BR>
reduce the risk quite a bit, but with smart stock shopping software, such
<BR>
expertise should be built in...so the home stock owner can enjoy the same risk
<BR>
reduction methods.
<BR>
<P><EM>&gt; &gt; Since increased artificial mind augmentation will add increased
</EM><BR>
<EM>&gt; &gt; logical abilities to
</EM><BR>
<EM>&gt; &gt; the average person, then the amount of illogical reasoning will
</EM><BR>
<EM>&gt; &gt; by definition
</EM><BR>
<EM>&gt; &gt; decline...
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; That doesn't follow, Mike. Increased logical reasoning does not
</EM><BR>
<EM>&gt; automatically decrease illogical reasoning. For logical reasoning to 'win
</EM><BR>
<EM>&gt; out' it has to be considered favourable to that of illogical reasoning, and
</EM><BR>
<EM>&gt; there's no guarantee that augmentation will or, indeed, should, bring that
</EM><BR>
<EM>&gt; about.
</EM><BR>
<P>No guarrantee, but I would be surprised if it did not come about. As far as I
<BR>
can tell, most educated people tend to act logical more frequently than
<BR>
uneducated people. Making it easier for people to learn, with augmentation,
<BR>
should increase this effect.
<BR>
<P><EM>&gt; &gt; So long as productivity growth and resource availability increase
</EM><BR>
<EM>&gt; &gt; faster than
</EM><BR>
<EM>&gt; &gt; population growth, then we remain on the track toward relatively
</EM><BR>
<EM>&gt; &gt; unlimited resources.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; But not to unrestricted and equal access to those resources for all, which
</EM><BR>
<EM>&gt; was my point.
</EM><BR>
<P>However there is no such thing as unrestricted and equal access. A person's own
<BR>
sense of utility acts as a natural restraint upon unlimited consumption. I may
<BR>
be able to buy as much Guiness as there is available, but there is only so much
<BR>
Guiness I need, want, or can consume in a given amount of time. This, coupled
<BR>
with the fact that each new generation of technology utilizes resources more
<BR>
efficiently, indicates to me that we are on the curve to 'practical' unlimited
<BR>
wealth for all (not total unlimited wealth).
<BR>
<P><EM>&gt; &gt; The market will decide what is good and what is bad.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; No, it won't. It will merely decide what the majority consider good and bad,
</EM><BR>
<EM>&gt; as it does now. You can't claim universal 'goodness' or 'badness' for
</EM><BR>
<EM>&gt; something.
</EM><BR>
<P>Well, you can, but that doesn't make it true. However as I have argued in the
<BR>
past, its my opinion that the laws of nature, physical and biological, impose a
<BR>
set of game rules on living in this universe. Using game theory it should be
<BR>
possible to figure out what are 'good' strategies and 'bad' strategies, given
<BR>
agreed upon goals. Deciding what the goals are is the question to ask. Given an
<BR>
agreed upon goal, there will be a set of 'good' and 'bad' things within the
<BR>
gamespace.
<BR>
<P><EM>&gt; &gt; Individuals,
</EM><BR>
<EM>&gt; &gt; as they gain more
</EM><BR>
<EM>&gt; &gt; logical, computational abilities, will understand more and more
</EM><BR>
<EM>&gt; &gt; that power domination
</EM><BR>
<EM>&gt; &gt; strategies are not beneficial to one's true self interest.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Why wouldn't they be? Note, I'm not asking why _are_ they in one's self
</EM><BR>
<EM>&gt; interest, I'm asking why they are actively _against_ that best interest.
</EM><BR>
<P>Because everyone has a self interest, and individuals who play power games may
<BR>
win for a short period of time, but the stats show that in the end they
<BR>
typically end up losing, especially as they become more radical in their
<BR>
domination, because they just piss off too many other people who have self
<BR>
interests that are violated. I read of a study last year that showed that the
<BR>
chance of a national leader to be assasinated is something like 30-40 percent. I
<BR>
think stats like that show that power games do have a limit to what can
<BR>
contribute to an individuals true self interest.
<BR>
<P><EM>&gt; &gt; &gt;         Oh, I don't know. Perhaps 'guilt' and 'loneliness' will
</EM><BR>
<EM>&gt; &gt; be considered
</EM><BR>
<EM>&gt; &gt; &gt; negative, 'bad', emotions, and someone will have decided to
</EM><BR>
<EM>&gt; &gt; wire them out,
</EM><BR>
<EM>&gt; &gt; &gt; as you suggested.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Anyone who thinks that eliminating emotions is a good thing has
</EM><BR>
<EM>&gt; &gt; some issues to work
</EM><BR>
<EM>&gt; &gt; out. Being transhuman does not mean less human, it means more
</EM><BR>
<EM>&gt; &gt; human, better human. I
</EM><BR>
<EM>&gt; &gt; don't see how you can acheive this by subtraction.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; I agree with you one hundred percent: that was the point of my comment.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt; &gt;         We are not about to overcome all future suffering, and
</EM><BR>
<EM>&gt; &gt; the removal of
</EM><BR>
<EM>&gt; &gt; &gt; death, and resurrection of the dead, will not end all evil.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; If our projections of the future are reasonably accurate...
</EM><BR>
<EM>&gt; &lt;snip&gt;
</EM><BR>
<EM>&gt; &gt; I estimate that this means about a 90% decrease in the fatality rate.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Sorry, my comment wasn't clear. I should have written, &quot;We are not about to
</EM><BR>
<EM>&gt; overcome all future suffering. Furthermore, the removal of death, and
</EM><BR>
<EM>&gt; resurrection of the dead, will not end all evil.&quot; I do think removal of
</EM><BR>
<EM>&gt; death is entirely possible, but that won't end evil or suffering. Why should
</EM><BR>
<EM>&gt; it?
</EM><BR>
<P>True. Some suffering is good, educational, even beneficial in the end. As in my
<BR>
previous comment, those that don't think so have some issues to deal with...
<BR>
<P><EM>&gt; &gt; Nobody who is not frozen can truly be resurrected...
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; I agree.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; &gt; Many, but not all people, are happy to die. Many, but not all
</EM><BR>
<EM>&gt; &gt; people are not happy with
</EM><BR>
<EM>&gt; &gt; their lives... see a resemblance?
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; Yes, but not a one-to-one mapping by any means.
</EM><BR>
<P>True, but I would not be surprised if there were a significant correlation.
<BR>
<P><EM>&gt; &gt; However, there are things that
</EM><BR>
<EM>&gt; &gt; all sane people do
</EM><BR>
<EM>&gt; &gt; agree on. Those things can be defined as 'good'.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; There are very few things that _all_ sane people agree on, and you are in
</EM><BR>
<EM>&gt; grave danger of creating a circular definition of sanity, whereby those who
</EM><BR>
<EM>&gt; are to be considered sane are those who agree on certain things.
</EM><BR>
<P>Good point. Who gets to choose the base set?
<BR>
<P><EM>&gt; &gt; Also, due to evolutionary fitness,
</EM><BR>
<EM>&gt; &gt; there are things which are more good or more bad than others.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; This is, at best, a restrictive definition of 'good' and 'bad'. &quot;Good&quot; and
</EM><BR>
<EM>&gt; &quot;bad&quot; go far beyond evolutionary fitness. For an assessment of something's
</EM><BR>
<EM>&gt; being 'good' or 'bad' to rest on its evolutionary value all other
</EM><BR>
<EM>&gt; considerations (cultural, societal, moral...) would have to be indeterminate
</EM><BR>
<EM>&gt; or ignored. For me, that's a 'bad' thing.
</EM><BR>
<P>I don't think they would be ignored, because those things are evolved things as
<BR>
well.
<BR>
<PRE>
--
TANSTAAFL!!!
<P>Michael S. Lorrey
Member, Extropy Institute
<A HREF="http://www.extropy.org">http://www.extropy.org</A>
Member, National Rifle Association
<A HREF="http://www.nra.org">http://www.nra.org</A>
&quot;Live Free or Die, Death is not the Worst of Evils.&quot;
                  - General John Stark
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="5186.html">Robert J. Bradbury: "Re: stunning multimedia site"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="5184.html">Robert J. Bradbury: "Re: THERMODYNAMICS [Re: Technology: Inverted energy source..]"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="5178.html">Sarah Marr: "RE: Why the future won't accommodate everyone!"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="5273.html">Brian Atkins: "Re: Why the future needs everyone!"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#5185">[ date ]</A>
<A HREF="index.html#5185">[ thread ]</A>
<A HREF="subject.html#5185">[ subject ]</A>
<A HREF="author.html#5185">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:05:34 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
