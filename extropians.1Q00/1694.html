<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: SOC: UK report (&amp; survey): &quot;Morals for Rob</TITLE>
<META NAME="Author" CONTENT="GBurch1@aol.com (GBurch1@aol.com)">
<META NAME="Subject" CONTENT="SOC: UK report (&amp; survey): &quot;Morals for Robots and Cyborgs&quot;">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>SOC: UK report (&amp; survey): &quot;Morals for Robots and Cyborgs&quot;</H1>
<!-- received="Fri Jan 28 18:49:48 2000" -->
<!-- isoreceived="20000129014948" -->
<!-- sent="Fri, 28 Jan 2000 20:46:00 EST" -->
<!-- isosent="20000129014600" -->
<!-- name="GBurch1@aol.com" -->
<!-- email="GBurch1@aol.com" -->
<!-- subject="SOC: UK report (&amp; survey): &quot;Morals for Robots and Cyborgs&quot;" -->
<!-- id="6c.1505ae6.25c3a058@aol.com" -->
<STRONG>From:</STRONG> <A HREF="mailto:GBurch1@aol.com?Subject=Re:%20SOC:%20UK%20report%20(&amp;%20survey):%20&quot;Morals%20for%20Robots%20and%20Cyborgs&quot;&In-Reply-To=&lt;6c.1505ae6.25c3a058@aol.com&gt;"><EM>GBurch1@aol.com</EM></A><BR>
<STRONG>Date:</STRONG> Fri Jan 28 2000 - 18:46:00 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="1695.html">James Daugherty: "Atkins Diet Testimonial--Test Results!"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="1693.html">eugene.leitl@lrz.uni-muenchen.de: "can the government require your keys?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#1694">[ date ]</A>
<A HREF="index.html#1694">[ thread ]</A>
<A HREF="subject.html#1694">[ subject ]</A>
<A HREF="author.html#1694">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
<EM>&gt;From The Irish Times,
</EM><BR>
<A HREF="http://www.ireland.com/newspaper/finance/2000/0128/tech3.htm">http://www.ireland.com/newspaper/finance/2000/0128/tech3.htm</A>
<BR>
-
<BR>
Friday, January 28, 2000
<BR>
<P>Study offers glimpse
<BR>
of robotic future
<BR>
<P>----------------------------------------------------------------------------
<BR>
<PRE>
----
By Madeleine Lyons
<P>WIRED ON FRIDAY: There are rare moments when developments in the world of
information technology (IT) come under the spotlight and the thin line
between reality and fiction becomes blurred.
<P>A new study &quot;Morals for Robots and Cyborgs&quot; reads like a modern day version
of Franken- stein. It offers a rare glimpse of the potential monster man may
have inadvertently created in the quest for greater convenience and
technical efficiency.
<P>The study, commissioned by the Bull Cara group, examines some of the ethical
and public policy issues surrounding the use of advanced computers,
especially robotics, digital agents and neuro-computer links.
<P>The primary aim of the report is to stimulate early debate on areas of
potential public concern that have been created by technology, and suggest
possible policy guidelines.
<P>According to Mr David Little, managing director of Bull Cara Group: &quot;It is
vital for the computer industry to open a dialogue with the public,
government, industry and academia if we wish to avoid the controversy that
dogged other sectors like genetically modified (GM) foods, cloning, human
fertilisation and trans-species organ donation.&quot;
<P>The central plank of the report is based on the writing of the rather
unusually named Perri 6, a senior research fellow at the University of
Strathclyde.
<P>Despite the bizarre moniker he took for himself more than 20 years ago,
Perri 6 is a respected academic who rose to prominence through his
involvement as a director of Demos, the UKbased think-tank, which has been
closely identified with supporters of New Labour.
<P>His study investigates the challenges for ethics and public policy raised by
technical advances. He outlines 15 principles of &quot;techno-ethics&quot; which range
from the need to monitor the economic effects of deploying artificial
intelligence, to ensuring we can manage and compensate the changes in demand
for human labour that may result from industrial thinking machines.
<P>He points out that concerns about new technologies, often prompted by the
ideas behind science fiction movies, may be misplaced, and the likelihood of
a world where intelligent machines like HAL, RoboCop or Marvin the Paranoid
Android are going to seize power is somewhat overstated.
<P>Instead he considers the potential economic impact of autonomous
artificially intelligent systems, the need to ensure privacy, health and
safety and the need to educate the wider community about advances in
general.
<P>&quot;For most of history, machines have been tools. Now they have the capacity
to make decisions, what kind of legal and ethical rules do we need to govern
them? A neural Net can provide some answers to medical problems as
efficiently as a doctor, but when they get it wrong they tend to kill the
patient. There are fundamental questions about liability, as well as privacy
and desirability - is a machine used by a criminal more like a gun or a
car?&quot; asks Perri 6.
<P>The academic investigation spans a number of areas from existing
technologies - intelligent software for example which refines its decisions
and behaviour through learning - to emerging technologies which predate
scenarios where wars might be conducted by robots on our behalf.
<P>One of the more practical conclusions makes the rather obvious point that
with technology replacing whole areas of formerly human responsibility,
there are implications for human labour. Perri 6 advises that politicians
should be prepared to undertake compensating measures to stimulate
employment opportunities for those who may be displaced by substitution.
With traditional retailing and supply chain management in a current state of
overhaul the advice is timely.
<P>The study touches on other, more notional, concerns including the moral
conduct of war by machines and regulatory issues for government. Perri 6 is
adamant there is huge potential for misuse of knowledge-based systems.
<P>&quot;Robots and digital agents could be used in the course of crime. The largest
category of investment in digital agents is in the military where they could
be used to replace soldiers. On one hand they are less likely to desert or
be captured, on the other, what happens if a machine turns in the
battlefield. Accountability and responsibility also need to be designed in,&quot;
Perri 6 says.
<P>There are also issues of privacy in cases where intelligent software is
deployed to learn over time about an individual's behaviour online,
including transactions and Internet tastes and preferences.
<P>This information once accurately identified is extremely commercially
valuable. Perri 6 calls for principles of software design and disclosure
which will protect the consumer from commercial predators.
<P>In conjunction with the paper a survey of public opinion was conducted by
Taylor Nelson Sofres, from 1,001 face-to-face interviews which took place in
the UK last October.
<P>The survey's findings indicate an alarming disparity between male and female
views on technology's progress.
<P>For example 15 per cent more women than men were concerned that machines had
already taken too many jobs (70 per cent), and 12 per cent more men than
women believed technological advances to be generally a positive thing (72
per cent).
<P>Techno-fear featured strongly in the survey, with more than half the
respondents agreeing we are in danger of entering a robot state where
everything is automated, and 81 per cent disagreeing with the principle of
embedding chips into humans.
<P>However, the inevitability of technological progress was largely agreed on,
with more than 70 per cent of respondents unconcerned about the spread of
technology, believing artificial intelligence to be generally a good thing.
<P>One of the most interesting conclusions of the survey, was the finding that
nearly half (48 per cent) said they would trust the government least to
monitor technological advances. Academia scored high here, coming in as the
most trusted monitoring body for 25 per cent of respondents, while the
computer industry would only be trusted by 14 per cent if it were to assume
this role.
<P>Both the study and survey offer a refreshing glimpse of what lies ahead for
information technologies, and point to some of the interesting debates that
need to be thrashed out. Bull Cara's involvement in the project indicates a
renewed interest by the European IT giant in industry progress. The company
needs to make up some ground it lost since it came to dominate the European
market in the early nineties, particularly in smart card and mainframe
systems.
<P>Perri 6's paper &quot;Morals for Robots and Cyborgs&quot; and the ac- companying
research can be viewed on Bull's website: www.bull.co.uk.
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="1695.html">James Daugherty: "Atkins Diet Testimonial--Test Results!"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="1693.html">eugene.leitl@lrz.uni-muenchen.de: "can the government require your keys?"</A>
<!-- nextthread="start" -->
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#1694">[ date ]</A>
<A HREF="index.html#1694">[ thread ]</A>
<A HREF="subject.html#1694">[ subject ]</A>
<A HREF="author.html#1694">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:02:52 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
