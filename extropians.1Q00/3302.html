<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: Informed consent and the exoself</TITLE>
<META NAME="Author" CONTENT="Dan Fabulich (daniel.fabulich@yale.edu)">
<META NAME="Subject" CONTENT="Re: Informed consent and the exoself">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: Informed consent and the exoself</H1>
<!-- received="Mon Feb 21 23:27:23 2000" -->
<!-- isoreceived="20000222062723" -->
<!-- sent="Tue, 22 Feb 2000 00:28:58 -0500 (EST)" -->
<!-- isosent="20000222052858" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Informed consent and the exoself" -->
<!-- id="Pine.GSO.4.10.10002220013200.2840-100000@morpheus.cis.yale.edu" -->
<!-- inreplyto="38B1FE81.E3D42519@pobox.com" -->
<STRONG>From:</STRONG> Dan Fabulich (<A HREF="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Informed%20consent%20and%20the%20exoself&In-Reply-To=&lt;Pine.GSO.4.10.10002220013200.2840-100000@morpheus.cis.yale.edu&gt;"><EM>daniel.fabulich@yale.edu</EM></A>)<BR>
<STRONG>Date:</STRONG> Mon Feb 21 2000 - 22:28:58 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3303.html">Zero Powers: "RE: what it's like to be uploaded"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3301.html">Spike Jones: "warning: long, non-related-to-extropianism post"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3285.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3307.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3307.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3302">[ date ]</A>
<A HREF="index.html#3302">[ thread ]</A>
<A HREF="subject.html#3302">[ subject ]</A>
<A HREF="author.html#3302">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
'Eliezer S. Yudkowsky?' 'There is no Eliezer S. Yudkowsky. Only Zuul':
<BR>
<P><EM>&gt; Actually, my current take calls for a comparative, rather than a
</EM><BR>
<EM>&gt; quantitative, goal system.  So under that system, you'd put in the
</EM><BR>
<EM>&gt; statement &quot;The humans want you to do X&quot;.  All else being equal, this
</EM><BR>
<EM>&gt; statement is the only consideration; all else not being equal, it can
</EM><BR>
<EM>&gt; be ignored.
</EM><BR>
<P>Well, at that point, it seems to me that you don't have to figure out
<BR>
what, in particular, it ought to do with its simulations, since its
<BR>
primary assignment is to figure out what it ought to do.  Leave questions
<BR>
like informed consent up to the expert(s).
<BR>
<P><EM>&gt; I don't think so.  Richness doesn't have to be extracted from the
</EM><BR>
<EM>&gt; environment; it can as easily be extracted from mathematics or
</EM><BR>
<EM>&gt; subjunctive simulations.
</EM><BR>
<P>Information like this CAN be extracted from simulations, but it's not
<BR>
possible to simulate something unless you already know quite a lot about
<BR>
how it operates in the wild, as well as (at least for our mundane
<BR>
processors) in what ways it's reasonable to abstract away from the messy
<BR>
details.  There's a lot that it can learn once it can start running
<BR>
simulations, but there's a long way from knowing &quot;I need a goal&quot; to
<BR>
knowing enough about humans to run a simulation.
<BR>
<P><EM>&gt; The general problem is that human beings are stupid, both passively and
</EM><BR>
<EM>&gt; actively, and over the course of hundreds of thousands of years we've
</EM><BR>
<EM>&gt; evolved personal and cultural heuristics for &quot;How not to be stupid&quot;. 
</EM><BR>
<EM>&gt; The entire discipline of science is essentially a reaction to our
</EM><BR>
<EM>&gt; tendency to believe statements for ideological reasons; if an AI doesn't
</EM><BR>
<EM>&gt; have that tendency, will it evolve the rigorous methods of science?
</EM><BR>
<P>It would be a mistake to assume that an AI will be smart across the board.
<BR>
It will be smart eventually, but you must assume that it will be stupid,
<BR>
though methodical, at first.  Historically, the guys who burn heretics
<BR>
have had nothing going for them if not rigor and method.
<BR>
<P>I'm not familiar with your distinction of active and passive stupidity; I
<BR>
take it you mean that a rock is passively stupid, whereas the guys who
<BR>
killed Galileo were actively stupid.  (A rock never makes mistakes?)  
<BR>
<P>Frankly, I find the idea that an AI will not be actively stupid
<BR>
suspicious.  Granted, post-Singularity it won't be actively stupid, but
<BR>
for most of the period that YOU have to worry about, you need to
<BR>
anticipate that the AI will be both passively and actively stupid.
<BR>
<P><EM>&gt; Anyway, it gets complicated.
</EM><BR>
<P>It certainly does.
<BR>
<P>-Dan
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-unless you love someone-
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;-nothing else makes any sense-
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.e. cummings
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3303.html">Zero Powers: "RE: what it's like to be uploaded"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3301.html">Spike Jones: "warning: long, non-related-to-extropianism post"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3285.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3307.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3307.html">Eliezer S. Yudkowsky: "Re: Informed consent and the exoself"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3302">[ date ]</A>
<A HREF="index.html#3302">[ thread ]</A>
<A HREF="subject.html#3302">[ subject ]</A>
<A HREF="author.html#3302">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:04:00 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
