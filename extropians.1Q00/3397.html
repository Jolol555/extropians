<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: Re: electronic intelligence and ethics</TITLE>
<META NAME="Author" CONTENT="Michael S. Lorrey (retroman@turbont.net)">
<META NAME="Subject" CONTENT="Re: electronic intelligence and ethics">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>Re: electronic intelligence and ethics</H1>
<!-- received="Wed Feb 23 07:46:42 2000" -->
<!-- isoreceived="20000223144642" -->
<!-- sent="Wed, 23 Feb 2000 09:56:05 -0500" -->
<!-- isosent="20000223145605" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="retroman@turbont.net" -->
<!-- subject="Re: electronic intelligence and ethics" -->
<!-- id="38B3F504.757BD0E8@turbont.net" -->
<!-- inreplyto="20000223021728.77503.qmail@hotmail.com" -->
<STRONG>From:</STRONG> Michael S. Lorrey (<A HREF="mailto:retroman@turbont.net?Subject=Re:%20electronic%20intelligence%20and%20ethics&In-Reply-To=&lt;38B3F504.757BD0E8@turbont.net&gt;"><EM>retroman@turbont.net</EM></A>)<BR>
<STRONG>Date:</STRONG> Wed Feb 23 2000 - 07:56:05 MST
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3398.html">Robin Hanson: "Re: national programs to raise the population's intelligence..."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3396.html">Robin Hanson: "Re: FW: a teen's view of heaven and hell...."</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3365.html">Zero Powers: "Re: electronic intelligence and ethics"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3369.html">Damien Broderick: "Re: electronic intelligence and ethics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3397">[ date ]</A>
<A HREF="index.html#3397">[ thread ]</A>
<A HREF="subject.html#3397">[ subject ]</A>
<A HREF="author.html#3397">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
Zero Powers wrote:
<BR>
<P><EM>&gt; &gt;From: &quot;Michael S. Lorrey&quot; &lt;<A HREF="mailto:retroman@turbont.net?Subject=Re:%20electronic%20intelligence%20and%20ethics&In-Reply-To=&lt;38B3F504.757BD0E8@turbont.net&gt;">retroman@turbont.net</A>&gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; But what else (if anything) will motivate them?  Will there be any
</EM><BR>
<EM>&gt; &gt;&quot;good&quot;
</EM><BR>
<EM>&gt; &gt; &gt; for them other than information?  Any &quot;evil&quot; other than ignorance?  Will
</EM><BR>
<EM>&gt; &gt; &gt; they care at all about such trivialities as emotion, fairness,
</EM><BR>
<EM>&gt; &gt;compassion
</EM><BR>
<EM>&gt; &gt; &gt; and pain?  Whether or not I want to survive the ascendancy of strong EI
</EM><BR>
<EM>&gt; &gt;will
</EM><BR>
<EM>&gt; &gt; &gt; depend largely upon this question.  Unfortunately I'll never know the
</EM><BR>
<EM>&gt; &gt; &gt; answers unless and until I survive to that time.  Or unless I am
</EM><BR>
<EM>&gt; &gt;persuaded
</EM><BR>
<EM>&gt; &gt; &gt; by the musings of this list.  I can't wait to hear your thoughts.
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt;Based on my arguments above, I think that since uploaded humans will
</EM><BR>
<EM>&gt; &gt;continue to
</EM><BR>
<EM>&gt; &gt;think of themselves as human, that their motivations will be very similar
</EM><BR>
<EM>&gt; &gt;as
</EM><BR>
<EM>&gt; &gt;they are now, there will merely be increased growth and maturity in an
</EM><BR>
<EM>&gt; &gt;uploaded
</EM><BR>
<EM>&gt; &gt;humans thinking. Because the uploaded human will have greater access to
</EM><BR>
<EM>&gt; &gt;information and capacity to make rational decisions, human society will
</EM><BR>
<EM>&gt; &gt;become
</EM><BR>
<EM>&gt; &gt;closer to the Baysean ideal, so less strife and stupidity will of course
</EM><BR>
<EM>&gt; &gt;occur
</EM><BR>
<EM>&gt; &gt;(except that by those who refuse to augment themselves, of course),
</EM><BR>
<EM>&gt; &gt;although I
</EM><BR>
<EM>&gt; &gt;don't know if it will dissapear entirely.
</EM><BR>
<EM>&gt;
</EM><BR>
<EM>&gt; So do you anticipate that strong EI (or AI if you prefer) will not precede
</EM><BR>
<EM>&gt; uploaded human minds?  It seems to me (granted I am *not* a scientist) that
</EM><BR>
<EM>&gt; we are much closer to EI than to uploading brain patterns.  Also seems to me
</EM><BR>
<EM>&gt; that once EI becomes strong enough it will be able to &quot;take over.&quot;  At that
</EM><BR>
<EM>&gt; point we may very well not be able to upload our minds without the
</EM><BR>
<EM>&gt; permission of the EI running the show.  From your comments it seems that you
</EM><BR>
<EM>&gt; feel strong EI will only come after, or even as the result of, human mind
</EM><BR>
<EM>&gt; uploading?
</EM><BR>
<P>Because I see 'uploading' not as an actual matter of scanning the brain and
<BR>
transferring its contents, like a drive copy, but as a mere matter of slow
<BR>
migration, with the mind concious throughout, and incorporating the new
<BR>
electronic capacity as its own throughout the process. The best analogy I can
<BR>
make is this:
<BR>
<P>I have a Jeep Cherokee. Eventually, all of its parts will wear out, but because
<BR>
I only replace one at a time, it is still the same Cherokee 4x4 now as it was
<BR>
when it was new, and eventually when it is comprised entirely of replacement
<BR>
parts, it will still be the 'same' Cherokee, as far as the rest of the world is
<BR>
concerned. Many of the replacement parts are not original designs, but later
<BR>
designs that are suitable substitutes for the originals. If I add running bars,
<BR>
a Thule rack, a better stereo, a car phone, satellite navigation, rally lights,
<BR>
and a lift kit, it will still be the same Jeep, just a more capable Jeep.
<BR>
<P>So, I do think that since we now have direct neural implant technologies, while
<BR>
we have no real AI technologies (I don't consider current AI to be anywhere near
<BR>
human leve intelligence, more on the order of a parrot.), then I think that we
<BR>
will develop AI as an equal or better intelligence than man as a result of our
<BR>
migratory augmentation method of upload.
<BR>
<P>Mike Lorrey
<BR>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3398.html">Robin Hanson: "Re: national programs to raise the population's intelligence..."</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3396.html">Robin Hanson: "Re: FW: a teen's view of heaven and hell...."</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="3365.html">Zero Powers: "Re: electronic intelligence and ethics"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3369.html">Damien Broderick: "Re: electronic intelligence and ethics"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3397">[ date ]</A>
<A HREF="index.html#3397">[ thread ]</A>
<A HREF="subject.html#3397">[ subject ]</A>
<A HREF="author.html#3397">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Thu Jul 27 2000 - 14:04:04 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
