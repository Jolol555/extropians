<!-- received="Thu Aug 29 16:24:49 1996 MST" -->
<!-- sent="Thu, 29 Aug 1996 18:23:33 -0400" -->
<!-- name="QueeneMUSE@aol.com" -->
<!-- email="QueeneMUSE@aol.com" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="9608291709.AA16741@dosh.hum.caltech.edu" -->
<!-- inreplyto="Thinking about the future..." -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
<i>QueeneMUSE@aol.com</i><br>
<i>Thu, 29 Aug 1996 18:23:33 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#567">[ date ]</a><a href="index.html#567">[ thread ]</a><a href="subject.html#567">[ subject ]</a><a href="author.html#567">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0568.html">QueeneMUSE@aol.com: "Re: Controlling AI (was: Thinking about the future...)"</a>
<li> <b>Previous message:</b> <a href="0566.html">Robin Hanson: "Why Asia is Rich"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0584.html">Stephen de Vries: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Anders Sandberg wrote:<br>
<p>
<i> &gt; &gt; I think it would be unlikely that we create successors</i><br>
<i> &gt;that out-compete us, most likely they will inhabit a somewhat different</i><br>
<i> &gt;ecological/memetic niche that will overlap with ours; competition a</i><br>
<p>
[ to which  Max More wrote:]<br>
<i> &gt;&gt;You make good points, Anders, about humans and nanite-AI's having possibly</i><br>
<i>&gt; different niches. However, there may be a period during which we're very</i><br>
<i>&gt; much in the same space. That's the period in which humans could be at risk</i><br>
<i>&gt; if AI/SIs have no regard for our interests. What I'm thinking is that it's</i><br>
<i>&gt; possible, even likely, that SI will be developed before really excellent</i><br>
<i>&gt; robotics. AI's in that case would not be roaming around much physically,</i><br>
but<br>
<i>&gt; they could exist in distributed form in the same computer networks that we</i><br>
<i>&gt; use for all kinds of functions crucial to us.</i><br>
<i> &gt;&gt;  If they need us for doing things physically, we would still have a</i><br>
strong<br>
<i>&gt; position. Nevertheless, powerful SI's in the computer networks, could exert</i><br>
<i>&gt; massive extortionary power, if they were so inclined. So I still think it</i><br>
<i>&gt; important that SI researchers pay attention to issues of what values and</i><br>
<i>&gt; motivations are built into SIs &gt;&gt;</i><br>
<p>
<p>
Ah yes,  the programmers ( as well as the programmed AI's)  motivations could<br>
be really useful or highly destructive! A theme for a many well loved  horror<br>
tale, indeed! ..or a solution to much strife on our world.<br>
Re: Values :    I am curious - we talk about the AI's replacing, destroying<br>
or overcoming humans or &gt;H's: Realistically - what would  AI's "needs" be?<br>
Would it have needs? - or more precisely would they precieve the concept of<br>
needs as we do, not being subject to the fight or flight domain we have to<br>
negotiate?We need food,nurturing,clothing,shelter,etc.. What AI conditions<br>
correspond to that? If we (thru mimicry of intelligence as we know it)<br>
 create them as similar to primate intelligence, then (?) reproduction<br>
/expansion-  but if NN intelligences program themselves, how could we predict<br>
what the agenda will be?As Max says here - they could exert massive power. Do<br>
we assume they would inherently take our values and expand or pervert them -<br>
an allegiance to their "creators"? Some how I don't see that, as inviting as<br>
it sounds.<br>
<p>
Even if they could "use" us for manual labor- and what would we produce for<br>
them?<br>
<p>
In essence, what would they want to destroy us *for*?  Comparatively<br>
aesthetic messiness? <br>
<p>
[PS Anders your post made me want to draw transhuman wet/dry multi- sided<br>
organelles, but then that gave me Borg images again...]<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0568.html">QueeneMUSE@aol.com: "Re: Controlling AI (was: Thinking about the future...)"</a>
<li> <b>Previous message:</b> <a href="0566.html">Robin Hanson: "Why Asia is Rich"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0584.html">Stephen de Vries: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
