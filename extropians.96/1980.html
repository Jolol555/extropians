<!-- received="Fri Oct 18 11:20:15 1996 MST" -->
<!-- sent="Fri, 18 Oct 1996 10:06:00 -0700" -->
<!-- name="Tim Freeman" -->
<!-- email="tim@infoscreen.com" -->
<!-- subject="Terror Management" -->
<!-- id="199610181706.KAA00081@infoscreen.com" -->
<!-- inreplyto="" -->
<title>extropians: Terror Management</title>
<h1>Terror Management</h1>
Tim Freeman (<i>tim@infoscreen.com</i>)<br>
<i>Fri, 18 Oct 1996 10:06:00 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1980">[ date ]</a><a href="index.html#1980">[ thread ]</a><a href="subject.html#1980">[ subject ]</a><a href="author.html#1980">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1981.html">Max More: "Re: Aurora, Land of the Libertarians!!"</a>
<li> <b>Previous message:</b> <a href="1979.html">map@snowline.net: "FYI (forwarded): LFB Book News: THE ULTIMATE RESOURCE II"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
In cryomsg 6194 (written May 1996), David Stodolsky<br>
(david@arch.ping.dk) said: <br>
<p>
   Research has shown that mortality salience increases the tendency<br>
   to conform to culturally acceptable systems of thought. See:<br>
   Solomon, S., Greenberg, J., &amp; Pyszczynski, T. (1991).<br>
   A terror management theory of social behavior:<br>
   The psychological functions of self-esteem and cultural worldviews.<br>
   In M. Zanna (Ed.) Advances in Experimental Social Psychology<br>
   (Vol. 24, pp. 93-159). New York: Academic Press.<br>
<p>
I recently acquired a copy of this, and I agree with David Stodolsky<br>
that terror management (TM) explains why so few people are interested<br>
in trying to use technology to postpone or prevent death.<br>
<p>
Briefly, this is the hypothesis: there is obvious survival value in<br>
trying to avoid death in the short term.  However, avoiding death in<br>
the long term has historically been impossible, so survival has been<br>
promoted by any psychological means (a "buffer") that prevents the<br>
wasted effort of applying the short-term death-avoidance strategies to<br>
the problem of long-term death avoidance.  In practice, the usual<br>
buffer has two parts:<br>
<p>
   1. A firmly-held belief about what makes life valuable.  A belief<br>
      can be more firmly held by a group than by an individual, since<br>
      the group consensus obscures the essential arbitraryness of the<br>
      belief.  This belief can reasonably be called "culture".<br>
   2. Behavior that conforms to the values of the culture.  Conformity<br>
      to the cultural value system is a major component of self-esteem.<br>
<p>
When people are reminded of death, they must strengthen the buffer, so<br>
they defend their culture.  Applying this to life extension,<br>
technological approaches to life extension remind people of death, and<br>
most cultures don't include any useful life extension techniques, so<br>
few people do anything intelligent to extend their lives.<br>
<p>
This theory makes several predictions that have been born out by<br>
experiment:<br>
<p>
   1. Remind the experimental subject of death, and remind the control<br>
      subjects of something inane like television.  Ask both groups to<br>
      determine the appropriate bail bond for a hypothetical arrested<br>
      prostitute.  Of those persons who have a worldview that<br>
      prostitution is bad, the persons who have been reminded of death give<br>
      a significantly larger number.  (Municipal court judges were used<br>
      as subjects in one run that replicated the result.  It is scary<br>
      that things like this might influence actual court outcomes.)<br>
<p>
   2. Similar preparation for the subjects, but confront the American<br>
      subjects with an apparently pro-American interviewer or an apparently<br>
      anti-American interviewer.  The subjects who were recently reminded of<br>
      death like the pro-American interviewer more and dislike the<br>
      anti-American interviewer more.<br>
<p>
Some time ago I also read Combatting Cult Mind Control by Steven<br>
Hassan (Park Street Press, 1988).  The author is an ex-Moonie who<br>
helps people escape from mind control cults.  He did not have the<br>
concept of TM, but TM explains why his technique works.  It turns out<br>
that mind control cults typically give the victim a belief system<br>
which the victim adopts as the "culture" to be defended a la TM.<br>
Frequently part of the belief system is an exit phobia, a belief that<br>
leaving the cult will cause some disaster to happen.  TM explains why<br>
this is so effective: disasters remind people of death and make people<br>
defend their culture (that is, the belief system of the cult).  TM<br>
also explains why people with low self-esteem tend to be sucked into<br>
cults more often.  If the existing defense mechanism is broken, a<br>
person is more willing to adopt a new one.<br>
<p>
The technique used by Hassan to help people leave cults is<br>
particularly interesting.  He confronts the cult member with someone<br>
who is an ex-member of *some other cult*.  For example, suppose we're<br>
trying to save a Moonie; we go find an ex-EST person to talk to him<br>
about cults.  (The Moonie does not believe he is in a cult.)  The<br>
Moonie's belief isn't directly threatened by conversations about how<br>
EST works as a cult, so TM does not prevent the ex-EST person from<br>
explaining to the Moonie how cults work and detailed things about how<br>
EST fit the profile of a cult.  Giving the Moonie this knowledge as<br>
part of an apparently idle conversation lays the groundwork for a<br>
future intervention where his non-Moonie friends and family try to<br>
persuade him that he is in a cult that does not help him achieve any<br>
reasonable goals.<br>
<p>
There are many other details too.  Our goal, of course, would be to<br>
pull people out of the prevailing deathist mind-set.  The difference<br>
between this and a cult is merely the size, and that the deathist<br>
consensus does not have a strong exit phobia (except some but not all<br>
Christians will believe they will burn in Hell if they believe us).<br>
<p>
There are also books out there like "Virus of the Mind" that are<br>
explicitly about meme engineering.<br>
<p>
At the moment I am reluctant to participate directly in trying to<br>
engineer the optimal propaganda technique, since my past experiences<br>
where I have accidentally pushed people into TM mode leave me somewhat<br>
nauseous and disgusted.  Now that I understand why that happened, I<br>
may have a different attitude in a few months.  Engineering the<br>
propaganda technique would definitely be a worthwhile exercise.<br>
<p>
I don't read the extropians list at the moment, so please cc me in any<br>
dialogue about this.<br>
<p>
Tim Freeman<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1981.html">Max More: "Re: Aurora, Land of the Libertarians!!"</a>
<li> <b>Previous message:</b> <a href="1979.html">map@snowline.net: "FYI (forwarded): LFB Book News: THE ULTIMATE RESOURCE II"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
