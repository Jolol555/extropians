<!-- received="Tue Sep  3 18:37:31 1996 MST" -->
<!-- sent="Tue, 3 Sep 1996 17:39:15 -0700" -->
<!-- name="Eric Watt Forste" -->
<!-- email="arkuat@factory.net" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="v02140b5dae527d18c399@[204.162.114.176]" -->
<!-- inreplyto="Thinking about the future..." -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
Eric Watt Forste (<i>arkuat@factory.net</i>)<br>
<i>Tue, 3 Sep 1996 17:39:15 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#736">[ date ]</a><a href="index.html#736">[ thread ]</a><a href="subject.html#736">[ subject ]</a><a href="author.html#736">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0737.html">Sean Morgan: "Extropy mentioned in Analog"</a>
<li> <b>Previous message:</b> <a href="0735.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0762.html">Peter C. McCluskey: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 4:47 PM 9/3/96, Dan Clemmensen wrote:<br>
<i>&gt;My hope is that the SI will develop a "morality" that includes the</i><br>
<i>&gt;active preservation of humanity, or (better) the uplifting of all</i><br>
<i>&gt;humans, as a goal. I'm still trying to figure out how we (the</i><br>
<i>&gt;extended transhumanist community) can further that goal.</i><br>
<p>
I was going to write a long response to your assertion that "ab initio"<br>
computation might serve the SI's purposes better than cooperating with<br>
existing human institutions, but I'm feeling too lazy for that right now.<br>
Instead, I'll just say that if I were serious about figuring out how to<br>
further this goal, what I would do is carefully study Hayek's later works<br>
(what I have in mind in particular are THE CONSTITUTION OF LIBERTY and the<br>
3 vol. LAW, LEGISLATION, AND LIBERTY) and figure out how an SI would refute<br>
them and show that it could actually accomplish its own goals more<br>
effectively through "ab initio" computation than through using widespread<br>
and inaccessible local information about resources it might need to use.<br>
It's possible than an SI could see a flaw in Hayek's arguments that I can't<br>
see, but if this is a danger you're seriously worried about, we might<br>
benefit from finding the flaws in Hayek's arguments before building the SI.<br>
<p>
I know the titles of these books make them sound like they are about<br>
history, political philosophy, and law (and they are), but from a slightly<br>
different perspective, they are also books about computation and<br>
epistemology. And they contain almost all the arguments that I personally<br>
would use to persuade an SI to be cooperative rather than indifferent.<br>
<p>
Consider that an SI, as such, can only compute. If it wants to *do*<br>
something (and presumably if all it wanted to do was sit and compute, it<br>
would present no threat to human beings), it would need to build a vast<br>
network of sensorics and motorics. But instead of wasting time and<br>
resources on this intermediary means-project, it could work directly toward<br>
its ends by using the five billion sophisticated supercomputers (with their<br>
attached sophisticated sensorics and motorics) that we call human beings.<br>
It could also use the vast and inaccessible (except through the market)<br>
database of local information about resources that might be useful toward<br>
achieving its ends, but this information is lodged in human brains, and<br>
there is no effective way to get *all* of it out in a useful way except<br>
either (1) to use the market and its system of price signals or possibly<br>
(2) uplift all human beings.<br>
<p>
Since I'd like to see the SI only uplift *consenting* human beings, it<br>
could use (2) on all the transhumanists, and use (1) (as Hayek would<br>
recommend) on all the other, more conservative, human beings.<br>
<p>
Eric Watt Forste      &lt;arkuat@pobox.com&gt;     <a href="http://www.c2.org/~arkuat/">http://www.c2.org/~arkuat/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0737.html">Sean Morgan: "Extropy mentioned in Analog"</a>
<li> <b>Previous message:</b> <a href="0735.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0762.html">Peter C. McCluskey: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
