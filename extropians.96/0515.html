<!-- received="Tue Aug 27 11:47:00 1996 MST" -->
<!-- sent="Tue, 27 Aug 1996 14:09:21 GMT2" -->
<!-- name="Stephen de Vries" -->
<!-- email="PHEN@wwg3.uovs.ac.za" -->
<!-- subject="AI at all costs. (Was thinking about the future)" -->
<!-- id="Pine.SOL.3.91.960827141617.15648D-100000@sun3" -->
<!-- inreplyto="" -->
<title>extropians: AI at all costs. (Was thinking about the future)</title>
<h1>AI at all costs. (Was thinking about the future)</h1>
Stephen de Vries (<i>PHEN@wwg3.uovs.ac.za</i>)<br>
<i>Tue, 27 Aug 1996 14:09:21 GMT2</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#515">[ date ]</a><a href="index.html#515">[ thread ]</a><a href="subject.html#515">[ subject ]</a><a href="author.html#515">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0516.html">Sean Hastings: "Re: Controlling AI (was: Thinking about the future...)"</a>
<li> <b>Previous message:</b> <a href="0514.html">Eugene Leitl: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0528.html">E. Shaun Russell: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0528.html">E. Shaun Russell: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0532.html">Peter Voss: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0540.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
As I see it, imortalists can be divided into two groups: those who <br>
want to live on through there current minds and/or bodies, and those <br>
who don`t care how the "I" fits into the picture as long as the <br>
descendants are "better" than the current version of "I".<br>
<p>
I lurch into the latter categorie, my loyalty lies with neg-entropy <br>
and complexity.  Self sacrifice in the face of a humanity threatening <br>
AI is not part of this belief system, (self-sacrifice is never an <br>
option), but neither is standing in the way of developing a <br>
superior intelligent technology ("Artificial" and "Sinthetic" are <br>
emotively biased terms).  People generally like the idea of growing <br>
bigger brains, as long as these are biological based and not anything <br>
as drastic as growing intelligences in a neural net (in-silico).<br>
<p>
But I digress, the argument between the two groups is routed in the <br>
identification of "I".  <br>
<p>
&lt;Beware, amature metaphysics follows&gt;<br>
"I" am not as small as my body + brain + mind, the only thing that is <br>
in essence me, is the "life force" which permeates all that is alive. <br>
NOTE: "Life force" is my metaphor, please feel free to customize it <br>
to your personnal imagery. BTW some call it 2.67, which is a <br>
critical ratio betwean order and chaos in A-life experiments.<br>
<p>
The life force is all that I can recognize to be at the center of <br>
"me", so my loyalty lies with it, not my current body, mind or <br>
thoughts.<br>
&lt;End of amature metaphysics section&gt;<br>
<p>
---------------------------------------------------------------------<br>
Stephen de Vries                            <br>
www.geocities.com/athens/7415<br>
<p>
   "Some will fall in love with life and drink it from a fountain<br>
    that is falling like an avalanche coming down a mountain"<br>
    - The Butthole Surfers<br>
    <br>
    <br>
                           <br>
  <br>
               <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0516.html">Sean Hastings: "Re: Controlling AI (was: Thinking about the future...)"</a>
<li> <b>Previous message:</b> <a href="0514.html">Eugene Leitl: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0528.html">E. Shaun Russell: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0528.html">E. Shaun Russell: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0532.html">Peter Voss: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0540.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Maybe reply:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
