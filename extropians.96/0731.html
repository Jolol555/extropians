<!-- received="Tue Sep  3 16:21:47 1996 MST" -->
<!-- sent="Tue, 3 Sep 96 15:11:43 PDT" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@dosh.hum.caltech.edu" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="9609032211.AA01936@dosh.hum.caltech.edu" -->
<!-- inreplyto="9608038418.AA841802732@smtplink.lse.ac.uk" -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
Robin Hanson (<i>hanson@dosh.hum.caltech.edu</i>)<br>
<i>Tue, 3 Sep 96 15:11:43 PDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#731">[ date ]</a><a href="index.html#731">[ thread ]</a><a href="subject.html#731">[ subject ]</a><a href="author.html#731">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0732.html">Ira Brodsky: "Re: A Race of humanoid drones for labor."</a>
<li> <b>Previous message:</b> <a href="0730.html">Eric Watt Forste: "Extropianism as a World Meme"</a>
<li> <b>In reply to:</b> <a href="0721.html">N.Bostrom@lse.ac.uk: "Re: Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0735.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
N.Bostrom@lse.ac.uk writes:<br>
<i>&gt;About assuring that an &gt;AI won't harm humans, Robin Hanson said that</i><br>
<i>&gt;the police would hunt it down if it misbehaved. ...</i><br>
<i>&gt;speculate about a machine that would be a million times faster than</i><br>
<i>&gt;any human brain, and with correspondingly great memory capacity. </i><br>
<i>&gt;Could such a machine, given some time, not </i><br>
<i>&gt;manipulate a human society by subtle suggestions that seem </i><br>
<i>&gt;very reasonable but unnoticeable affects a general change in </i><br>
<i>&gt;attitude and policy?  ...         </i><br>
<i>&gt;My contention is that with only one full-blown &gt;AI in the world, if it</i><br>
<i>&gt;were malicious, the odds would be on the side that it could annihilate</i><br>
<i>&gt;humanity within decades.</i><br>
 <br>
Sure, given one mean super-AI, and rest of the world far behind, we<br>
would be at its mercy.  Simliar fears come from one person in control<br>
of any vastly superior technology, be it nanotech, nukes, homemade<br>
black holes, whatever.  But realistically, any one AI probably won't<br>
be too far ahead of any other AI, so they can police each other.<br>
<p>
Robin Hanson  hanson@hss.caltech.edu  <a href="http://hss.caltech.edu/~hanson/">http://hss.caltech.edu/~hanson/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0732.html">Ira Brodsky: "Re: A Race of humanoid drones for labor."</a>
<li> <b>Previous message:</b> <a href="0730.html">Eric Watt Forste: "Extropianism as a World Meme"</a>
<li> <b>In reply to:</b> <a href="0721.html">N.Bostrom@lse.ac.uk: "Re: Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0735.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
