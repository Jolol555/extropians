<!-- received="Sat Dec  7 18:04:40 1996 MST" -->
<!-- sent="Sat, 07 Dec 1996 18:36:53 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity-worship" -->
<!-- id="199612071908.MAA08663@primenet.com" -->
<!-- inreplyto="Singularity-worship" -->
<title>extropians: Re: Singularity-worship</title>
<h1>Re: Singularity-worship</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sat, 07 Dec 1996 18:36:53 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3714">[ date ]</a><a href="index.html#3714">[ thread ]</a><a href="subject.html#3714">[ subject ]</a><a href="author.html#3714">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3715.html">Eliezer Yudkowsky: "Re: Privacy (was RE: FYI: MEDIA &amp; Greenpeace"</a>
<li> <b>Previous message:</b> <a href="3713.html">Eliezer Yudkowsky: "Re: Shooting room paradox (addendum)"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3716.html">Paul Wakfer: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; The trouble I have is that you used the term "self-justifying", I've never </i><br>
<i>&gt; seen a self-justifying sentence, at least I don't think I have, but I really </i><br>
<i>&gt; don't know what that means.</i><br>
<p>
"If this sentence is true, Santa Claus exists."<br>
If the sentence is true, then the condition is true AND the conditional<br>
is true and so Santa Claus exists.<br>
The conditional IS true.<br>
Santa Claus does exist.<br>
Q.E.D.<br>
<p>
<i>&gt; By far the deepest problem in Philosophy, why is there something rather than </i><br>
<i>&gt; nothing?</i><br>
I don't know.  That there is in point of fact something illustrates that<br>
there are self-justifying causes.  By analogy, there may be<br>
self-justifying goals.  And, the problem is neither deepest - nor the<br>
most complicated.<br>
<p>
<i>&gt; - From your statement above we can safely conclude that another example of a  </i><br>
<i>&gt; non-self-justifying entity would be any idea any human being has ever been  </i><br>
<i>&gt; able to formulate in his head. If EVERYTHING is non self justifying then the  </i><br>
<i>&gt; concept has no contrast and so no value.</i><br>
Your first statement is true, but your second is not.  See above.<br>
<p>
<i>&gt; You mentioned that you took Prozac. The only reason to take Prozac is if </i><br>
<i>&gt; despite its negative features it made your brain operate in a way you liked </i><br>
<i>&gt; better than when you did not take Prozac. Evolution never came up with a  </i><br>
<i>&gt; gland that secrets Prozac. Why do you take Prozac?</i><br>
It was recommended by someone who, in retrospect, did not know what he<br>
was doing.  There was some hope, however, since people on Prozac DO obey<br>
Algernon's Law.  A surplus of mental energy and self-esteem is NOT an<br>
evolutionary advantage, however easier it makes daily life; it<br>
short-circuits some of evolution's most powerful goads and<br>
behavior-modification tools.<br>
<p>
<i>&gt; What's the difference between computational and cognitive causality?</i><br>
<i>&gt; Nothing, unless you believe in the soul and other such mumbo jumbo.</i><br>
<p>
Computational causality is what makes a Turing machine move forwards in<br>
time.  Cognitive causality is what makes a person say: "A causes B" and<br>
is a problem in AI/cognitive science rather than philosophy.<br>
<p>
<i>&gt; What's the difference between computational and thermodynamic?</i><br>
Thermodynamic causality is a statistical application of Occam's Razor.<br>
See <a href="http://tezcat.com/~eliezer/workarounds.html">http://tezcat.com/~eliezer/workarounds.html</a><br>
<p>
<i>&gt; What's the difference between cognitive and platonic?</i><br>
<i>&gt; Nothing, except cognitive wants to put mind in a special category for some </i><br>
<i>&gt; ill-defined reason.</i><br>
Platonic is the reason why 2 + 2 = 4; it is a form of causality which<br>
does not involve time.  Cognitive causality is a set of algorithms.<br>
<p>
<i>&gt; What's the difference between computational and platonic?</i><br>
Would you agree to the statement:  "All computations are equally<br>
existent regardless of any physical implementation?"<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3715.html">Eliezer Yudkowsky: "Re: Privacy (was RE: FYI: MEDIA &amp; Greenpeace"</a>
<li> <b>Previous message:</b> <a href="3713.html">Eliezer Yudkowsky: "Re: Shooting room paradox (addendum)"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3716.html">Paul Wakfer: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
