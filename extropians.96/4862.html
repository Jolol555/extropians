<!-- received="Fri Dec 27 15:55:35 1996 MST" -->
<!-- sent="Fri, 27 Dec 1996 17:21:11 -0500" -->
<!-- name="Michael Lorrey" -->
<!-- email="retroman@tpk.net" -->
<!-- subject="Re: Profiting on tragedy? (was Humour)" -->
<!-- id="199612272222.OAA15770@pure.PureAtria.COM" -->
<!-- inreplyto="Profiting on tragedy? (was Humour)" -->
<title>extropians: Re: Profiting on tragedy? (was Humour)</title>
<h1>Re: Profiting on tragedy? (was Humour)</h1>
Michael Lorrey (<i>retroman@tpk.net</i>)<br>
<i>Fri, 27 Dec 1996 17:21:11 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4862">[ date ]</a><a href="index.html#4862">[ thread ]</a><a href="subject.html#4862">[ subject ]</a><a href="author.html#4862">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4863.html">John K Clark: "The Holocaust"</a>
<li> <b>Previous message:</b> <a href="4861.html">Ray Peck: "organizers"</a>
<li> <b>Maybe in reply to:</b> <a href="4815.html">John P. Satta: "Profiting on tragedy? (was Humour)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4868.html">Kathryn Aegis: "Re: Profiting on tragedy? (was Humour)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Lee Daniel Crocker wrote:<br>
<i>&gt; </i><br>
<i>&gt; &gt; &gt; I'm not sure I understand the connection between Extropianism and the Final</i><br>
<i>&gt; &gt; &gt; Solution. They seem diametrically opposed to me. I grant you that some</i><br>
<i>&gt; &gt; &gt; extropian concepts could be misconstrued or misrepresented.</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt; Superintelligent robots = Aryans, humans = Jews.</i><br>
<i>&gt; &gt; The only thing preventing this is sufficiently intelligent robots.</i><br>
<i>&gt; </i><br>
<i>&gt; Nonsense.  What will prevent it is sufficiently /moral/ robots.</i><br>
<i>&gt; Intelligence is a not a sufficient condition for morality, and</i><br>
<i>&gt; perhaps not even a necessary one.</i><br>
<i>&gt; </i><br>
<i>&gt; If one buys Rand's contention that normative philosophy (ethics,</i><br>
<i>&gt; politics) can be rationally derived from objective reality, then we</i><br>
<i>&gt; can assume that very intelligent robots will reason their way into</i><br>
<i>&gt; benevolence toward humans.  I, for one, am not convinced of Rand's</i><br>
<i>&gt; claim in this regard, so I would wish to have explicit moral codes</i><br>
<i>&gt; built into any intelligent technology that could not be overridden</i><br>
<i>&gt; except by their human creators.  If such intelligences could reason</i><br>
<i>&gt; their way toward better moral codes, they would still have to</i><br>
<i>&gt; convince us humans, with human reason, to build them.</i><br>
<p>
however, suppose the lone genius who develops uploading technology is<br>
some riduculed, misunderstood individual who has been persecuted since<br>
infancy. He/she uploads, becomes the God of the planet, and as stupider<br>
and stupider individuals continue to piss him or her off, he/shee<br>
decides to end the pestering mosquitoes in his/her ear with a few<br>
hundred megatons placed in the most efficient pattern to wipe out the<br>
annoyance. its the Lawnmower Man Syndrome, or Charlie's Law, to use<br>
Eliezers mythology.<br>
<p>
you must admit, the most likely to upload first would also be those<br>
individuals farthest up the bell curve already, and thus run the risk of<br>
also harboring persecution complexes etc.... Another of the Luddites<br>
fears: that all those geeks they picked on as kids will come back to<br>
haunt them, rule them, or just screw up their credit records..... These<br>
individuals you could not "build" morality into. You could provide<br>
extensive psych help prior to uploading, but such problems are just as<br>
likely to be amplified the farther up the bell curve the individual<br>
transcends to. ALso, consider "accidental" transcendance: an unwatched<br>
AI. Look at the "True Names" story by Vinge in this area. The DON.MAC<br>
program was a low level AI kernel that was forgotten about. As it grew,<br>
it continued to do the job to which it was programmed: protect the<br>
network, even to the point of protecting it from its makers.<br>
<p>
That such warning fiction exists illustrates that such fears are<br>
present. As stated prviously, even with my 160 IQ, a goodly portion of<br>
humanity ticks me off on a daily basis. I could not imagine the amount<br>
of patience a 1600 IQ AI, or IA upload, would have to practice on a<br>
daily basis to keep from starting Armageddon just to end the annoyance. <br>
<pre>
-- 
TANSTAAFL!!!
<p>
			Michael Lorrey
---------------------------------------------------------
President			retroman@tpk.net
Northstar Technologies		Agent Lorrey@ThePentagon.com
Inventor of the Lorrey Drive	Silo_1013@ThePentagon.com
<a href="http://www.tpk.net/~retroman/">http://www.tpk.net/~retroman/</a>
---------------------------------------------------------
Inventor, Webmaster, Ski Guide, Entrepreneur, Artist, 
Outdoorsman, Libertarian, Certified Genius.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4863.html">John K Clark: "The Holocaust"</a>
<li> <b>Previous message:</b> <a href="4861.html">Ray Peck: "organizers"</a>
<li> <b>Maybe in reply to:</b> <a href="4815.html">John P. Satta: "Profiting on tragedy? (was Humour)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4868.html">Kathryn Aegis: "Re: Profiting on tragedy? (was Humour)"</a>
<!-- reply="end" -->
</ul>
