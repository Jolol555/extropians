<!-- received="Thu Sep  5 21:39:25 1996 MST" -->
<!-- sent="Thu, 05 Sep 1996 22:50:55 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="dgc@shirenet.com" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="2.2.16.19960905134555.300f35d0@earthlink.net" -->
<!-- inreplyto="Thinking about the future..." -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
Dan Clemmensen (<i>dgc@shirenet.com</i>)<br>
<i>Thu, 05 Sep 1996 22:50:55 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#818">[ date ]</a><a href="index.html#818">[ thread ]</a><a href="subject.html#818">[ subject ]</a><a href="author.html#818">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0819.html">John K Clark: "The Joys Of Flesh"</a>
<li> <b>Previous message:</b> <a href="0817.html">Geoff Busker: "Re: Flesh: what is it good for?"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
QueeneMUSE@aol.com wrote:<br>
<i>&gt; </i><br>
<i>&gt; In a message dated 96-09-05 15:27:46 EDT, Dan writes:</i><br>
<i>&gt; </i><br>
<i>&gt; &lt;&lt; . (My actual model is that some</i><br>
<i>&gt; &gt;computer</i><br>
<i>&gt; &gt;nerd at MIT will do this while drinking Jolt cola at 2 AM when he should</i><br>
<i>&gt; &gt;be studying</i><br>
<i>&gt; &gt;for an english exam.) As a joke, the nerd will type in the command "make</i><br>
<i>&gt; &gt;yourself smarter."</i><br>
<i>&gt; &gt;The then-current rule set will be smart enough to act on the command but</i><br>
<i>&gt; &gt;too stupid</i><br>
<i>&gt; &gt;to get the joke.</i><br>
<i>&gt; &gt; &gt;&gt;</i><br>
<i>&gt; </i><br>
<i>&gt; In my limited understanding of how NN works, this command is neither a joke ,</i><br>
<i>&gt; nor a human try to make AI "unbenign"-  but the current method of programming</i><br>
<i>&gt; - error correction for, example:  improved pattern recognition. In essence it</i><br>
<i>&gt; is a neccessary part of building up sufficient intelligence to make an</i><br>
<i>&gt; "artificial" being or intelligence. This 'learn all you can command ' I</i><br>
<i>&gt; understood as a given, but was interested in exploring how  *after* it gained</i><br>
<i>&gt; "consciousness - or replicated it's own AI's-   which  motivation AI would</i><br>
<i>&gt; use, that which *we* programmed, or it's *own* directives - as it "wakes up"</i><br>
<i>&gt; and perhaps questions its own "meaning of life" or existence and purpose (</i><br>
<i>&gt; assuming it could ever get that kind of consciousness).</i><br>
<i>&gt; Nadia</i><br>
<p>
My understanding of the nominal "expert system" is not good enough to<br>
describe as "limited". There is a slight difference, however, between<br>
"learn all you can" and "make yourself smarter." "Learn" might be<br>
interpreted as "add to your database". "get smarter", might cause<br>
the system to begin distributing itself to other processors, or<br>
optiimize its own code, or interface to another inference engine. I<br>
was thinking in these terms. After such self-augmentation, the resulting <br>
SI might indeed develop the philosophical questions you raise. I might<br>
be smart enough to answer them, or it might decide it needs to be<br>
smarter in order to answer them, and embark on additional<br>
self-augmentation.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0819.html">John K Clark: "The Joys Of Flesh"</a>
<li> <b>Previous message:</b> <a href="0817.html">Geoff Busker: "Re: Flesh: what is it good for?"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
