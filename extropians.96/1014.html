<!-- received="Wed Sep 18 07:45:43 1996 MST" -->
<!-- sent="Wed, 18 Sep 1996 15:34:52 +0200 (MET DST)" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="FYI: autoreplication (Re: Nano vs Macro Self-Replication (fwd)) (long)" -->
<!-- id="Pine.SOL.3.91.960918153400.291J-100000@sun2" -->
<!-- inreplyto="autoreplication (Re: Nano vs Macro Self-Replication (fwd)) (long)" -->
<title>extropians: FYI: autoreplication (Re: Nano vs Macro Self-Replication (fwd)) (long)</title>
<h1>FYI: autoreplication (Re: Nano vs Macro Self-Replication (fwd)) (long)</h1>
Eugene Leitl (<i>Eugene.Leitl@lrz.uni-muenchen.de</i>)<br>
<i>Wed, 18 Sep 1996 15:34:52 +0200 (MET DST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1014">[ date ]</a><a href="index.html#1014">[ thread ]</a><a href="subject.html#1014">[ subject ]</a><a href="author.html#1014">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1015.html">Damien Broderick: "Re: JP Barlow, democracy and ACF"</a>
<li> <b>Previous message:</b> <a href="1013.html">Peter James: "Re: TWA 800: FBI slams missile theory"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
---------- Forwarded message ----------<br>
Date: Tue, 17 Sep 1996 12:42:11 -0400<br>
From: Robert Freitas &lt;rfreitas@calweb.com&gt;<br>
To: nanotech@cs.rutgers.edu<br>
Newgroups: sci.nanotech<br>
Subject: Re: Nano vs Macro Self-Replication<br>
<p>
<p>
I.  Self-Modification and Self-Replication<br>
<p>
<i>&gt; From: Anthony G. Francis on Thu, Sep 5, 1996 5:43 AM</i><br>
<i>&gt; Personally, I don't think we have a chance of building self-modifying</i><br>
<i>&gt; and self-replicating nanomachines until we can do it with</i><br>
<i>&gt; macromachines (or at least macrosystems), since we are far less</i><br>
<i>&gt; experienced with nanotech.</i><br>
<p>
(A)  Mr. Francis is probably correct, regarding "self-<br>
replication."<br>
<p>
After all, macroscale (~1-10 cm) self-replicating machines have <br>
already been designed, built, and successfully operated (e.g. <br>
Jacobson, 1958;  Morowitz, 1959;  Penrose, 1959;  references in <br>
NASA CP-2255, 1982).  (True, these were all very SIMPLE <br>
replicators.  But they DID replicate.)  Additionally, <br>
(nanoscale) replicating molecular systems have been designed, <br>
constructed, and successfully operated by chemists.  Only the <br>
microscale realm remains "unreplicated" by human technology.  <br>
Since self-replication can now be done at the macro scale, we <br>
are now conceptually prepared to implement this function at the <br>
micro scale via nanotech, once our nanoscale tools become more <br>
refined.  So in that sense, I agree with Mr. Francis.<br>
<p>
(B) Regarding "self-modification," Mr. Francis is almost <br>
certainly incorrect.  Of course, any machine can be programmed <br>
or designed to randomly modify itself.  (e.g., "once every <br>
minute, unscrew a bolt and throw it away.")  However, since <br>
self-modifications that degrade performance or shorten life are <br>
useless, I presume Mr. Francis is referring to an evolutionary <br>
process in which a device responds positively to challenges <br>
arising from its operating environment, modifying its hardware <br>
or software to maintain or to enhance its fitness or <br>
survivability in its changing environment.<br>
<p>
To the extent such evolution is an undirected or blind process, <br>
many trials involving minor changes are required to find, by <br>
pseudo-random search, a single design change that will prove <br>
helpful.  Basic physical scaling laws mandate that, all else <br>
being equal, physical replication speed is a linear function of <br>
size.  Thus the smaller the replicator, the greater the number <br>
of trial offspring it can sire, and test for fitness, per unit <br>
time interval.  (This is because manipulator velocity is scale <br>
invariant, while travel distance decreases linearly with size.)  <br>
Macroscale replicators (using blind trials) are far less likely <br>
to be able to generate enough trial offspring to stumble upon <br>
beneficial modifications, in any reasonable amount of time.  <br>
Microscale replicators, on the other hand, should be able to <br>
generate offspring a million times faster (or more), thus are <br>
far more likely to randomly turn up productive modifications, <br>
hence to "evolve."<br>
<p>
To the extent that such evolution is an intelligently directed <br>
process, microscale replicators still enjoy the same tremendous <br>
scaling advantage in computational speed.   Microscale <br>
replicators built using nanotech will use nanocomputers (e.g. <br>
diamondoid rods with nanometer-scale features) to design, build, <br>
and analyze their directed-modification offspring machines.  Per <br>
unit mass or per unit volume, these nanocomputers will operate <br>
at least a million times faster than computers built using <br>
macroscale tools (e.g. silicon chips with ~micron-scale <br>
features) that will direct the macroscale replicators.<br>
<p>
Of course, macroscale replicators can be evolved slowly using <br>
macroscale computers.  (Indeed, this is called "the history of <br>
human technology.")  Or, nanocomputers could be used to direct <br>
the evolution of macroscale replicators, which will go a bit <br>
faster.  But clearly the theoretically fastest evolutionary <br>
speed will come from nanoscale computers directing nanoscale <br>
replicators.<br>
<p>
Since self-modifying replicators should actually be easier to <br>
implement at the nanoscale than at the macroscale, macroscale <br>
experience with self-evolving mechanical systems is probably <br>
unnecessary.<br>
<p>
<p>
II.  Infinite Regress and the Fallacy of the Substrate<br>
<p>
<i>&gt; There is an argument that self-replicating machines can _only_ be </i><br>
<i>&gt; built with nanotechnology, since components have to worry about </i><br>
<i>&gt; quality control on their components, which have to worry about </i><br>
<i>&gt; quality control on their subcomponents, and so on, leading to an </i><br>
<i>&gt; otherwise infinite regress that only comes to an end when you </i><br>
<i>&gt; get to atoms, which for identical isotopes can be treated as </i><br>
<i>&gt; perfectly interchangeable.</i><br>
<p>
This argument, as stated, has at least two fundamental flaws.<br>
<p>
First, since self-replicating machines have already been built <br>
using macrotechnology (see above references), it is therefore <br>
already a fact that nanotechnology is NOT required to build <br>
replicators.  QED.  End of discussion.<br>
<p>
Second, the author of this argument assumes that "components <br>
have to worry about quality control on their components."  He <br>
has fallen prey to what I call the "Fallacy of the Substrate."  <br>
I shall explain.<br>
<p>
Many commentators, whether implicitly or explicitly, assume that <br>
replication -- in order to qualify as "genuine self-replication" <br>
-- must take place in a sea of highly-disordered (if not <br>
maximally disordered) inputs.  This assumption is unwarranted, <br>
theoretically unjustifiable, and incorrect.<br>
<p>
The most general theoretical conception of replication views <br>
replication as akin to a manufacturing process.  In this <br>
process, a stream of inputs enters the manufacturing device.  A <br>
different stream of outputs exits the manufacturing device.  <br>
When the stream of outputs is specified to be identical to the <br>
physical structure of the manufacturing device, the <br>
manufacturing device is said to be "self-replicating."<br>
<p>
Note that in this definition, there are no restrictions of any <br>
kind placed upon the nature of the inputs.  On the one hand, <br>
these inputs could consist of a 7,000 oK plasma containing equal <br>
numbers of atoms of all the 92 natural elements -- by some <br>
measures, a "perfectly random" or maximally chaotic input <br>
stream.  On the other hand, the input stream could consist of <br>
cubic-centimeter blocks of pure elements.  Or it could consist <br>
of prerolled bars, sheets, and wires.  Or it could consist of <br>
preformed gears, ratchets, levers and clips.  Or it could <br>
consist of more highly refined components, such as <br>
premanufactured motors, switches, gearboxes, and computer chips.  <br>
A manufacturing device that accepts ANY of these input streams, <br>
and outputs precise physical copies of itself, is clearly self-<br>
replicating.<br>
<p>
During our 1980 NASA study on replicating systems, one amusing <br>
illustration of the Fallacy of the Substrate that we invented <br>
was the self-reproducing PUMA robot.  This robot is <br>
conceptualized as a complete mechanical device, plus a fuse that <br>
must be inserted into the robot to make it functional.  In this <br>
case, the input substrate consists of two distinct parts:  (1) a <br>
stream of 99.99%-complete robots, arriving on one conveyor belt, <br>
and (2) a stream of fuses arriving on a second conveyor belt.  <br>
The robot combines these two streams, and the result of this <br>
manufacturing process is a physical duplicate of itself.  Hence, <br>
the robot has in fact "reproduced."  You may argue that the <br>
replicative act somehow seems trivial and uninspiring, but the <br>
act is a reproductive act, nonetheless.<br>
<p>
Therein lies the core of the Fallacy of the Substrate:  <br>
"Replication" can occur on any of an infinite number of input <br>
substrates.  Depending on its design, a particular device may be <br>
restricted to replication from only a very limited range of <br>
input substrates.  Or, it may have sufficient generality to be <br>
able to replicate itself from a very broad range of substrates.  <br>
In some sense this generality is a measure of the device's <br>
survivability in diverse environments.  But it is clearly <br>
fallacious to suggest that "replication" occurs only when <br>
duplication of the original manufacturing device takes place <br>
from a highly disordered substrate.<br>
<p>
<i>&gt;From a replicating systems design perspective, two primary </i><br>
questions must always be addressed:  (1) What is the anticipated <br>
input substrate?  (2) Does the device contain sufficient <br>
knowledge, energy, and physical manipulatory skills to convert <br>
the anticipated substrate into copies of itself?  Macroscale <br>
self-replicating devices that operate on a simple, well-ordered <br>
input substrate of ~2-5 distinct parts (and up to ~10 parts per <br>
device, I believe) were demonstrated in the laboratory nearly 40 <br>
years ago.  Japanese robot-making factories use the same robots <br>
as they produce, inside the factory, hence these factories may <br>
be regarded as at least partially self-replicating.  I have no <br>
doubt that a specialized replicating machine using an input <br>
substrate of up to ~100 distinct (modularized) components (and <br>
~1000 total parts) could easily be built using current <br>
technology.  Future advances may gradually extend the generality <br>
of this input substrate to 10^4, 10^6, perhaps even to 10^8 <br>
distinct parts.<br>
<p>
Of course, the number of distinct parts is not the sole measure <br>
of replicative complexity.  After all, a nanodevice which, when <br>
deposited on another planet, can replicate itself using only the <br>
92 natural elements is using only 92 different "parts" (atoms).<br>
<p>
If you remain frustrated by the above definition of replication, <br>
try to imagine a multidimensional volumetric "substrate space", <br>
with the number of different kinds of parts along one axis, the <br>
average descriptive complexity per part along another axis, the <br>
relative concentration of useful parts as a percentage of all <br>
parts presented on still another axis, the number of parts per <br>
subsystem and the number of subsystems per device on two <br>
additional axes, and the relative randomicity of parts <br>
orientation in space (jumbleness) along yet another axis.  A <br>
given manufacturing device capable of outputting copies of <br>
itself, a device which we shall call a "replicator," has some <br>
degree of replicative functionality that maps some irregular <br>
volume in this substrate space.  The fuse-sticking PUMA robot <br>
occupies a mere point in this space;  a human being or an amoeba <br>
occupies a somewhat larger volume.  A nanoreplicator able to <br>
make copies of itself out of raw dirt would occupy a still <br>
larger volume of substrate space.  We would say that a <br>
replicator which occupies a smaller volume of substrate space <br>
has lesser replicative complexity than one which occupies a <br>
greater volume.  But it is STILL a "replicator."<br>
<p>
So if someone wishes to hypothesize that replicators "cannot be <br>
built" on some scale or another, they must be careful (1) to <br>
specify the input substrate they are assuming, and (2) to prove <br>
that the device in question is theoretically incapable of self-<br>
replication from that particular substrate.  Using pre-made <br>
parts is not "cheating."  Remember:  Virtually all known <br>
replicators -- including human beings -- rely heavily on input <br>
streams consisting of "premanufactured parts" most of which <br>
cannot be synthesized "in house."<br>
<p>
Because of their superior speed of operation in both thought and <br>
action, there is little question that microscale replicators <br>
constructed from nanoscale components are theoretically capable <br>
of far greater replicative complexity than macroscale <br>
replicators constructed of macroscale parts.  But replicators <br>
can be built at EITHER scale.<br>
<p>
<p>
III.  Linear vs. Exponential Processes<br>
<p>
<i>&gt; Actually, it gets worse than that.  The real world is full of dust, and</i><br>
<i>&gt;friction wears down surfaces.  The only way in which these manifestations of</i><br>
<i>&gt; Murphy's Law can be handled is at their smallest pieces -- otherwise, smaller</i><br>
<i>&gt; bits of dust get wedged in the gears of the repair tools, and the process grinds</i><br>
<i>&gt; to a halt.  </i><br>
<p>
There are two arguments advanced here:  (A) that dust particles <br>
can insert themselves between moving surfaces, immobilizing <br>
these moving surfaces and causing the machine to halt; and (B) <br>
that frictional abrasion from environmental dust particles <br>
degrades parts until these parts eventually fail.<br>
<p>
(A)  A correct system design will take full account of all <br>
particles likely to be encountered in the normal operating <br>
environment.  Proper component design should ensure that dust <br>
particle diameter &lt;&lt; typical part diameter, and that moving <br>
parts have sufficient compliance such that dust particles of the <br>
maximum anticipated size can pass through the mechanism without <br>
incident.  It may be necessary to enclose critical component <br>
systems within a controlled environment to preclude entry of <br>
particles large enough to jam the mechanism.  But this is a <br>
design specification -- an engineering choice -- and not a <br>
fundamental limitation of replicative systems engineering.<br>
<p>
(B)  A process such as frictional abrasion is a LINEAR <br>
degenerative process.  Assuming proper design, in which dust <br>
particle diameter &lt;&lt; typical part diameter, component-surface <br>
error caused by abrasion slowly accumulates until some critical <br>
threshold is surpassed, after which the device malfunctions and <br>
ceases to replicate.<br>
<p>
However, the generative (replicative) process will be <br>
EXPONENTIAL (or at least polynomial, once you reach large <br>
populations where physical crowding becomes an important factor) <br>
if the replicators (1) produce fertile offspring and (2) have <br>
full access to all necessary inputs. <br>
<p>
Now, an exponential generative process can ALWAYS outcompete a <br>
linear degenerative process, given two assumptions:  (1) the <br>
degenerative time constant (e.g. mean time to abrasive failure <br>
of the replicator) ~&gt; the generative time constant (e.g. the <br>
replicator's gestation + maturation period), AND (2) the number <br>
of fertile offspring per generation (e.g., size of the litter) <br>
~&gt;1.  Assumption (1) should always be true, because a <br>
"replicator" that breaks down before it has given birth to even <br>
a single fertile offspring is a poor design hardly worthy of the <br>
name.  Assumption (2) should usually be true as well.  Most <br>
device designs I've seen involve one machine producing one or <br>
more offspring.  (Fertile offspring per generation can in theory <br>
be &lt;1 if members of many generations cooperate in the <br>
construction of a single next-generation offspring -- the "it <br>
takes a village" scenario.)  Thus, even in the absence of simple <br>
strategies such as component redundancy or a component "repair <br>
by replacement" capability which would further enhance <br>
reliability, component degeneration may slow -- but should not <br>
halt -- the replicative cascade.<br>
<p>
<p>
IV.  Interchangeable Parts and Large Numbers<br>
<p>
<i>&gt; In addition, all manufacturing depends on interchangable </i><br>
<i>&gt; parts.... when you start making relatively small things such </i><br>
<i>&gt; as in microtech, then an extra layer of atoms can make a big </i><br>
<i>&gt; difference, and these differences keep the parts from being </i><br>
<i>&gt; interchangable.  The opposite tack, of making things really </i><br>
<i>&gt; big, sounds nice, but you're going to need about a billion </i><br>
<i>&gt; subcomponents, if I correctly remember the best estimates of </i><br>
<i>&gt; Von Neumann's work.</i><br>
<p>
Once you have clearly specified the input substrate you will be <br>
working with, then parts size and the component compliance <br>
becomes a design decision that is completely under the control <br>
of the engineer.  If your input substrate contains parts that <br>
are likely to have a few extra layers of atoms, then your design <br>
must accommodate that level of positional imprecision during <br>
normal operations.<br>
<p>
Almost certainly, a replicating machine may someday be built <br>
that has a billion parts.  However, a replicating machine can <br>
ALSO be built with only three parts.  (I have pictures of one <br>
such device in operation, in my files.)  The assumption that <br>
vast numbers of parts are required to build a replicator -- even <br>
a nanoreplicator -- are simply unwarranted.  Indeed, I fully <br>
expect that the first 8-bit programmable nanoscale assembler <br>
(e.g. of Feynman Prize fame) that is capable of self-replication <br>
will employ an input substrate of no more than a few dozen <br>
different types of parts, and will be constructed of fewer than <br>
1000 of these parts -- possibly MUCH fewer.  These <br>
premanufactured parts may be supplied to the assembler as <br>
outputs of some other (chemical? biotech? STM?) nanoscale <br>
process.<br>
<p>
<p>
V.  The Efficient Replicator Scaling Conjecture<br>
<p>
<i>&gt; So it *might* actually be possible to build a macro-based </i><br>
<i>&gt; self-rep system.  But I suspect that it would be a lot more </i><br>
<i>&gt; complicated.</i><br>
<p>
I have formulated a conjecture ("the proof of which the margin <br>
is too narrow to contain") that the most efficient replicator <br>
will operate on a substrate consisting of parts that are <br>
approximately of the same scale as the parts with which it is <br>
itself constructed.  Hence a robot made of ~1 cm parts will <br>
operate most efficiently in an environment in which 1-cm parts <br>
(of appropriate types) are presented to it for assembly.  Such a <br>
robot would be less efficient if it was forced to build itself <br>
out of millimeter or micron-scale parts, since the robot would <br>
have to preassemble these smaller parts into the 1-cm parts it <br>
needed for the final assembly process.  Similarly, input parts <br>
much larger than 1 cm would have to be disassembled or milled <br>
down to the proper size before they could be used, also <br>
consuming additional time, knowledge, and physical resources -- <br>
thus reducing replicative efficiency.<br>
<p>
If this conjecture is correct, then it follows that to most <br>
efficiently replicate from an atomic or molecular substrate, you <br>
would want to use atomic or molecular-scale parts -- that is, <br>
nanotechnology.<br>
<p>
<p>
VI.  Lunar SRS IC Chips Are NOT Vitamin Parts!<br>
<p>
<i>&gt; the self replicating machine shop (which still requires </i><br>
<i>&gt; vitamin ICs) mentioned in the 1980 NASA Summer Study.</i><br>
<p>
No!  Unlike previous studies which assumed only 90-96% closure, <br>
our theoretical design goal for the self-replicating lunar <br>
factory was 100% parts and energy (but not necessarily <br>
information) closure.  This SPECIFICALLY included on-site chip <br>
manufacturing, as discussed in Section 4.4.3 of the NASA report <br>
and in Zachary (1981), cited in the report.  Of the original <br>
100-ton seed, we estimated the chipmaking facility would mass 7 <br>
tons and would draw about 20 kW of power (NASA CP-2255, Appendix <br>
5F, p.293).<br>
<p>
100% materials closure was achieved "by eliminating the need for <br>
many...exotic elements in the SRS design...[resulting in] the <br>
minimum requirements for qualitative materials closure....This <br>
list includes reagents necessary for the production of <br>
microelectronic circuitry."  (NASA CP-2255, pp. 282-283)<br>
<p>
<p>
<p>
Robert A. Freitas Jr.<br>
<p>
Member, Replicating Systems Concepts Team<br>
1980 NASA Summer Study<br>
<p>
Editor,<br>
Advanced Automation for Space Missions (NASA CP-2255, 1982)<br>
<p>
<p>
<p>
***************************************************************************<br>
Please email all technical problems to alexboko@umich.edu, not to the list.<br>
<a href="http://www.us.itd.umich.edu/~alexboko/mlist.html">http://www.us.itd.umich.edu/~alexboko/mlist.html</a> is our web site.<br>
<a href="ftp://us.itd.umich.edu/users/alexboko/th/">ftp://us.itd.umich.edu/users/alexboko/th/</a> is our ftp site.<br>
***************************************************************************<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1015.html">Damien Broderick: "Re: JP Barlow, democracy and ACF"</a>
<li> <b>Previous message:</b> <a href="1013.html">Peter James: "Re: TWA 800: FBI slams missile theory"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
