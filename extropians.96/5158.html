<!-- received="Tue Dec 31 14:45:08 1996 MST" -->
<!-- sent="Tue, 31 Dec 1996 15:00:24 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Goal-based AI" -->
<!-- id="199612312128.NAA24043@idiom.com" -->
<!-- inreplyto="Goal-based AI" -->
<title>extropians: Re: Goal-based AI</title>
<h1>Re: Goal-based AI</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Tue, 31 Dec 1996 15:00:24 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#5158">[ date ]</a><a href="index.html#5158">[ thread ]</a><a href="subject.html#5158">[ subject ]</a><a href="author.html#5158">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="5159.html">Eliezer Yudkowsky: "Re: Goal-based AI"</a>
<li> <b>Previous message:</b> <a href="5157.html">Eric Watt Forste: "Re: The "stupid" masses"</a>
<li> <b>Maybe in reply to:</b> <a href="5105.html">Lee Daniel Crocker: "Goal-based AI"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="5159.html">Eliezer Yudkowsky: "Re: Goal-based AI"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; Eli writes:</i><br>
<i>&gt; &gt;I say, program 'em right, give 'em ethics instead of emotion, and</i><br>
<i>&gt; &gt;let 'em loose.</i><br>
<i>&gt; </i><br>
<i>&gt; Um, excuse me. This presumes a distinction between ethics and emotion</i><br>
<i>&gt; that has yet to be adequately explained. </i><br>
<i>&gt; </i><br>
<i>&gt; I hope you're not going to reply to this with more of your usual </i><br>
<i>&gt; capitalized phrases like "the Meaning of Life" (as if there were only</i><br>
<i>&gt; one) or "the Purpose of the Universe" (again, as if there were only</i><br>
<i>&gt; one).</i><br>
<p>
Nope.  I figure that if, after God knows how many kilobytes of cognitive<br>
science and clear, physically based, source-code-available definitions<br>
of the precise and exact cognitive difference between a self-justifying<br>
goal system and an evolved set of priorities, including multiple posts<br>
and a page on the Web, repeating myself isn't going to help.<br>
<p>
Also, I have never used the phrase "Purpose of the Universe"; then I'd<br>
have to justify (a) the existence of God and (b) mapping our<br>
goal-oriented cognitive architectures onto him.<br>
<p>
As the great Dogbert once said (paraphrasing):<br>
"The year 2000 is coming.  God uses a decimal counting system and He<br>
likes round numbers."<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="5159.html">Eliezer Yudkowsky: "Re: Goal-based AI"</a>
<li> <b>Previous message:</b> <a href="5157.html">Eric Watt Forste: "Re: The "stupid" masses"</a>
<li> <b>Maybe in reply to:</b> <a href="5105.html">Lee Daniel Crocker: "Goal-based AI"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="5159.html">Eliezer Yudkowsky: "Re: Goal-based AI"</a>
<!-- reply="end" -->
</ul>
