<!-- received="Tue Aug  6 22:17:18 1996 MST" -->
<!-- sent="Tue, 6 Aug 1996 21:18:38 -0700" -->
<!-- name="Eric Watt Forste" -->
<!-- email="arkuat@factory.net" -->
<!-- subject="Re: Intrinsic vs. Extrinsic" -->
<!-- id="v02140b0aae2db7751417@[204.162.114.176]" -->
<!-- inreplyto="Intrinsic vs. Extrinsic" -->
<title>extropians: Re: Intrinsic vs. Extrinsic</title>
<h1>Re: Intrinsic vs. Extrinsic</h1>
Eric Watt Forste (<i>arkuat@factory.net</i>)<br>
<i>Tue, 6 Aug 1996 21:18:38 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#192">[ date ]</a><a href="index.html#192">[ thread ]</a><a href="subject.html#192">[ subject ]</a><a href="author.html#192">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0193.html">Alexander 'Sasha' Chislenko: "FWD: Libertarian Programmers' Guild"</a>
<li> <b>Previous message:</b> <a href="0191.html">Eric Watt Forste: "Re: Private Space  (was: Trans-extropian principles)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt;Intrinsic goal: get some honey. Why? Because I just happen to want</i><br>
<i>&gt;some honey.  Why?  Because ...  er ..., gee, I have this mental state</i><br>
<i>&gt;that says I desire honey.  Why?  Well, either the mental state is a</i><br>
<i>&gt;stupid mistake arising from general mental flakeyness (and the desire</i><br>
<i>&gt;for honey is therefore a stupid goal), or the mental state has some</i><br>
<i>&gt;valid cause outside of itself, such as evolution plus a need for</i><br>
<i>&gt;calories or nutritional completeness or some such.  Why?  Well, I need</i><br>
<i>&gt;calories or nutritional completeness so I can stay alive and healthy.</i><br>
<i>&gt;So now the goal has become either extrinsic or stupid, right?</i><br>
<p>
All goals are "stupid" in *this* sense, because the desire to remain alive<br>
and healthy arises in what you are dismissing as "general mental<br>
flakiness". Once you get to the point where you can rearrange yourself so<br>
as to enjoy anything (the perfect Stoic), well, you have to have some other<br>
reason for *choosing* to do something, right? That's what I'm proposing<br>
generalizable extrinsicity for. If you have complete control over what you<br>
choose to be pleased by and what you choose to be displeased by, perhaps<br>
all that's left as a rational goal is to keep your options open, or rather,<br>
to open them further, as wide as possible.<br>
<p>
But what you call "stupidity", I call "autonomy".<br>
<p>
Another way to look at the dichotomy (which I'm bringing up but have no<br>
interest in defending) is to say that intrinsic goals are goals the<br>
recognition of the attainment of which causes a stimulus of some sort to<br>
the "pleasure center" in the brain. *Purely* extrinsic goals do no such<br>
thing. If you rearrange yourself so as to particularly enjoy some<br>
"extrinsic" activity, then that activity becomes a mixed goal, both done<br>
intrinsically for its own sake and also extrinsically as a means to further<br>
ends.<br>
<p>
One interesting fact from psychology is that human beings seem to be<br>
capable of arranging their minds (over the long term, or having their minds<br>
arranged for them by outside conditioning) so that damn near anything can<br>
cause a pleasure response. That is, people can *learn* to enjoy nearly<br>
anything. The intrinsic/extrinsic dichotomy should certainly not be seen as<br>
any kind of magical, hard-and-fast distinction. It's fuzzy, and most human<br>
values partake of both sides.<br>
<p>
<p>
<i>&gt;If we call it extrinsic, we should take the trouble to remember the</i><br>
<i>&gt;original thing that made us want to call it intrinsic -- the emotion</i><br>
<i>&gt;with which it was held.  It's the emotion that makes satisfying the</i><br>
<i>&gt;goal non-drudgery; I don't think it is important that the emotion is</i><br>
<i>&gt;the ultimate justification of the action.  Emotions are quite</i><br>
<i>&gt;flexible, so it is very risky to use them as an ultimate</i><br>
<i>&gt;justification.</i><br>
<p>
There isn't any such thing as "ultimate justification"; in fact, it's a<br>
contradiction in terms. If I didn't believe that, I might also retort<br>
"human intellect is quite flexible, so it is very risky to use it as an<br>
ultimate justification".<br>
<p>
<p>
<i>&gt;Quite often people think a goal is somehow "true" if you don't know</i><br>
<i>&gt;where it came from.  This is quite analogous with Christians who think</i><br>
<i>&gt;that Faith is good simply because there is no rational reason to do</i><br>
<i>&gt;it.  Yuck.  I prefer extrinsic goals, since IMO the allegedly</i><br>
<i>&gt;intrinsic ones are either stupid goals or are really extrinsic goals</i><br>
<i>&gt;that are not well-understood.  Calling them intrinsic stops the</i><br>
<i>&gt;understanding.  Among non-philosophers, intrinsic goals are called</i><br>
<i>&gt;"fun".  These are the frivolous goals Lyle was talking about.</i><br>
<p>
You say you prefer extrinsic goals, instrumental goals, to intrinsic ones.<br>
But extrinsicity or instrumentality implies some further end in mind, and<br>
you say nothing about the further end that you have in mind when you say<br>
you favor extrinsic goals. I guess what you're saying is that you've<br>
decided to adopt "generalizable extrinsicity" as your primary intrinsic<br>
goal, and I didn't even have to talk you into it. Gosh, that was easy. I<br>
guess I'm on the right track.<br>
<p>
<p>
<i>&gt;Having fun is okay, but don't use it to justify your actions.</i><br>
<p>
What do you propose as an alternative? All I can make out is that you're<br>
agreeing with me about "generalizable extrinsicity". If you're disagreeing<br>
with me, I'm not sure where.<br>
<p>
My point in defending "frivolous goals" was this. What Newton was doing<br>
during the plague year at Woolsthorpe Manor was extremely frivolous. It was<br>
a purely upper-class intellectual pursuit with no practical application<br>
that anyone at the time could have proposed. Even if it did have a<br>
practical application that someone might have foreseen at the time, I can<br>
assure you that this had absolutely nothing to do with Newton's motivation.<br>
Newton himself thought his work during the plague year was frivolous; he<br>
didn't bother writing it up for years, and then, after finishing the first<br>
book of Principia Mathematica, he let it sit in a drawer for several more<br>
years until Halley found it and talked him into finishing and publishing<br>
it.<br>
<p>
What Archimedes and Euclid were doing when they developed Greek mathematics<br>
to its height was likewise a purely frivolous goal. They had no reason to<br>
believe that what they were doing would ever be useful to anyone but<br>
philosophers, and they did it anyway, because they were philosophers and<br>
that is what they enjoyed doing. Apollonius's study of conic sections lay<br>
unused, a purely frivolous accomplishment, for almost two millenia until<br>
Kepler, in his own frivolous astronomical pursuits, found a new<br>
philosophical application for them.<br>
<p>
My point then is that we had better be tolerant of people's frivolous<br>
goals, because the only way to see what new and generally-extrinsically<br>
valuable things might arise from them is to wait and see. Hayek makes this<br>
point over and over again.<br>
<p>
And given that much, I don't think it would do too much harm for you to be<br>
tolerant of your own frivolous goals. You'll never know what you missed out<br>
on if you ruthlessly suppress them all.<br>
<p>
Eric Watt Forste      &lt;arkuat@pobox.com&gt;     <a href="http://www.c2.org/~arkuat/">http://www.c2.org/~arkuat/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0193.html">Alexander 'Sasha' Chislenko: "FWD: Libertarian Programmers' Guild"</a>
<li> <b>Previous message:</b> <a href="0191.html">Eric Watt Forste: "Re: Private Space  (was: Trans-extropian principles)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
