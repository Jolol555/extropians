<!-- received="Wed Sep  4 17:49:07 1996 MST" -->
<!-- sent="Wed, 04 Sep 1996 19:03:20 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="dgc@shirenet.com" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="199609042346.QAA01247@pure.pure.com" -->
<!-- inreplyto="Thinking about the future..." -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
Dan Clemmensen (<i>dgc@shirenet.com</i>)<br>
<i>Wed, 04 Sep 1996 19:03:20 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#790">[ date ]</a><a href="index.html#790">[ thread ]</a><a href="subject.html#790">[ subject ]</a><a href="author.html#790">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Previous message:</b> <a href="0789.html">Ray Peck: "WEB: Submit your favorite sites to Yahoo"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Eric Watt Forste wrote:<br>
<i>&gt; </i><br>
<i>&gt; At 4:47 PM 9/3/96, Dan Clemmensen wrote:</i><br>
<i>&gt; &gt;My hope is that the SI will develop a "morality" that includes the</i><br>
<i>&gt; &gt;active preservation of humanity, or (better) the uplifting of all</i><br>
<i>&gt; &gt;humans, as a goal. I'm still trying to figure out how we (the</i><br>
<i>&gt; &gt;extended transhumanist community) can further that goal.</i><br>
<i>&gt; </i><br>
[<br>
SNIP of a worthwhile discussion of part of an SI moral basis]<br>
<p>
<i>&gt; Consider that an SI, as such, can only compute. If it wants to *do*</i><br>
<i>&gt; something (and presumably if all it wanted to do was sit and compute, it</i><br>
<i>&gt; would present no threat to human beings), it would need to build a vast</i><br>
<i>&gt; network of sensorics and motorics. But instead of wasting time and</i><br>
<i>&gt; resources on this intermediary means-project, it could work directly toward</i><br>
<i>&gt; its ends by using the five billion sophisticated supercomputers (with their</i><br>
<i>&gt; attached sophisticated sensorics and motorics) that we call human beings.</i><br>
<i>&gt; It could also use the vast and inaccessible (except through the market)</i><br>
<i>&gt; database of local information about resources that might be useful toward</i><br>
<i>&gt; achieving its ends, but this information is lodged in human brains, and</i><br>
<i>&gt; there is no effective way to get *all* of it out in a useful way except</i><br>
<i>&gt; either (1) to use the market and its system of price signals or possibly</i><br>
<i>&gt; (2) uplift all human beings.</i><br>
<i>&gt; </i><br>
<p>
In the same way that I believe humanity has only short-term utility to<br>
the SI as a<br>
knowledge resource, I also believe that humanity has only short-term<br>
utility<br>
as a sensory-motor resource. building a vast sensor-motor resource is<br>
straightforward,<br>
given nanotechnology or even a more conventionally-constructed set of<br>
general<br>
-prupose robots. To use humans for this purpose entails the same kind of<br>
interactions<br>
humans use with each other, such as contracts, mangagment, etc. A<br>
self-augmenting<br>
SI should achieve higher efficiency than this in a matter of a few<br>
weeks.<br>
  If I were part of the decision-making part of the first SI, I'd start<br>
by<br>
augmenting the computer part of myself to increase my intelligence. I'd<br>
then use<br>
my increased intelligence to 1) take control of the finincial system (or<br>
at least<br>
of a serious amount of money) and 2) solve the remaining engineering<br>
problems<br>
associated with practical nanotech. I'd then send purchase orders to<br>
machine tool<br>
manufacturers, hire humans, and build the initial nanotech assemblers.<br>
<i>&gt;From there,</i><br>
I'd be able to self-replicate the namotech to build whatever<br>
sensor-motor system I<br>
want, and also to add additional computing capacity as needed. This SI<br>
would<br>
have more "intelligence" and more sensors and effectors than all of<br>
humanity<br>
combined, in a matter of weeks. The only thing missing is the "knowledge<br>
base",<br>
the bulk of which is available via "ab initio" methods and much of the<br>
rest of<br>
which is available via uploading of consenting humans. If my current<br>
morality contributes to the morality of the SI, then the SI will try to<br>
actrively preserve<br>
the humanity of those humans who so desire, but I cannot justify this by<br>
any<br>
utilitarian argumant. I'm hoping that the SI's intelligence and<br>
knowledge will<br>
result in its discovery of a compelling reason to be nice to humanity.<br>
<p>
Note: I think the SI will come into existance within a decade, probably<br>
as a human-computer collaboration which initially augments itself by<br>
using the internet.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Previous message:</b> <a href="0789.html">Ray Peck: "WEB: Submit your favorite sites to Yahoo"</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
