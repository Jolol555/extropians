<!-- received="Thu Dec  5 20:50:49 1996 MST" -->
<!-- sent="Thu, 05 Dec 1996 21:33:28 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity-worship" -->
<!-- id="199612060116.RAA22956@off.ugcs.caltech.edu" -->
<!-- inreplyto="Singularity-worship" -->
<title>extropians: Re: Singularity-worship</title>
<h1>Re: Singularity-worship</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Thu, 05 Dec 1996 21:33:28 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3671">[ date ]</a><a href="index.html#3671">[ thread ]</a><a href="subject.html#3671">[ subject ]</a><a href="author.html#3671">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3672.html">Twirlip of Greymist: "Re: MATH: Weird probability arguments"</a>
<li> <b>Previous message:</b> <a href="3670.html">Eliezer Yudkowsky: "Re: Singularity-worship"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3707.html">Peter C. McCluskey: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; &gt;The SAT - not IQ tests, just the SAT - measures the ability to trace</i><br>
<i>&gt; &gt;single causal links.</i><br>
<i>&gt; This is a remarkably strong assertion, backed up by exactly nothing.</i><br>
<i>&gt; Philosophers are still debating what the phrase "causal link" means,</i><br>
<i>&gt; so I'm surprised to find that you seem to think that we have a test</i><br>
<i>&gt; that measures the ability to trace these things.</i><br>
<p>
Of course philosophers are still debating over what causality is.  This<br>
is probably because the last time I checked, there were no less than<br>
eight separate and distinct phenomena that could arguably be called<br>
"causality", and philosophers still haven't untangled the four types<br>
they know about - computational, platonic, thermodynamic and cognitive<br>
causality.<br>
<p>
You appear to be interested in "cognitive causality", that is, the way<br>
in which the human mind assigns causal links.  This is a matter solely<br>
for cognitive science/artificial intelligence and doesn't affect<br>
philosophy in the least, except that philosophers need to know what's in<br>
their heads so they don't get it mixed up with the rest of the Universe.<br>
<p>
As for my assertion about the SAT, it's backed up in Algernon's Law. <br>
The short version is that I scored astronomically high on the SAT (age<br>
eleven, 670V/740M, came in second for the 7th grade of the entire<br>
Midwest) but have a relatively normal IQ of 143, and I do causal<br>
analysis, so the SAT apparently tests just that.  Don't ask me why.<br>
<p>
<i>&gt; I'm not asking for a general definition of</i><br>
<i>&gt; "meaning", just for a definition of the phrase "meaning of life" as you</i><br>
<i>&gt; use it.</i><br>
<p>
Didn't I just do that?  The meaning of life may be defined as a<br>
self-justifying goal.  It's the ethical equivalent of the First Cause,<br>
which has no causal precedents.  The Meaning of Life is simply something<br>
meaningful in and of itself, without being part of a greater goal or<br>
being urged on us by evolution.<br>
<p>
<i>&gt; The word "self-justifying" is empty of content. Justification is a</i><br>
<i>&gt; relationship between two distinct information structures. If *anything*</i><br>
<i>&gt; is self-justifying, then everything is self-justifying; hence, the</i><br>
<i>&gt; phrase "self-justifying" does not distinguish a set to which it applies</i><br>
<i>&gt; from a set to which it does not apply. Terms that do not distinguish are</i><br>
<i>&gt; empty of content. Or perhaps you are prepared to explain to me what is</i><br>
<i>&gt; the precise difference between self-justifying and non-self-justifying</i><br>
<i>&gt; entities?</i><br>
<p>
You've been taking too many philosophy courses.  The above diatribe is<br>
not distinct from:  "Reference is a relationship between two sentences. <br>
If one sentence is self-referential, they all are."  And yet, not all<br>
sentences are self-referential, nor is the term "self-referential" empty<br>
of content.<br>
<p>
An example of a self-justifying entity would be the reason why anything<br>
exists at all.  An example of a non-self-justifying entity would be the<br>
goal of crossing the room.<br>
<p>
<i>&gt; If that's your definition of smartness, then I doubt that there is</i><br>
<i>&gt; any such entity. There is no such thing as "generalized problem</i><br>
<i>&gt; solving skill"; rather, there are different skills which are useful</i><br>
<i>&gt; for solving different kinds of problems. We have exactly no reason</i><br>
<i>&gt; to believe that all skills are reducible to some hypothetical </i><br>
<i>&gt; "uberskill" called "intelligence" or "smartness"... these latter</i><br>
<i>&gt; words refer to ill-defined bundles of skills, and you simply </i><br>
<i>&gt; cannot measure ill-defined bundles.</i><br>
<p>
What a philosopher!  Suppose I say:  "Smartness is an abstraction,<br>
existing solely in the human mind, from the observation - also existing<br>
in the human mind - that System X - also in the mind - can solve problem<br>
Y - also in the mind.  To give this term, "smartness", a useful<br>
definition, we say that if System X can solve more problems than System<br>
Y, or solve them more elegantly - where elegance is in the mind - then<br>
System X is smarter than System Y.  The terms used may not precisely<br>
reflect the truth, not having definitions down to the level of such<br>
definitively real items as quarks or whatever the fundamental particles<br>
may be, but if we attempted so foolish an endeavor as to make all mental<br>
assertions correspond precisely to reality, we wouldn't be able to think<br>
or walk across the room.  The most we can hope for is terms which are<br>
useful, experimentally testable, and precise.  I believe that<br>
"smartness", or - so I don't get another lecture on there being multiple<br>
types of smartness - that type of smartness which has to do with the<br>
rotation of mental pictures - is experimentally testable, precise, and<br>
useful.  Other types of smartness are more vaguely defined due to our<br>
primitive grasp of cognitive science, but are still useful.<br>
<p>
<i>&gt; The primary thing I object to about your "diatribes", as you call</i><br>
<i>&gt; them, is that you are treating a large number of important open</i><br>
<i>&gt; questions as if they were closed questions. As for your tagline,</i><br>
<i>&gt; that's why I took this private.</i><br>
<p>
You came a bit close with that question about causality.  I won't say<br>
what the other four types are.  This letter at least is being redirected<br>
towards the list, since apparently there are still people out there who<br>
have trouble with my working definition of the Meaning of Life.<br>
<p>
Yours,<br>
Eliezer S. Yudkowsky.<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3672.html">Twirlip of Greymist: "Re: MATH: Weird probability arguments"</a>
<li> <b>Previous message:</b> <a href="3670.html">Eliezer Yudkowsky: "Re: Singularity-worship"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3707.html">Peter C. McCluskey: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
