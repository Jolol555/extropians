<!-- received="Tue Aug 27 11:44:27 1996 MST" -->
<!-- sent="Tue, 27 Aug 1996 14:56:55 +0200 (MET DST)" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Individual Freedoms" -->
<!-- id="Pine.SOL.3.91.960827141617.15648D-100000@sun3" -->
<!-- inreplyto="199608270159.SAA15463@primenet.com" -->
<title>extropians: Re: Individual Freedoms</title>
<h1>Re: Individual Freedoms</h1>
Eugene Leitl (<i>Eugene.Leitl@lrz.uni-muenchen.de</i>)<br>
<i>Tue, 27 Aug 1996 14:56:55 +0200 (MET DST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#514">[ date ]</a><a href="index.html#514">[ thread ]</a><a href="subject.html#514">[ subject ]</a><a href="author.html#514">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<li> <b>Previous message:</b> <a href="0513.html">Tim_Robbins@aacte.nche.edu: "controlling AI"</a>
<li> <b>In reply to:</b> <a href="0512.html">Natasha V. More: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0537.html">Dave Sill: "Re: Individual Freedoms"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
As a kid I wanted the maxime of my actions to be maximum happines <br>
integrated over population integrated over time. Full stop. (modest, huh?)<br>
<p>
Alas, these halcyon days of unreflected altruism are over. For one there <br>
is no mechanism to measure happiness, especially to predict it a priori <br>
to choose one branch from a multitude of alternatives.<br>
<p>
Additionally, most human properties are distributed in an (assymetric) <br>
bell-shaped curve and not an infinitesimally thin spike. A compromise <br>
trying to satisfy everybody, in the end will fail to meet the expectations <br>
of everyone. A sufficiently long sequence of strong filters blocks out <br>
all alternatives.<br>
<p>
In the end, I wound up pursuing a weighted altruism, where personal (&amp; <br>
those of kin) happiness comes first, everybody else's later. But then we <br>
live in world where almost nobody has ever heard about game theory and <br>
iterated prisonner's dilemma...<br>
<p>
How does one shape a behaviour in a world where the majority seems to <br>
pursue a suboptimal strategy?<br>
<p>
'gene<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<li> <b>Previous message:</b> <a href="0513.html">Tim_Robbins@aacte.nche.edu: "controlling AI"</a>
<li> <b>In reply to:</b> <a href="0512.html">Natasha V. More: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0537.html">Dave Sill: "Re: Individual Freedoms"</a>
<!-- reply="end" -->
</ul>
