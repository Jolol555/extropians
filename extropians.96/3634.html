<!-- received="Wed Dec  4 15:15:00 1996 MST" -->
<!-- sent="Wed, 04 Dec 1996 13:52:22 -0800" -->
<!-- name="James Rogers" -->
<!-- email="jamesr@best.com" -->
<!-- subject="Re: We need better tools to make better tools. &lt;guaRANTeed&gt;" -->
<!-- id="1.5.4.32.19961204215222.002d1eac@best.com" -->
<!-- inreplyto="We need better tools to make better tools. &lt;guaRANTeed&gt;" -->
<title>extropians: Re: We need better tools to make better tools. &lt;guaRANTeed&gt;</title>
<h1>Re: We need better tools to make better tools. &lt;guaRANTeed&gt;</h1>
James Rogers (<i>jamesr@best.com</i>)<br>
<i>Wed, 04 Dec 1996 13:52:22 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3634">[ date ]</a><a href="index.html#3634">[ thread ]</a><a href="subject.html#3634">[ subject ]</a><a href="author.html#3634">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3635.html">James Rogers: "RE: we need better tools..."</a>
<li> <b>Previous message:</b> <a href="3633.html">James Rogers: "Re: A thread that has nothing to do with memes or the"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3731.html">Eugene Leitl: "Re: We need better tools to make better tools. &lt;guaRANTeed&gt;"</a>
<li> <b>Reply:</b> <a href="3731.html">Eugene Leitl: "Re: We need better tools to make better tools. &lt;guaRANTeed&gt;"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 08:29 PM 12/4/96 +0100, you wrote:<br>
<p>
<i>&gt;&gt; In the Alpha AXP, this is primarily a result of mediocre CPU design rather</i><br>
<i>&gt;&gt; than something you can blame on the compilers.  The Alpha has a very deep</i><br>
<i>&gt;</i><br>
<i>&gt;A simple question: why must the compilers be large, slow monsters, having </i><br>
<i>&gt;to know lots of things about your hardware setup? (That should be the </i><br>
<i>&gt;domain of the OS). This wasn't the rule just a few years ago. Gcc is </i><br>
<i>&gt;terribly difficult to optimize for Alpha (it is an internal </i><br>
<i>&gt;representation problem), Digital's dedicated compiler performs much better. </i><br>
<i>&gt;This isn't God-given, men build both machines and write compilers for them.</i><br>
<p>
If you left all the hardware details to the OS, you wouldn't be able to do<br>
much optimization.  You would be trusting that the OS was optimized,<br>
something I am not yet willing to do.  Granted, compilers *are* slow and<br>
large, but for some languages (like C++) and systems, the complexity of<br>
compiling software can approach absurdity.  I once tried to write a<br>
compiler.  Not an easy task if you are concerned with optimization.<br>
<p>
Actually, I think somebody needs to reinvent what an OS is supposed to do.<br>
Take NT (which I am using to write this email) for example.  That OS is so<br>
bulky and has so much baggage it would be difficult to write a really small<br>
or fast piece of software for it.  Most versions of Unix have become the<br>
same way.  More often than not, the OS gets in the way.  There are a lot of<br>
good experimental OSs out there, but unfortunately, most don't have enough<br>
support to be useable.  If I had lots of time and money, I would start<br>
building a brand new computing environment from the ground up.<br>
<p>
The one thing I liked about DOS, as limited as it was, was that it allowed<br>
you to really write compact, fast apps.  If it natively multi-tasked, and<br>
had full support for 32-bit operation, I might still be working on it.<br>
<p>
<i>&gt;When was the last time you read your compiler in one hour, and understood </i><br>
<i>&gt;it, at least sufficiently to modify it constructively? (Hint: read a </i><br>
<i>&gt;modern optimizing Forth compiler, which is just just a few pages of </i><br>
<i>&gt;printout, one should definitely recite'em at these lyrics readings. Its </i><br>
<i>&gt;a goddam work of art). The last time the ole edit-compile-crash iteration </i><br>
<i>&gt;took unperceivable milliseconds, not minutes? Where you could do dynamic </i><br>
<i>&gt;surgery on a live system, with true incremental compiling?</i><br>
<p>
Oh no.  Another Forth evangelist!  ;)<br>
<p>
<i>&gt;We had to wait since the '60 for gc to become industrial mainstream, nay, </i><br>
<i>&gt;not even mainstream: it is still considered top-notch newfangledness. </i><br>
<i>&gt;This should tell us something about current tech's potential for </i><br>
<i>&gt;optimization. Remember USCD p-System, Wirth's Oberon project, Lisp machines, </i><br>
<i>&gt;Taos, Forth chips. Now we see pieces of them cropping up in mainstream </i><br>
<i>&gt;products. </i><br>
<i>&gt;</i><br>
<i>&gt;&gt; pipeline, but almost no look-ahead or intelligent pre-fetch/decode logic.</i><br>
<i>&gt;</i><br>
<i>&gt;What if your CPU core is so simple, you cannot afford a hardware </i><br>
<i>&gt;multiplier, apart from things like FPU, pipeline, BPU, &amp;c&amp;c?</i><br>
<i>&gt;</i><br>
<i>&gt;Consider a WSI system: a 64 bit primitive CPU, a few kBytes of SRAM to </i><br>
<i>&gt;contain the VM, 128 kBytes of DRAM, a router with, say, 12 links. How much </i><br>
<i>&gt;complexity can we afford before die yield drops to zero? Surely not much </i><br>
<i>&gt;beyond 1 MTransistors. (Those working in a Valley silicon foundry, please </i><br>
<i>&gt;step forth, to cite chapter &amp; verse).</i><br>
<p>
The major CPU producers seem to be getting acceptible yields at<br>
3-5MTransistors, depending on which company you are talking about.  I know<br>
Intel gets &gt;80% yield by mid-cycle for most of its CPU products.  I think<br>
their initial yields are something like 15% though.<br>
<p>
<i>&gt;There is simply no way to put above complexity into a die as tiny as </i><br>
<i>&gt;that. Moreover, it would be an entirely wrong direction: it would keep </i><br>
<i>&gt;the CPU architecture converging towards a CAM (it is easy to see </i><br>
<i>&gt;convergenece in extreme cases of both), which is a nonalgorthmic machine, </i><br>
<i>&gt;making no distinction between code and data, everything being just a </i><br>
<i>&gt;hyperactive bit soup.</i><br>
<p>
We are currently seeing and will probably continue to see a trend towards<br>
multi-chip modules.  This is certainly coming true as far as memory is<br>
concerned.  It's more profitable to connect a lot of little chips than to<br>
make one big one.  Companies like Cray have been doing things this way for a<br>
while.  And of course, Intel did it to get the cache size and performance<br>
they wanted on the P6.  I estimate most of the next generation of chips for<br>
many of the major manufacturers will be MCMs.<br>
<p>
<i>&gt;To approach it from a different direction: consider a 1 MBit DRAM. If we </i><br>
<i>&gt;ignore all I/O, we can surely organize it in 1 kWords a la 1 kBit each. </i><br>
<i>&gt;So we need a 1 kBit SRAM register to refresh it occasionally, and an </i><br>
<i>&gt;incrementing PC to step through, as fast as the core lets us. We can add </i><br>
<i>&gt;shift capability to the register, we can take two of them, add an adder, </i><br>
<i>&gt;basic logics, a segmented ALU design (selectable comb tooth width), a </i><br>
<i>&gt;variety of primitive logic engines to protect parts of the word, to </i><br>
<i>&gt;shuffle things back &amp; forth, etc. Anyway, starting from this points one </i><br>
<i>&gt;does not have too many choices how the final beast has to look like. I </i><br>
<i>&gt;have seen the MediaProcessor people independantly reinventing a lot of </i><br>
<i>&gt;my machinery I thought was cool but ad hoc. (My design is still better, </i><br>
<i>&gt;though ;)</i><br>
<p>
These architectures can be fast, but how well would something like this<br>
really work for general computing applications such as spreadsheets?  The<br>
instruction set would be kind of poor for efficient general computing.<br>
<p>
<i>&gt;&gt; The result is that the pipeline is flushed pretty often, which is only</i><br>
<i>&gt;&gt; worstened by its depth.  Also, the high clock rates make pipeline stalls</i><br>
<i>&gt;</i><br>
<i>&gt;So let's drop the pipeline, and move the core onto the die, as much of it </i><br>
<i>&gt;as die yield can take before wafer yield drops to zero.</i><br>
<p>
It is okay to have a pipeline.  It is just poor design to have such a deep<br>
and dependant one when you have essentially no branch prediction or<br>
look-ahead logic.  A well-designed pipeline is what allows you to get the<br>
high clock speeds out of silicon processes.  Either keep it simple and<br>
short, or long but with a lot of intelligent pre-pipeline logic.  The thing<br>
with simple and short is, you have to have either a very simple instruction<br>
set, or a *very* good compiler.  Personally, I don't think current compilers<br>
are up to the challenge.<br>
<p>
<i>&gt;</i><br>
<i>&gt;&gt; (due to things like cache misses) more serious than they would be in slower</i><br>
<i>&gt;</i><br>
<i>&gt;So let's abolish the cache, giving core DRAM almost cache quality, </i><br>
<i>&gt;mapping a tiny SRAM islet into the address space, while eliminating </i><br>
<i>&gt;worst-case scenarios (locality is nonexistant in certain problems, if fact </i><br>
<i>&gt;it can be conjectured that access locality is a pathologicial case, an </i><br>
<i>&gt;artefact of the human programmer).</i><br>
<p>
Isn't this the way modern caches are essentially done?<br>
<p>
<i>&gt;&gt; clocked chips.  Add on top of this an inefficient superscalar</i><br>
<i>&gt;</i><br>
<i>&gt;Astronomic clocks aren't everything, they just increase power dissipation </i><br>
<i>&gt;(wasn't that an exponential relation?) and are of no use if the core </i><br>
<i>&gt;cannot deliver requested words. Clock rates beyond 2-4 GHz aren't viable </i><br>
<i>&gt;with Si tech anyway (physics starting harrumphing in the background), and </i><br>
<i>&gt;GaAs is a much weaker substrate, when it comes to integration density, </i><br>
<i>&gt;which is the key.</i><br>
<p>
High clock rates force a deeper pipeline because you still have gate latency<br>
to contend with.  Deeper pipelines mean you have more time to complete one<br>
instruction.  If your clock is getting faster and your gates aren't, the<br>
only solution is to deepen the pipeline.<br>
<p>
The obvious physical limit for Si is when clock speed equals switching<br>
speed, although realistically this isn't true, since it would require<br>
ridiculous level of complexity (a 100 level pipeline?).  I am not sure if<br>
they have determined the maximum theoretical switching speed for a Si<br>
transistor yet.  The best they can do right now is to just improve the<br>
fan-in/fan-out limits (like BiCMOS) and generally decrease structural latency.<br>
<p>
<p>
<i>&gt;I say take a 40 kTransistor, highly tweaked CPU (Chuck does this), clock </i><br>
<i>&gt;it as high as it can take without melting, considering dense packing of </i><br>
<i>&gt;a WSI system (about 1 GHz with current high-end structures),</i><br>
<i>&gt;flush your code into the tiny SRAM by hand, put it and a 128 k DRAM on a </i><br>
<i>&gt;a die, them wafer with 100s of 'em dies, letting them all work in </i><br>
<i>&gt;parallel. What are the wafer costs, about $500? Even if it sells for 1 k$, </i><br>
<i>&gt;it is still acceptable. </i><br>
<p>
At 40 kTransistors, how wide will the ALU be?  I assume this does not<br>
include any type of FP capability.<br>
<p>
<i>&gt;Who is going to program this? The multimedia craze will greedily gulp </i><br>
<i>&gt;down every imaginable DSP resources you can throw at it, as will GA and </i><br>
<i>&gt;ANN stuff.</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; implementation, and you have a chip that virtually *requires* handcrafted</i><br>
<i>&gt;&gt; assembly language to run efficiently.</i><br>
<i>&gt;</i><br>
<i>&gt;I think we might see a (brief) revival of handcrafted assembly, at least </i><br>
<i>&gt;in the nanoOS kernel methods. Apps will stop being monolithic, instead </i><br>
<i>&gt;being live things, multiplying over nodes dynamically or shrinking </i><br>
<i>&gt;likewise, goaded by the OS load leveler.</i><br>
<p>
I still use assembly for computationally complex functions in some types of<br>
software.  I still can't believe the kind of speed I can get out of<br>
handcrafted assembler sometimes, even on old systems.  <br>
<p>
<i>&gt;&gt; One of the reasons Intel's late generation chips have done so well,</i><br>
<i>&gt;&gt; performance-wise, is that Intel probably has one of the best pre-execution</i><br>
<i>&gt;&gt; logic designs and techniques on any CPU, RISC or otherwise.  Add to this</i><br>
<i>&gt;</i><br>
<i>&gt;Intel has grown sufficiently rich to afford the best people, as has M$. I </i><br>
<i>&gt;once laughed about them, ignored them. I cannot, anymore. They have </i><br>
<i>&gt;demolished the markets, and upon the ruined marketplace (all thanks, ye </i><br>
<i>&gt;smart customers) their braindead designs even look good, since there is </i><br>
<i>&gt;no competition.</i><br>
<p>
Many aspects of Intel's designs are quite good.  Other parts I question,<br>
though.  I think a lot of their bad design decisions are done to cater to<br>
the consumer market that built them.<br>
<p>
<i>&gt;Once you are big enough, investments into best manpower, new process </i><br>
<i>&gt;research, long-term planning, industrial espionage and open market </i><br>
<i>&gt;warfare can make you only bigger. It is profit maximization, that has </i><br>
<i>&gt;brought us peu a peu device introduction, instead of a longer stages of </i><br>
<i>&gt;drastic designs.</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; that Intel easily has one of the most efficient superscalar implementations,</i><br>
<i>&gt;</i><br>
<i>&gt;I don't think vector/scalar division makes at all sense. Precambrian life </i><br>
<i>&gt;forms, designed to become extinct.</i><br>
<i>&gt;</i><br>
<i>&gt;&gt; and you get some real performance out of an old architecture.  One of the</i><br>
<i>&gt;&gt; few RISC companies that I think has a really solid architecture concept</i><br>
is HP.<br>
<i>&gt;</i><br>
<i>&gt;Alas, HP RISC is dying, as does Alpha. When speaking of monopolies...</i><br>
<p>
Actually, HP RISC is being kind of absorbed by Intel.  I guess either the P7<br>
or P8 will include a version which will include a PA-RISC decoder.  This is<br>
one feature of Intel's latest chips that I think is pretty cool.  Have an<br>
architecture specific decoder sitting upon a powerful generic RISC core.<br>
They could probably put a decoder for just about any common architecture on<br>
top of that.  Now if you could select your hardware architecture emulation<br>
via software, *that* would be *too cool*.<br>
 <br>
<i>&gt;</i><br>
<i>&gt;One DSP design from TI features 4 DSP cores, 4 on-die SRAM areas, </i><br>
<i>&gt;connected by a on-die crossbar, choreographed by a vanilla CPU. TI is </i><br>
<i>&gt;pretty innovative in terms of DSP/embedded hybrids, putting core on the </i><br>
<i>&gt;die and to make DSPs cascadable (up to 6 fast links).</i><br>
<p>
Let me see...this would be the TMS320C80, if I am not mistaken.<br>
Theoretical throughput of 2,000 DSP MIPS, or something like that.<br>
<p>
Doesn't IBM have a new architecture (MFast?) that has a 32 DSP-core mesh?<br>
I vaguely remember reading something about this.  10,000 DSP MIPS<br>
theoretical throughput (although I understand for most operations it is<br>
something like 2-5 kMIPS).<br>
<p>
<i>&gt;&gt; I'll take it one step further:  An OS you can't customize is useless.</i><br>
<i>&gt;&gt; </i><br>
<i>&gt;</i><br>
<i>&gt;Have YOU rebuilt your kernel tonight? ;)</i><br>
<p>
Not since about two weeks ago :)<br>
 <br>
-James Rogers<br>
 jamesr@best.com<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3635.html">James Rogers: "RE: we need better tools..."</a>
<li> <b>Previous message:</b> <a href="3633.html">James Rogers: "Re: A thread that has nothing to do with memes or the"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3731.html">Eugene Leitl: "Re: We need better tools to make better tools. &lt;guaRANTeed&gt;"</a>
<li> <b>Reply:</b> <a href="3731.html">Eugene Leitl: "Re: We need better tools to make better tools. &lt;guaRANTeed&gt;"</a>
<!-- reply="end" -->
</ul>
