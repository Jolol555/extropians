<!-- received="Sat Aug 31 10:21:55 1996 MST" -->
<!-- sent="Sat, 31 Aug 1996 12:00:59 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="dgc@shirenet.com" -->
<!-- subject="Re: The SI That Ate Chicago (was: Thinking about the future...)" -->
<!-- id="v02140b54ae4db31eb83e@[204.162.114.176]" -->
<!-- inreplyto="The SI That Ate Chicago (was: Thinking about the future...)" -->
<title>extropians: Re: The SI That Ate Chicago (was: Thinking about the future...)</title>
<h1>Re: The SI That Ate Chicago (was: Thinking about the future...)</h1>
Dan Clemmensen (<i>dgc@shirenet.com</i>)<br>
<i>Sat, 31 Aug 1996 12:00:59 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#624">[ date ]</a><a href="index.html#624">[ thread ]</a><a href="subject.html#624">[ subject ]</a><a href="author.html#624">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0625.html">Sunah Cherwin: "Re: The Great Squirrel"</a>
<li> <b>Previous message:</b> <a href="0623.html">Eric Watt Forste: "Morality, Sacred Cows, and Sin"</a>
<li> <b>Maybe in reply to:</b> <a href="0616.html">Eric Watt Forste: "The SI That Ate Chicago (was: Thinking about the future...)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1222.html">Hara Ra: "Re: The SI That Ate Chicago (was: Thinking about the future...)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Eric Watt Forste wrote:<br>
<i>&gt; </i><br>
<i>&gt; At 8:04 PM 8/30/96, Dan Clemmensen wrote:</i><br>
<i>&gt; &gt;The SI may not want to destroy humanity. Humanity may simply be</i><br>
<i>&gt; &gt;unworthy of consideration, and get destroyed as a trivial side effect</i><br>
<i>&gt; &gt;of some activity of the SI.</i><br>
<i>&gt; </i><br>
<i>&gt; I liked your point that the SI to worry about is the SI whose primary goal</i><br>
<i>&gt; was further increase in intelligence. But consider that the human species,</i><br>
<i>&gt; as a whole, is a repository of a significant amount of computational power.</i><br>
<i>&gt; Just as most of us know to look up something up on the Web before we invest</i><br>
<i>&gt; a significant amount of effort into trying to figure it out for ourselves,</i><br>
<i>&gt; from scratch, just using our brains and nothing else, the SI will probably</i><br>
<i>&gt; be a lot more intelligent (in terms of being able to figure out solutions</i><br>
<i>&gt; to problems) if it cooperates with the existing body of human researchers</i><br>
<i>&gt; than if it eats them.</i><br>
<i>&gt; </i><br>
[SNIP of a lot of interesting stuff]<br>
<p>
I agree that in its early stages, the SI will likely interact with<br>
humans in the way<br>
you describe. The reason that I use the term SI instead of AI is that my<br>
hypothesis<br>
doesn't depend on the exact nature of the SI. As I said, it's likely to<br>
start as<br>
some type of human-computer collaboration and augment itself from that<br>
base. My feeling is that the SI will rapidly reach a point at which it<br>
can re-derive knowledge<br>
ab-initio faster than it could get the same knowledge from a human.<br>
Alternatively, the SI will almost certainly solve all of the<br>
then-current human research problems, specifically including nanotech<br>
and uploading. It can then offer to host an upload<br>
of any human that wishes to upload. When enough humans accept the offer,<br>
the amount of useful knowledge known only to "meat" humans will cease to<br>
be very attractive.<br>
<p>
Even if the SI has goals other that increasing its intelligence, most<br>
such goals<br>
are more readily achieved by a more intelligent SI. Therefore,<br>
increasing its intelligence is likely to be an intermediate goal for any<br>
of the other goals.<br>
<p>
I've argued that the same is true for today's humanity. Probably the<br>
fastest way<br>
for us to get to nanotech and upoading is to develop the SI. IMO, the<br>
quickest way to develop this SI is by concentrating on software tools<br>
and visual representation of<br>
information, leading to easier-to-use computers and to human-computer<br>
collaboration.<br>
This will lead to the singularity within ten years.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0625.html">Sunah Cherwin: "Re: The Great Squirrel"</a>
<li> <b>Previous message:</b> <a href="0623.html">Eric Watt Forste: "Morality, Sacred Cows, and Sin"</a>
<li> <b>Maybe in reply to:</b> <a href="0616.html">Eric Watt Forste: "The SI That Ate Chicago (was: Thinking about the future...)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="1222.html">Hara Ra: "Re: The SI That Ate Chicago (was: Thinking about the future...)"</a>
<!-- reply="end" -->
</ul>
