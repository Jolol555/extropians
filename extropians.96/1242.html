<!-- received="Thu Sep 26 05:41:31 1996 MST" -->
<!-- sent="Thu, 26 Sep 1996 13:34:35 +0200 (MET DST)" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: objectivists hate libertarians" -->
<!-- id="Pine.SOL.3.91.960924141717.1105I-100000@sun2" -->
<!-- inreplyto="Pine.SGI.3.91.960923103255.14709A-100000@jack.factory.net" -->
<title>extropians: Re: objectivists hate libertarians</title>
<h1>Re: objectivists hate libertarians</h1>
Eugene Leitl (<i>Eugene.Leitl@lrz.uni-muenchen.de</i>)<br>
<i>Thu, 26 Sep 1996 13:34:35 +0200 (MET DST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1242">[ date ]</a><a href="index.html#1242">[ thread ]</a><a href="subject.html#1242">[ subject ]</a><a href="author.html#1242">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1243.html">Anders Sandberg: "Re: Serial consciousness"</a>
<li> <b>Previous message:</b> <a href="1241.html">James Daugherty: "RE: Are Conspiracies Stronger Than Truth?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Mon, 23 Sep 1996, Eric Watt Forste wrote:<br>
<p>
<i>&gt; On Mon, 23 Sep 1996, Eugene Leitl wrote:</i><br>
<i>&gt; &gt; I think this is bullshit. I am fairly Libertarian, and I am strongly pro </i><br>
<i>&gt; &gt; capitalism. Maximizing individual freedom has no intrinsic value. It is </i><br>
<i>&gt; &gt; the maximization of in toto (over population, over time) happiness which </i><br>
<i>&gt; &gt; has value. Why? </i><br>
<i>&gt; </i><br>
<i>&gt; Eugene, I appreciate your sentiments, but I really don't think this </i><br>
<i>&gt; stance makes any more sense to me than the objectivists' stance. </i><br>
<p>
That was my point. Trying to find rational reasons for why we do things <br>
is a cheap rationalization ;) . There are none. Ultimatively, this is a <br>
hardware function. It does what it was designed to do (by the Blind <br>
Watchmaker), no more, no less. (Admit some random factor for GA <br>
optimization).<br>
<p>
Assuming everything else is just a case of antromorphism.<br>
<p>
<i>&gt; Maximizing happiness sounds like maximizing complexity to me; an effort </i><br>
<i>&gt; to maximize something that we have *no* clue how to *measure* is just a</i><br>
<p>
This assumes that happiness does exist. (Ok, it probably does ;) What <br>
one can do, is to define a happiness metric. This would require e.g. <br>
statistically evaluated polling, and clearly it gives us no a priori <br>
clue, which future trajectory from countless possible to select to land in <br>
an alternative world with the max integrated happiness. This would require <br>
future models, which are progressively inaccurate if not altoghether <br>
questionable.<br>
<p>
Another arbitrary assumption would be how to distribute happiness. <br>
Equidistributed? Weighted? Does one integrate over population? Over time? <br>
Both?<br>
 <br>
<i>&gt; metaphor, and exactly as misleading as some of the metaphors that the </i><br>
<i>&gt; Objectivists have recourse to.</i><br>
<i>&gt; </i><br>
<i>&gt; (If anyone figures out how to measure these things, or how to measure </i><br>
<i>&gt; life or extropy for that matter, please let me know.)</i><br>
<p>
One could define a life metric, at least a boolean one. Since life is a <br>
complex phenomenon, it would be somewhat context (observer) dependant.<br>
<p>
Extropy is not a formal concept. It was never intended to be one. <br>
Information/entropy can be measured, though.<br>
<p>
<i>&gt; &gt; [ objective reality? ]</i><br>
<i>&gt; </i><br>
<i>&gt; Now, this I also find curious because Darwinian evolution is in itself </i><br>
<i>&gt; our best argument for believing in objective reality. Darwinian evolution </i><br>
<p>
If one wants to define objective reality as something having the same <br>
impact on different individua (of course it can't, since no one can <br>
occupy the same voxel region of spacetime, but most of them are quite <br>
dull, anyway), yes.<br>
<p>
<i>&gt; is the explanation that each of us has recourse to when accounting for </i><br>
<i>&gt; how our individual minds came into existence. Of course there is an </i><br>
<i>&gt; outside; if there weren't, then our own existence as individuals would be </i><br>
<i>&gt; a puzzling lacuna in the explanatory structure of our thought. If there </i><br>
<p>
I think we can quite assume existance of the outside being an axiom. <br>
Everybody not agreeing, can now safely quit quarreling with figments of <br>
his own overactive imagination ;)<br>
<p>
<i>&gt; weren't an outside, we'd be able to explain all our percepts in terms of </i><br>
<i>&gt; our own activity, but we would lack any explanation for our own activity.</i><br>
<p>
Right. A bad model. Resembling recursive homunkuli to explain cognition. <br>
Infinite regress, while each stage having the same complexity. Baad model.<br>
 <br>
<i>&gt; The definition that I am currently experimenting with: objective </i><br>
<i>&gt; reality is that part of reality which is the way it is independently of </i><br>
<i>&gt; the influence of any individual person's mind. By a strong construction </i><br>
<i>&gt; of this definition, only offplanet things are "objective reality" by now.</i><br>
<p>
Only these currently outside the light cone beginning with spacetime <br>
point signifying your birth ;)<br>
 <br>
<i>&gt; Certainly most of the objects surrounding you, the monitor you are </i><br>
<i>&gt; reading, etc, are not independent of the causal influence of mind and </i><br>
<i>&gt; thought. One might say that technology is the admixture of subjective</i><br>
<p>
Of course they are not. Theoretically, you can influence everying within <br>
your light cone. If the system is extremely ergodic, it even _will_<br>
be influenced, whether you wish it, or not. <br>
<p>
<i>&gt; reality (thought and feeling) with objective reality (that which is </i><br>
<i>&gt; independent of thought and feeling). Some people seem to think that what </i><br>
<i>&gt; we are all trying to do here is to bring subjective reality into thorough </i><br>
<i>&gt; admixture with the rest of the poor dead "objective reality" universe.</i><br>
<p>
This one went right beyond me. Huh?<br>
<p>
<i>&gt; However, I must insist that I still do not think the objective/subjective </i><br>
<i>&gt; dichotomy is a very useful one philosophically. It's a good thing to get </i><br>
<p>
_Can_ philosophy be useful at all? ;)<br>
<p>
<i>&gt; exhausted thinking about, if you need that kind of exercise, but it tells </i><br>
<p>
Mental calisthenics is fun. At the very least it keeps you from going <br>
human turnip too soon. Medicine men say that, at least.<br>
<p>
<i>&gt; us practically nothing about what we ought to be doing, and isn't that </i><br>
<i>&gt; the point?</i><br>
<p>
Yes. Moreover, it can keep us from thinking other, more constructive <br>
thoughts, and doing others, more constructive tasks. We always quietly <br>
assume that thinking enhances our fitness. In some (most?) cases it does <br>
not. A bummer, eh?<br>
<p>
Thinking can reduce reaction time in a dangerous situation. People with <br>
good reflexes are certainly better equipped than powerful ponderers. Just <br>
think about fertility vs. IQ distribution. Does anybody have actual <br>
statistics at hand?<br>
 <br>
<i>&gt; So I suppose I'm actually agreeing with Eugene. He seems to think that </i><br>
<i>&gt; there is no point to elaborating the objective/subjective boundary, and </i><br>
<p>
Yep. Unless one wants to exercise the neurotransmitter vesicles ;)<br>
<p>
<i>&gt; I'm inclined to agree with him. But to deny the existence of this </i><br>
<i>&gt; boundary, or to deny the existence of that objective reality that </i><br>
<i>&gt; explains our individual existences just closes up the minds of most </i><br>
<i>&gt; people who might otherwise have been listening to you.</i><br>
<p>
Sigh... I have a strong impression that you might be right. For what <br>
its worth, I believe (just a sentiment, of course) in existance of <br>
external, let's call it objective, reality.<br>
 <br>
<i>&gt; &gt; Knowledge: a bag of tricks. Ethics: cooperation emergence due to </i><br>
<i>&gt; &gt; evolution pressure. Deterministic as hell.</i><br>
<i>&gt; </i><br>
<i>&gt; Determinism/indeterminism is another one of these questions that I don't </i><br>
<i>&gt; like to see my friends taking sides on. This is an open question! It may </i><br>
<p>
I wasn't implying strict determinism! It's just that there is a trend <br>
for complexity, and for increasingly benign cooperation strategies, <br>
them cropping up sooner or later. To predict its exact occurence is <br>
awfully hard if not impossible, of course.<br>
<p>
<i>&gt; be decades, centuries, or thousands of years before we have an answer to </i><br>
<i>&gt; this question (and I'd be willing to settle for a proof that an "answer" </i><br>
<i>&gt; is impossible), but it is certainly an open question right now.</i><br>
<p>
It certainly is.<br>
 <br>
<i>&gt; How could a computer fully predict the future course of its own </i><br>
<i>&gt; computation in a manner that we could usefully distinguish from its mere </i><br>
<i>&gt; carrying out of that computation? It could not. If I could prove that it </i><br>
<p>
Agree absolutely.<br>
<p>
<i>&gt; could not, then I would have proved that the determinism/indeterminism </i><br>
<i>&gt; question is a permanently open one, at least to the satisfaction of those </i><br>
<p>
No. A complex system can "understand" a drastically simpler one. It can <br>
contain a primitive model of itself (in fact it probably must to <br>
survive, it has to represent its surroundings, and itself within its <br>
surrounds for future planning. Some bipedal primates go to great length <br>
even to build metamodels, etc.). We all do.<br>
<p>
<i>&gt; few people who think that human beings are a kind of computer. I suspect</i><br>
<p>
No, not a computer. I just think information is a basic property of all <br>
material systems (compare definitions of statistical entropy/information <br>
theory entropy), even extremely weird objects like singularities obey <br>
them, just as is energy. Consider observer interference in a QM <br>
measurement process. Information has about the same status as energy, imo.<br>
<p>
I think there is some equivalency between systems. Consider trajectories of <br>
a system's statespace evolution. If I can track it with a model with <br>
sufficient accuracy, the model and the system is equivalent. If it <br>
wasn't, all modelling would be just an exercise in futility.<br>
<p>
Whether the system is a gas box, or a human mind is the same.<br>
 <br>
Consider statespace velocity times trajectory (info-theory) entropy for <br>
an abstract computation index. I can't think of a system I can't <br>
benchmark it off hand.<br>
<p>
<i>&gt; Eugene is one of them. Me, I like to keep an open mind, although it gets </i><br>
<i>&gt; harder every year.</i><br>
<p>
I can't know human mind is just computation, of course. I just suspect. I <br>
might be wrong, of course.<br>
 <br>
<i>&gt; In the meantime, I'll be looking into more Popper. He was obviously </i><br>
<i>&gt; fascinated by this question, and I haven't read everything he had to say </i><br>
<i>&gt; about it yet.</i><br>
<p>
Alas, I haven't time to dig into philosophy... It's great fun, but <br>
this pesky reality always interferes :(<br>
 <br>
<i>&gt; &gt; I dunno... Going for the right goals, but for wrong reasons? What's wrong </i><br>
<i>&gt; &gt; with that? These objectivists are certainly not utilitarists. But they </i><br>
<i>&gt; &gt; are certainly irrational.</i><br>
<i>&gt; </i><br>
<i>&gt; Utilitarianism is irrational too. Most of the people that "utilitarian</i><br>
<p>
Not if utilitarism tries to derive implementable future strategies from <br>
guessing the shape of the Great &amp; Mysterious Fitness Function. If there is <br>
such a thing, that is.<br>
<p>
<i>&gt; libertarians" look to for guidance in difficult political questions (I</i><br>
<p>
I think the iterated prisonner's dilemma (iPD) might well give us handy <br>
rules for dealing with our co-humans. I mean: what can we lose? Just <br>
building a wrong strategy from a wrong model. So what? It rarely kills <br>
one, at least not immediately. Why should I resist the evolutionary <br>
process, once I am aware it exists? I may. I may not. Free will? Who <br>
cares.<br>
<p>
<i>&gt; have in mind David Friedman here) deny that they are utilitarians, and for</i><br>
<i>&gt; damn good reason: David Friedman is *not* a utilitarian, and neither am I.</i><br>
<i>&gt; Unless "utilitarian" suddenly means something utterly different from the</i><br>
<i>&gt; very clear technical meaning that was established at the climax of</i><br>
<i>&gt; utilitarian thought in late nineteenth-century Britain.  Frankly, of late</i><br>
<p>
Alas, I am a cave man. I have no idea what these distinguished gentlemen <br>
thought and wrote. My (very fuzzy) understanding of utilitarism is based <br>
on some "The Mind's I" contribution, about God being utilitarist, and such.<br>
<p>
<i>&gt; I like Hayek's thinking best, and he's certainly no utilitarian either.</i><br>
<i>&gt; Nor is he an objectivist, though I think Rand approved of him. If</i><br>
<i>&gt; objectivists want to criticize libertarians, that's okay with me (though I</i><br>
<i>&gt; really wonder about their motivation), but if they seek to criticize</i><br>
<i>&gt; libertarians on the grounds that libertarians are utilitarians, then they</i><br>
<i>&gt; are attacking straw men... a time-honored Objectivist recreation, I'm</i><br>
<i>&gt; afraid. </i><br>
<p>
World's a funny place ;)<br>
 <br>
<i>&gt; I suspect what makes them *really* nervous is that so many libertarians</i><br>
<i>&gt; are vague Taoists or Discordians who, while continuing to keep their</i><br>
<i>&gt; intellectual tools for thinking about philosophy sharp, have utterly</i><br>
<i>&gt; abandoned any and all philosophical *commitments*. And who feel happier</i><br>
<i>&gt; that way. And whose valuable political commitments aren't even slightly</i><br>
<i>&gt; harmed by such lack of philosophical commitment. But most seriously</i><br>
<i>&gt; committed Objectivists I've known don't even know how to begin arguing</i><br>
<i>&gt; against this stance by any means other than the ad hominem. I would be</i><br>
<p>
Hey, that's a perfectly rational thing to do! Ad hominem works great in a <br>
debate. That's why it has been invented. We're still not ripe for a <br>
rational (whatever that might be...) discourse yet, it seems. For now, <br>
studying rhetoric, and having a Ph.D. in social engineering (wonderful <br>
term, whoever invented it ;) helps a lot in the real world.<br>
<p>
<i>&gt; very interested in seeing some clear, calm, rational arguments against</i><br>
<i>&gt; this stance. </i><br>
<i>&gt; </i><br>
<i>&gt; (I'd also be interested in seeing a solid refutation of Hayek, too, but </i><br>
<i>&gt; I'm not getting my hopes up or anything.)</i><br>
<i>&gt; </i><br>
<p>
'gene<br>
_________________________________________________________________________________<br>
<i>| <a href="mailto:">mailto:</a> ui22204@sunmail.lrz-muenchen.de | transhumanism &gt;H, cryonics,         |</i><br>
<i>| <a href="mailto:">mailto:</a> Eugene.Leitl@uni-muenchen.de    | nanotechnology, etc. etc.           |</i><br>
<i>| <a href="mailto:">mailto:</a> c438@org.chemie.uni-muenchen.de | "deus ex machina, v.0.0.alpha"      |</i><br>
<i>| icbmto: N 48 10'07'' E 011 33'53''      | <a href="http://www.lrz-muenchen.de/~ui22204">http://www.lrz-muenchen.de/~ui22204</a> |</i><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="1243.html">Anders Sandberg: "Re: Serial consciousness"</a>
<li> <b>Previous message:</b> <a href="1241.html">James Daugherty: "RE: Are Conspiracies Stronger Than Truth?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
