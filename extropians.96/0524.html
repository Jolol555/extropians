<!-- received="Tue Aug 27 12:24:54 1996 MST" -->
<!-- sent="Mon, 26 Aug 1996 18:37:38 -0700" -->
<!-- name="Peter Voss" -->
<!-- email="p.voss@ix.netcom.com" -->
<!-- subject="Re: Controlling AI (was: Thinking about the future...)" -->
<!-- id="2.2.16.19960826171318.2a670ac2@popd.ix.netcom.com" -->
<!-- inreplyto="Controlling AI (was: Thinking about the future...)" -->
<title>extropians: Re: Controlling AI (was: Thinking about the future...)</title>
<h1>Re: Controlling AI (was: Thinking about the future...)</h1>
Peter Voss (<i>p.voss@ix.netcom.com</i>)<br>
<i>Mon, 26 Aug 1996 18:37:38 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#524">[ date ]</a><a href="index.html#524">[ thread ]</a><a href="subject.html#524">[ subject ]</a><a href="author.html#524">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0525.html">Twirlip of Greymist: "PHIL: Information _is_ the new soul"</a>
<li> <b>Previous message:</b> <a href="0523.html">John K Clark: "The Great Filter"</a>
<li> <b>Maybe in reply to:</b> <a href="0491.html">Peter Voss: "Controlling AI (was: Thinking about the future...)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0538.html">Max More: "Re: Controlling AI (was: Thinking about the future...)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt;At 01:06 PM 8/26/96 GMT2, Stephen de Vries wrote:</i><br>
<i>&gt; Do you want to live on through your genes, or your memes ?</i><br>
<p>
Max answered that better than I could - after all he wrote The Book (on<br>
identity).<br>
<p>
Just a comment on Anders' thoughts re the similarity between genetic and<br>
memetic evolution: I am quite suspicious of stretching this metaphor/analogy<br>
too far. It is important to remember that it IS a metaphor. It might be a<br>
useful discussion to identify differences. Any takers ?<br>
<p>
I liked your 'hitching a ride into a posthuman world... on the brainstem'.<br>
That may just protect us from rogue AIs.<br>
<p>
Let me also fuel my endless (but enjoyable) debate with Robin who cautions<br>
Max not to 'attribute too much to values and too little to social<br>
institutions'. Social institution ARE caused by and based on values.<br>
Philosophy can help us figure out values that may give us the kind of<br>
institutions that we want - eg. Extropy Institute is first and foremost a<br>
result of peoples value.<br>
<p>
Another good thread might be Robin's suggestion as to what kind of AI's we<br>
should fear.<br>
<p>
Peter<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0525.html">Twirlip of Greymist: "PHIL: Information _is_ the new soul"</a>
<li> <b>Previous message:</b> <a href="0523.html">John K Clark: "The Great Filter"</a>
<li> <b>Maybe in reply to:</b> <a href="0491.html">Peter Voss: "Controlling AI (was: Thinking about the future...)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0538.html">Max More: "Re: Controlling AI (was: Thinking about the future...)"</a>
<!-- reply="end" -->
</ul>
