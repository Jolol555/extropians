<!-- received="Fri Nov 22 02:00:02 1996 MST" -->
<!-- sent="Fri, 22 Nov 1996 02:36:13 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="eliezer@pobox.com" -->
<!-- subject="Interim purpose" -->
<!-- id="199611151908.MAA22093@primenet.com" -->
<!-- inreplyto="" -->
<title>extropians: Interim purpose</title>
<h1>Interim purpose</h1>
Eliezer Yudkowsky (<i>eliezer@pobox.com</i>)<br>
<i>Fri, 22 Nov 1996 02:36:13 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3178">[ date ]</a><a href="index.html#3178">[ thread ]</a><a href="subject.html#3178">[ subject ]</a><a href="author.html#3178">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3179.html">David Musick: "Transforming Ourselves"</a>
<li> <b>Previous message:</b> <a href="3177.html">Max More: "Re: God"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
This is a conversation I am echoing to the Extropian mailing list. The<br>
other principal does not read the mailing list.<br>
<p>
---------------------<br>
Date: Thu, 21 Nov 1996 01:27:08 -0800<br>
From: Tim Freeman &lt;tim@infoscreen.com&gt;<br>
<p>
I read your pages starting at<br>
<p>
   <a href="http://tezcat.com/~eliezer/beyond.shtml">http://tezcat.com/~eliezer/beyond.shtml</a><br>
<p>
following the citation you posted to the Extropians list.<br>
<p>
I agree with your criticism of the story about the person getting his<br>
hand fixed after it was run over with a car.  Cars, biological people,<br>
and hands are all obsoleted by other elements in the scenario.<br>
<p>
I don't agree that getting to to the Singularity ASAP should be the<br>
interim goal.  Instead, I think the goal should be to get to the<br>
Singularity with as high a probability as possible.  First priority is<br>
that somebody gets to it; second priority is that I get to it (perhaps<br>
repeatedly self-transcending along the way).  The human suffering that<br>
happens between now and then is small in the grand scheme of things,<br>
and is insignificant compared to the suffering or lost experience that<br>
would happen in any scenario that doesn't end in Singularity.<br>
<p>
Drexler once said (I paraphrase) the sooner nanotech happens, the<br>
slower it will happen.  That is, the sooner we start work on trying to<br>
achieve nanotech, the more primitive the supporting technology around<br>
it will be, so a greater amount of time will pass between when it<br>
starts to attract enough attention for people to start planning for<br>
the consequences, and the time when those consequences happen.  So<br>
there is some overlap between the goals of doing it soon and doing it<br>
with high probability.<br>
<p>
It seems to me that there is a good chance it won't happen by 2035.<br>
We haven't a clue about how to build a stable transhuman society, or<br>
even a stable transhuman for that matter.  The social practices of<br>
biological humans are going to be hard to incorporate into our<br>
creations, and there's a good chance that they wouldn't be the right<br>
practices to incorporate anyway.  The disequilibrium introduced by<br>
technology will slow the progress of the technology.  It is prudent to<br>
position yourself so you will be able to wait.  Life extension is<br>
important.  Calorie Restriction is the best technology available now,<br>
IMO.  Cryonics comes a close second; the question with it in my mind<br>
is whether too much change will happen before the people are revived<br>
for those people to be anything other than pets.<br>
<p>
I agree with you that it might be worthwhile trying to form an<br>
intensional community of people consciously striving for stability in<br>
the presence of change.  In The Diamond Age by Neal Stephenson, Nell<br>
notices at one point that she needs to be in a tribe to accomplish<br>
anything, since any individual can be overcome by a group.  Algernons<br>
would have a particularly intense need to be in a tribe of people who<br>
would have capabilities complementary to their own.<br>
<p>
I know three people who are competent to do life extension research<br>
but aren't doing it now because the money isn't forthcoming.  I don't<br>
think the immediate obstacle is lack of vision or skill; I think it is<br>
lack of money backing the right projects.  In my mind this raises the<br>
importance of ordinary success in the business world, since that is<br>
ultimately where the money has to come from.  <br>
<p>
Tim Freeman<br>
--------------------------------------<br>
Date: Thu, 21 Nov 1996 19:07:03 -0600<br>
From: Eliezer Yudkowsky &lt;eliezer@pobox.com&gt;<br>
<p>
<i>&gt; I know three people who are competent to do life extension research</i><br>
<i>&gt; but aren't doing it now because the money isn't forthcoming.  I don't</i><br>
<i>&gt; think the immediate obstacle is lack of vision or skill; I think it is</i><br>
<i>&gt; lack of money backing the right projects.  In my mind this raises the</i><br>
<i>&gt; importance of ordinary success in the business world, since that is</i><br>
<i>&gt; ultimately where the money has to come from.</i><br>
<p>
Oh, aye, indeed, and precisely.<br>
Lack of financial backing is probably the major obstacle at this time.<br>
My hope is to solve that problem, personally, if it persists. If Bill<br>
Gates - who is funding life-extension research - suddenly gets stricken<br>
by a vision of the Singularity, that would probably accelerate it by 1-2<br>
years. <br>
<p>
<i>&gt; Algernons would have a particularly intense need to be in a tribe of </i><br>
<i>&gt; people who would have capabilities complementary to their own.</i><br>
<p>
The right "tribe", given me, could probably build up enough money to<br>
make it to the Singularity in, say, five years max. The only reason I'm<br>
not doing that right now is because I want another six months (or two,<br>
or eight) to accumulate fame, through methods I shall not speak of,<br>
before looking for companions and venture capital.<br>
<p>
<i>&gt; It seems to me that there is a good chance it won't happen by 2035.</i><br>
<p>
If it doesn't happen by 2035, it's not going to happen at all. The<br>
minimum-time path to the Singularity is the maximum-probability path to<br>
the Singularity; the problem at this point isn't lack of technology,<br>
it's lack of time. How long do you think things are going to last?<br>
<p>
<i>&gt; We haven't a clue about how to build a stable transhuman society, or</i><br>
<i>&gt; even a stable transhuman for that matter.</i><br>
<p>
Stable transhumans are a problem, yes, but even an unstable transhuman<br>
could probably make it to the Singularity in three months. They don't<br>
need to be *that* stable. Even if they don't survive, they will make the<br>
sacrifice. A fatal Neural Growth Factor is better than none.<br>
<p>
As for a stable transhuman society, don't worry. Just don't worry.<br>
It will be stable. A society of Algernons won't be stable. A society of<br>
Countersphexists would probably be stable, assuming it survived. A<br>
society of transhumans with Countersphexist abilities plus the abilities<br>
of a full human isn't going to have anything to worry about. They would<br>
make it to the Singularity in between two weeks and six months.<br>
<p>
<i>&gt; Cryonics comes a close second; the question with it in my mind</i><br>
<i>&gt; is whether too much change will happen before the people are revived</i><br>
<i>&gt; for those people to be anything other than pets.</i><br>
<p>
Two words: Moravec Transfer.<br>
The Powers will be ethical. I am more certain of that than I am of the<br>
sun rising tomorrow. For the Powers to knock us off for our spare atoms<br>
without even making backups, our survival would have to somehow threaten<br>
the Powers AND human life would have to have no meaning.<br>
<p>
<i>&gt; Drexler once said (I paraphrase) the sooner nanotech happens, the</i><br>
<i>&gt; slower it will happen.  That is, the sooner we start work on trying to</i><br>
<i>&gt; achieve nanotech, the more primitive the supporting technology around</i><br>
<i>&gt; it will be, so a greater amount of time will pass between when it</i><br>
<i>&gt; starts to attract enough attention for people to start planning for</i><br>
<i>&gt; the consequences, and the time when those consequences happen.  So</i><br>
<i>&gt; there is some overlap between the goals of doing it soon and doing it</i><br>
<i>&gt; with high probability.</i><br>
<p>
Like heck. It's entirely possible that the actual time to Singularity is<br>
precisely 14 hours after I (or the right Algernons) walk into a<br>
nanotechnology lab. They're completely right to get as much substrate as<br>
possible in place *now*; one breakthrough and we'd need it all.<br>
<p>
Seeing as how this discussion is more interesting than all other threads<br>
on the Extropian list, I propose we move it there. Am I seconded?<br>
<p>
Up and Out,<br>
Eliezer S. Yudkowsky<br>
-------------------------------------<br>
Date: Thu, 21 Nov 1996 20:25:38 -0800<br>
From: Tim Freeman &lt;tim@infoscreen.com&gt;<br>
<p>
<i>&gt;If Bill Gates - who is funding life-extension research - suddenly gets</i><br>
<i>&gt;stricken by a vision of the Singularity, that would probably</i><br>
<i>&gt;accelerate it by 1-2 years.</i><br>
<p>
I didn't know Bill Gates is funding life-extension research.  Is there<br>
evidence for this you can disclose?  There is at least one relatively<br>
small-budget experiment I'd like to make sure he considered funding:<br>
Does aminoguanadine extend the lifespan of (put your rodent of choice<br>
here)?  It allegedly prevents non-enzymatic glycolysation, and it<br>
seemed to prevent some signs of aging in a relatively short pilot<br>
experiment.<br>
<p>
I said:<br>
<i>&gt; Cryonics comes a close second; the question with it in my mind</i><br>
<i>&gt; is whether too much change will happen before the people are revived</i><br>
<i>&gt; for those people to be anything other than pets.</i><br>
<p>
and you said:<br>
<i>&gt;Two words: Moravec Transfer.</i><br>
<i>&gt;The Powers will be ethical. I am more certain of that than I am of the</i><br>
<i>&gt;sun rising tomorrow. For the Powers to knock us off for our spare atoms</i><br>
<i>&gt;without even making backups, our survival would have to somehow threaten</i><br>
<i>&gt;the Powers AND human life would have to have no meaning.</i><br>
<p>
I'm not too concerned about being revived by evil people; I don't<br>
think evil people would take the trouble.  I am concerned about being<br>
revived into a situation that is far enough advanced that even with<br>
the available improvements I have nothing to contribute, and am<br>
therefore irrelevant.  If you focus on the consequences, there is no<br>
important difference between being irrelevant and being dead.<br>
<p>
<i>&gt;Seeing as how this discussion is more interesting than all other threads</i><br>
<i>&gt;on the Extropian list, I propose we move it there. Am I seconded?</i><br>
<p>
Fine with me (that is, feel free to quote anything I said to you).  Be<br>
aware that I don't read that list except occasionally via the<br>
archives.  It ruins my focus.<br>
<p>
Tim Freeman<br>
----------------------------------<br>
Date: Fri, 22 Nov 1996 02:27:52 -0600<br>
From: Eliezer Yudkowsky &lt;eliezer@pobox.com&gt;<br>
<p>
<i>&gt; I didn't know Bill Gates is funding life-extension research.  Is there</i><br>
<i>&gt; evidence for this you can disclose?</i><br>
<p>
Um, not offhand. I read once - maybe in Great Mambo Chicken - that "Bill<br>
Gates is pouring money into biotechnology companies, looking for the<br>
secret of eternal youth." Dunno where to start checking it out.<br>
<p>
<i>&gt; I'm not too concerned about being revived by evil people; I don't</i><br>
<i>&gt; think evil people would take the trouble.  I am concerned about being</i><br>
<i>&gt; revived into a situation that is far enough advanced that even with</i><br>
<i>&gt; the available improvements I have nothing to contribute, and am</i><br>
<i>&gt; therefore irrelevant.  If you focus on the consequences, there is no</i><br>
<i>&gt; important difference between being irrelevant and being dead.</i><br>
<p>
Uploading is generally followed by upgrading.<br>
Do you think that's impossible or that nobody's going to bother?<br>
<p>
It's not going to be impossible for a Power.<br>
<p>
And with computer power doubling every two seconds, I think they'll have<br>
the room sooner or later.<br>
<p>
And why wouldn't they bother to direct a fraction of a fraction of a<br>
subconscious sub-personality to put in the necessary effort?<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3179.html">David Musick: "Transforming Ourselves"</a>
<li> <b>Previous message:</b> <a href="3177.html">Max More: "Re: God"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
