<!-- received="Fri Dec 27 14:39:18 1996 MST" -->
<!-- sent="Fri, 27 Dec 1996 13:02:56 -0800 (PST)" -->
<!-- name="Lee Daniel Crocker" -->
<!-- email="lcrocker@calweb.com" -->
<!-- subject="Re: Profiting on tragedy? (was Humour)" -->
<!-- id="199612272102.NAA18952@web2.calweb.com" -->
<!-- inreplyto="32C36660.4038@pobox.com" -->
<title>extropians: Re: Profiting on tragedy? (was Humour)</title>
<h1>Re: Profiting on tragedy? (was Humour)</h1>
Lee Daniel Crocker (<i>lcrocker@calweb.com</i>)<br>
<i>Fri, 27 Dec 1996 13:02:56 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#4853">[ date ]</a><a href="index.html#4853">[ thread ]</a><a href="subject.html#4853">[ subject ]</a><a href="author.html#4853">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4854.html">Eric Watt Forste: "Re: Humour"</a>
<li> <b>Previous message:</b> <a href="4852.html">arkuat: "MEMETICS: Evol. psych. connection between drugs and cults"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4910.html">Eugene Leitl: "Re: Profiting on tragedy? (was Humour)"</a>
<li> <b>Reply:</b> <a href="4910.html">Eugene Leitl: "Re: Profiting on tragedy? (was Humour)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; &gt; I'm not sure I understand the connection between Extropianism and the Final</i><br>
<i>&gt; &gt; Solution. They seem diametrically opposed to me. I grant you that some</i><br>
<i>&gt; &gt; extropian concepts could be misconstrued or misrepresented.</i><br>
<i>&gt; </i><br>
<i>&gt; Superintelligent robots = Aryans, humans = Jews.</i><br>
<i>&gt; The only thing preventing this is sufficiently intelligent robots. </i><br>
<p>
Nonsense.  What will prevent it is sufficiently /moral/ robots.<br>
Intelligence is a not a sufficient condition for morality, and<br>
perhaps not even a necessary one.<br>
<p>
If one buys Rand's contention that normative philosophy (ethics,<br>
politics) can be rationally derived from objective reality, then we<br>
can assume that very intelligent robots will reason their way into<br>
benevolence toward humans.  I, for one, am not convinced of Rand's<br>
claim in this regard, so I would wish to have explicit moral codes<br>
built into any intelligent technology that could not be overridden<br>
except by their human creators.  If such intelligences could reason<br>
their way toward better moral codes, they would still have to<br>
convince us humans, with human reason, to build them.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="4854.html">Eric Watt Forste: "Re: Humour"</a>
<li> <b>Previous message:</b> <a href="4852.html">arkuat: "MEMETICS: Evol. psych. connection between drugs and cults"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="4910.html">Eugene Leitl: "Re: Profiting on tragedy? (was Humour)"</a>
<li> <b>Reply:</b> <a href="4910.html">Eugene Leitl: "Re: Profiting on tragedy? (was Humour)"</a>
<!-- reply="end" -->
</ul>
