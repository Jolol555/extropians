<!-- received="Tue Aug 27 17:29:08 1996 MST" -->
<!-- sent="Tue, 27 Aug 1996 16:27:56 -0700" -->
<!-- name="Peter Voss" -->
<!-- email="p.voss@ix.netcom.com" -->
<!-- subject="Re: AI at all costs. (Was thinking about the future)" -->
<!-- id="2.2.16.19960827150326.08f7959c@popd.ix.netcom.com" -->
<!-- inreplyto="AI at all costs. (Was thinking about the future)" -->
<title>extropians: Re: AI at all costs. (Was thinking about the future)</title>
<h1>Re: AI at all costs. (Was thinking about the future)</h1>
Peter Voss (<i>p.voss@ix.netcom.com</i>)<br>
<i>Tue, 27 Aug 1996 16:27:56 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#532">[ date ]</a><a href="index.html#532">[ thread ]</a><a href="subject.html#532">[ subject ]</a><a href="author.html#532">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0533.html">Eric Watt Forste: "The Great Filter"</a>
<li> <b>Previous message:</b> <a href="0531.html">E. Shaun Russell: "Extropian Poetry"</a>
<li> <b>Maybe in reply to:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0540.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
At 02:09 PM 27/8/96 GMT2, Stephen de Vries wrote:<br>
<p>
<i>&gt;As I see it, imortalists can be divided into two groups: those who </i><br>
<i>&gt;want to live on through there current minds and/or bodies, and those </i><br>
<i>&gt;who don`t care how the "I" fits into the picture as long as the </i><br>
<i>&gt;descendants are "better" than the current version of "I".</i><br>
<p>
You set up a false dichotomy. The first group does not want to live only<br>
through their *current* minds and bodies. We want to transform them and to<br>
add to them progressively so as to maintain identity in the process. We also<br>
want to choose which aspects of our minds and bodies to retain and for how<br>
long. You are right in saying that we care about our 'I's. Very much so!<br>
<p>
<i>&gt;I lurch into the latter categorie, my loyalty lies with neg-entropy </i><br>
<i>&gt;and complexity.  Self sacrifice in the face of a humanity threatening </i><br>
<i>&gt;AI is not part of this belief system, (self-sacrifice is never an </i><br>
<i>&gt;option), but neither is standing in the way of developing a </i><br>
<i>&gt;superior intelligent technology ("Artificial" and "Sinthetic" are </i><br>
<i>&gt;emotively biased terms).  People generally like the idea of growing </i><br>
<i>&gt;bigger brains, as long as these are biological based and not anything </i><br>
<i>&gt;as drastic as growing intelligences in a neural net (in-silico).</i><br>
<p>
May I point out a contradiction ? 'I lurch...' Here you use 'I' in the<br>
conventional sense - it cannot mean anything else. Then in 'self-sacrifice'<br>
you refer to some kind of collective consciousness or evolutionary process.<br>
You do indeed believe in self-sacrifice in the usual meaning of the word 'I'<br>
and 'self'.<br>
<p>
<i>&gt;"I" am not as small as my body + brain + mind, the only thing that is </i><br>
<i>&gt;in essence me, is the "life force" which permeates all that is alive.... </i><br>
<i>&gt;The life force is all that I can recognize to be at the center of </i><br>
<i>&gt;"me", so my loyalty lies with it, not my current body, mind or thoughts.</i><br>
<p>
You confuse two quite separate concepts: 'I' and 'life'. You *are* alive,<br>
you *have* 'life-force'(LF). 'You' are not equal to LF. Other entities also<br>
have it. So even if you believe in some collective consciousness, nature or<br>
LF then 'you' is a part of that and is not identical too it.<br>
<p>
If your loyalty lies with the 'life-force', then that is indeed a very<br>
fundamental difference to what some (most?) of us believe. I must regard<br>
anyone who truly believes that I am less important than the 'life-force' ie.<br>
that I can be sacrificed to it, as extremely dangerous. We *are* back to<br>
altruism: sacrifice of self to a 'higher' good - God, religion, race,<br>
country, nature, progress, etc. - Scary.<br>
<p>
Peter<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0533.html">Eric Watt Forste: "The Great Filter"</a>
<li> <b>Previous message:</b> <a href="0531.html">E. Shaun Russell: "Extropian Poetry"</a>
<li> <b>Maybe in reply to:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0540.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
