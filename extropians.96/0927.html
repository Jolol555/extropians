<!-- received="Thu Sep 12 17:30:57 1996 MST" -->
<!-- sent="Thu, 12 Sep 96 16:19:35 PDT" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@dosh.hum.caltech.edu" -->
<!-- subject="Re: Darwinian Extropy" -->
<!-- id="9609122319.AA22293@dosh.hum.caltech.edu" -->
<!-- inreplyto="3235FE9F.7803@shirenet.com" -->
<title>extropians: Re: Darwinian Extropy</title>
<h1>Re: Darwinian Extropy</h1>
Robin Hanson (<i>hanson@dosh.hum.caltech.edu</i>)<br>
<i>Thu, 12 Sep 96 16:19:35 PDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#927">[ date ]</a><a href="index.html#927">[ thread ]</a><a href="subject.html#927">[ subject ]</a><a href="author.html#927">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0928.html">David Musick: "100% Natural"</a>
<li> <b>Previous message:</b> <a href="0926.html">Robin Hanson: "Long Economic Cycles"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Dan Clemmensen writes:<br>
<i>&gt;&gt; &gt;... There may not be a lot of diverse SIs</i><br>
<i>&gt;&gt; &gt;in the universe. There may be only one per system, and they may all</i><br>
<i>&gt;&gt; &gt;have reached the same super-logical conclusion that star travel is</i><br>
<i>&gt;&gt; &gt;uneconomical in terms of the resources that SIs use.</i><br>
<i>&gt;&gt;</i><br>
<i>&gt;&gt; ... to make your scenario plausible, you need a plausible process which</i><br>
<i>&gt;&gt; creates this massive convergence to a preference with almost no weight</i><br>
<i>&gt;&gt; on long-time-scale returns. </i><br>
<i>&gt;</i><br>
<i>&gt;... An SI is likely to have conscious control of its internal</i><br>
<i>&gt;archecture, so the postulated subconscious human group-think may not</i><br>
<i>&gt;be relevant.</i><br>
<i>&gt;Please note: I'm still not arguing that my model of an SI is the</i><br>
<i>&gt;correct one, only that it's plausible.</i><br>
<p>
It seems to me that in the absence of a process pushing conformity,<br>
one should expect diversity, at least when we're talking about<br>
motivations across the entire visible universe.  Yes, it's possible<br>
there is such a process we don't know anything about, but this simple<br>
statement does not make the conclusion "plausible", only "posibble".<br>
Otherwise any not-logically-impossible conclusion would be<br>
"plausible".<br>
<p>
<i>&gt;Your [Anders'] scenario may be plausible, but I feel that my scenario</i><br>
<i>&gt;is more likely: the Initial SI (for example an experimenter together</i><br>
<i>&gt;with a workstation and a bunch of software) is capable of rapid</i><br>
<i>&gt;self-augmentation.  Since the experimenter and the experiment are</i><br>
<i>&gt;likely to be oriented toward developing an SI, the self-augmentation</i><br>
<i>&gt;is likely to result in rapid intelligence gain. </i><br>
<p>
Most complex systems we know of are capable of rapid<br>
self-augmentation.  People can change, companies can change, and<br>
nations can change.  *Useful* rapid change is a lot harder, however,<br>
and you have offered no plausible argument why such useful rapid<br>
change is any more likely here than for other complex systems.  Again,<br>
yes, it is logically possible.  But that is hardly a plausibility<br>
argument.<br>
<p>
Robin Hanson  hanson@hss.caltech.edu  <a href="http://hss.caltech.edu/~hanson/">http://hss.caltech.edu/~hanson/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0928.html">David Musick: "100% Natural"</a>
<li> <b>Previous message:</b> <a href="0926.html">Robin Hanson: "Long Economic Cycles"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
