<!-- received="Wed Aug 28 10:16:16 1996 MST" -->
<!-- sent="Wed, 28 Aug 1996 11:29:05 GMT2" -->
<!-- name="Stephen de Vries" -->
<!-- email="PHEN@wwg3.uovs.ac.za" -->
<!-- subject="Re: AI at all costs. (Was thinking about the future)" -->
<!-- id="199608280652.XAA02403@primenet.com" -->
<!-- inreplyto="AI at all costs. (Was thinking about the future)" -->
<title>extropians: Re: AI at all costs. (Was thinking about the future)</title>
<h1>Re: AI at all costs. (Was thinking about the future)</h1>
Stephen de Vries (<i>PHEN@wwg3.uovs.ac.za</i>)<br>
<i>Wed, 28 Aug 1996 11:29:05 GMT2</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#540">[ date ]</a><a href="index.html#540">[ thread ]</a><a href="subject.html#540">[ subject ]</a><a href="author.html#540">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Previous message:</b> <a href="0539.html">Max More: "Re: Extropian Poetry"</a>
<li> <b>Maybe in reply to:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Tue, 27 Aug Peter Voss writes:<br>
<p>
<i>&gt; Stephen de Vries wrote:</i><br>
<i>&gt;</i><br>
<i>&gt; &gt;I lurch into the latter categorie, my loyalty lies with neg-entropy </i><br>
<i>&gt; &gt;and complexity.  Self sacrifice in the face of a humanity threatening </i><br>
<i>&gt; &gt;AI is not part of this belief system, (self-sacrifice is never an </i><br>
<i>&gt; &gt;option), but neither is standing in the way of developing a </i><br>
<i>&gt; &gt;superior intelligent technology ("Artificial" and "Sinthetic" are </i><br>
<i>&gt; &gt;emotively biased terms).  People generally like the idea of growing </i><br>
<i>&gt; &gt;bigger brains, as long as these are biological based and not anything </i><br>
<i>&gt; &gt;as drastic as growing intelligences in a neural net (in-silico).</i><br>
<i>&gt; </i><br>
<i>&gt; May I point out a contradiction ? 'I lurch...' Here you use 'I' in the</i><br>
<i>&gt; conventional sense - it cannot mean anything else.</i><br>
<p>
Yes, it doesn`t.<br>
<p>
<i>&gt; Then in 'self-sacrifice'</i><br>
<i>&gt; you refer to some kind of collective consciousness or evolutionary process.</i><br>
<i>&gt; You do indeed believe in self-sacrifice in the usual meaning of the word 'I'</i><br>
<i>&gt; and 'self'.</i><br>
<p>
Sorry for the shabby definitions, in "self-sacrifice" I intended <br>
"self" to represent the LF.<br>
<p>
<i>&gt; &gt;"I" am not as small as my body + brain + mind, the only thing that is </i><br>
<i>&gt; &gt;in essence me, is the "life force" which permeates all that is alive.... </i><br>
<i>&gt; &gt;The life force is all that I can recognize to be at the center of </i><br>
<i>&gt; &gt;"me", so my loyalty lies with it, not my current body, mind or thoughts.</i><br>
<i>&gt; </i><br>
<i>&gt; You confuse two quite separate concepts: 'I' and 'life'. You *are* alive,</i><br>
<i>&gt; you *have* 'life-force'(LF). 'You' are not equal to LF. Other entities also</i><br>
<i>&gt; have it. So even if you believe in some collective consciousness, nature or</i><br>
<i>&gt; LF then 'you' is a part of that and is not identical too it.</i><br>
<p>
True, if we continue with this analogy, then the life force is the <br>
order in my particles, I am the particles + the order in them.<br>
<p>
<i>&gt; If your loyalty lies with the 'life-force', then that is indeed a very</i><br>
<i>&gt; fundamental difference to what some (most?) of us believe. I must regard</i><br>
<i>&gt; anyone who truly believes that I am less important than the 'life-force' ie.</i><br>
<i>&gt; that I can be sacrificed to it, as extremely dangerous.</i><br>
<p>
Only a nose hair.<br>
<p>
<i>&gt; We *are* back to</i><br>
<i>&gt; altruism: sacrifice of self to a 'higher' good - God, religion, race,</i><br>
<i>&gt; country, nature, progress, etc. - Scary.</i><br>
<p>
Again we differ on the definition of self.  I(Stephen de Vries, I.D. <br>
no. 75060751810...) regard myself rather as a fanatic than an <br>
altruist.<br>
<p>
If there is nothing worth dying for, then there`s nothing worth living <br>
for.<br>
<p>
Fundamentally yours<br>
---------------------------------------------------------------------<br>
Stephen de Vries                            <br>
www.geocities.com/athens/7415<br>
<p>
   "Some will fall in love with life and drink it from a fountain<br>
    that is falling like an avalanche coming down a mountain"<br>
    - The Butthole Surfers<br>
    <br>
    <br>
                           <br>
  <br>
               <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<li> <b>Previous message:</b> <a href="0539.html">Max More: "Re: Extropian Poetry"</a>
<li> <b>Maybe in reply to:</b> <a href="0515.html">Stephen de Vries: "AI at all costs. (Was thinking about the future)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0541.html">Stephen de Vries: "Re: AI at all costs. (Was thinking about the future)"</a>
<!-- reply="end" -->
</ul>
