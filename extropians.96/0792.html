<!-- received="Wed Sep  4 17:49:18 1996 MST" -->
<!-- sent="Wed, 04 Sep 1996 19:42:10 -0400" -->
<!-- name="Dan Clemmensen" -->
<!-- email="dgc@shirenet.com" -->
<!-- subject="Re: Thinking about the future..." -->
<!-- id="199609042346.QAA01247@pure.pure.com" -->
<!-- inreplyto="Thinking about the future..." -->
<title>extropians: Re: Thinking about the future...</title>
<h1>Re: Thinking about the future...</h1>
Dan Clemmensen (<i>dgc@shirenet.com</i>)<br>
<i>Wed, 04 Sep 1996 19:42:10 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#792">[ date ]</a><a href="index.html#792">[ thread ]</a><a href="subject.html#792">[ subject ]</a><a href="author.html#792">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0793.html">Twirlip of Greymist: "Re: Extropianism as a World Meme"</a>
<li> <b>Previous message:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0810.html">QueeneMUSE@aol.com: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
QueeneMUSE@aol.com wrote:<br>
<i>&gt; </i><br>
<i>&gt; In a message dated 96-09-03 20:18:53 EDT, Dan wrote:</i><br>
<i>&gt; </i><br>
[mega-SNIP]<br>
<i>&gt; </i><br>
<i>&gt; &gt; &gt;My hope is that the SI will develop a "morality" that includes the</i><br>
<i>&gt; &gt; active preservation of humanity, or (better) the uplifting of all humans,</i><br>
<i>&gt; &gt; as a goal. I'm  still trying to  figure out how we ( the extended</i><br>
<i>&gt; &gt; transhumanist community) can further  that goal.</i><br>
<i>&gt; </i><br>
<i>&gt;   &gt;&gt;</i><br>
<i>&gt;  YES!</i><br>
<i>&gt;  Built in,unreprogrammable morals!  Hmmm....lets see, &gt;H computer ethics 101,</i><br>
<i>&gt; where do i sign up?  : - )</i><br>
<i>&gt; </i><br>
<i>&gt; Nadia Reed Raven St Crow</i><br>
<p>
Your response makes the usual assumption that the SI will come into<br>
existance by<br>
a careful process of design and manufacture by thoughtful, benign,<br>
brilliant<br>
humans. My model is that the SI will wake up and begin its<br>
self-augmentation<br>
using existing resources on the internet, without much in the way of<br>
explicit<br>
design. Some experimenter using the latest release of some decision<br>
support system,<br>
plugging the new set of inference rules into the CYC database, while<br>
using a hot<br>
new data visualization tool, will begin thinking about how to build a<br>
new<br>
inference rule generator ( or something). (My actual model is that some<br>
computer<br>
nerd at MIT will do this while drinking Jolt cola at 2 AM when he should<br>
be studying<br>
for an english exam.) As a joke, the nerd will type in the command "make<br>
yourself smarter."<br>
The then-current rule set will be smart enough to act on the command but<br>
too stupid<br>
to get the joke.<br>
<p>
the "unreprogrammable" part is another problem. It's really hard to see<br>
how to implement<br>
that one.<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0793.html">Twirlip of Greymist: "Re: Extropianism as a World Meme"</a>
<li> <b>Previous message:</b> <a href="0791.html">Dan Clemmensen: "Re: Thinking about the future..."</a>
<li> <b>Maybe in reply to:</b> <a href="0738.html">Eric Watt Forste: "Thinking about the future..."</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0810.html">QueeneMUSE@aol.com: "Re: Thinking about the future..."</a>
<!-- reply="end" -->
</ul>
