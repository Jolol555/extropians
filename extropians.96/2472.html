<!-- received="Sun Nov  3 11:06:12 1996 MST" -->
<!-- sent="Sun, 03 Nov 1996 10:40:11 -0500" -->
<!-- name="Michael Lorrey" -->
<!-- email="retroman@tpk.net" -->
<!-- subject="Re: Uploading" -->
<!-- id="199611031620.IAA09744@well.com" -->
<!-- inreplyto="Uploading" -->
<title>extropians: Re: Uploading</title>
<h1>Re: Uploading</h1>
Michael Lorrey (<i>retroman@tpk.net</i>)<br>
<i>Sun, 03 Nov 1996 10:40:11 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2472">[ date ]</a><a href="index.html#2472">[ thread ]</a><a href="subject.html#2472">[ subject ]</a><a href="author.html#2472">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2473.html">Michael Lorrey: "Re: How Many Points is a Soul?"</a>
<li> <b>Previous message:</b> <a href="2471.html">John K Clark: "Thought Experiments About Copies"</a>
<li> <b>Maybe in reply to:</b> <a href="2725.html">John K Clark: "Uploading"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2511.html">Michael Lorrey: "Re: Uploading"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
John K Clark wrote:<br>
<i>&gt; </i><br>
<i>&gt; -----BEGIN PGP SIGNED MESSAGE-----</i><br>
<i>&gt; </i><br>
<i>&gt; James Rogers  jamesr@best.com  On Fri, 1 Nov 1996 Wrote:</i><br>
<i>&gt;</i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;If I am not mistaken, the "Information can not be moved,</i><br>
<i>&gt;                 &gt;only copied" theorem has been proven  mathematically.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; I very much doubt such a murky idea can even be expressed mathematically,</i><br>
<i>&gt; much less be proved or disproved.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;I am not saying it is impossible to upload; it is impossible</i><br>
<i>&gt;                 &gt;only in the sense of uploading a single, existing stream of</i><br>
<i>&gt;                 &gt;consciousness as opposed to creating a new stream of</i><br>
<i>&gt;                 &gt;consciousness.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; Every time the telephone rings my stream of consciousness is interrupted,</i><br>
<i>&gt; when you read this post your consciousness is different than it would be if</i><br>
<i>&gt; you were reading another post. I don't see why that is such a big deal that</i><br>
<i>&gt; it makes us different people.</i><br>
<p>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;If consciousness is based upon information and information</i><br>
<i>&gt;                 &gt;processing, my above statements  hold.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; Unless the religious people are right, consciousness must be based on</i><br>
<i>&gt; information processing, that's why I don't understand your theory. You're</i><br>
<i>&gt; saying, I think, that information exists outside our physical universe,</i><br>
<i>&gt; if so  then the information in my head and the information in my upload a</i><br>
<i>&gt; thousand  miles away must be the same, after all you also say " a physical</i><br>
<i>&gt; translation  in space of the substrate is irrelevant".  Also, I don't see why</i><br>
<i>&gt; you keep distinguishing between "originals" and "copies", if your theory is</i><br>
<i>&gt; right then everything in the physical universe is a "copy".</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;There can be many instances of a single brain, each with its</i><br>
<i>&gt;                 &gt;own consciousness.</i><br>
<p>
I beleive that there is a significant difference between copying a<br>
conciousness, which operates independently of a root conciousness, and a<br>
gradual process of gradually copying one's various files one at a time,<br>
verifying operability, and then transfering processing tothe new file<br>
from the old, and deleting the old.  This would maintain the individual<br>
stream of conciousness, while the first, in the instance of destructive<br>
copying, would not, relative to the original wetware. When we talk about<br>
stream of conciousness, we need to maintain that this is relative to the<br>
original copy.  It does not matter if the original copy shuts down for<br>
defragging once a day, it is still itself because it only copied and<br>
erased minute fractions of its conciousness at any one time, and we know<br>
that a human can operate with a significant loss of brain capacity, just<br>
not with a total loss, although facetiously, I can think of some<br>
congressmen who seem to be doing just fine.<br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt; Yes, I believe it would be possible in theory for a brain to generate more</i><br>
<i>&gt; than one consciousness, and I think it's possible for one consciousness to</i><br>
<i>&gt; run  on several brains.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;Information is only encoded on objects that exist in the</i><br>
<i>&gt;                 &gt;physical universe.</i><br>
<i>&gt; </i><br>
<i>&gt; I don't understand why you say "only encoded" like it's not important,</i><br>
<i>&gt; because you also say "For information to exist, it must be encoded on a</i><br>
<i>&gt; substrate".</i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;If every piece of substrate containing a specific piece of</i><br>
<i>&gt;                 &gt;information is destroyed, the information is destroyed</i><br>
<i>&gt;                 &gt;permanently.</i><br>
<i>&gt; </i><br>
<i>&gt; Not necessarily. It would be difficult to destroy the information that</i><br>
<i>&gt; 2 + 2 = 4 because nobody knows where or how it's encoded. Even Shakespeare's</i><br>
<i>&gt; plays could be rediscovered by a monkey banging on a typewriter,  it would</i><br>
<i>&gt; take a long time, but not an infinitely long time.</i><br>
<p>
THis is merely obfuscation.  What he is saying is that a total loss of<br>
one's wetware at once equates to total loss of ones stream of<br>
conciouness.  Small losses can be accomodated for, and if copies of<br>
individual sectors can be used to augment ones bioware, then one could<br>
eventually slowly transfer one's conciousness, bit by bit to a new<br>
substrate.<br>
<p>
Here's a metaphor: You are an octopus in a bottle that has a small neck.<br>
THe bottle is opened and connected to another small necked bottle that<br>
has food in it (gotta have an attractor). The octopus could:<br>
<p>
A) Bud off a clone of itself and send it to the new bottle, whilst the<br>
clone is still baby sized. THe downside is that the original octopus is<br>
still in the old bottle and is getting hungrier, while the new octopus<br>
doesn't seem to give a whit.<br>
<p>
B) Slowly move, one leg of itself at a time, into the new bottle (I've<br>
seen this happen) until finally it squeezes its head through the neck,<br>
and is in the new bottle, munching away happily<br>
<i>&gt; </i><br>
<i>&gt; To my mind this does indeed give some support to the idea that information</i><br>
<i>&gt; can exist external to the physical universe, but certainly not to the idea</i><br>
<i>&gt; that there is a fundamental difference between a copy and an original or that</i><br>
<i>&gt; exactly the same information can't be encoded in 2 very different ways.</i><br>
<i>&gt; </i><br>
<i>&gt; </i><br>
<i>&gt;                 &gt;although our intelligence could be extended fairly easily,</i><br>
<i>&gt;                 &gt;our consciousness is irremovably tied to the overall</i><br>
<i>&gt;                 &gt;structure of our brain.</i><br>
<i>&gt; </i><br>
<i>&gt; I think that intelligent behavior and consciousness must be inextricably</i><br>
<i>&gt; linked, otherwise I don't see why we would be aware at all. However important</i><br>
<i>&gt; subjective feelings may be to us, Evolution is only interested in behavior</i><br>
<i>&gt; because only behavior enhances survival. Evolution would never have given us</i><br>
<i>&gt; consciousness unless it was needed for intelligence, that's one reason I</i><br>
<i>&gt; think the Turing Test works.</i><br>
Right and no intelligent being would freely give up his or her own<br>
conciousness for another, unless the stakes were pretty grim and in your<br>
face.<br>
<p>
We want to be immortal and uploaded as ourselves, not as somebody else<br>
who thinks "they is us."<br>
<p>
Mike Lorrey<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2473.html">Michael Lorrey: "Re: How Many Points is a Soul?"</a>
<li> <b>Previous message:</b> <a href="2471.html">John K Clark: "Thought Experiments About Copies"</a>
<li> <b>Maybe in reply to:</b> <a href="2725.html">John K Clark: "Uploading"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2511.html">Michael Lorrey: "Re: Uploading"</a>
<!-- reply="end" -->
</ul>
