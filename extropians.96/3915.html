<!-- received="Wed Dec 11 19:52:33 1996 MST" -->
<!-- sent="Wed, 11 Dec 1996 13:59:05 -0600" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity-worship" -->
<!-- id="1.5.4.32.19961212023207.0033e85c@best.com" -->
<!-- inreplyto="Singularity-worship" -->
<title>extropians: Re: Singularity-worship</title>
<h1>Re: Singularity-worship</h1>
Eliezer Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Wed, 11 Dec 1996 13:59:05 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3915">[ date ]</a><a href="index.html#3915">[ thread ]</a><a href="subject.html#3915">[ subject ]</a><a href="author.html#3915">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3916.html">Julio R. Vaquer: "Re: techno music/kraftwerk"</a>
<li> <b>Previous message:</b> <a href="3914.html">James Rogers: "Re: Beyond The Beyond"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3932.html">Eliezer Yudkowsky: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<i>&gt; Sounds like a fine idea, but I used no sophistry.</i><br>
<p>
You weren't the one I was thinking of, actually.<br>
<p>
To quote (by permission) Eric Watt Forste:<br>
<i>&gt; The word "self-justifying" is empty of content. Justification is a</i><br>
<i>&gt; relationship between two distinct information structures. If *anything*</i><br>
<i>&gt; is self-justifying, then everything is self-justifying; hence, the</i><br>
<i>&gt; phrase "self-justifying" does not distinguish a set to which it applies</i><br>
<i>&gt; from a set to which it does not apply. Terms that do not distinguish are</i><br>
<i>&gt; empty of content. Or perhaps you are prepared to explain to me what is</i><br>
<i>&gt; the precise difference between self-justifying and non-self-justifying</i><br>
<i>&gt; entities?</i><br>
<p>
<i>&gt; When you claim to have a  </i><br>
<i>&gt; solution to the deepest problem in Philosophy you should be prepared to  </i><br>
<i>&gt; defend it vigorously, have answers to difficult questions, and not just </i><br>
<i>&gt; expect everyone to automatically call you a genius.</i><br>
<p>
I am not objecting to genuine challenges to my ideas.  A reflexive<br>
argument that can be instantiated with any word whatsoever is not a<br>
genuine challenge.  Only the last sentence had any logical value, and I<br>
answered that with an example.<br>
<p>
I have explicitly denied a solution to the First Cause AND I have<br>
explicitly said that the First Cause is not the deepest problem in<br>
philosophy.<br>
<p>
And what is this whole business where every time I give a rational reply<br>
to an objection (rational or otherwise), people respond with a personal<br>
attack?  Whether I am a genius has no impact on the logical strength of<br>
my ideas on the First Cause, so I don't really care, speaking in my<br>
capacity as a philosopher, whether people call me a genius or not.  My<br>
capacity as the originator of Algernon's Law might have different ideas;<br>
there, my intellectual capacities are actually relevant.<br>
<p>
--------<br>
<i>&gt; That would seem to easily cover both of you cases. To repeat for the third </i><br>
<i>&gt; time, what's the difference between cognitive and computational causality?</i><br>
<p>
I am not claiming that cognitive causality will not run on a Turing<br>
machine.  I am saying that, when discussing "causality", one must be<br>
aware of how one's own cognitive architecture affects one's viewpoint. <br>
It is not particularly relevant whether our causal-analysis modules will<br>
run on a Turing Machine; the important thing is to say how they work. <br>
We know how Turing machines work.  Do you know how causal analysis<br>
works?  Can you design a computer program that will do it?  A Universal<br>
Turing Machine is not an acceptable answer to this AI problem.<br>
<p>
"Cognitive causality" is how humans perceive causality.  It is the study<br>
of those cognitive modules which perform causal analysis.  It is<br>
distinct from the study of Turing machines, much as designing<br>
spreadsheet programs is distinct from the study of Turing machines.<br>
<p>
<i>&gt; &gt; Disclaimer:  Unless otherwise specified, I'm not telling you</i><br>
<i>&gt; &gt; everything I know.</i><br>
<i>&gt; I think you're telling me far more than you know.</i><br>
After much work, I have thought up a gracious and clever response to<br>
this.<br>
"The change is permanent, and thanks for the tip."<br>
<pre>
-- 
         sentience@pobox.com      Eliezer S. Yudkowsky
          <a href="http://tezcat.com/~eliezer/singularity.html">http://tezcat.com/~eliezer/singularity.html</a>
           <a href="http://tezcat.com/~eliezer/algernon.html">http://tezcat.com/~eliezer/algernon.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3916.html">Julio R. Vaquer: "Re: techno music/kraftwerk"</a>
<li> <b>Previous message:</b> <a href="3914.html">James Rogers: "Re: Beyond The Beyond"</a>
<li> <b>Maybe in reply to:</b> <a href="4069.html">John K Clark: "Singularity-worship"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="3932.html">Eliezer Yudkowsky: "Re: Singularity-worship"</a>
<!-- reply="end" -->
</ul>
