<!-- received="Fri Sep  6 17:56:47 1996 MST" -->
<!-- sent="Fri, 6 Sep 1996 13:14:34 +0200 (MET DST)" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: The Joys Of Flesh" -->
<!-- id="Pine.SOL.3.91.960906113418.11922F-100000@sun2" -->
<!-- inreplyto="199609060357.UAA15393@well.com" -->
<title>extropians: Re: The Joys Of Flesh</title>
<h1>Re: The Joys Of Flesh</h1>
Eugene Leitl (<i>Eugene.Leitl@lrz.uni-muenchen.de</i>)<br>
<i>Fri, 6 Sep 1996 13:14:34 +0200 (MET DST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#824">[ date ]</a><a href="index.html#824">[ thread ]</a><a href="subject.html#824">[ subject ]</a><a href="author.html#824">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0825.html">Sarah Marr: "Re: The Joys Of Flesh"</a>
<li> <b>Previous message:</b> <a href="0823.html">Eugene Leitl: "Re: Econ of Etalk and Cities"</a>
<li> <b>In reply to:</b> <a href="0820.html">Sean Hastings: "Re: The Joys of Flesh (was: The Poor Masses)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0833.html">Sarah Marr: "Re: The Joys of Flesh (was: The Poor Masses)"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
On Thu, 5 Sep 1996, John K Clark wrote:<br>
<p>
<i>&gt; -----BEGIN PGP SIGNED MESSAGE-----</i><br>
<i>&gt; </i><br>
<i>&gt; Thu, 5 Sep 1996 Eugene Leitl &lt;Eugene.Leitl@lrz.uni-muenchen.de&gt;</i><br>
<i>&gt; [ von Neumann hardware no target for uploading ]</i><br>
<i>&gt; The term "Von Neumann machine" can have 2 unrelated meanings, a computer with </i><br>
<i>&gt; a Von Neumann architecture or a machine that can duplicate itself from raw </i><br>
<i>&gt; matter.           </i><br>
<p>
I meant the computer architecture. I believe the macroscopic <br>
autoreplicators are most commonly called as von Neumann probes (von <br>
Neumann has designed an abstract autoreplicator, inventing the cellular <br>
automaton (CA) computation paradigm in the process. The original <br>
automaton was huge, counting some 100 k cells, currently tiny <br>
autoreplicators loops have been invented, consisting from just a few cells. <br>
An animation of this can be found online somewhere, a few edges off <br>
<p>
  <a href="http://alife.santafe.edu">http://alife.santafe.edu</a>  <br>
<p>
). <br>
<p>
Btw, a house-sized structure with _massive_ liquid cooling built from <br>
current-to-near future WSI circuitry, burning several 100 MW would equal to <br>
a human equivalent. Such a structure could in theory be built automatically, <br>
e.g. on the surface of Luna by a von Neumann probe. It would be _not_ <br>
a von Neumann machine, though, apart from drastic power and volume demands, <br>
which render such machines uneconomical, but for transient (SI bootstrap) <br>
purposes.<br>
<p>
<i>&gt; [ volume of a human equivalent, if molecular circuitry platformed ]</i><br>
<i>&gt; </i><br>
<i>&gt; Using the figure Hans Moravec came up with,  10^13 calculations per second to</i><br>
<p>
Alas, if your refer to the estimations in the retina chapter of "Mind <br>
Childeren", then Moravec is cheating. He made lots of arbitrary <br>
assumptions about neural circuitry collapsibility, instead of utilizing a <br>
solid, not even pessimistic estimate. I wrote a short, pretty uncivil <br>
critique about how realistic his estimates are, unfortunately the <br>
transhuman archive has been nuked, so I can't give you an URL.<br>
<p>
Considering about 1 MBit equivalent for storage for a single neuron, 8 <br>
bits/synapse, a 10 k average connectivity and about 1 kEvents/synapse,<br>
assuming about 100*10^9 neurons, the computed cps values are somewhat <br>
drastic. Moreover, this is _nonlocal_ MOPS (since we're at meaningless <br>
operations per second), and all performance estimates which plot linearly <br>
on a logarithmic scale are assuming on-die (regs &amp; prim. cache) accesses. <br>
Drop this constraint, and you'll see a saturation. The only thing which <br>
truly goes up exponentially, is the amount of transistors on one die, but <br>
even this won't last for long (unless we abandon semiconductor photolitho): <br>
maximum die size is limited due to random defect hits, number of dies is <br>
limited due to achievable wafer size and the size of the structures is <br>
limited since you run into quantum effects very soon (apart from enhanced <br>
defect susceptibility for tiny structures).<br>
<p>
Taken together, these facts allow us to safely neglect all strong AI <br>
claims on human equivalent by 2030 or somesuch. Vaporware, again.<br>
<p>
(Btw, I'm a strong AI proponent, and an uploader. But you just can't <br>
 expect funds to flow if you continuously fail to deliver the performance <br>
 promised. That be social, not technical engineering, but that be real <br>
 nevertheless).<br>
<p>
<i>&gt; emulate the human brain, Drexler determined that an uploaded human mind would </i><br>
<i>&gt; not be very big. Less than an ounce of matter, mostly carbon, and about 15</i><br>
<p>
Though Moravec comes from robotics &amp; Drexler is certainly a great <br>
scientist, they are no specialists in neuroscience. And it shows.<br>
 <br>
<i>&gt; watts of energy should be enough for an upload, much less if you use </i><br>
<i>&gt; reversible computing. That's cheating a little because you'd also need a </i><br>
<p>
Afaik, no groundbreaking demonstration of such reversible logics has been <br>
done yet. It bears about that many promise as quantum cryptography and <br>
quantum computers, imo. (Very little, if any).<br>
<p>
<i>&gt; cooling system for the nano computer, but even so, it wouldn't use more </i><br>
<i>&gt; energy than a dim light bulb and would probably weigh less.</i><br>
<p>
I think diamond rod logic is a bit slow (my estimates are based on <br>
molecular circuitry CAM, which switches drastically faster), as well as <br>
based on much too low (Moravec's) estimates.<br>
 <br>
<i>&gt; If you wanted VR too you'd need a little more power to simulate a rich</i><br>
<p>
AR, not VR. VR is something different. You can buy VR even now, and it <br>
gets cheaper rapidly. See Doom, Quake, whatever. Don't need dedicated <br>
renderer chips anymore, clever algorithmics can render great fakespace. <br>
All we  need are cheap trackers, and great displays, e.g. TI's MDM or <br>
retina-writer based to make it an off-shelf technology. 5-10 years from <br>
now this will be found in every U.S. - living room.<br>
  <br>
<i>&gt; environment, an entire virtual world for the upload, but it wouldn't amount </i><br>
<p>
Basically, you'd need about twice the resources to run you + body + AR <br>
environments, if not more. If you abandon most of the body model, and <br>
settle for an abstracted environment, then drastically less. How much <br>
less, no one can currently tell. However, you'll still need noticeably <br>
more than a being without. Will you be able to pay for this additional <br>
resources? On the really long run?<br>
<p>
<i>&gt; to much, because speed would not be an issue. Even if the computer that was</i><br>
<i>&gt; simulating you and the virtual world was very slow, from your point of view </i><br>
<i>&gt; it would seem infinitely fast. If the machine had performance problems all </i><br>
<p>
Of course, but I'd rather bang out the maximum of given number of atoms, <br>
seconds and watts I can have. So I'd rather run at superrealtime, <br>
possibly significantly so. 100* seems realistic, 1000* is stretching it.<br>
<p>
Nanoists claim 10^6*, which is bogus.<br>
<p>
<i>&gt; you'd have to do is have the part of the computer that was simulating you</i><br>
<i>&gt; slowed down or even stopped, while leaving the part of the computer that</i><br>
<i>&gt; simulated the rest of the universe running at normal speed. Regardless of how</i><br>
<i>&gt; many calculations it would take to convince you that the simulation was real</i><br>
<i>&gt; it could be done instantly, from your point of view. Once the machine was</i><br>
<i>&gt; caught up, our part  of the computer could be carefully restarted till the</i><br>
<i>&gt; next speed bottleneck.</i><br>
<p>
Yes, but if I supposed to live indefinitely, I'd like to eke out the max <br>
amount of ticks, until I can't use Sol for energy source anymore. Ok, I <br>
can fuse the light elements in the Oort cloud, but what will I do when <br>
even these resources are depleted? (Disclaimer: should transcension prove <br>
to be impossible, etc.).<br>
 <br>
<i>&gt;                 &gt;practicablity of strong Drexlerian nanotechnology has not </i><br>
<i>&gt;                 &gt;been demonstrated yet. </i><br>
<i>&gt; </i><br>
<i>&gt; The practicality of nanotechnology has been demonstrated by life. The</i><br>
<p>
That's why I said "strong Drexlerian nanotechnology" instead of <br>
"nanotechnology". <br>
<p>
Of course life's weak wet maspar nanotech, that's what I always say when <br>
nanoists claim drastically enhanced performance. It might be greater, <br>
sufficiently so to wipe all life on Earth in a Gray Goo scenario, yet <br>
insufficiently so to claim orders over orders of magnitude. One tends <br>
always to forget that atoms ain't that little, at least in relation to <br>
most cellular structures.<br>
<p>
Should strong Drexlerian nanotech be infeasible, we would be stuck with a <br>
protein autossembling version of it. No big deal, since the fabricated <br>
molecular circuitry is about one, max two orders of magnitude more bulky <br>
than the diamondoid one. Since it's not mechanical, but uses <br>
electronically excited molecules, it should be pretty fast.<br>
<p>
<i>&gt; practicability of strong Drexlerian Nanotechnology has not been demonstrated</i><br>
<i>&gt; for the simply reason that it is not practical, yet. What Drexler has shown is</i><br>
<i>&gt; that it is an engineering problem not a scientific one, that it, there is no</i><br>
<p>
Wait a moment.<br>
<p>
Drexler claims a repetition positioning accuracy of 100 pm.<br>
I'd like to see the quantum calculations of the mechanosynthesis <br>
reaction, allowing to deposit perfect, or nearly perfect diamondoid <br>
lattice. (I know he did them). Then I'd like to see an experimental <br>
confirmation, since QM calculations are unreliable, to say the very least <br>
(just read the CCL list, and look at all the simplifying assumption a QM <br>
run needs. Lots of simulated trash has been produced in this way).<br>
<p>
My estimate, that 10, not 100 pm are needed. Just look at a diamondoid <br>
lattice from above, and look at the periode constant. When zigzagged, C-C <br>
bond are a lot shorter. Sterical things.<br>
<p>
Then I'd like to know, whether the deflection amplitude calculations were <br>
done on a solid diamond rod, or a real cantilever structure.<br>
<p>
Then I'd like to know, whether the amount of defects in the lattice (on <br>
what are his calculations based?) do not decrease mechanical stability, <br>
resulting in a progressive amplification of errors in subsequent clones.<br>
<p>
Then I'd like to see the estimate, what a chemisorbed/physisorbed <br>
species, which are extremely mobile &amp; have a very high surface <br>
concentration do to the reactive moiety tip.<br>
<p>
Then I'd like to know, whether the mechanosynthesis reaction set is <br>
sufficiently all-purpose to allow catabolics/anabolics of all need <br>
structures.<br>
<p>
And that's an ad hoc list, written up by a nonspecialist. Great worms <br>
come in small cans, no?<br>
<p>
<i>&gt; known physical reason that would make it impossible.</i><br>
<p>
No known physical reasons, indeed. We want to know, whether a) a given <br>
structure can exist b) whether we can build the first instance of this <br>
structure c) this structure is sufficiently powerful to at least a make <br>
a sufficiently accurate copy of itself.<br>
<p>
That's a lot of constraints, and all of them physical. These are greatly <br>
alleviated for a macroscopic replicator, but bite very deep if you start <br>
tweaking at atomic scales.<br>
<p>
Soft nanotech is possible, but it does not utilize mechanosynthesis at <br>
such prominent scale. Claiming the problems to be merely engineering, is <br>
not good marketing, imo.<br>
                            <br>
<i>&gt;                 &gt;Anyway, diamond rod logic is too slow in comparison to </i><br>
<i>&gt;                 &gt;molecular switches, which operate on electronically excited </i><br>
<i>&gt;                 &gt;molecular states/quantum dot arrays.</i><br>
<i>&gt;  </i><br>
<i>&gt; Not too slow for an upload. The acoustic speed in a diamond is 1.75 X 10^4 </i><br>
<i>&gt; meters per second, pretty slow compared to the speed if light at 3 X 10^8 </i><br>
<i>&gt; but very fast compared to the signals the brain uses at about 100 meters a</i><br>
<i>&gt; second or less, sometimes much less. Because they would be so small, diamond</i><br>
<i>&gt; rod logic would be far faster than any electronic logic circuits we have today,</i><br>
<i>&gt; and enormously faster than the old steam powered biological brain each of us</i><br>
<i>&gt; uses today.  </i><br>
<p>
An another brazen claim. Diamond rods, being things mechanical, are <br>
deposited once. They represent states be being in different <br>
configurations.<br>
<p>
Now neurons are mobile, they _change their physical circuitry_. <br>
Connectivity's changing, weight's are changing. Lacking this flexibilty, <br>
you'll have to simulate this. Now neurons utilize a very high <br>
connectivity, being topologically aligned on a high-dimensional <br>
hypergrid. There are excellent reasons to suspect this connectivity to be <br>
crucial -- so you have to simulate this connectivity. So you can't do it <br>
directly in hardware, you must start sending bits, instead of pushing <br>
rods (because of sterical constraints, mechanical flabbiness of diamond <br>
on large distances, etc.).<br>
<p>
So're losing lots of orders of magnitude this way. At least 3 of them, <br>
easily.<br>
 <br>
<i>&gt; Fast as it is I'm sure we can do better. Drexler uses rod logic because it's </i><br>
<i>&gt; easier to design than nanometer electronic logic, and if you want to show a </i><br>
<i>&gt; proof of concept it makes sense to do so as simply as possible.</i><br>
<p>
I know that, he says that much in "Nanosystems". But his estimates of <br>
SI's in a box are based on diamond rod logic, and they're off doubly so <br>
because he assumes diamond rod is drastically better than neuronal <br>
circuitry. (For all that is worth, it _should_ be better, but by not that <br>
much).<br>
 <br>
Btw, for the record, I am not saying that strong Drexlerian nanotech is <br>
infeasible, only that we just can't tell yet. Assuming anything else, <br>
claiming great performance, but failing to deliver it _soon_ is extremely <br>
damaging to one's credulity, and hence financing. We've all have seen <br>
what happened to strong AI in the 1980's, must nanotechnology funding <br>
suffer such fate?<br>
<p>
(I'm aware that nanotechnology is currently mostly self-financed, but <br>
this is likely to change in near future, or so I hope).<br>
 <br>
<i>&gt;                      &gt;&gt;Tim_Robbins@aacte.nche.edu</i><br>
<i>&gt;                      &gt;&gt;Honestly, am I the only extropian who likes the flesh?</i><br>
<i>&gt; </i><br>
<i>&gt;         &gt;You might have no choice. You seem to assume that &gt;H level</i><br>
<i>&gt;         &gt;intelligences to be actively benign, leaving you a sufficient part</i><br>
<i>&gt;         &gt;of resources.</i><br>
<i>&gt; </i><br>
<i>&gt; I agree with Eugene. If the &gt;H are nice enough to let us live, it will</i><br>
<i>&gt; probably be in VR. They won't want us using up a lot of resources in the</i><br>
<i>&gt; "real" world and they would probably be a bit squeamish about letting us fool</i><br>
<p>
Complexity delta from us to them would be about that between us and a <br>
nematode, maybe greater. I just hope, that their evolved cooperation will <br>
be _very_ benign, and they will protect us from lesser, but more vicious <br>
inhabitants of the digital reality.<br>
<p>
<i>&gt; around at that level of reality, like letting a monkey run around in an</i><br>
<i>&gt; operating room. They'll probably want a firewall to protect themselves from</i><br>
<i>&gt; our stupidity.</i><br>
<p>
I think they will use drastically different interfaces, not fakespace <br>
renderers, even higher-dimensional. A Dyson Sphere computer might well be <br>
just one vast, complex entity, where a module hierarchy exists, where the <br>
lowest level would be a human, not a neuron. (Probably, running <br>
BorgOSv456546546.3453.34524112 ;)<br>
 <br>
Alas, we just can't tell what the future will bring. The only sure thing <br>
about the future is -- it will be beyond our wildest dreams.<br>
<p>
<i>&gt; </i><br>
<i>&gt;                                             John K Clark     johnkc@well.com</i><br>
<i>&gt; [ pgp sig snipped ]</i><br>
_________________________________________________________________________________<br>
<i>| <a href="mailto:">mailto:</a> ui22204@sunmail.lrz-muenchen.de | transhumanism &gt;H, cryonics,         |</i><br>
<i>| <a href="mailto:">mailto:</a> Eugene.Leitl@uni-muenchen.de    | nanotechnology, etc. etc.           |</i><br>
<i>| <a href="mailto:">mailto:</a> c438@org.chemie.uni-muenchen.de | "deus ex machina, v.0.0.alpha"      |</i><br>
<i>| icbmto: N 48 10'07'' E 011 33'53''      | <a href="http://www.lrz-muenchen.de/~ui22204">http://www.lrz-muenchen.de/~ui22204</a> |</i><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0825.html">Sarah Marr: "Re: The Joys Of Flesh"</a>
<li> <b>Previous message:</b> <a href="0823.html">Eugene Leitl: "Re: Econ of Etalk and Cities"</a>
<li> <b>In reply to:</b> <a href="0820.html">Sean Hastings: "Re: The Joys of Flesh (was: The Poor Masses)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="0833.html">Sarah Marr: "Re: The Joys of Flesh (was: The Poor Masses)"</a>
<!-- reply="end" -->
</ul>
