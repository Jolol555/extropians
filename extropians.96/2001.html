<!-- received="Fri Oct 18 16:06:33 1996 MST" -->
<!-- sent="Fri, 18 Oct 1996 18:02:54 -0500 (EST)" -->
<!-- name="Lyle Burkhead" -->
<!-- email="LYBRHED@delphi.com" -->
<!-- subject="the Turing test" -->
<!-- id="2.2.16.19961018210607.0cd7a48e@earthlink.net" -->
<!-- inreplyto="" -->
<title>extropians: the Turing test</title>
<h1>the Turing test</h1>
Lyle Burkhead (<i>LYBRHED@delphi.com</i>)<br>
<i>Fri, 18 Oct 1996 18:02:54 -0500 (EST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2001">[ date ]</a><a href="index.html#2001">[ thread ]</a><a href="subject.html#2001">[ subject ]</a><a href="author.html#2001">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2002.html">David Musick: "The Worker / Employer Relationship"</a>
<li> <b>Previous message:</b> <a href="2000.html">Eric Watt Forste: "Re: Incremental Progress (was: Private Property and Capitalism)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2018.html">Anders Sandberg: "Re: Is Nothing Finite?"</a>
<li> <b>Reply:</b> <a href="2018.html">Anders Sandberg: "Re: Is Nothing Finite?"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Ira Brodsky writes, <br>
<p>
<i>&gt; I think we need something more than just your pronouncements to </i><br>
<i>&gt; take this seriously.  How about a press release, or even a signed letter </i><br>
<i>&gt; from the Chair of CMU Computer Science department?</i><br>
<i>&gt;</i><br>
<i>&gt; I don't know you.  If you represent CMU's Comp. Sci. department, </i><br>
<i>&gt; and this is an official announcement, please say so.</i><br>
<p>
The idea of the Turing test is that you are supposed to figure out, just <br>
from conversing through a terminal, that you are talking to a program.  <br>
If the only way you can tell who you are talking to is to look behind <br>
the curtain, then the program wins.  So please don't ask me to give you <br>
letters.  That's an admission of defeat on your part.  If you call the cs <br>
department at CMU, they will, naturally, deny any knowledge of this.  <br>
(Of course the students themselves are watching this dialogue with <br>
great hilarity, and cheering their program on.)  <br>
<p>
I wrote, <br>
<p>
::Ira, how can you confidently say "way above anything yet achieved<br>
::by AI?"  You only know what has been achieved in the past.<br>
::The point is, this program from CMU is *new*.  It is a quantum leap<br>
::beyond earlier AI programs.  This is the first time an AI program<br>
::has been unleashed on an unsuspecting world, and left to fend for itself.<br>
::And it is doing very well.<br>
<p>
to which Ira replied, <br>
<p>
<i>&gt; Lyle, how could I possibly say, with confidence, anything more?  </i><br>
<i>&gt; What is this new AI?  How is it an advance over previous AI?  </i><br>
<p>
It is an advance over previous AI in that it doen't depend on smoke <br>
and mirrors (see below).  It has a (potentially) complete model of the <br>
world.  It understands causality.  It understands its place in the world.  <br>
It can learn from experience.  It can imagine being in different <br>
situations.  Therefore, it can hold a conversation for an extended <br>
period without arousing suspicion, and it can continue to do this even <br>
after its interlocutors have been apprised of the situation.  <br>
<p>
<i>&gt; Has it been subjected to any independent evaluations?  </i><br>
<p>
This is parrot-talk.  Why do you have to depend on somebody else's <br>
evaluation?  It's being evaluated by everyone who encounters it.  <br>
<p>
<i>&gt; Again, all we have to go on are your personal pronouncements.  </i><br>
<p>
Plus your own judgment about what's real and what isn't.  <br>
<p>
<p>
Hal Finney writes, <br>
<p>
<i>&gt; For information about the current state of the art in </i><br>
<i>&gt; Turing Test passing programs, see the Loebner Prize home page,</i><br>
<p>
This is no longer the state of the art.  It's a fast-moving field.  <br>
<p>
Hal continues, <br>
<p>
<i>&gt; These programs are all smoke and mirrors, using conversational</i><br>
<i>&gt; trickery to try to distract and misdirect the judge for long enough</i><br>
<i>&gt; that he doesn't notice the utter lack of understanding which the</i><br>
<i>&gt; program really possesses.  It's kind of like watching David Letterman</i><br>
<i>&gt; fly.  You might not be able to distinguish him from someone really</i><br>
<i>&gt; flying given the constraints of limited time and viewing angles, but</i><br>
<i>&gt; that doesn't mean there's no difference.</i><br>
<i>&gt; </i><br>
<i>&gt; When you look at the larger body of transcripts you begin to see the</i><br>
<i>&gt; repetitions, the errors, the flashy but canned statements, and you</i><br>
<i>&gt; realize how little is actually there.</i><br>
<p>
Yes.  This is an apt description of the AI programs of the past.  <br>
<p>
<i>&gt; Lyle's game is amusing but as in many such cases the facts are </i><br>
<i>&gt; ultimately more interesting.  The real question is whether the </i><br>
<i>&gt; Turing test is valid, and in particular just how much interaction is </i><br>
<i>&gt; necessary before we can know that the program is showing real </i><br>
<i>&gt; understanding.</i><br>
<p>
Another question to ponder is what would be involved in going <br>
from the smoke and mirrors programs of the "current state of the art" <br>
to a program that really is intelligent.  <br>
<p>
I certainly agree that, as you say, "the facts are ulitmately more <br>
interesting."  In the past I have been taken to task for this attitude.  <br>
Now I find myself in the odd position of trying to convince Extropians <br>
that AI exists.   <br>
<p>
Lyle <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2002.html">David Musick: "The Worker / Employer Relationship"</a>
<li> <b>Previous message:</b> <a href="2000.html">Eric Watt Forste: "Re: Incremental Progress (was: Private Property and Capitalism)"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2018.html">Anders Sandberg: "Re: Is Nothing Finite?"</a>
<li> <b>Reply:</b> <a href="2018.html">Anders Sandberg: "Re: Is Nothing Finite?"</a>
<!-- reply="end" -->
</ul>
