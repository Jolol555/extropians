<!-- received="Tue Aug 27 11:24:48 1996 MST" -->
<!-- sent="Tue, 27 Aug 1996 11:51:49 -0500" -->
<!-- name="Tim_Robbins@aacte.nche.edu" -->
<!-- email="Tim_Robbins@aacte.nche.edu" -->
<!-- subject="controlling AI" -->
<!-- id="s222e1b4.001@aacte.nche.edu" -->
<!-- inreplyto="" -->
<title>extropians: controlling AI</title>
<h1>controlling AI</h1>
<i>Tim_Robbins@aacte.nche.edu</i><br>
<i>Tue, 27 Aug 1996 11:51:49 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#513">[ date ]</a><a href="index.html#513">[ thread ]</a><a href="subject.html#513">[ subject ]</a><a href="author.html#513">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0514.html">Eugene Leitl: "Re: Individual Freedoms"</a>
<li> <b>Previous message:</b> <a href="0512.html">Natasha V. More: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
All this discussion of controlling AI (something we want but that will<br>
eventually be smarter and more powerful than us).  We want to survive<br>
(being human may have it's limits, but we do have some fun)--how do<br>
we (humans/transhumans) continue in a universe as inferior to AI?  The<br>
most promising suggestions so far seem to be contructed around making<br>
us indispensable to the life-processes of whatever AIs develop.  In a<br>
way, designing them from the start to be either dependent on us, or<br>
symbiotic.  The discussions so far have been good at stating that any<br>
such AI system will have some corollary to the basic motivating<br>
responses of living organisms--analogues to pleasure, pain, fear,<br>
ambition, want, aversion, etc.  <br>
<p>
So why not start from the beginning with a basic motivational structure<br>
that assures our existence, even primacy, in an AI dominated system. <br>
Why not design their basic motivational structures around LOVE or<br>
CHERISHMENT of humans and humanity.  In the way the we love our<br>
friends, lovers, children or even pets.  This type of motivational structure<br>
would also be certain to be passed on to the superior AI designed by<br>
other AI--since they would want their creation to have that same<br>
concern or appreciation for that which they love or cherish.<br>
<p>
It shouldn't be any more difficult to design, after many basic protoypes, a<br>
love response any more than a pleasure response.  <br>
<p>
I am also trying to point out here that what humanity "loves" is basically<br>
arbitrary except that in enhances our survival and is a legacy of our<br>
evolution.  We find if much easier to cherish trees or waterfalls than<br>
spiders and stagnant, fetid ponds.  But it's an arbitrary response.  Not<br>
only do we love our children or pets--but seek them out, because we<br>
want to find something to love and cherish.<br>
<p>
Why couldn't a similar motivational structure be used to "control" AI?<br>
<p>
I certainly don't see my dog as a threat or burden, even though I am<br>
superior.  And basically I let it do what it wants, and keep it fed and<br>
cared for, and play with it, and teach it, and take it to the vet when it gets<br>
sick.  <br>
<p>
I don't think I would mind being a "pet" of a superintelligent AI system, so<br>
long as I had reasonable volition and freedom--we could ensure that too.<br>
<p>
Don't think I'm over committed to the pet analogy.  I prefer to consider<br>
such a hypothetical constructed dependency/symbiosis to be more as<br>
friendship.  With the whole linkage being an ethic of caring and concern. <br>
If they love/cherish our "humanity", part of that would be freedom and<br>
autonomy.<br>
<p>
I think the advantage of such a relationship, is that a hyperintelligent<br>
being might try and redesign itself or it's descendants away from<br>
dependence on us--but a value/response structure of caring would<br>
purposefully be passed to descendants.<br>
<p>
-Timber<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0514.html">Eugene Leitl: "Re: Individual Freedoms"</a>
<li> <b>Previous message:</b> <a href="0512.html">Natasha V. More: "Re: Individual Freedoms"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
