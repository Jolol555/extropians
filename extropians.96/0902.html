<!-- received="Tue Sep 10 11:42:07 1996 MST" -->
<!-- sent="Tue, 10 Sep 96 10:30:37 PDT" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@dosh.hum.caltech.edu" -->
<!-- subject="Re: Darwinian Extropy" -->
<!-- id="9609101730.AA17086@dosh.hum.caltech.edu" -->
<!-- inreplyto="3234D081.889@shirenet.com" -->
<title>extropians: Re: Darwinian Extropy</title>
<h1>Re: Darwinian Extropy</h1>
Robin Hanson (<i>hanson@dosh.hum.caltech.edu</i>)<br>
<i>Tue, 10 Sep 96 10:30:37 PDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#902">[ date ]</a><a href="index.html#902">[ thread ]</a><a href="subject.html#902">[ subject ]</a><a href="author.html#902">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0903.html">Anders Sandberg: "Re: Extropian Standpoint on Capital Punishment?"</a>
<li> <b>Previous message:</b> <a href="0901.html">John K Clark: "Word? steric"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Dan Clemmensen writes:<br>
<i>&gt;What if the only logical conclusion A system-wide SI can reach</i><br>
<i>&gt;it that out-system resoureces are uneconomical?</i><br>
<i>&gt;Both of your arguments make the same funcamental assuption that</i><br>
<i>&gt;there is more than one SI in a star system.  ...</i><br>
<i>&gt;the opposite assumption, that a single SI takes over the star system.</i><br>
<i>&gt;... There may not be a lot of diverse SIs</i><br>
<i>&gt;in the universe. There may be only one per system, and they may all</i><br>
<i>&gt;have reached the same super-logical conclusion that star travel is</i><br>
<i>&gt;uneconomical in terms of the resources that SIs use. </i><br>
<p>
Whether something is "economical" or not is relative to the<br>
preferences of the decision-maker.  And the preferences of a single<br>
person like ourselves can effectively be a weighted average of many<br>
different preferences, as if we were composed of parts with many<br>
different preferences.<br>
<p>
So to make your scenario plausible, you need a plausible process which<br>
creates this massive convergence to a preference with almost no weight<br>
on long-time-scale returns.  One way to get convergence of preferences<br>
is via evolutionary selection, but that process seems to select<br>
exactly for the preferences you don't want in your scenario.<br>
<p>
Robin Hanson  hanson@hss.caltech.edu  <a href="http://hss.caltech.edu/~hanson/">http://hss.caltech.edu/~hanson/</a><br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="0903.html">Anders Sandberg: "Re: Extropian Standpoint on Capital Punishment?"</a>
<li> <b>Previous message:</b> <a href="0901.html">John K Clark: "Word? steric"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
