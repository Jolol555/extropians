<!-- received="Sun Nov 17 02:57:41 1996 MST" -->
<!-- sent="Sun, 17 Nov 1996 04:32:31 -0500 (EST)" -->
<!-- name="Lyle Burkhead" -->
<!-- email="LYBRHED@delphi.com" -->
<!-- subject="Transforming Ourselves" -->
<!-- id="199611170832.AAA12263@pure.PureAtria.COM" -->
<!-- inreplyto="" -->
<title>extropians: Transforming Ourselves</title>
<h1>Transforming Ourselves</h1>
Lyle Burkhead (<i>LYBRHED@delphi.com</i>)<br>
<i>Sun, 17 Nov 1996 04:32:31 -0500 (EST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3049">[ date ]</a><a href="index.html#3049">[ thread ]</a><a href="subject.html#3049">[ subject ]</a><a href="author.html#3049">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3050.html">Max M: "Re: the robot scenario"</a>
<li> <b>Previous message:</b> <a href="3048.html">Ray Peck: "Re: Legions of Soldiers with Railguns (Future of Warfare)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
David Musick writes, <br>
<p>
<i>&gt; I have often considered the possibility that our creations will </i><br>
<i>&gt; outsmart  humanity, becoming much more powerful and intelligent </i><br>
<i>&gt; than humans and being out of the control of humans.  </i><br>
<i>&gt; This seems like the logical result of creating intelligent machines </i><br>
<i>&gt; which are used to manufacture all sorts of things, including other, </i><br>
<i>&gt; more intelligent machines and robots.  </i><br>
<p>
Ok.  Try generalizing the idea of machines.  They don't have to be <br>
made of metal or even silicon.  Governments are human creations.  <br>
Corporations are human creations -- "machines" or "robots" if you will,  <br>
not always controllable by us, which are used to manufacture all sorts <br>
of things, including other, more intelligent machines and robots.  <br>
<p>
David segues into, <br>
<p>
<i>&gt; So, what can we do to prevent ourselves from being destroyed? </i><br>
<p>
Wait a minute -- destroyed?  Just because an entity is more powerful <br>
and intelligent than humans doesn't mean it's going to set out to destroy <br>
us.  Sun Microsystems is way more intelligent and powerful than I am, <br>
but I don't consider it a threat to my existence.  <br>
<p>
David continues, <br>
<p>
<i>&gt; The only real solution I see is self-augmentation/transformation </i><br>
<i>&gt; and intense cyborganization.  We must improve ourselves dramatically </i><br>
<i>&gt; by integrating  powerful machines in our bodies and minds </i><br>
<i>&gt; in order to survive.  We must... We must... We must... &lt;snip&gt; </i><br>
<i>&gt; To survive, we must become more than we are now.  Much more.  </i><br>
<p>
To survive?  Why?  As we build more and more intelligent machines, <br>
life becomes less of a struggle for most people.  <br>
<p>
<i>&gt; It's survival of the fittest.  It always has been, and it always will be.  </i><br>
<i>&gt; The universe is a huge tournament.  Those who don't qualify for the </i><br>
<i>&gt; later rounds don't live to participate in the later rounds.  To remain </i><br>
<i>&gt; in the game for long, one must be constantly training oneself, </i><br>
<i>&gt; transforming oneself, making oneself better. </i><br>
<p>
Apparently you expect some kind of Paget scenario, in which our <br>
robot-creations declare war on us.  If events do develop along those <br>
lines, which is possible but unlikely, transforming ourselves will be <br>
no guarantee of survival.  Survival will be problematic for everyone, <br>
whether they are engaged in self-transformation or not.  <br>
<p>
If survival is really an issue, the first thing to understand is that <br>
you can't survive by yourself.  You have to be part of an army (yet <br>
another kind of "robot" or "machine").  <br>
<p>
<i>&gt; There is much we can do *right now* to begin transforming </i><br>
<i>&gt; ourselves.  The first step is developing a strong mental discipline.  </i><br>
<i>&gt; We can each find ways to improve our minds, to make them faster, </i><br>
<i>&gt; more intelligent, more creative.  We can improve our learning skills </i><br>
<i>&gt; by engaging ourselves in many new activities, continually practicing </i><br>
<i>&gt; learning new things and learning how to learn even faster... etc.  </i><br>
<p>
Well, yes, I'm doing that, but not because I think such activities <br>
are necessary to survive.  I would do it anyway, even if I didn't feel <br>
threatened at all.  Wouldn't you?  <br>
<p>
Lyle <br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="3050.html">Max M: "Re: the robot scenario"</a>
<li> <b>Previous message:</b> <a href="3048.html">Ray Peck: "Re: Legions of Soldiers with Railguns (Future of Warfare)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
