<!-- received="Sat Oct 26 14:32:28 1996 MST" -->
<!-- sent="Sat, 26 Oct 1996 21:22:59 +0100" -->
<!-- name="Dr. Rich Artym" -->
<!-- email="rartym@galacta.demon.co.uk" -->
<!-- subject="Re: Perversion attacks" -->
<!-- id="199610262022.VAA18808@galacta.demon.co.uk" -->
<!-- inreplyto="Perversion attacks" -->
<title>extropians: Re: Perversion attacks</title>
<h1>Re: Perversion attacks</h1>
Dr. Rich Artym (<i>rartym@galacta.demon.co.uk</i>)<br>
<i>Sat, 26 Oct 1996 21:22:59 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2224">[ date ]</a><a href="index.html#2224">[ thread ]</a><a href="subject.html#2224">[ subject ]</a><a href="author.html#2224">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2225.html">Dr. Rich Artym: "Re: Private Property and Capitalism"</a>
<li> <b>Previous message:</b> <a href="2223.html">Dr. Rich Artym: "Re: On Being Extropian"</a>
<li> <b>Maybe in reply to:</b> <a href="2185.html">Lyle Burkhead: "Perversion attacks"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2300.html">Dan Clemmensen: "Re: Perversion attacks"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
In message &lt;32724489.853@shirenet.com&gt;, Dan Clemmensen writes:<br>
<p>
<i>&gt; Interesting. Both Lyle and Anders have objected to my scenario of</i><br>
<i>&gt; the "transcendence" of an SI by takeover of the internet by a program</i><br>
<i>&gt; that uses the computing resources to augmemt its own intelligence.</i><br>
<p>
Dan, the problem I see for your scenario isn't that it may not arise at<br>
all (quite the opposite --- I think that learning neural/fuzzy AI automata<br>
will see the light of day long before strong nanotech), but that when/if<br>
it does arise then it will be subject to the same constraints that have<br>
dogged Mankind since the dawn of time, namely the limits to growth that<br>
result from lack of atomic-level control over matter.<br>
<p>
That's why I see the knee of the high-order curve that leads to the<br>
Singularity happening after nanotech, rather than after emergence of SI.<br>
Having said that, the order may be irrelevant.  Over an appropriate<br>
timescale (less than geological :-), these two events are likely to<br>
coincide, if one believes in reductionism and the direct emergence of<br>
AI once an appropriate artificial neural substrate is available.  Heck,<br>
we're nearly there now, even without nanotech.  Interesting times.<br>
<p>
Rich.<br>
<pre>
-- 
###########  Dr. Rich Artym  ================  PGP public key available
# galacta #  Email   : rich@galacta.demon.co.uk         158.152.156.137
# -&gt;demon #  Web     : <a href="http://www.galacta.demon.co.uk">http://www.galacta.demon.co.uk</a>   194.222.245.150
# -&gt;ampr  #  AMPR    : rich@g7exm[.uk].ampr.org 44.131.164.1 BBS:GB7MSW
# -&gt;NTS   #  Fun     : Unix, X, TCP/IP, kernel, O-O, C++, SoftEng, Nano
###########  More fun: Regional IP Coordinator Hertfordshire + N.London
</pre>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2225.html">Dr. Rich Artym: "Re: Private Property and Capitalism"</a>
<li> <b>Previous message:</b> <a href="2223.html">Dr. Rich Artym: "Re: On Being Extropian"</a>
<li> <b>Maybe in reply to:</b> <a href="2185.html">Lyle Burkhead: "Perversion attacks"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2300.html">Dan Clemmensen: "Re: Perversion attacks"</a>
<!-- reply="end" -->
</ul>
