<!-- received="Sun Oct 20 01:50:19 1996 MST" -->
<!-- sent="Sun, 20 Oct 1996 02:59:33 -0600" -->
<!-- name="Ira Brodsky" -->
<!-- email="ibrodsky@ix8.ix.netcom.com" -->
<!-- subject="Re: the Turing test" -->
<!-- id="v01530503ae8f927ca579@[204.32.166.175]" -->
<!-- inreplyto="the Turing test" -->
<title>extropians: Re: the Turing test</title>
<h1>Re: the Turing test</h1>
Ira Brodsky (<i>ibrodsky@ix8.ix.netcom.com</i>)<br>
<i>Sun, 20 Oct 1996 02:59:33 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2043">[ date ]</a><a href="index.html#2043">[ thread ]</a><a href="subject.html#2043">[ subject ]</a><a href="author.html#2043">[ author ]</a>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2044.html">QueeneMUSE@aol.com: "Re: Emotions "vestigial"? was Re: On being Extropian"</a>
<li> <b>Previous message:</b> <a href="2042.html">Ira Brodsky: "Re: Emotions "vestigial"? was Re: On being Extropian"</a>
<li> <b>Maybe in reply to:</b> <a href="2250.html">Lyle Burkhead: "the Turing test"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2052.html">Chris Hind: "Re: the Turing test"</a>
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
Lyle Burkhead wrote:<br>
<p>
<i>&gt;The idea of the Turing test is that you are supposed to figure out, just</i><br>
<i>&gt;from conversing through a terminal, that you are talking to a program.</i><br>
<i>&gt;If the only way you can tell who you are talking to is to look behind</i><br>
<i>&gt;the curtain, then the program wins.  So please don't ask me to give you</i><br>
<i>&gt;letters.  That's an admission of defeat on your part.  If you call the cs</i><br>
<i>&gt;department at CMU, they will, naturally, deny any knowledge of this.</i><br>
<i>&gt;(Of course the students themselves are watching this dialogue with</i><br>
<i>&gt;great hilarity, and cheering their program on.)</i><br>
<p>
<p>
What double-talk.  You have announced there is an AI on this list, but<br>
assure us those responsible will deny it.  At best, you are not one to be<br>
trusted with secrets.  At worst, your reaction to my request that CMU<br>
confirm what you have already told us is disingenuous.<br>
<p>
<p>
<i>&gt;It is an advance over previous AI in that it doen't depend on smoke</i><br>
<i>&gt;and mirrors (see below).  It has a (potentially) complete model of the</i><br>
<i>&gt;world.  It understands causality.  It understands its place in the world.</i><br>
<i>&gt;It can learn from experience.  It can imagine being in different</i><br>
<i>&gt;situations.  Therefore, it can hold a conversation for an extended</i><br>
<i>&gt;period without arousing suspicion, and it can continue to do this even</i><br>
<i>&gt;after its interlocutors have been apprised of the situation.</i><br>
<p>
<p>
"It" has achieved consciousness!  But Lyle Burkhead is the only person (or<br>
AI?) outside a small circle who knows anything about it...<br>
<p>
<p>
<i>&gt;&gt; Has it been subjected to any independent evaluations?</i><br>
<i>&gt;</i><br>
<i>&gt;This is parrot-talk.  Why do you have to depend on somebody else's</i><br>
<i>&gt;evaluation?  It's being evaluated by everyone who encounters it.</i><br>
<p>
<p>
Real people with real inventions are not afraid of independent evaluation.<br>
To call a basic, universal demand of good science "parrot-talk" throws your<br>
credibility (and motivation) into question.<br>
<p>
<p>
<i>&gt;Hal Finney writes,</i><br>
<p>
[snip}<br>
<p>
<i>&gt;&gt; Lyle's game is amusing but as in many such cases the facts are</i><br>
<i>&gt;&gt; ultimately more interesting.  The real question is whether the</i><br>
<i>&gt;&gt; Turing test is valid, and in particular just how much interaction is</i><br>
<i>&gt;&gt; necessary before we can know that the program is showing real</i><br>
<i>&gt;&gt; understanding.</i><br>
<i>&gt;</i><br>
<i>&gt;Another question to ponder is what would be involved in going</i><br>
<i>&gt;from the smoke and mirrors programs of the "current state of the art"</i><br>
<i>&gt;to a program that really is intelligent.</i><br>
<i>&gt;</i><br>
<i>&gt;I certainly agree that, as you say, "the facts are ulitmately more</i><br>
<i>&gt;interesting."  In the past I have been taken to task for this attitude.</i><br>
<i>&gt;Now I find myself in the odd position of trying to convince Extropians</i><br>
<i>&gt;that AI exists.</i><br>
<p>
<p>
Quite a leap: extropians doubt that "AI exists" because they question<br>
whether a *particular* AI exists.  Again, the only thing they have to go on<br>
is your personal claim.  The fact you resist independent verification of<br>
what you have already told us suggests either a). you are not being<br>
completely honest, or b). you are proof that an AI can be sinister.<br>
<p>
In any event, I am now completely convinced that your intelligence is<br>
artificial. But I am uncertain as to whether it is your circuits or grey<br>
matter that should be overheating about now.  &lt;g&gt;<br>
<p>
<p>
<p>
<p>
Ira Brodsky<br>
Datacomm Research Company<br>
Wilmette, Illinois<br>
<!-- body="end" -->
<hr>
<p>
<ul>
<!-- next="start" -->
<li> <b>Next message:</b> <a href="2044.html">QueeneMUSE@aol.com: "Re: Emotions "vestigial"? was Re: On being Extropian"</a>
<li> <b>Previous message:</b> <a href="2042.html">Ira Brodsky: "Re: Emotions "vestigial"? was Re: On being Extropian"</a>
<li> <b>Maybe in reply to:</b> <a href="2250.html">Lyle Burkhead: "the Turing test"</a>
<!-- nextthread="start" -->
<li> <b>Next in thread:</b> <a href="2052.html">Chris Hind: "Re: the Turing test"</a>
<!-- reply="end" -->
</ul>
