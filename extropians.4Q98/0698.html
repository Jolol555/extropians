<!-- received="Fri Oct 30 15:45:31 1998 MST" -->
<!-- sent="Fri, 30 Oct 1998 18:01:09 -0500" -->
<!-- name="Michael Lorrey" -->
<!-- email="retroman@together.net" -->
<!-- subject="Re: AI soldiers" -->
<!-- id="363A4535.24B3235B@together.net" -->
<!-- inreplyto="AI soldiers" -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropy: Re: AI soldiers</title>
<meta name=author content="Michael Lorrey">
<link rel=author rev=made href="mailto:retroman@together.net" title ="Michael Lorrey">
</head><body>
<h1>Re: AI soldiers</h1>
Michael Lorrey (<i>retroman@together.net</i>)<br>
<i>Fri, 30 Oct 1998 18:01:09 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#698">[ date ]</a><a href="index.html#698">[ thread ]</a><a href="subject.html#698">[ subject ]</a><a href="author.html#698">[ author ]</a>
<!-- next="start" -->
<li><a href="0699.html">[ Next ]</a><a href="0697.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0693.html">Bernard Hughes</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Bernard Hughes wrote:

<p>
<i>&gt; Following up on the silicon brain story posted earlier, I came across another</i><br>
<a href="0693.html#0698qlink1">&gt; interesting article in the EEtimes</a><br>
<i>&gt;</i><br>
<i>&gt; <a href="http://www.eetimes.com/story/OEG19981026S0015">http://www.eetimes.com/story/OEG19981026S0015</a></i><br>
<i>&gt;</i><br>
<i>&gt; This one is about a Raytheon project to build an artificial soldier topped off with</i><br>
<i>&gt; the Cog head from MIT. The neural net system proposed is of a type that is new to</i><br>
<i>&gt; me, in that it assumes that the information passed among neurons comes as a result</i><br>
<i>&gt; of the temporal synchrony among signals. Anybody else come across that theory?</i><br>
<i>&gt;</i><br>
<i>&gt;  Building an autonomous, heavily armed soldier strikes me as a risky way to try out</i><br>
<i>&gt; AI theory. A fixed place ABM system is one thing, but a general purpose killer</i><br>
<i>&gt; robot seems like asking for trouble. If programming "do not harm humans" has some</i><br>
<i>&gt; challenges, "kill all humans except for the friendly ones" seems fraught with</i><br>
<i>&gt; peril. Reminds me of an old SF tale, I think called "I made you", in which a dying</i><br>
<i>&gt; engineer is pinned down by the robot sentinel he built.</i><br>
<i>&gt;</i><br>
<i>&gt;  I'd vote for keeping these guys immobile unless you are *really* sure of your IFF</i><br>
<i>&gt; programming.</i><br>
<i>&gt;</i><br>

<p>
The motivation for robot soldiers does not come from ground commanders, but from bean
counters and politicians. Any ground commander knows that a) you don't own any peice of
land until you stick an 18 year old kid with a rifle on top of it, b) the worst threat
to a free democracy is a professional army at the beck and call of the leadership with
no personal stake in maintaining civil liberties. Such 'Robocop' concepts are flawed
from basic principles, and should be stomped out wherever some idiot gets a hair up his
butt to build one, unless the AI is granted citizenship and recognized as 'human
equivalent' form the start (not bloody likely). Anything less is a prescription for
tyrrany.

<p>
Mike Lorrey
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0699.html">[ Next ]</a><a href="0697.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0693.html">Bernard Hughes</a>
<!-- nextthread="start" -->
</ul>
</body></html>
