<!-- received="Mon Dec 21 14:39:38 1998 MST" -->
<!-- sent="Mon, 21 Dec 1998 15:41:45 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Truth machines" -->
<!-- id="367EC092.9DD472F7@pobox.com" -->
<!-- inreplyto="Truth machines" -->
<!-- version=1.10, linesinbody=88 -->
<html><head><title>extropy: Re: Truth machines</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Truth machines</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 21 Dec 1998 15:41:45 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3351">[ date ]</a><a href="index.html#3351">[ thread ]</a><a href="subject.html#3351">[ subject ]</a><a href="author.html#3351">[ author ]</a>
<!-- next="start" -->
<li><a href="3352.html">[ Next ]</a><a href="3350.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3343.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3358.html">Billy Brown</a>
</ul>
<!-- body="start" -->

<p>
Billy Brown wrote:
<br>
<i>&gt; </i><br>
<a href="3343.html#3351qlink1">&gt; A truth machine would reduce the problems of autocracy by telling the</a><br>
<i>&gt; autocrat who he can trust.  As a result, he has less need to actually</i><br>
<i>&gt; oppress anyone.  Stupid dictators will do so anyway, but smart ones will</i><br>
<i>&gt; realize they can now have their cake and eat it too.  They can give the</i><br>
<i>&gt; subjects enough freedom to create a healthy, functioning free market without</i><br>
<i>&gt; risking revolt, because it is so easy to round up the actual</i><br>
<i>&gt; revolutionaries.</i><br>

<p>
<a name="3358qlink1">Smart dictators?  How many dictators do you know of who are smart enough
to privately acknowledge that free-market economies work better? 
Besides which, I find it rather hard to believe that even a system of
truth machines could create a healthy, functioning free-market
<a name="3358qlink2">autocracy.</a>  If you shoot everyone who thinks about rebelling, nobody is
left to do the work.  Shoot only those people who actually begin
planning, and eventually a completely spontaneous uprising will knock
off the dictator.  Autocracy fundamentally relies on massive poverty and
fear and I don't think truth machines are strong enough to change that. 
Nanotechnology, where the autocrat is simply stronger</a> than the rest of
<a name="3358qlink3">the population, might make autocracy practicable.</a>

<p>
<a name="3391qlink1"><a href="3343.html#3351qlink2">&gt; Democracy, on the other hand, would not function even as well as it does</a><br>
<i>&gt; now.  The truth machine would give us politicians who actually believe</i><br>
<i>&gt; whatever the majority opinion happens to be one the major issues of an</i><br>
<i>&gt; election, which is not a good thing when the majority is usually wrong.</i><br>
<i>&gt; Worse, it would remove one of the major barriers that prevents all those</i><br>
<i>&gt; stupid regulations from being enforced - imagine what agencies like the IRS,</i><br>
<i>&gt; the EPA and OSHA would do with it.</i><br>

<p>
<a name="3358qlink4">The question is whether truth machines enhance the collective
intelligence by eliminating liars and exploiters, or dehance by
requiring rationalization and eliminating dissent.</a>  Perhaps the majority
opinion will change for the better when their sole choice is between
honest fundamentalists, honest liberals, honest conservatives, honest
communists, and honest libertarians.  It's the people selling dumb
little compromises, and the people dishonestly pretending to go along
with the majority opinion, who are the current problem.
</a>

<p>
<a name="3391qlink2">Perhaps true rational debate will become possible when everyone has to
acknowledge the honesty and goodwill of all the others.  The whole
opinion space would be reshaped; it's not just a question of the current
space being enforced.  I think that on the whole it would wind up being
an enhancement, but your position is certainly defensible.</a>

<p>
<a name="3391qlink3">If I turn out to be wrong, I'd have to drastically change my current
strategy.  Why?  Similar questions apply to collaborative filtering -
does it enhance intelligence by seeking out correct arguments and
skeptical counterarguments, or does it dehance intelligence by telling
everyone only what they want to believe?</a>

<p>
<a name="3391qlink4">Both, of course, but who wins?  Regardless of the initial percentages,
is there sufficient conflict for the advantages of the enhanced users to
become apparent and the enhanced users to become the majority?

<p>
Are there enough democracies for one of them to turn libertarian and
incorruptible under the influence of truth machines (or collaborative
filtering) and export leaders to all the others?

<p>
My intuition perceives truth machines and collaborative filtering as
fundamentally similar.</a>

<p>
<a name="3391qlink5"><a href="3343.html#3351qlink3">&gt; In a world with truth machines, autocracy could easily be a more viable form</a><br>
<i>&gt; of government than democracy.</i><br>

<p>
You have a definite point, and perhaps it will depend strongly on
initial conditions.  A theocracy might have internal faction fights, but
could easily fill the government and army with people who are not only
"not planning revolution" but who fanatically believe in the current
government.  Regular interrogations could eliminate doubts (or in
extreme cases doubters) and thus allow a wealthy theocracy, without the
secularism that usually accompanies affluence.

<p>
Basically the question is "Do you prefer Bill Clinton, a slimebucket
who's too busy compromising to be a real communist, or do you prefer Al
Gore, a reasonably intelligent person who's an environmentalist?"  On
the whole, I'd poison Clinton any day.  Slimebuckets do more damage to a
democracy than honest fanatics.  I serve intelligence, and there is
basically no circumstance under which I prefer stupidity</a> to
intelligence.  Unless the other guy is, not just the loyal opposition,
but actually sighting down a rifle at me.
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3352.html">[ Next ]</a><a href="3350.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3343.html">Billy Brown</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="3358.html">Billy Brown</a>
</ul>
</body></html>
