<!-- received="Wed Dec  9 11:58:00 1998 MST" -->
<!-- sent="Wed, 09 Dec 1998 12:59:34 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity: AI Morality" -->
<!-- id="366EC891.31073418@pobox.com" -->
<!-- inreplyto="Singularity: AI Morality" -->
<!-- version=1.10, linesinbody=30 -->
<html><head><title>extropy: Re: Singularity: AI Morality</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Singularity: AI Morality</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Wed, 09 Dec 1998 12:59:34 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2343">[ date ]</a><a href="index.html#2343">[ thread ]</a><a href="subject.html#2343">[ subject ]</a><a href="author.html#2343">[ author ]</a>
<!-- next="start" -->
<li><a href="2344.html">[ Next ]</a><a href="2342.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2331.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2417.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
Robin Hanson wrote:
<br>
<i>&gt; </i><br>
<a name="2417qlink1"><a href="2331.html#2343qlink1">&gt; Well we could do a little more; we might create lots of different AIs</a><br>
<i>&gt; and observer how they treat each other in contained environments.  We might</i><br>
<i>&gt; then repeatedly select the ones whose behavior we deem "moral."  And once</i><br>
<i>&gt; we have creatures whose behavior seems stably "moral" we could release them</i><br>
<i>&gt; to participate in the big world.</i><br>

<p>
Anything that can safely be stuffed into a contained environment isn't any
sort of AI that we need to worry about.  Such threat management techniques are
useful only against programs that can be filed and forgotten.  Remember, we're
talking about Culture Minds and Vingean Powers, not your mail filter.  Yours
is a way to ensure the integrity of the global data network, not to protect
the survival of humanity.</a>

<p>
<a name="2353qlink1">As for pulling this trick on genuine SIs:

<p>
This would ENSURE that at least one of the SIs went nuts, broke out of your
little sandbox, and stomped on the planet!  This multiplies the risk factor by
a hundred times for no conceivable benefit!  I would rather have three million
<a name="2417qlink2">lines of Asimov Laws written in COBOL than run evolutionary simulations!</a>  No
matter how badly you screw up ONE mind, there's a good chance it will shake it
off and go sane!</a>
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2344.html">[ Next ]</a><a href="2342.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2331.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2417.html">Robin Hanson</a>
</ul>
</body></html>
