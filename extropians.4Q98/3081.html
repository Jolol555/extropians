<!-- received="Wed Dec 16 13:41:24 1998 MST" -->
<!-- sent="Wed, 16 Dec 1998 14:43:10 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Failure of AI a prediction of Neal Stephenson's "The Diamond Age"" -->
<!-- id="36781B55.45142855@pobox.com" -->
<!-- inreplyto="Failure of AI a prediction of Neal Stephenson's "The Diamond Age"" -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropy: Re: Failure of AI a prediction of Neal Stephenson's "The Diamond Age"</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Failure of AI a prediction of Neal Stephenson's "The Diamond Age"</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Wed, 16 Dec 1998 14:43:10 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3081">[ date ]</a><a href="index.html#3081">[ thread ]</a><a href="subject.html#3081">[ subject ]</a><a href="author.html#3081">[ author ]</a>
<!-- next="start" -->
<li><a href="3082.html">[ Next ]</a><a href="3080.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3054.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Anders Sandberg wrote:
<br>
<i>&gt; </i><br>
<a href="3054.html#3081qlink1">&gt; I think FTL travel is impossible (without shortcuts and tricks like</a><br>
<i>&gt; wormholes).</i><br>

<p>
Well, nobody (except the folks on Star Trek) was claiming that you could
just get out and push.  This is like saying the sky is blue unless it isn't.

<p>
<a href="3054.html#3081qlink2">&gt; So? Suppose it really turns out that there are souls (of the kind</a><br>
<i>&gt; people commonly believe in). Would that invalidate extropianism? Not</i><br>
<i>&gt; the least, it would just mean we have to adjust our plans. Like for</i><br>
<i>&gt; example study how to make AI with souls.</i><br>

<p>
Yes, this is exactly the point I was trying to convey last year during
the debate about Turing computability; even if the Atheist's Worst Case
is true and there are noncomputable indestructible structures
interfacing our neurons, this does not mean that these structures are
outside physics, logic, or the scientific method.  At absolute worst
they might be intrinsically incomprehensible to our intelligence, but
even so all the specifications for producing any effects involved would
have to be encoded in a few megabytes of DNA.  So there are no
emotional/political/social reasons for preferring Strong AI or the
Church-Turing thesis to their negations; they are simply open questions
to be resolved by experiment.

<p>
I do happen to believe reality is noncomputable; but I don't think it's
intrinsic to our reasoning methods (to consciousness, perhaps, but not
to intuitions or emotions).  In the event that I'm wrong about the
latter, we would simply dissect neurons until we could duplicate the
effect in silicon.  None of this presents any sort of impassable obstacle.
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3082.html">[ Next ]</a><a href="3080.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3054.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
</body></html>
