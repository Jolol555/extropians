<!-- received="Sun Nov 22 17:29:16 1998 MST" -->
<!-- sent="Mon, 23 Nov 1998 00:28:02 +0000" -->
<!-- name="Nick Bostrom" -->
<!-- email="bostrom@ndirect.co.uk" -->
<!-- subject="Delicate complexity? (was: RE: computronium prime-oxide_" -->
<!-- id="199811230029.AAA16296@andromeda.hosts.netdirect.net.uk" -->
<!-- inreplyto="199811191832.KAA12398@hal.sb.rain.org" -->
<!-- version=1.10, linesinbody=33 -->
<html><head><title>extropy: Delicate complexity? (was: RE: computronium prime-oxide_</title>
<meta name=author content="Nick Bostrom">
<link rel=author rev=made href="mailto:bostrom@ndirect.co.uk" title ="Nick Bostrom">
</head><body>
<h1>Delicate complexity? (was: RE: computronium prime-oxide_</h1>
Nick Bostrom (<i>bostrom@ndirect.co.uk</i>)<br>
<i>Mon, 23 Nov 1998 00:28:02 +0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1571">[ date ]</a><a href="index.html#1571">[ thread ]</a><a href="subject.html#1571">[ subject ]</a><a href="author.html#1571">[ author ]</a>
<!-- next="start" -->
<li><a href="1572.html">[ Next ]</a><a href="1570.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1382.html">Hal Finney</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2290.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
Hal Finney wrote:

<p>
<i>&gt; they ran into balancing problems, where trivial</i><br>
<a href="1382.html#1571qlink1">&gt; strategies would dominate (often a problem with alife simulations).</a><br>
<i>&gt; At last report they were introducing various ad hoc rules and limitations</i><br>
<i>&gt; to try to get robust evolutionary behavior.</i><br>

<p>
At this most basic level, complexity or growth in compexity does 
certainly not seem to be the most likely or natural situation. But 
since it's boring (for the human psychology), we change the 
parameters in the simulation until we get something interesting. It 
makes me wonder if we may not be prone to overestimate the likelihood 
that the far future will be complex.


<p>
<a name="2290qlink1"><a name="1646qlink1"><a name="1573qlink1">It appears to me that Anders and Robin (and Max?) have a tendency</a> to 
think that there are lots of checks and balances in the nature of 
things, and that tradeoffs and diminishing returns guarantee that a 
large variety of different strategies will always co-exist. Eliezer 
and other extreme singularians (and to some extent me) seem to think 
that the world and posthuman society might well be more brittle, and 
that system could easily end up in one of the "boring" states, 
i.e. simple states.</a> (If the universe were transformed into a giant 
</a>
pleasure-machine, for example, it might be a simple state, but not a 
boring one from the insiders point-of-view.) In a factor analysis of 
different thinking styles in transhumanism, I would expect this to 
turn out to be one of the basic dimensions.

<p>
Nick Bostrom
<br>
<a href="http://www.hedweb.com/nickb">http://www.hedweb.com/nickb</a>      n.bostrom@lse.ac.uk
Department of Philosophy, Logic and Scientific Method
London School of Economics
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1572.html">[ Next ]</a><a href="1570.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1382.html">Hal Finney</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2290.html">Robin Hanson</a>
</ul>
</body></html>
