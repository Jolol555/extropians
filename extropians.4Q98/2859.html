<!-- received="Mon Dec 14 17:59:23 1998 MST" -->
<!-- sent="Mon, 14 Dec 1998 16:58:40 -0800" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: Challenge of Design Complexity" -->
<!-- id="3.0.3.32.19981214165840.00cf5f30@econ.berkeley.edu" -->
<!-- inreplyto="36758553.3A6048D7@pobox.com" -->
<!-- version=1.10, linesinbody=37 -->
<html><head><title>extropy: Re: Challenge of Design Complexity</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: Challenge of Design Complexity</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Mon, 14 Dec 1998 16:58:40 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2859">[ date ]</a><a href="index.html#2859">[ thread ]</a><a href="subject.html#2859">[ subject ]</a><a href="author.html#2859">[ author ]</a>
<!-- next="start" -->
<li><a href="2860.html">[ Next ]</a><a href="2858.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2828.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="2957qlink1">Eliezer S. Yudkowsky wrote:
<br>
<a href="2828.html#2859qlink1">&gt;&gt;            At the world level, average IQ scores have increased</a><br>
<i>&gt;&gt;            dramatically over the last century (the Flynn effect), as the</i><br>
<i>&gt;&gt;            world has learned better ways to think and to teach.</i><br>
<i>&gt;&gt;            Nevertheless, IQs have improved steadily, instead of</i><br>
<i>&gt;&gt;            accelerating. Similarly, for decades computer and</i><br>
<i>&gt;&gt;            communication aids have made engineers much "smarter,"</i><br>
<i>&gt;&gt;            without accelerating Moore's law. While engineers got</i><br>
<i>&gt;&gt;            smarter, their design tasks got harder.</i><br>
<i>&gt;</i><br>
<i>&gt;And, to summarize briefly my reply from the Singularity debate:</i><br>
<i>&gt;</i><br>
<i>&gt;All your examples, and moreover all your assumptions, deal with (1) roughly</i><br>
<i>&gt;constant intelligence and (2) a total lack of positive feedback.  That is, the</i><br>
<i>&gt;model treats with the curve of a constant optimizing ability, which quite</i><br>
<i>&gt;naturally peters out.  The improvements are not to the optimizing ability,</a> but</i><br>
<i>&gt;to something else.  The Flynn effect improves brains, not evolution.  Moore's</i><br>
<i>&gt;law improves hardware, and even VLSI design aids, but not brains.  There's no</i><br>
<i>&gt;positive feedback into anything, much less intelligence.  With intelligence</i><br>
<i>&gt;enhancement, each increment of intelligence results in a new prioritized list,</i><br>
<i>&gt;since improving intelligence changes which improvements can be contemplated or perceived.</i><br>

<p>
<a name="2867qlink1">To me these are theories of a "magic something else."  Sure, you admit, 
IQ has increased, knowledge has grown, communication has improved, and 
we have better decision &amp; design aids.  But to you none of this counts 
as "feedback" because "intelligence" is "something else," something not 
captured in all the usual concepts of and measures of intelligence, and
something which has not improved in eons.   But when we learn to improve 
that something else, you say, watch out!  Maybe, I say, but maybe there 
is no magic frozen now but oh so powerful something else. 
</a>


<p>
Robin Hanson  
<pre>
hanson@econ.berkeley.edu     <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar             FAX: 510-643-8614 
140 Warren Hall, UC Berkeley, CA 94720-7360 510-643-1884     
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2860.html">[ Next ]</a><a href="2858.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2828.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
