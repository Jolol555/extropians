<!-- received="Mon Dec 14 08:49:48 1998 MST" -->
<!-- sent="Mon, 14 Dec 1998 09:49:24 -0600" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="Challenge of Design Complexity" -->
<!-- id="003f01be2779$53f93680$352501c0@mfg130" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=46 -->
<html><head><title>extropy: Challenge of Design Complexity</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>Challenge of Design Complexity</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Mon, 14 Dec 1998 09:49:24 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2751">[ date ]</a><a href="index.html#2751">[ thread ]</a><a href="subject.html#2751">[ subject ]</a><a href="author.html#2751">[ author ]</a>
<!-- next="start" -->
<li><a href="2752.html">[ Next ]</a><a href="2750.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2788.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
<a name="2788qlink1">I was reading some of the previous debates on the Singularity in the list
archives recently, when it struck me that there is a major factor that does
not seem to have been seriously considered.

<p>
<a name="3234qlink1">Simply put, the more advanced a technology becomes, the more work it takes
to improve it.  As technology advances there is a general tendency</a> for
<a name="3234qlink2">everything to become more complex, which means more work for the engineers.</a></a>
<a name="3234qlink3">Sometimes you can counteract this trend with better information technology
(the Internet is a good example), but not always (look at the amount of
human effort needed to build successive CPU designs - its a pretty steep
upward trend).</a>

<p>
<a name="3234qlink4">IMO, this principle has several important implications:

<p>
First, it means that advanced nanotechnology is not possible without major
breakthroughs in automated engineering and/or intelligence enhancement.  Why
not?  Well, diamondoid parts might be simple repeating structures,</a> but
<a name="3234qlink5">something like smart matter or utility fog requires that you decide what to
do with every single atom (that's about 10^22 design decisions per pound of
object!).  It isn't practical to design that with human minds.</a>

<p>
<a name="3234qlink6">Second, a self-enhancing AI can't expect to optimize its way into an SI
unless it has SI-level hardware to run on.  It might, if it is very lucky,</a>
<a name="3234qlink7">but it is more likely to proceed in a series of sharp upward jumps separated
by lulls while it waits for faster hardware.  You probably need nanotech to
build the computers to run an SI, and you can't design the nanotech</a> unless
<a name="3234qlink8">you are pretty close to being an SI anyway.

<p>
Because of these factors, a Singularity is likely to have a slow takeoff.
You may have sudden jumps (when the first sentient AI goes online, or the
first general-purpose assembler goes into operation), but each improvement
simply leads to a new plateau while you wait for the rest of your tech base
to catch up.  The open-ended, geometric nature of the critical</a> enabling
<a name="3234qlink9">technologies (computers, telecommunications, and eventually AI and
intelligence enhancement in general) means that the overall rate of progress
will continue to increase, but a sudden discontinuity is unlikely.</a>
<a name="3234qlink10">Something that looks like a Singularity from a human perspective is still
quite likely, but to the people who make it happen it will look like just
another day of steady progress.</a>

<p>
<a name="3234qlink11">So what do you guys think?</a>

<p>
Billy Brown, MCSE+I
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2752.html">[ Next ]</a><a href="2750.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2788.html">Robin Hanson</a>
</ul>
</body></html>
