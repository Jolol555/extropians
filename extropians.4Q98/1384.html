<!-- received="Thu Nov 19 12:22:34 1998 MST" -->
<!-- sent="Thu, 19 Nov 1998 12:19:56 -0800" -->
<!-- name="Hal Finney" -->
<!-- email="hal@rain.org" -->
<!-- subject="Re: distributed AI was Re: computronium prime-oxide" -->
<!-- id="199811192019.MAA12575@hal.sb.rain.org" -->
<!-- inreplyto="distributed AI was Re: computronium prime-oxide" -->
<!-- version=1.10, linesinbody=29 -->
<html><head><title>extropy: Re: distributed AI was Re: computronium prime-oxide</title>
<meta name=author content="Hal Finney">
<link rel=author rev=made href="mailto:hal@rain.org" title ="Hal Finney">
</head><body>
<h1>Re: distributed AI was Re: computronium prime-oxide</h1>
Hal Finney (<i>hal@rain.org</i>)<br>
<i>Thu, 19 Nov 1998 12:19:56 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1384">[ date ]</a><a href="index.html#1384">[ thread ]</a><a href="subject.html#1384">[ subject ]</a><a href="author.html#1384">[ author ]</a>
<!-- next="start" -->
<li><a href="1385.html">[ Next ]</a><a href="1383.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1363.html">Timothy Bates</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="1386qlink1">Timothy Bates, &lt;tbates@bunyip.bhs.mq.edu.au&gt;, writes:
<br>
<a href="1363.html#1384qlink1">&gt; I asked Daniel Dennett if he was a Turing functionalist: he said yes and </a><br>
<i>&gt; no ;-)</i><br>
<i>&gt;</i><br>
<i>&gt; I think he said yes, but that interaction is critical, he views </i><br>
<i>&gt; intelligence as being embedded in the machines environment as well as in </i><br>
<i>&gt; its own hardware. For this reason he doubted that a paper tape Turing </i><br>
<i>&gt; machine could be conscious as the environmental context on which </i><br>
<i>&gt; consciousness is scaffolded (in his, but not my) view, would be invisible </i><br>
<i>&gt; to it: a kind of Nyquist limit for implementation speeds.</i><br>

<p>
I don't understand this view.

<p>
Do you think Dennett would predict that a person would instantly become
unconscious if he were put into a complete sensory deprivation booth?
It seems pretty obvious to me that he would continue to be conscious.
There was a fad for sensory deprivation in the 1970s and from what I
understand you sometimes would begin to hallucinate after a while, but
you certainly still remained conscious (and I suspect the hallucination
had much to do with expectations).

<p>
In any case, surely the Turing machine could include a modest VR
simulation in addition to the brain simulation, sufficient to provide
virtual environmental interaction.  Or would Dennett claim that
consciousness only occurs when the TM interacts with the "real world"?
That would seem absurd.
</a>

<p>
Hal
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1385.html">[ Next ]</a><a href="1383.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1363.html">Timothy Bates</a>
<!-- nextthread="start" -->
</ul>
</body></html>
