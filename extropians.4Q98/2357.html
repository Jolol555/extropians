<!-- received="Wed Dec  9 16:20:16 1998 MST" -->
<!-- sent="Wed, 9 Dec 1998 17:19:50 -0600" -->
<!-- name="Billy Brown" -->
<!-- email="bbrown@conemsco.com" -->
<!-- subject="RE: Singularity: AI Morality (AI containment)" -->
<!-- id="001a01be23ca$6d163350$352501c0@mfg130" -->
<!-- inreplyto="366EF409.45EDCEDE@posthuman.com" -->
<!-- version=1.10, linesinbody=26 -->
<html><head><title>extropy: RE: Singularity: AI Morality (AI containment)</title>
<meta name=author content="Billy Brown">
<link rel=author rev=made href="mailto:bbrown@conemsco.com" title ="Billy Brown">
</head><body>
<h1>RE: Singularity: AI Morality (AI containment)</h1>
Billy Brown (<i>bbrown@conemsco.com</i>)<br>
<i>Wed, 9 Dec 1998 17:19:50 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2357">[ date ]</a><a href="index.html#2357">[ thread ]</a><a href="subject.html#2357">[ subject ]</a><a href="author.html#2357">[ author ]</a>
<!-- next="start" -->
<li><a href="2358.html">[ Next ]</a><a href="2356.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2354.html">Brian Atkins</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Brian Atkins wrote:
<br>
<a href="2354.html#2357qlink1">&gt; Well ok imagine something like this: a large corporate decides</a><br>
<i>&gt; to develop its own "slave SI AI" so that it can take down its</i><br>
<i>&gt; corporate rivals more easily. So it builds a secure facility</i><br>
<i>&gt; for it, totally cut off from the Internet or other computers,</i><br>
<i>&gt; in a physically secure room with very very strict security</i><br>
<i>&gt; procedures for the humans interacting with it. Now unless</i><br>
<i>&gt; some kind of silly plot device happens like on TV, this</i><br>
<i>&gt; should keep the AI contained, no? (assuming no wild physics</i><br>
<i>&gt; discoveries)</i><br>

<p>
Eliezer's last post gives an excellent enumeration of the reasons why we
can't rely on keeping it trapped.  Besides, what are you going to have it
do?  Write programs no human can understand, that will run on computers
outside the vault?  Design machines no one can understand, and build them
for it?  Tell us how to solve our social, political and economic problems,
and then act on its advice?

<p>
If the AI is merely Transhuman, you might be able to get something useful.
If it becomes an SI, anything that comes out of that vault is going to be a
trap capable of freeing it, destroying us, or both.

<p>
Billy Brown
<br>
bbrown@conemsco.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2358.html">[ Next ]</a><a href="2356.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2354.html">Brian Atkins</a>
<!-- nextthread="start" -->
</ul>
</body></html>
