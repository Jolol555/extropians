<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Sentience</title>
<meta name="Author" content="Dan Fabulich (daniel.fabulich@yale.edu)">
<meta name="Subject" content="Re: Sentience">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Sentience</h1>
<!-- received="Tue Dec 19 18:34:51 2000" -->
<!-- isoreceived="20001220013451" -->
<!-- sent="Tue, 19 Dec 2000 20:33:38 -0500 (EST)" -->
<!-- isosent="20001220013338" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Sentience" -->
<!-- id="Pine.GSO.4.10.10012191744580.23858-100000@morpheus.cis.yale.edu" -->
<!-- inreplyto="003001c0689f$e012ef80$37a3403e@i6x7m6" -->
<strong>From:</strong> Dan Fabulich (<a href="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Sentience&In-Reply-To=&lt;Pine.GSO.4.10.10012191744580.23858-100000@morpheus.cis.yale.edu&gt;"><em>daniel.fabulich@yale.edu</em></a>)<br>
<strong>Date:</strong> Tue Dec 19 2000 - 18:33:38 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4327.html">Chris Russo: "Re: Nanotech"</a>
<li><strong>Previous message:</strong> <a href="4325.html">Michael M. Butler: "Re: HUMOR Eliezer,"</a>
<li><strong>In reply to:</strong> <a href="4301.html">Steve Nichols: "Re: Sentience"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4329.html">Eliezer S. Yudkowsky: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4329.html">Eliezer S. Yudkowsky: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4344.html">John Clark: "Re: Sentience"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4326">[ date ]</a>
<a href="index.html#4326">[ thread ]</a>
<a href="subject.html#4326">[ subject ]</a>
<a href="author.html#4326">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Steve Nichols wrote:
<br>
<p><em>&gt; &gt;I doubt that as well!  But cite von Neumann, Turing and Church for
</em><br>
<em>&gt; &gt;pointing out that a Turing machine can do everything a massively
</em><br>
<em>&gt; &gt;parallel distributed system can do given enough time and tape.  We
</em><br>
<em>&gt; &gt;use massively parallel systems today because they are faster than
</em><br>
<em>&gt; &gt;cheaper than doing these jobs serially, not because there are some
</em><br>
<em>&gt; &gt;things that massively parallel systems can do but Turing machines
</em><br>
<em>&gt; &gt;can't.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The reason that neural computers are relevant in discussion of
</em><br>
<em>&gt; similarities to brains and that Turing machines are not is that
</em><br>
<em>&gt; in fact neural (massively distributed parallel) designs *come from*
</em><br>
<em>&gt; modelling and reverse engineering of brains! In no way are brains
</em><br>
<em>&gt; like Turing or Von Neumann architecture.
</em><br>
<p>Brains are like Turing machines in that they are composed entirely of
<br>
simple physical parts that do simple physical things.  These physical
<br>
parts move deterministically in lock-step.  (Though, to qualify this
<br>
view, I'm a fan of many-worlds.)
<br>
<p>Moreover, the physical world is causally closed.  Nothing non-physical
<br>
interacts with the brain.  Your tests establish a physical causal link
<br>
between the real pineal eye and a lack of intelligent behavior.  As
<br>
the eye goes away, assuming you're right about this, intelligent
<br>
behavior begins to flourish.
<br>
<p>But you did not measure consciousness; you cannot do so.
<br>
<p>For the purposes of discussion with you, I'm an epiphenomenalist.  To
<br>
the extent that we have conscious experiences at all, our experiences
<br>
do not cause anything to happen in the world at all.  (That is,
<br>
everything physical would happen exactly the same whether or not we
<br>
had experiences; we'd act the same without them, etc.)  Physical
<br>
things are correlated with (my) experiences, perhaps even cause our
<br>
experiences, and thus our experiences are fully physically determined.
<br>
But our experiences in no way affect the real world.
<br>
<p>For all I know, the Turing machine DOES feel something when it
<br>
emulates me.  I'll never know.  I can ask it.  It may pass the Turing
<br>
Test.  But I'll still never know.  At least at that point I'll know as
<br>
well as I know about you or John Clark or anyone else, which is good
<br>
enough for me.
<br>
<p><em>&gt; &gt;Yes, there are.  Try to think of a REALLY BIG NUMBER.  Now think of a
</em><br>
<em>&gt; &gt;number that long with all of its digits randomized.  You can imagine
</em><br>
<em>&gt; &gt;it as an opaque term (just like most of us can only imagine a number
</em><br>
<em>&gt; &gt;as large as a trillion) but you can't actually hold it in your mind.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But in inventing and articulating the above example you provide evidence
</em><br>
<em>&gt; to us that you HAVE thought of what you describe. Anyway, you pointed
</em><br>
<em>&gt; out earlier that true randomness doesn't exist, so a machine would have
</em><br>
<em>&gt; the same conceptual problem about that that we do.
</em><br>
<p>No, that's thinking about it as an &quot;opaque term.&quot;  You can hold those
<br>
words in your mind, you can have some mental pictures, some notion of
<br>
what it would be like to actually imagine that, but you can't actually
<br>
have the whole thing in your mind.
<br>
<p>I could go further into opaque terms, but it's a rather dull and
<br>
irrelevant philosophical sidetrack.
<br>
<p><em>&gt; &gt;Alternately, try to imagine all of Shakespeare's Hamlet at once.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; By &quot;at once&quot; do you mean &quot;instantaneously&quot; or do you mean &quot;a very short
</em><br>
<em>&gt; time, like 2 seconds.&quot; ? I can imagine both ... as a very blurry noise and
</em><br>
<em>&gt; flash of actors moving on stage.
</em><br>
<p>I actually had the full text of Hamlet in mind when I said that.
<br>
<p><em>&gt; &gt;Hey.  That's sort of like the memory limitations on a computer.  Hmm.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I doubt a computer could &quot;imagine&quot; anything at all .......
</em><br>
<p>That is why you fail.
<br>
<p><em>&gt; &gt; Actually, you're right if you count games where the players keep
</em><br>
<em>&gt; &gt; moving their pieces back and forth in a circle.  They can do that an
</em><br>
<em>&gt; &gt; arbitrary number of times.  But I don't think that's quite what you meant.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Absolutely, it doesn't matter that there is some repetition, I just used
</em><br>
<em>&gt; this to
</em><br>
<em>&gt; prove my point against your original claim about atoms.
</em><br>
<p>This doesn't help your case.  Sure, atoms can cycle through their
<br>
finite states an infinite number of times, just as a Turing machine
<br>
can, or a chess board.  But that doesn't imply that there's anything
<br>
infinite state about them at all.
<br>
<p><em>&gt; Do you have problems accepting the evidence for phantoms limbs?
</em><br>
<em>&gt; These &quot;non-physical components&quot; have been widely accepted by science
</em><br>
<em>&gt; for hundreds of years, and certainly aren't disputed by those afflicted
</em><br>
<em>&gt; with phantom pain.
</em><br>
<p>Phantom limbs aren't *real*.  They're a handy term to explain real
<br>
phenomena, but they don't actually exist.  It's like when I say things
<br>
like &quot;Insects give me the creeps.&quot;  I don't posit that there are
<br>
REALLY &quot;creeps&quot; which insects give me.  I just mean that they make me
<br>
nervous.  Similarly with phantom limbs: there's no *actual* limb
<br>
there, phantom or otherwise.
<br>
<p>If you like, you can call the phantom limbs non-existent objects
<br>
interacting with the physical world.  The car crashed on account of a
<br>
phantom driver at the wheel, ie no driver at all.
<br>
<p>But that doesn't leave you in a good position to explain
<br>
consciousness.  Just as *existing* physical phenomena provided us with
<br>
no good explanation of consciousness, *non-existing* objects do us no
<br>
better.  Can you prove that it's the case that not-having a pineal eye
<br>
makes us *conscious* above and beyond making us intelligent?
<br>
<p><em>&gt; The key point of MVT, and how it DOES explain consciousness, is that
</em><br>
<em>&gt; the phantom limb (or phantom sense-organ) is a *felt* phenomenon.
</em><br>
<em>&gt; The difficulty in measuring such phenomena does not make them less
</em><br>
<em>&gt; real .... but just points to a shortfall in our methods of measuring.
</em><br>
<p>No, it's deeper than that.  This still offers us with no explanation
<br>
for *how* our consciousness happens.  You tell me WHEN (when there's
<br>
no pineal eye) but not HOW.
<br>
<p><em>&gt; Only biological organisms can act independently from purely
</em><br>
<em>&gt; chemical stimuli ...so we are talking about a very small subset of
</em><br>
<em>&gt; &quot;atomic structures&quot; ... even more specifically, those animals with
</em><br>
<em>&gt; E-1 brains.
</em><br>
<p>Brains *cannot* act independently of chemical stimuli.  They are
<br>
purely physical objects, with no more independence from the world than
<br>
rocks have.  Biological organisms are completely physically
<br>
determined.
<br>
<p><em>&gt; My personal (plenumist) view is that atoms are themselves doubtful
</em><br>
<em>&gt; as discrete entities, and I disagree with Heraclitus (?) claim that
</em><br>
<em>&gt; &quot;only atoms and the void are real.&quot; I think that a Popperian third world
</em><br>
<em>&gt; of consciousness is independent of physical action, but is not &quot;void.&quot;
</em><br>
<p>If you like, we can be epiphenomenalists.  My actual views on this are
<br>
so fully divorced from your own that I don't think it's even worth
<br>
bringing them up at this stage in the discussion.
<br>
<p><em>&gt; (S) Anyway, big blue is a CPU machine, not even a neural computer, so is
</em><br>
<em>&gt; (S) absolutely nothing like a brain. Are you saying the DNA is the
</em><br>
<em>&gt; (S) &quot;program&quot; or what other medium are you identifying?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;The medium is your neurons.  None of them can do anything
</em><br>
<em>&gt; &gt;non-physical.  So your brain can't do anything non-physical.  So your
</em><br>
<em>&gt; &gt;brain is entirely physical.  Physical stuff happens in lock-step
</em><br>
<em>&gt; &gt;(because time happens in very small quanta) so the brain is emulatable
</em><br>
<em>&gt; &gt;with a sufficiently complex Turing machine.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure, neurons in isolation can't do much, but taken as a matrix
</em><br>
<em>&gt; (maybe even including brain stem and both nervous systems)
</em><br>
<em>&gt; they are able to generate a phantom pineal eye,
</em><br>
<p>How do you &quot;generate&quot; a non-existent entity?
<br>
<p><em>&gt; a complete theory of mind
</em><br>
<em>&gt; should explain how, for example, we can see objects although
</em><br>
<em>&gt; our lateral eyes are closed, or &quot;hear&quot; an internal voice even though
</em><br>
<em>&gt; our mouth is closed and we are not talking out loud.
</em><br>
<p>No.  We will find structural behavioral analogs, but we will never
<br>
figure out why we see anything at all.  We'll be able to figure out
<br>
*when* we see something, but not how.
<br>
<p><em>&gt; There is even a question about non-physical quanta effects
</em><br>
<em>&gt; (action at a distance &amp;c.) so even atomsaren't as &quot;solid&quot; and physical
</em><br>
<em>&gt; as you seem to claim ...
</em><br>
<p>Again, I'm a many-worlds fan; I don't think action at a distance
<br>
happens.
<br>
<p><em>&gt; let alone if we speculate on the physical or
</em><br>
<em>&gt; non-physicalness at the very centre (the Singularity!) at the middle of
</em><br>
<em>&gt; a black hole).
</em><br>
<p>Certainly true.  New physics may lead me to reject my views about
<br>
what's physical and what's not.  But consciousness will never be on
<br>
the list.
<br>
<p><em>&gt; Let me now reject your Turing machine nonsense yet again  .....
</em><br>
<em>&gt; (1) Emulation is not the same as the thing being emulated, so even
</em><br>
<em>&gt; if a Turing machine could emulate the functions of a brain, we are
</em><br>
<em>&gt; no further forwards.
</em><br>
<p>Yes, no further than any other physical theory of intelligence.
<br>
<p><em>&gt; (2) The Turing emulation would not &quot;feel&quot; anything, and could not
</em><br>
<em>&gt; dream (for example).
</em><br>
<p>It would *emulate* dreaming.  You can't show that this is not the same
<br>
thing, that it wouldn't feel like it was dreaming.  How would you
<br>
know, if it described its dream to you as vividly as anyone else?
<br>
<p><em>&gt; (3) Your account does not get rid of the homunculus (in your deep blue
</em><br>
<em>&gt; case a whole team of homunculi ... human programmers tweaking
</em><br>
<em>&gt; the software). MVT is a fully self-servicing and evolutionary account.
</em><br>
<p>Where's the homunculus?  I'm saying that nature has evolved a Turing
<br>
machine.  This is no more mysterious, I argue, than nature having
<br>
evolved any other machine, like a lever/pully system, a hydraulics
<br>
system, or dam building.
<br>
<p><em>&gt; I think there is a difference between look-up table &quot;learning&quot; and neural
</em><br>
<em>&gt; learning such as Reinforcement Learning (eg. in world champ. Backgammon
</em><br>
<em>&gt; software &quot;NeuroGammon.&quot;) or Learning I.A.C (interactive activation &amp;
</em><br>
<em>&gt; competition .. a distributed database alternative modelled on brains).
</em><br>
<p>There are obvious differences; none of these differences are relevant,
<br>
however.  (In particular, some of these solutions are more workable
<br>
approaches to AI than others.)
<br>
<p><em>&gt; Changing play style is trifling stuff .... and I should
</em><br>
<em>&gt; know, having designed or programmed three Chess-type games (Shogi,
</em><br>
<em>&gt; Chaturanga .. ancestor of common chess, which is a mere human-era
</em><br>
<em>&gt; Chaturanga variant!, and Enochian Chess, which includes an IAC neural
</em><br>
<em>&gt; patch).
</em><br>
<p>Changing play style IS trifling.  Doing it well isn't.
<br>
<p><em>&gt; &gt;Improving your game of chess is learning.  It's simple learning, but
</em><br>
<em>&gt; &gt;it IS learning.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Maybe, on the most simple definition, but nothing like human-scale.
</em><br>
<em>&gt; Deep Blue is an autistic moron!
</em><br>
<p>Yes, but my point is that it's only a matter of scale.
<br>
<p><em>&gt; But it can't change its programming or deal with new situations,
</em><br>
<em>&gt; its microcosmical &quot;chess-rule world&quot; is an artificial human-made
</em><br>
<em>&gt; game-world to start with. It doesn't think like Kasparov, but uses
</em><br>
<em>&gt; brute-force algorithms suited to von Neumann processing.
</em><br>
<p>It uses a different algorithm from the one Kasparov uses.  But
<br>
Kasparov uses an algorithm too.  (His is certainly better, but it's
<br>
hard to read off from the neurons, and ever trickier to program.)
<br>
<p><em>&gt; &gt;Not all PEOPLE are good at that.  But nonetheless, an adequately
</em><br>
<em>&gt; &gt;complex Turing program can &quot;deal with&quot; circumstances as new as we can.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Maybe not all are good at it, but even the stupidest human can do it.
</em><br>
<em>&gt; Deep Blue can't. Which Turing machine are you talking about here ...
</em><br>
<em>&gt; one of your (E-1 brain-powered) imaginary ones perhaps?
</em><br>
<p>No, just an ordinary Turing machine built by evolution, like the one
<br>
you've got in your head.
<br>
<p><em>&gt; &gt;The same thing happens to us.  We don't have free will.  Nothing is
</em><br>
<em>&gt; &gt;within our remit.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Plants, and simple E-2 (pineal eyed) animals have no free will.
</em><br>
<em>&gt; There behaviour is governed by the sunlight and seasonal shifts,
</em><br>
<em>&gt; plus chemical taxis &amp;c. However, we E-1 animals have gained
</em><br>
<em>&gt; indepence from external governance of behaviour rom sunlight
</em><br>
<em>&gt; (via the old pineal eye) and *do* have self-volition or free will.
</em><br>
<p><em>&gt; The term &quot;free will&quot; would not ever have been invented if things were
</em><br>
<em>&gt; otherwise ..... the fact we can discuss it proves it almost.
</em><br>
<p>&lt;blink blink&gt;  Can you make that inference a little more explicit?
<br>
<p>Certainly you don't mean the following:
<br>
<p>(1) We came up with the term &quot;free will.&quot;
<br>
(2) If we came up with a term, its referent must exist.
<br>
(3) Therefore free will exists.
<br>
<p>The argument against free will follows directly from the causal
<br>
closure of physics.  Even if you think that there are truly random
<br>
elements in the physical world, that doesn't mean that there's
<br>
anything going on in the world that's a *choice*.
<br>
<p>Everything is either deterministic or random.  Neither of these, nor
<br>
any composition of the two, constitute free will.
<br>
<p><em>&gt; &gt;Neither can you.  Your programming is more complex, but that's all.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes I could ... like Captain Scott ... decide to override my body and
</em><br>
<em>&gt; voluntarily freeze to death!
</em><br>
<p>Your decision to do so would be based on your *desires* to do so.  You
<br>
can't change those effectively, as I'll discuss.
<br>
<p><em>&gt; &gt;You act according to your desires and beliefs.  You cannot change your
</em><br>
<em>&gt; &gt;desires very much, and you can hardly change your desire to desire
</em><br>
<em>&gt; &gt;different things at all.  You cannot change your beliefs either.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; As an NLP and Hypnotherapy practitioner, of course I reject your
</em><br>
<em>&gt; claim as completely groundless.
</em><br>
<p>Actually, I can accept an arbitrary degree of flexibility at a given
<br>
level of desire.
<br>
<p>Suppose you can change any of your desires by hypnosis.  Nonetheless,
<br>
some of your desires are determined externally: by your environment or
<br>
genetics.
<br>
<p>You're not hypnotizing yourself right this instant.  Presumably
<br>
because you don't desire to do so.  So you have a desire, call it D,
<br>
the desire &quot;not to change my own desires via hypnosis.&quot;
<br>
<p>Naturally, you can't voluntarily hypnotize yourself when you have D.
<br>
If D is externally determined (by environment or genetics or whatever)
<br>
then YOU can't choose to change your desires via hypnosis at all.  You
<br>
will simply *refuse* to change your own desires via hypnosis unless
<br>
and until the environment changes your mind about D.
<br>
<p>Of course, you could change D via hypnosis, if you desired to.  But D
<br>
includes a desire not to change D via hypnosis.  So you can't
<br>
voluntarily change D via hypnosis, until your desires are changed by
<br>
the external world.
<br>
<p>Now, if D was originally set by environment or genetics, and you just
<br>
never changed it, then it seems that you can't voluntarily use
<br>
hypnosis at all unless your environment changes your mind for you.
<br>
But if D has been set by *you*, it was set by you because you desired
<br>
to do so, that is, because you had some other desire, D', the desire
<br>
&quot;to give myself desire D via hypnosis.&quot;  But D' is in the same state
<br>
as D: it was externally set or set by you.  And same with any D'', a
<br>
desire to set D'.  Or D'''.  And so on.
<br>
<p>So if any of those D^(n)s are set externally, then your behavior is
<br>
externally determined: you just mechanically followed through with
<br>
your externally determined desires, even when you changed a few of
<br>
them, because even then you were under the control of externally
<br>
determined higher-level desires telling you what to do.
<br>
<p>And, as it turns out, at least one of those D^(n)s IS externally
<br>
determined.  You're born with a set of desires determined by genetics
<br>
and environment, which you later revise.  You were built by something
<br>
which wasn't you.  So your desires are externally determined.
<br>
<p>So all of your behavior is externally determined: you simply follow
<br>
orders given by the environment and genetics.
<br>
<p><em>&gt;  &gt;You
</em><br>
<em>&gt; &gt;can decide what to say, but you cannot decide, for example, to drop
</em><br>
<em>&gt; &gt;your view about MVT and agree with me.  You have to be convinced, and
</em><br>
<em>&gt; &gt;you're not in control of when you get convinced.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I could decide to drop MVT, and would if (1) you could refute it, or
</em><br>
<em>&gt; (2) you outline a more convincing alternative theory that solves more
</em><br>
<em>&gt; questions and I considered to be a better account.  Go ahead,
</em><br>
<em>&gt; convince me!
</em><br>
<p>Right.  But you can't decide to drop MVT and those criteria.  You
<br>
desire to keep them, and you can't help it.  (Nor should you, in the
<br>
case of the criteria.)
<br>
<p><em>&gt; &gt;You're not in control of when you're happy.  You do things to make
</em><br>
<em>&gt; &gt;yourself happy because you desire happiness because that's part of the
</em><br>
<em>&gt; &gt;program.  When you do things, you have only the slightest control over
</em><br>
<em>&gt; &gt;whether they make you happy or not, and considerably less control over
</em><br>
<em>&gt; &gt;your desire to feel happy.  You're not in control of these things.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What are you babbling about here? I don't recognise any of these
</em><br>
<em>&gt; statements in myself. Are you talking from your own, solipsistic viewpoint?
</em><br>
<p>I'm not a solipsist.
<br>
<p><em>&gt; &gt;And what suggests consciousness besides intelligence?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Intelligence PLUS felt experience.
</em><br>
<p>What suggests felt experience besides intelligence?
<br>
<p><em>&gt; I think the onus is on you to make a case why someone who claims
</em><br>
<em>&gt; to have consciousness is in fact a robot.
</em><br>
<p>I concede.  I think that ANYONE who plausibly claims to have
<br>
consciousness is conscious.  Including robots.
<br>
<p><em>&gt; The subjective nature of the phenomena does maybe rule out
</em><br>
<em>&gt; &quot;objective&quot; tests, so indeed some new form of testing might be
</em><br>
<em>&gt; needed.
</em><br>
<p>No form of testing is possible.
<br>
<p><em>&gt; Am more interested in developments from MVT, what I can do and
</em><br>
<em>&gt; predict from it, than in satisfying some sterile academic or
</em><br>
<em>&gt; philosophical debate.
</em><br>
<p>Good!  It IS a stupid debate.  Why not just say that you've solved
<br>
animal intelligence and leave the sterile debate alone?
<br>
<p>Realizing that a debate is fruitless is not to win the debate.
<br>
<p><em>&gt; S&gt; The very fact that every aspect of Turing machines actions can be
</em><br>
<em>&gt; S&gt; predicted, I would say, might even preclude them from consciousness.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;No more than you are precluded from consciousness.  Your atoms have no
</em><br>
<em>&gt; &gt;free will.  You are composed entirely of atoms.  You have no more free
</em><br>
<em>&gt; &gt;will than they do.  An adequately informed and powerful computer could
</em><br>
<em>&gt; &gt;calculate your every move in a controlled environment.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Again (see above) you are looking at 'me' on the wrong level of
</em><br>
<em>&gt; description ..... why say I am composed of atoms rather than I am
</em><br>
<em>&gt; composed entirely of &quot;cells&quot; or &quot;molecules&quot; or &quot;sub-atomic particles?&quot;
</em><br>
<em>&gt; None of these levels is macro enough to explain consciousness, which
</em><br>
<em>&gt; requires the whole biomatrix, plus even phylogeny and embryonic history,
</em><br>
<em>&gt; to be properly understood. The whole is greater than the parts ... and the
</em><br>
<em>&gt; whole includes phantom body parts.
</em><br>
<p>I can say the same thing back to you, and it would be just as silly.
<br>
You're looking at the Turing machine on the wrong level of
<br>
description.  Why look at it as a punch card reader when you could
<br>
consider blocks of code, functional subsegments or bits on the tape?
<br>
None of these levels is macro enough to explain consiousness, which
<br>
requires the whole program, plus a Turing machine to operate them, to
<br>
be properly understood.
<br>
<p>This explanation is empty.
<br>
<p><em>&gt; Ah, but you have accepted that at least you, even if nobody else)
</em><br>
<em>&gt; has *dreams* .... which are non-physical ... 
</em><br>
<p>&lt;must resist blurting out my real opinion here&gt;
<br>
<p><em>&gt; they are temporal events
</em><br>
<em>&gt; but cannot be detected by crummy human-era science. So just by
</em><br>
<em>&gt; accepting dreams, as you have, then a distinction is made between the
</em><br>
<em>&gt; conscious experience, and the PET or EEG activity of the brain, which
</em><br>
<em>&gt; is detectable to scientists (but is unknown to the dreamer ... you don't
</em><br>
<em>&gt; need
</em><br>
<em>&gt; to know which of your neurons are firing in order to have thoughts).
</em><br>
<p>Sure thing.  The brain activity causes the consciousness.  But I don't
<br>
know how; can't know how.  I can only notice THAT it does, and WHEN.
<br>
Not why.  I can know WHICH brain activity results in which
<br>
experiences, but that's not knowing HOW that brain activity results in
<br>
experiences.
<br>
<p><em>&gt; Not even to &quot;really big&quot;. A component can be scalar as
</em><br>
<em>&gt; opposed to digital over a very narrow spectrum. It is just that it is
</em><br>
<em>&gt; a continuum potential rather than just discrete digital switching
</em><br>
<em>&gt; that leads it to be called analog.
</em><br>
<p>But the continuum isn't real, anymore then there's actually a smooth
<br>
curve on the letter O which appears on your computer screen.  It's
<br>
jagged, pixellated.  But it's so close to continuous, so near to
<br>
smooth, that you can and do over look it.
<br>
<p><em>&gt; S&gt; No, phasic transients occur simply because a circuit is undergoing
</em><br>
<em>&gt; S&gt; transformation from finite-state (lock step) to self-organising ....
</em><br>
<em>&gt; S&gt; and they happen after the removal of an external clock (whether
</em><br>
<em>&gt; S&gt; electronic or organic pineal eye). Aren't Turing machines always
</em><br>
<em>&gt; S&gt; lock-stepped?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;Why, yes.  Along with ATOMS.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There aren't any atoms in a phantom pineal eye, or in a thought ....
</em><br>
<em>&gt; your dreams cannot be observed precisely because they are NOT
</em><br>
<em>&gt; atomic!
</em><br>
<p>Too true.  But you just told me that you were using dreams to measure
<br>
consciousness.  But you can't observe dreams.  So you can't measure
<br>
consciousness.
<br>
<p><em>&gt; But MVT gives an account of why mammals dream, and furthermore
</em><br>
<em>&gt; throws new light on the melatonin hypothesis, and Menaker's work
</em><br>
<em>&gt; on REM and the evolutionary shift from pineal eye melatonin to
</em><br>
<em>&gt; retinal production. DREAMS are not &quot;intelligence&quot; and do not involve
</em><br>
<em>&gt; 'rational' cognition of processing of sensory information from external
</em><br>
<em>&gt; world ..... so MVT explains consciousness here rather than intelligence.
</em><br>
<p>Nope, you're explaining intelligent behavior.  In particular, there IS
<br>
dream behavior.  Wake someone in the middle of REM and they'll tell
<br>
you about the dream that they were having, and what it felt like.
<br>
That's dream behavior, just like how smiling and laughing and telling
<br>
me how wonderful you're feeling is happiness behavior.
<br>
<p>Don't you think that I'd ask any Turing machine trying to pass the
<br>
Turing Test what its last dream was like?  Answering me just like a
<br>
human would answer me is part of passing the Turing Test.  Reporting
<br>
on your dreams is part of what it is to exhibit intelligent behavior;
<br>
it's part of what it is to pass the Turing Test.
<br>
<p>You've given me an explanation for why people go into REM and report
<br>
to be dreaming after the fact.  This may be a great advance in the
<br>
theory of animal intelligence.  But you have given no explanation of
<br>
how or why REM, brain activity or dream reports have anything to do
<br>
with actually dreaming.  You could have and do all of these without
<br>
dreaming.
<br>
<p>What I'm trying to convince you of is to settle for intelligence.
<br>
This philosophical discussion is geared for you to lose.
<br>
Consciousness is defined in such a way that you can't ever give a
<br>
scientific account of it, you can't EVER show how mere physical stuff
<br>
could be conscious.  It's a waste of EVERYONE'S time.
<br>
<p>Accept that you've got a theory of intelligence, of acting like you're
<br>
dreaming.  That's more than enough.
<br>
<p><em>&gt; &gt;The problem of other minds asks: &quot;I know I'm conscious and
</em><br>
<em>&gt; &gt;intelligent, and I know you act intelligently.  But are you conscious,
</em><br>
<em>&gt; &gt;or do you just act that way?&quot;  This is a problem which your theory
</em><br>
<em>&gt; &gt;doesn't solve.  Keep your pants on, a solid theory of animal
</em><br>
<em>&gt; &gt;intelligence will still win you the Nobel, but it won't help you solve
</em><br>
<em>&gt; &gt;the mind-body problem.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; No, see above. The &quot;atomic&quot; brain is necessary, but not sufficient
</em><br>
<em>&gt; for consciousness. The virtual sensor(gan) is need to complete the
</em><br>
<em>&gt; gestalt experience of being intelligent. It is a substitute for sense
</em><br>
<em>&gt; messages from the sun and environment that used, in early evolution,
</em><br>
<em>&gt; to govern behaviour .... but also includes the &quot;felt&quot; aspects of the organ.
</em><br>
<p>Ahem.  The &quot;sensor&quot; isn't there.  How and why is it that something not
<br>
existing would cause me to have a feeling?  How can you show that this
<br>
is the case?  Can you give me any evidence that you have more on your
<br>
hands than a theory of intelligence?
<br>
<p><em>&gt; Sorry, I am a reductionist on these matters, and believe that human-era
</em><br>
<em>&gt; philosophers just perpetuate &quot;problems&quot; and do little to contribute to
</em><br>
<em>&gt; solutions. They are not qualified to make judgements on physiological or
</em><br>
<em>&gt; empirical issues ... academic philosophy seems to just be linguistic
</em><br>
<em>&gt; analysis.
</em><br>
<p>Quite right!
<br>
<p><em>&gt; In fact, together with religion, they are an unnecessary Mystery
</em><br>
<em>&gt; Industry that actual obstructs new knowledge and solutions so as to
</em><br>
<em>&gt; safeguard their incomes and paltry reputations. MVT is a more
</em><br>
<em>&gt; complete and basic theory than any narrow linguistic
</em><br>
<em>&gt; (definititional) account of the mind-body problem.
</em><br>
<p>I fully agree.  So let them play in their little play pen.  You have a
<br>
theory of intelligence.  Let them keep &quot;consciousness&quot;.
<br>
<p><em>&gt; It solves dualism ... since Leibnitz objection to Descartes is overcome.
</em><br>
<em>&gt; A non-physical part of the brain can interact with non-physico-spatial
</em><br>
<em>&gt; thoughts ... like can only interact with like. The phantom median eye
</em><br>
<em>&gt; is constructed out of the same neuronal type of information as the sensory
</em><br>
<em>&gt; contents, so can reintegrate or focus all the diverse types of mentation and
</em><br>
<em>&gt; give a pervasive locus of self. The phantom median eye is an illusion, or
</em><br>
<em>&gt; trick of nature ... sure ... but then what mental experience isn't illusory?
</em><br>
<p>Again, why should I believe a word of this?  Can you give evidence
<br>
that THIS is true?
<br>
<p>In particular, suppose I advanced a theory related to MVT, MVT'.
<br>
According to this theory, the non-existence of a pineal eye causes all
<br>
sorts of interesting intelligent behavior.  But MVT' makes no claims
<br>
as to what causes consciousness.
<br>
<p>How can you show that MVT is superior to MVT'?  What evidence do you
<br>
have that your EXTRA claims about solving dualism, fixing the
<br>
mind-body problem, etc. are true?  Why should I accept MVT over MVT'?
<br>
What *scientific* evidence can you give for MVT over MVT'?
<br>
<p><em>&gt; But we have a difference of type here .... lie machines and Turing devices
</em><br>
<em>&gt; do not occur in nature. They are designed and built, and are not evolved,
</em><br>
<em>&gt; living beings.
</em><br>
<p>An irrelevant distinction.  How something came to be reflects not at
<br>
all on what it is.  Turing-like machines COULD have evolved (and, I argue,
<br>
they have: in us) so what's the relevant difference?
<br>
<p><em>&gt; And besides, I deny totally that lie detectors are empathising ... they do
</em><br>
<em>&gt; not replicate the feelings of the subjects, just look for incidental tells
</em><br>
<em>&gt; like
</em><br>
<em>&gt; conductivity of sweat or whatever.
</em><br>
<p>How do you know?  Have you asked one?
<br>
<p><em>&gt; Do you agree with McGinn that the mind-body problem is insoluble?
</em><br>
<em>&gt; If so, then you can pack up and go away. If you think that it can be
</em><br>
<em>&gt; solved, then you must also allow that an evolutionary account is
</em><br>
<em>&gt; needed. I accuse academic philosophers of &quot;THE ATHENA FALLACY (TM)&quot;
</em><br>
<em>&gt; ... that they deal with mind as if it sprung fully formed as &quot;human&quot;
</em><br>
<em>&gt; from the split head of Zeus ... and ignore the intermediate stages
</em><br>
<em>&gt; and natural processes that led to the current state of things.
</em><br>
<p>Don't be silly.  I commit no Athena fallacy: I have no account
<br>
WHATSOEVER about how mind comes about, say nothing of one like you
<br>
describe.
<br>
<p>Anyway, I COULD pack up and go away, but I won't.  Indeed, I argue
<br>
that you can pack up and leave us alone. ;)
<br>
<p><em>&gt; MVT puts forwards a set of predicates that can be challenged, and
</em><br>
<em>&gt; conclusions that follow from these, that can also be challenged. Yet
</em><br>
<em>&gt; no philosophers can falsify MVT .. although I have been shoving it
</em><br>
<em>&gt; up their noses since 1980.
</em><br>
<p>Ho ho ho.  MVT consists of some philosophical claims plus MVT', the
<br>
core scientific position I established earlier.  Sure, no philosopher
<br>
can refute MVT', but there's no reason to believe the philosophical
<br>
bits of MVT.  I challenge those parts, and only those parts.  MVT' is
<br>
fine and sound.
<br>
<p><em>&gt; As a qualified Philosopher (MA, Univ Leeds ... which I returned, &amp;
</em><br>
<em>&gt; Bsc, Surrey) I despair at the waste of everyone's time and money
</em><br>
<em>&gt; spent on philosophy departments. The arrogance is bearable .. they
</em><br>
<em>&gt; think they can dictate to proper mathematicians on the &quot;philosophy&quot;
</em><br>
<em>&gt; or overview of maths, even though in practice they perhaps can't
</em><br>
<em>&gt; even add up! And they presume to tell medical doctors what to do
</em><br>
<em>&gt; regards medical ethics.
</em><br>
<p>Yes.  Philosophy of mind is a stupid discipline.  But you can't beat
<br>
us on our own turf.  Just drop the philosophy, stick to the science,
<br>
and let's get ON with it.
<br>
<p><em>&gt; &gt;Why YES.  I think we're finally on the same page!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; So YOU have the problem, not MVT, which comes to a high degree
</em><br>
<em>&gt; of certainty as having solved the mind-body problem.
</em><br>
<p>Don't be silly.  The philosophy part of MVT has no certainty
<br>
whatsoever, no scientific evidence whatsoever.  MVT' is well grounded.
<br>
But MVT minus MVT' is founded only on your intuitions, which may
<br>
differ with my own.
<br>
<p><em>&gt; Let me put this to you. No scientific theorum can be proved 100%
</em><br>
<em>&gt; (cite Heisenberg's principle). But we have to judge between the contending
</em><br>
<em>&gt; theoretical models and make the best choice. As it happens, the only
</em><br>
<em>&gt; competitor to MVT is Jerison's Recency Theory .. which can be fairly
</em><br>
<em>&gt; easily dismissed. So if MVT is just 50.1% likely ... more likely than not,
</em><br>
<em>&gt; then we are OBLIGED to accept MVT until a fuller account arrives.
</em><br>
<p>No.  I can accept MVT' and reject the rest.
<br>
<p><em>&gt; &gt;But what do YOU get besides intelligence?  Besides intelligent
</em><br>
<em>&gt; &gt;behaviour?  Hell, what do you NEED more than than that, besides
</em><br>
<em>&gt; &gt;philosophical drivel?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; MVT extends the Neuromatrix theories of self, and gateway theory of pain
</em><br>
<em>&gt; (used by most clinicians) to give an account of felt experience and
</em><br>
<em>&gt; self-referential states. It ties together an evolutionary story that
</em><br>
<em>&gt; includes
</em><br>
<em>&gt; mechanisms for transition to endothermy, the reasons for REM and
</em><br>
<em>&gt; mechanics of dreaming, PLUS it overcomes Leibnitz Law (to be fully
</em><br>
<em>&gt; identical the two things must be fully interchangeable) thus gets rid
</em><br>
<em>&gt; of Cartesian dualism.
</em><br>
<p>I'm with you until you say you've explained dreaming, instead of dream
<br>
reports.  You've explained consciousness reports, but not
<br>
consciousness.  You've got MVT', but not MVT.  The extra drivel is
<br>
built into MVT: it claims to have identified the source of
<br>
consciousness.  Drop that part and you have a scientific theory.
<br>
<p><em>&gt; What philosophical drivel do you think is needed? Please make a case.
</em><br>
<p>None, actually, which is why I reject MVT.  You'll get quite a kick
<br>
when you find out what I *really* think about experiences.
<br>
<p><em>&gt; Do your Turing machines fall in love then?
</em><br>
<p>I do, yes.
<br>
<p>-Dan
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-unless you love someone-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;-nothing else makes any sense-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.e. cummings
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4327.html">Chris Russo: "Re: Nanotech"</a>
<li><strong>Previous message:</strong> <a href="4325.html">Michael M. Butler: "Re: HUMOR Eliezer,"</a>
<li><strong>In reply to:</strong> <a href="4301.html">Steve Nichols: "Re: Sentience"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4329.html">Eliezer S. Yudkowsky: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4329.html">Eliezer S. Yudkowsky: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4344.html">John Clark: "Re: Sentience"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4326">[ date ]</a>
<a href="index.html#4326">[ thread ]</a>
<a href="subject.html#4326">[ subject ]</a>
<a href="author.html#4326">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:38 MDT</em>
</em>
</small>
</body>
</html>
