<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Attacks (was Re: Why would AI want to be friend</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Attacks (was Re: Why would AI want to be friendly?)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Attacks (was Re: Why would AI want to be friendly?)</h1>
<!-- received="Sun Oct  1 18:37:53 2000" -->
<!-- isoreceived="20001002003753" -->
<!-- sent="Sun, 01 Oct 2000 17:39:40 -0700" -->
<!-- isosent="20001002003940" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Attacks (was Re: Why would AI want to be friendly?)" -->
<!-- id="39D7D94C.E0C254E6@objectent.com" -->
<!-- inreplyto="39D7C6EC.4C695832@pobox.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Attacks%20(was%20Re:%20Why%20would%20AI%20want%20to%20be%20friendly?)&In-Reply-To=&lt;39D7D94C.E0C254E6@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Oct 01 2000 - 18:39:40 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0042.html">Michael M. Butler: "&lt;HUMOR?&gt; Rumors of war..."</a>
<li><strong>Previous message:</strong> <a href="0040.html">Michael M. Butler: "Survival and such, was: re Eugene's &lt;etc.&gt;"</a>
<li><strong>In reply to:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0068.html">Eugene Leitl: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0068.html">Eugene Leitl: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#41">[ date ]</a>
<a href="index.html#41">[ thread ]</a>
<a href="subject.html#41">[ subject ]</a>
<a href="author.html#41">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Samantha Atkins wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If that was what it was then I would also find it revolting.  But I
</em><br>
<em>&gt; &gt; think a more interesting set of possibilities might be present.  Today
</em><br>
<em>&gt; &gt; we kill or lock away for life those we consider irredeemably criminal.
</em><br>
<em>&gt; &gt; Putting the person instead in a VR with karmic consequence mode turned
</em><br>
<em>&gt; &gt; on would a) not involve the irreversible destruction of the individual;
</em><br>
<em>&gt; &gt; b) give them a chance to learn and grow without harming other people.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That is an unacceptable violation of individual freedoms.  If someone *wants*
</em><br>
<em>&gt; to walk into an environment with karmic consequences, they have the right to
</em><br>
<em>&gt; do so.  Nobody has the right to impose that on them.  Once the Sysop Scenario
</em><br>
<em>&gt; is achieved - once &quot;society&quot; has the technological power to upload a criminal
</em><br>
<em>&gt; into a karmic environment - society no longer has any conceivable right to do
</em><br>
<em>&gt; so.  The criminal is no longer a threat to anyone.  There's no need to
</em><br>
<em>&gt; discourage future crimes.
</em><br>
<p>Is it a more acceptable violation of individual freedom to kill someone
<br>
outright because they are dangerous to others?  Is it more acceptable to
<br>
force people to change regardless of what sort of world they prefer to
<br>
live in?  Is it more acceptable to impose an ultra-hitech future on
<br>
those simply in no way able to deal with it?  I can see that it is not
<br>
palatable to put people into a VR involuntarily.  But that violation may
<br>
be smaller than the larger violations that would occur otherwise.  It is
<br>
that possibility I want to raise.  
<br>
<p>How is the criminal not a threat to anyone?  What if I don't want to be
<br>
fragged even if the friendly SI will resurrect me instantaneously? 
<br>
There is plent of need to discourage criminal abuses regardless of
<br>
whether there is an SI.  Or do you want the human race to go totally
<br>
infantile where nothing is real, nothing is at stake and nothing can
<br>
really be changed at all?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Pain is *never* an intrinsic good, no matter who it happens to!  Certain
</em><br>
<em>&gt; people, by their actions, make themselves more &quot;targetable&quot; than others - if
</em><br>
<em>&gt; either a murderer or an innocent human must die, then it might as well be the
</em><br>
<em>&gt; murderer.  Adolf Hitler, for example, is so targetable that we could shoot him
</em><br>
<em>&gt; on the million-to-one off-chance that it might save someone's life.  But once
</em><br>
<em>&gt; there's no longer any need for *anyone* to suffer, then nobody is targetable 
</em><br>
<p>I don't propose to &quot;target&quot; anyone.  I simply am floating the idea that
<br>
the ultimate in freedom with infinite room to grow is to be able to live
<br>
within whatever world-constraints one most wishes and see how that is.   
<br>
<p>What do you think humans will do exactly once your sort of SI is a
<br>
reality?  
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0042.html">Michael M. Butler: "&lt;HUMOR?&gt; Rumors of war..."</a>
<li><strong>Previous message:</strong> <a href="0040.html">Michael M. Butler: "Survival and such, was: re Eugene's &lt;etc.&gt;"</a>
<li><strong>In reply to:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0068.html">Eugene Leitl: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0068.html">Eugene Leitl: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#41">[ date ]</a>
<a href="index.html#41">[ thread ]</a>
<a href="subject.html#41">[ subject ]</a>
<a href="author.html#41">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
