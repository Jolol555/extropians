<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: AI safeguards [Was: Re: Humor: helping Eliezer to f</title>
<meta name="Author" content="Max More (max@maxmore.com)">
<meta name="Subject" content="AI safeguards [Was: Re: Humor: helping Eliezer to fulfill his full potential]">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>AI safeguards [Was: Re: Humor: helping Eliezer to fulfill his full potential]</h1>
<!-- received="Mon Nov  6 09:39:53 2000" -->
<!-- isoreceived="20001106163953" -->
<!-- sent="Mon, 06 Nov 2000 08:39:58 -0800" -->
<!-- isosent="20001106163958" -->
<!-- name="Max More" -->
<!-- email="max@maxmore.com" -->
<!-- subject="AI safeguards [Was: Re: Humor: helping Eliezer to fulfill his full potential]" -->
<!-- id="4.3.2.7.2.20001106083318.02f77cd0@mail.flashcom.net" -->
<!-- inreplyto="3A06BF07.F84D8594@posthuman.com" -->
<strong>From:</strong> Max More (<a href="mailto:max@maxmore.com?Subject=Re:%20AI%20safeguards%20[Was:%20Re:%20Humor:%20helping%20Eliezer%20to%20fulfill%20his%20full%20potential]&In-Reply-To=&lt;4.3.2.7.2.20001106083318.02f77cd0@mail.flashcom.net&gt;"><em>max@maxmore.com</em></a>)<br>
<strong>Date:</strong> Mon Nov 06 2000 - 09:39:58 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1997.html">S.J. Van Sickle: "Re: Optimal Eating"</a>
<li><strong>Previous message:</strong> <a href="1995.html">Mecsepbeef@aol.com: "Re: Humor: helping Eliezer to fulfill his full potential"</a>
<li><strong>In reply to:</strong> <a href="1987.html">Brian Atkins: "Re: Humor: helping Eliezer to fulfill his full potential"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2000.html">Eliezer S. Yudkowsky: "Re: AI safeguards [Was: Re: Humor: helping Eliezer to fulfill hisfull  potential]"</a>
<li><strong>Reply:</strong> <a href="2000.html">Eliezer S. Yudkowsky: "Re: AI safeguards [Was: Re: Humor: helping Eliezer to fulfill hisfull  potential]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1996">[ date ]</a>
<a href="index.html#1996">[ thread ]</a>
<a href="subject.html#1996">[ subject ]</a>
<a href="author.html#1996">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
At 06:24 AM 11/6/00, Brian wrote:
<br>
<p><em>&gt;P.S. we aren't the only ones out there... recently we have come across a
</em><br>
<em>&gt;competing AI project that we rate as having a significant (greater than zero)
</em><br>
<em>&gt;chance of &quot;waking up&quot;... and it is set for completion circa 2003 at the 
</em><br>
<em>&gt;latest.
</em><br>
<em>&gt;I really think it would be good if there was an equivalent of Foresight for
</em><br>
<em>&gt;the AI area... Foresight for now is still so focused on nanotech they don't
</em><br>
<em>&gt;see the chance to expand into a more general Foresight organization covering
</em><br>
<em>&gt;all of Bill Joy's worries.
</em><br>
<p>Brian, this is one of the very issues that I already have down as a 
<br>
discussion area for the early-2001 ExI retreat. The topic as I've been 
<br>
thinking of it is: &quot;Machine intelligence: Threat or opportunity?&quot; That 
<br>
title is meant as an attractor for a range of possible discussions, 
<br>
including competing scenarios for the developmental pathway and pace of AI 
<br>
(including the Moravec runaway scenario vs. the Kurzweil integration 
<br>
scenario); the feasibility of safeguards and how these might be 
<br>
implemented; and how to promote the convergence of humans and their 
<br>
technology to reduce the probability of the runaway scenario.
<br>
<p>Although I'm not quite ready yet to unveil the current stage of planning 
<br>
for the 2001 Retreat, I'm letting this part slip out since its pertinent to 
<br>
your message. I can also say that we're aiming for February or March, and 
<br>
the Retreat will probably be held in Las Vegas.
<br>
<p>Onward!
<br>
<p>Max
<br>
------------------------
<br>
Max More,
<br>
<a href="mailto:max@maxmore.com?Subject=Re:%20AI%20safeguards%20[Was:%20Re:%20Humor:%20helping%20Eliezer%20to%20fulfill%20his%20full%20potential]&In-Reply-To=&lt;4.3.2.7.2.20001106083318.02f77cd0@mail.flashcom.net&gt;">max@maxmore.com</a> or <a href="mailto:more@extropy.org?Subject=Re:%20AI%20safeguards%20[Was:%20Re:%20Humor:%20helping%20Eliezer%20to%20fulfill%20his%20full%20potential]&In-Reply-To=&lt;4.3.2.7.2.20001106083318.02f77cd0@mail.flashcom.net&gt;">more@extropy.org</a>
<br>
www.maxmore.com
<br>
President, Extropy Institute. www.extropy.org
<br>
Senior Content Architect, ManyWorlds Consulting: www.manyworlds.com
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1997.html">S.J. Van Sickle: "Re: Optimal Eating"</a>
<li><strong>Previous message:</strong> <a href="1995.html">Mecsepbeef@aol.com: "Re: Humor: helping Eliezer to fulfill his full potential"</a>
<li><strong>In reply to:</strong> <a href="1987.html">Brian Atkins: "Re: Humor: helping Eliezer to fulfill his full potential"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2000.html">Eliezer S. Yudkowsky: "Re: AI safeguards [Was: Re: Humor: helping Eliezer to fulfill hisfull  potential]"</a>
<li><strong>Reply:</strong> <a href="2000.html">Eliezer S. Yudkowsky: "Re: AI safeguards [Was: Re: Humor: helping Eliezer to fulfill hisfull  potential]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1996">[ date ]</a>
<a href="index.html#1996">[ thread ]</a>
<a href="subject.html#1996">[ subject ]</a>
<a href="author.html#1996">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:19 MDT</em>
</em>
</small>
</body>
</html>
