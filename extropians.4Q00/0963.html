<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<title>extropians: Re: I'm ba-ack!</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: I'm ba-ack!">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: I'm ba-ack!</h1>
<!-- received="Wed Oct 11 12:35:07 2000" -->
<!-- isoreceived="20001011183507" -->
<!-- sent="Wed, 11 Oct 2000 11:34:45 -0700" -->
<!-- isosent="20001011183445" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: I'm ba-ack!" -->
<!-- id="00c401c033b2$133660e0$39bc473f@jrmolloy" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="b4966mzv42u.fsf_-_@sans04.nada.kth.se" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20I'm%20ba-ack!&In-Reply-To=&lt;00c401c033b2$133660e0$39bc473f@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Oct 11 2000 - 12:34:45 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0964.html">Timothy Tiedemann: "On Nietzche"</a>
<li><strong>Previous message:</strong> <a href="0962.html">Spudboy100@aol.com: "Fusion &amp; Public Spending"</a>
<li><strong>In reply to:</strong> <a href="0933.html">Anders Sandberg: "I'm ba-ack!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0977.html">Dave Sill: "Re: I'm ba-ack!"</a>
<li><strong>Reply:</strong> <a href="0977.html">Dave Sill: "Re: I'm ba-ack!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#963">[ date ]</a>
<a href="index.html#963">[ thread ]</a>
<a href="subject.html#963">[ subject ]</a>
<a href="author.html#963">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Anders Sandberg&quot;:
<br>
<em>&gt; Hi again! After four months of conferences, symposia and courses on
</em><br>
<em>&gt; transhumanism, psychology, neurocience, biomodelling and everything
</em><br>
<em>&gt; else I have finally time to settle back into the list. Seems
</em><br>
<em>&gt; everything is as usual here, everybody happy and gay and debating AI,
</em><br>
<em>&gt; guns, death penalties and cryonics :-)
</em><br>
<p>Welcome back, Anders.
<br>
<p>Yes, the list is about the same as ever. Same old topics, same old complaints,
<br>
same old... same old. Interesting that people who engage a discussion of
<br>
accelerating change (of the extropic kind) do not themselves seem to change
<br>
their minds, their opinions, their politics, their attitudes, or their
<br>
philosophical positions.
<br>
<p>You took courses on transhumanism!?!? Where do they offer courses on
<br>
transhumanism?
<br>
<p><em>&gt; The idea that some will go on towards Singularity (or whatever) and
</em><br>
<em>&gt; the rest will remain, is of course one of the main Scary Arguments
</em><br>
<em>&gt; Against the Singularity (cf. Stuart Brand, _The Clock of the Long Now_
</em><br>
<em>&gt; and Jaron Lanier's edge piece). Exponential growth might also imply
</em><br>
<em>&gt; exponential growth of differences, and this is generally viewed as a
</em><br>
<em>&gt; bad thing. After lecturing some first year students on waguely
</em><br>
<em>&gt; transhumanism related stuff, I noticed this was one of the arguments
</em><br>
<em>&gt; against it that seemed to work best. Well worth considering.
</em><br>
<p>I don't understand how the exponential growth of differences (a bad thing) works
<br>
best as an argument against technological singularity. Or do I misunderstand?
<br>
<p><em>&gt; The problem is relevant not just for the Singularity but any knowledge
</em><br>
<em>&gt; economy: if there are no strong rules against changing social class,
</em><br>
<em>&gt; but doing so depends merely on an act of will/ambition/ability, the
</em><br>
<em>&gt; resulting situation will still have some who due to their own values,
</em><br>
<em>&gt; passivity, culture or whatever remain down. The door is open, but they
</em><br>
<em>&gt; either think it is closed, to hard to get past or that remaining is
</em><br>
<em>&gt; good. The problem with this division is that it cannot be redressed
</em><br>
<em>&gt; using traditional means like redistributing money or rights, but would
</em><br>
<em>&gt; need some ways of redistributing or improving ambition (the later
</em><br>
<em>&gt; might actually be doable, by creating a more practically optimist
</em><br>
<em>&gt; social atmosphere). And even then we would have the people who do not
</em><br>
<em>&gt; wish to rise to the heavens.
</em><br>
<p>In addition, some people know that even if technological singularity occurs in
<br>
ten years, it will be too late for them... their health will not sustain them
<br>
that long, and they can't afford cryonic suspension. Others realize that, due to
<br>
their economic situation and the fact they are past their prime, they don't
<br>
stand a chance of joining the singularity clique. Anti-geezer sentiments run
<br>
high among young turks (although you may not be as sensitive to this issue as
<br>
some of us). Sure, geezers want to &quot;rise to the heavens&quot; ...the problem relates
<br>
to being tied down by decades of psychic baggage and an unattractive persona.
<br>
Who would we rather recruit, a bevy of nubile young extro-girls, or some lame
<br>
old duck who can't even learn computer languages, but who still wants to join
<br>
the party? (Hint: the geezers can't even make it to the party.)
<br>
<p><em>&gt; Ethically, I would say transhumanism values diversity and individual
</em><br>
<em>&gt; development. But it is not based on some narrow definition of linear
</em><br>
<em>&gt; progress - we are a bit too postmodern for that - so what kind of
</em><br>
<em>&gt; individual development is desirable is in the end up to the individual
</em><br>
<em>&gt; to make a decision about. A bit like the subjective optimality
</em><br>
<em>&gt; definition of health in Freita's _Nanomedicine_. Now, as I see this,
</em><br>
<em>&gt; when applied to the incomplete singularity scenario, this leads to the
</em><br>
<em>&gt; conclusion that it is completely OK to decide not to join in due to
</em><br>
<em>&gt; one's value system. In fact, it increases the diversity of
</em><br>
<em>&gt; humanity.
</em><br>
<p>I think transhumanism values change and extropic progress more than it values
<br>
developing individuals who, because of their need for remedial and augmented
<br>
mental prosthetics, have difficulty keeping up (never mind making a positive
<br>
contribution). For example, I'd really like to take some courses in psychology,
<br>
neuroscience, biomodelling, robotics, computer science, and network
<br>
administration, but guess what... I have trouble mastering HTML -- and by the
<br>
time I could learn it, it would be replaced by XML or VML (voice markup language
<br>
a la Kurzweil and Co.). When it comes to diversity in the technological
<br>
singularity, &quot;many are called, but few are chosen.&quot; Speaking just for myself
<br>
(crotchety geezers don't really like others speaking for them you know) I've
<br>
noticed quite a bit of resistance to AI ideas and technological singularity from
<br>
Extropy list participants who have better credentials than I'll be able to
<br>
garner even if I wanted to. I see technological singularity the way Moravec
<br>
describes it in reference to Mind Children: I can help in some small way to
<br>
launch the process, but I'll not be able to do what SI will be able to do, so
<br>
like a proud parent giving away the bride, I just wish it the best and cherish
<br>
the promise of its bountiful future through tears of joy. Like &quot;so long kids...
<br>
live forever and prosper infinitely.&quot; Anyway, I know &gt;H AI doesn't want an old
<br>
fart like me around on its honeymoon. &lt;gag me with a virtual spoon&gt;
<br>
<p><em>&gt; What might happen is of course that the posthumans (or people of the
</em><br>
<em>&gt; new economy or whatever) want to make sure people staying behind do
</em><br>
<em>&gt; this due to their own values as a rational decision, rather than just
</em><br>
<em>&gt; due to mistaken information, habit or something else. Hence they will
</em><br>
<em>&gt; want to give an unbiased image of what they are missing out on (here I
</em><br>
<em>&gt; will just assume ethical posthumans; posthumans with an ideological
</em><br>
<em>&gt; axe to grind is another matter of course). Education becomes very
</em><br>
<em>&gt; relevant.
</em><br>
<p>Posthumans should be so friendly (like AI). I'll more than likely be staying
<br>
behind not because of values, mistaken info, habit, etc., but because there's no
<br>
way for me to go without being a burden, and besides, my heroes won't be onboard
<br>
anyway (you know, Socrates, Galileo, Moses, Buddha, Mohammed, Krishna, Lao Tzu,
<br>
Osho, Kabir, et al.). The more I think about it, the more I suspect Sasha had
<br>
the right idea. When faced with years and years of toil to earn enough capital
<br>
to freely join technological singularity, it seems more reasonable, rational,
<br>
and yes, responsible to simply opt out. That way, it's like I'm joining my
<br>
heroes, the grateful dead. Furthermore, we really don't have any guarantee that
<br>
the future will not repeat the horrors of the past: Five thousand wars in the
<br>
last three thousand years. And look what's going on in the Middle East today.
<br>
It's only depressing if you plan to be around for more than a few more years.
<br>
<p>Stay hungry,
<br>
<p>--J. R.
<br>
3M TA3
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0964.html">Timothy Tiedemann: "On Nietzche"</a>
<li><strong>Previous message:</strong> <a href="0962.html">Spudboy100@aol.com: "Fusion &amp; Public Spending"</a>
<li><strong>In reply to:</strong> <a href="0933.html">Anders Sandberg: "I'm ba-ack!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0977.html">Dave Sill: "Re: I'm ba-ack!"</a>
<li><strong>Reply:</strong> <a href="0977.html">Dave Sill: "Re: I'm ba-ack!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#963">[ date ]</a>
<a href="index.html#963">[ thread ]</a>
<a href="subject.html#963">[ subject ]</a>
<a href="author.html#963">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:16 MDT</em>
</em>
</small>
</body>
</html>
