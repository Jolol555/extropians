<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Eugene's nuclear threat</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Eugene's nuclear threat</h1>
<!-- received="Mon Oct  2 17:48:50 2000" -->
<!-- isoreceived="20001002234850" -->
<!-- sent="Mon, 02 Oct 2000 16:50:46 -0700" -->
<!-- isosent="20001002235046" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Eugene's nuclear threat" -->
<!-- id="39D91F56.A2644F24@objectent.com" -->
<!-- inreplyto="200010021740.KAA03079@finney.org" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D91F56.A2644F24@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Mon Oct 02 2000 - 17:50:46 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0121.html">Geoff Tillman: "Re: MacLeod's Cassini Division (spoiler warning)"</a>
<li><strong>In reply to:</strong> <a href="0099.html">hal@finney.org: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0173.html">Robin Hanson: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0173.html">Robin Hanson: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#122">[ date ]</a>
<a href="index.html#122">[ thread ]</a>
<a href="subject.html#122">[ subject ]</a>
<a href="author.html#122">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="mailto:hal@finney.org?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D91F56.A2644F24@objectent.com&gt;">hal@finney.org</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Eugene writes:
</em><br>
<em>&gt; &gt; What can be possibly more poisonous than the end of the world as we
</em><br>
<em>&gt; &gt; know it(tm) and death of all or most human beings?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You need to make several assumptions to get to this from the starting
</em><br>
<em>&gt; point of someone trying to develop a &quot;wild&quot; self-enhancing AI through
</em><br>
<em>&gt; evolutionary techniques:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  - that the process will work at all to get any kind of AI
</em><br>
<em>&gt;  - that the AI won't hit a bottleneck somewhere on its self-improvement
</em><br>
<em>&gt;    trajectory
</em><br>
<em>&gt;  - that the super-intelligent AI will want to wipe out humans
</em><br>
<em>&gt;  - that it will succeed
</em><br>
<em>&gt; 
</em><br>
<em>&gt; and also, I should add,
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  - that this will be a bad thing.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Without belaboring this last point, I do think that there is a
</em><br>
<em>&gt; difference between seeing humanity wiped out by mindless gray goo,
</em><br>
<em>&gt; versus having the human race supplanted by an expanding, curious,
</em><br>
<em>&gt; exploratory new super-intelligent life form.  
</em><br>
<p>Excuse me, but we are an expanding, curious, exploratory and
<br>
super-intelligent life form.  It would be much more &quot;chauvanistic&quot; to
<br>
claim that just because the newest intelligent life form think much
<br>
faster and so on that all former lifeforms should simply be junked as
<br>
clearly obsolete.  That attitude might make sense for a full Borg
<br>
mentality but is that the type of mentality, the kind of ethics, the
<br>
goal state we want to produce?  Because it is up to us to pick our
<br>
ethics, to pick the aim of this work going forward.  For now at least.  
<br>
<p>All the dreams of all the generations of humans that were part of our
<br>
getting here ending in something that ends humanity forever rather than
<br>
transforming it - I do not consider that for one second to be a &quot;good&quot;
<br>
thing.  It is as bad as it gets.  If anyone thinks it is &quot;good&quot; to see
<br>
humanity destroyed rather than transformed then please explain to me
<br>
what your standard of the &quot;good&quot; is.
<br>
<p><p><em>&gt;If we step back a bit
</em><br>
<em>&gt; from our humanist chauvinism (and forgetting that we ourselves might be
</em><br>
<em>&gt; targets of the malicious AI), we generally do justify the destruction of
</em><br>
<em>&gt; less intellectually advanced life forms in favor of more advanced ones.
</em><br>
<p>But is that a correct choice or the very evidence of chauvinism, short
<br>
sightedness and a lack of system level thinking?
<br>
<p><em>&gt; People do this every day when they eat.
</em><br>
<p>Not in the same league at all. Some of us are or have been vegans simply
<br>
because eating other higher level lifeforms seems barbaric.  There is
<br>
nothing stopping us a few decades hence from synthesizing all foods (as
<br>
long as we actually require them). 
<br>
<p><em>&gt;  From a sufficiently removed
</em><br>
<em>&gt; perspective, replacing the human race with an intelligence vastly more
</em><br>
<em>&gt; aware, more perceptive, more intelligent and more conscious may not be
</em><br>
<em>&gt; entirely evil.  I don't say it should happen, but it is something to
</em><br>
<em>&gt; consider in evaluating the morality of this outcome.
</em><br>
<em>&gt;
</em><br>
<p>You can only evaluate a morality within a framework allowing valuing. 
<br>
What framework allows you to step completely outside of humanity and
<br>
value this as a non-evil possibility?
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0121.html">Geoff Tillman: "Re: MacLeod's Cassini Division (spoiler warning)"</a>
<li><strong>In reply to:</strong> <a href="0099.html">hal@finney.org: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0173.html">Robin Hanson: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0173.html">Robin Hanson: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#122">[ date ]</a>
<a href="index.html#122">[ thread ]</a>
<a href="subject.html#122">[ subject ]</a>
<a href="author.html#122">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
