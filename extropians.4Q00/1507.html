<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: JOIN THE EXI! FUND THE REVOLUTION!</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: JOIN THE EXI! FUND THE REVOLUTION!">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: JOIN THE EXI! FUND THE REVOLUTION!</h1>
<!-- received="Tue Oct 24 01:04:00 2000" -->
<!-- isoreceived="20001024070400" -->
<!-- sent="Tue, 24 Oct 2000 03:05:39 -0400" -->
<!-- isosent="20001024070539" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: JOIN THE EXI! FUND THE REVOLUTION!" -->
<!-- id="39F534C3.DCB972C8@posthuman.com" -->
<!-- inreplyto="39F52C2C.AE8EAD8D@objectent.com" -->
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20JOIN%20THE%20EXI!%20FUND%20THE%20REVOLUTION!&In-Reply-To=&lt;39F534C3.DCB972C8@posthuman.com&gt;"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 24 2000 - 01:05:39 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<li><strong>Previous message:</strong> <a href="1506.html">Brian Atkins: "Re: Extropian congressional lobby"</a>
<li><strong>In reply to:</strong> <a href="1504.html">Samantha Atkins: "Re: JOIN THE EXI! FUND THE REVOLUTION!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<li><strong>Reply:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1507">[ date ]</a>
<a href="index.html#1507">[ thread ]</a>
<a href="subject.html#1507">[ subject ]</a>
<a href="author.html#1507">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
When Eliezer speaks of &quot;The Singularity&quot; (tm?) he means a friendly one.
<br>
<p>ExI also plays a big role in helping create a friendly vs. non-friendly
<br>
event horizon IMO. Imagine if we never had these discussions about these
<br>
things, and you had AI researchers going off and doing clueless stuff that
<br>
would have a much higher chance of ending badly. Hmm well actually they do
<br>
that anyway, but at least _some_ of them are getting more awake regarding
<br>
the all important friendly AI issue.
<br>
<p>Samantha Atkins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Zero Powers wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &quot;Your dollars accomplish around a hundred times as much&quot;???  Really?
</em><br>
<em>&gt; &gt; [snip]
</em><br>
<em>&gt; &gt; &gt; Don't get me wrong, I'm not knocking Exi or agreeing with Ian.  But I think
</em><br>
<em>&gt; &gt; &gt; your comments might be just as much an overstatement as his post was.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Hey, get with the Singularity.  Billions of lives are at stake here.  If the
</em><br>
<em>&gt; &gt; ExI has a total pre-Singularity lifetime budget of, say, $1M (sadly, probably
</em><br>
<em>&gt; &gt; a huge overestimate) and it contributes a hundredth of one percent to the
</em><br>
<em>&gt; &gt; &quot;win&quot; - assuming we win - then that's the equivalent of, say, six lives for
</em><br>
<em>&gt; &gt; ten dollars.  Alternatively, if the existence of ExI means the Singularity
</em><br>
<em>&gt; &gt; happens four days sooner, then that's also the equivalent of six lives for ten
</em><br>
<em>&gt; &gt; dollars.  Can the Red Cross match that?  I really don't think so.  I think
</em><br>
<em>&gt; &gt; they'd be hard put to save another six lives with another thousand dollars.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I hope you are tongue in cheek.  Billions of lifes are at stake in the
</em><br>
<em>&gt; world in any case.  It is not at all clear that getting to the
</em><br>
<em>&gt; Singularity will be a net good thing that will aid rather than
</em><br>
<em>&gt; destroying billions of lives.  The work has to be much broader imho than
</em><br>
<em>&gt; simply racing toward Singularity.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; - samantha
</em><br>
<p><pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.singinst.org/">http://www.singinst.org/</a>
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<li><strong>Previous message:</strong> <a href="1506.html">Brian Atkins: "Re: Extropian congressional lobby"</a>
<li><strong>In reply to:</strong> <a href="1504.html">Samantha Atkins: "Re: JOIN THE EXI! FUND THE REVOLUTION!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<li><strong>Reply:</strong> <a href="1508.html">Damien Broderick: "`friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1507">[ date ]</a>
<a href="index.html#1507">[ thread ]</a>
<a href="subject.html#1507">[ subject ]</a>
<a href="author.html#1507">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:18 MDT</em>
</em>
</small>
</body>
</html>
