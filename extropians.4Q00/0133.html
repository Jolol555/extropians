<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Let's hear Eugene's ideas</title>
<meta name="Author" content="hal@finney.org (hal@finney.org)">
<meta name="Subject" content="Re: Let's hear Eugene's ideas">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Let's hear Eugene's ideas</h1>
<!-- received="Mon Oct  2 19:49:37 2000" -->
<!-- isoreceived="20001003014937" -->
<!-- sent="Mon, 2 Oct 2000 18:45:23 -0700" -->
<!-- isosent="20001003014523" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Let's hear Eugene's ideas" -->
<!-- id="200010030145.SAA04498@finney.org" -->
<!-- inreplyto="Let's hear Eugene's ideas" -->
<strong>From:</strong> <a href="mailto:hal@finney.org?Subject=Re:%20Let's%20hear%20Eugene's%20ideas&In-Reply-To=&lt;200010030145.SAA04498@finney.org&gt;"><em>hal@finney.org</em></a><br>
<strong>Date:</strong> Mon Oct 02 2000 - 19:45:23 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0134.html">Spike Jones: "Re: Violence in schools (Was Re: Back off!  Im gay!)"</a>
<li><strong>Previous message:</strong> <a href="0132.html">Dehede011@aol.com: "Re: Capitalists and concentration camps"</a>
<li><strong>Maybe in reply to:</strong> <a href="0114.html">Eliezer S. Yudkowsky: "Let's hear Eugene's ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0139.html">J. R. Molloy: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Reply:</strong> <a href="0139.html">J. R. Molloy: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Reply:</strong> <a href="0159.html">Brian Atkins: "Re: Let's hear Eugene's ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#133">[ date ]</a>
<a href="index.html#133">[ thread ]</a>
<a href="subject.html#133">[ subject ]</a>
<a href="author.html#133">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Brian Atkins writes:
<br>
<em>&gt; Well as I said to Eugene- look around at the reality of the next 20 years
</em><br>
<em>&gt; (max). There are likely to be no Turing Police tracking down and containing
</em><br>
<em>&gt; all these AIs that all the hackers and scientists out there will dream up.
</em><br>
<p>That's not clear.  First, it could easily take longer than 20 years to
<br>
get superhuman AI, for several reasons:
<br>
<p>&nbsp;- We may not have nanotech in 20 years
<br>
&nbsp;- We may hit Moore's Wall before then as computer speeds turn out to be
<br>
&nbsp;&nbsp;&nbsp;on an S curve just like every other technology before them
<br>
&nbsp;- Software may continue to improve as it has in the past (i.e. not very
<br>
&nbsp;&nbsp;&nbsp;fast)
<br>
&nbsp;- AI researchers have a track record of over-optimism
<br>
<p>Secondly, I suspect that in this time frame we are going to see
<br>
increased awareness of the dangers of future technology, with Joy's
<br>
trumpet blast just the beginning.  Joy included &quot;robotics&quot; in his troika
<br>
of technological terrors (I guess calling it &quot;AI&quot; wouldn't have let him
<br>
keep to the magic three letters).  If we do see an Index of of Forbidden
<br>
Technology, it is entirely possible that AI research will be included.
<br>
<p>Third, realistically the AI scenario will take time to unfold.  As I
<br>
have argued repeatedly, self-improvement can't really take off until
<br>
we can build super-human intelligence on our own (because IQ 100 is
<br>
self-evidently not smart enough to figure out how to do AI, or else
<br>
we'd have had it years ago).  So the climb to human equivalence will
<br>
continue to be slow and frustrating.  Progress will be incremental,
<br>
with a gradual expansion of capability.
<br>
<p>I see the improved AI being put to work immediately because of the many
<br>
commercial opportunities, so the public will generally be well aware of
<br>
the state of the art.  The many difficult ethical and practical dilemmas
<br>
that appear when you have intelligent machines will become part of the
<br>
public dialogue long before any super-human AI could appear on the scene.
<br>
<p>Therefore I don't think that super-intelligent AI will catch society by
<br>
surprise, but will appear in a social milieu which is well aware of the
<br>
possibility, the potential, and the peril.  If society is more concerned
<br>
about the dangers than the opportunities, then we might well see Turing
<br>
Police enforcing restrictions on AI research.
<br>
<p>Hal
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0134.html">Spike Jones: "Re: Violence in schools (Was Re: Back off!  Im gay!)"</a>
<li><strong>Previous message:</strong> <a href="0132.html">Dehede011@aol.com: "Re: Capitalists and concentration camps"</a>
<li><strong>Maybe in reply to:</strong> <a href="0114.html">Eliezer S. Yudkowsky: "Let's hear Eugene's ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0139.html">J. R. Molloy: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Reply:</strong> <a href="0139.html">J. R. Molloy: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Reply:</strong> <a href="0159.html">Brian Atkins: "Re: Let's hear Eugene's ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#133">[ date ]</a>
<a href="index.html#133">[ thread ]</a>
<a href="subject.html#133">[ subject ]</a>
<a href="author.html#133">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
