<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: MVT: all-conquering philosophy?</title>
<meta name="Author" content="Dan Fabulich (daniel.fabulich@yale.edu)">
<meta name="Subject" content="Re: MVT: all-conquering philosophy?">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: MVT: all-conquering philosophy?</h1>
<!-- received="Thu Dec 28 23:58:10 2000" -->
<!-- isoreceived="20001229065810" -->
<!-- sent="Fri, 29 Dec 2000 01:58:02 -0500 (EST)" -->
<!-- isosent="20001229065802" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: MVT: all-conquering philosophy?" -->
<!-- id="Pine.GSO.4.10.10012282237180.9776-100000@morpheus.cis.yale.edu" -->
<!-- inreplyto="000901c06edf$4813e680$53b2403e@i6x7m6" -->
<strong>From:</strong> Dan Fabulich (<a href="mailto:daniel.fabulich@yale.edu?Subject=Re:%20MVT:%20all-conquering%20philosophy?&In-Reply-To=&lt;Pine.GSO.4.10.10012282237180.9776-100000@morpheus.cis.yale.edu&gt;"><em>daniel.fabulich@yale.edu</em></a>)<br>
<strong>Date:</strong> Thu Dec 28 2000 - 23:58:02 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4783.html">Luke Howison: "RE: Beaming Up via Nanotech"</a>
<li><strong>Previous message:</strong> <a href="4781.html">John Clark: "Re: Beaming Up via Nanotech"</a>
<li><strong>In reply to:</strong> <a href="4706.html">Steve Nichols: "MVT: all-conquering philosophy?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4782">[ date ]</a>
<a href="index.html#4782">[ thread ]</a>
<a href="subject.html#4782">[ subject ]</a>
<a href="author.html#4782">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Steve Nichols wrote:
<br>
<p><em>&gt; S&gt; OK, do you take a Rylean view that &quot;mind&quot; is a category mistake and only
</em><br>
<em>&gt; S&gt; seems a thing because language exists that describes it as an 'object?'
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;No, but I reserve &quot;category error&quot; to refer to a very particular kind
</em><br>
<em>&gt; &gt;of logical error.  I think the notion of a &quot;mind&quot; and &quot;mental events&quot;
</em><br>
<em>&gt; &gt;makes logical sense, that there's nothing logically contradictory
</em><br>
<em>&gt; &gt;about them.  I think one can be a consistent epiphenomenalist.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; So you reject Ryle's general approach, which is behaviourist
</em><br>
<em>&gt; in much the same way that yours seems to be?
</em><br>
<p>No, I agree with Ryle with the notion that &quot;consciousness&quot; is a kind
<br>
of mistake if taken literally, though not a &quot;category error.&quot;  Calling
<br>
Ryle a &quot;behaviourist&quot; is to throw him in a box with a ridiculously
<br>
wide range of people, including Skinner.  Better to call us
<br>
&quot;physicalists&quot;, since I disagree with most behaviorists, but agree
<br>
with some others.
<br>
<p><em>&gt; &gt;To the extent that I agree with Ryle, I take him to be telling a
</em><br>
<em>&gt; &gt;plausible story about what led us to conclude that consciousness is
</em><br>
<em>&gt; &gt;really out there, that we shouldn't reinterpret &quot;consciousness&quot; to
</em><br>
<em>&gt; &gt;refer to non-mental entities.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; OK. I also think that language is faulty and misleading in general,
</em><br>
<em>&gt; which I why I am starting to develop a word-free visual philosophy
</em><br>
<em>&gt; (some examples at www.extropia.net vis phil sector).
</em><br>
<p>Being visual is not enough.  All the ordinary philosophical problems
<br>
can be translated into, for example, American Sign Language, with only
<br>
a few complications.  After all, writing is visual.  The difference is
<br>
in how much formal structure your language has, and how much is left
<br>
to be inferred from humanity and charity.  On the formal end, you've
<br>
got the propositional calculus and Lojban.  On the informal end,
<br>
you've got abstract dance, jazz, painting, and others.  In the middle
<br>
towards the formal end you've got speech; ASL is a little less formal
<br>
than speech, and more dependent on &quot;context&quot; (ie charity and humanity)
<br>
<p>Philosophical analysis is something worth doing; if philosophical
<br>
issues don't appear at all in some more-informal visual language, then
<br>
that just tells me that you can't do philosophy in that language.  If
<br>
translating problems into a certain language makes a certain answer
<br>
appear obvious, then that may be a compelling argument for that
<br>
answer, as we currently take to be the case with the propositional
<br>
calculus.  But just as you can't have an analytic discussion about
<br>
mind in the language of jazz, (no, you can't, [no, you can't,]) that
<br>
doesn't mean that we should stop playing/listening to jazz or stop
<br>
having analytic discussions about the metaphysics of mind.
<br>
<p><em>&gt; Yes, a shorter or more elegant proof in maths is better than one
</em><br>
<em>&gt; using more terms. I claim MVT is the simplest and most elegant
</em><br>
<em>&gt; account. MVT also explains more phenomena, and reduces several
</em><br>
<em>&gt; other theories in science (and philosophy) to a more basic account.
</em><br>
<p>On philosophical grounds, then, I say that MVT doesn't seem very
<br>
elegant to me; that it doesn't even seem to be right on philosophical
<br>
terms, on account of the qualitative differences between &quot;holes&quot; (as
<br>
missing functionality) and feelings.
<br>
<p><em>&gt; &gt;After the fact, we now regard these to be normative
</em><br>
<em>&gt; &gt;scientific values, principles which guide our scientific beliefs.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Are &quot;principles&quot; physical then? Otherwise your determinist position
</em><br>
<em>&gt; starts to come apart ... What about &quot;desires&quot; ... didn't you say that
</em><br>
<em>&gt; our beliefs only come from desires (or was it vice-versa)?
</em><br>
<p>We change parts of our programming from time to time, but when we do,
<br>
we follow a metaprogram.  Metaprograms change from time to time, but
<br>
when they do, it happens under a metametaprogram.  And so on.
<br>
<p>Determinism doesn't rule out the possibility of history any more than
<br>
it demands fatalism; all I've described here is a bit of history of
<br>
science.
<br>
<p><em>&gt; That may be true if words are your ONLY medium of communication.
</em><br>
<em>&gt; The &quot;questioning&quot; idea might not be problematic if we commune using
</em><br>
<em>&gt; touch signals, or visual display predominantly. &quot;Questioning&quot; might
</em><br>
<em>&gt; translate to a &quot;feeling of puzzlement&quot; of a particular grain. I might
</em><br>
<em>&gt; want to say that we can rely on and trust our *feelings* (that MVT
</em><br>
<em>&gt; is the true account) more than lots of us currently do. Or I might
</em><br>
<em>&gt; appeal to pattern completion and recognition, and suggest that our
</em><br>
<em>&gt; judgement be based on a satisfactory visualisation of the matter.
</em><br>
<p>Yes, but I don't share those feelings with you.
<br>
<p><em>&gt; S&gt; The category of a particular area of space as a &quot;hole&quot; is indeed
</em><br>
<em>&gt; S&gt; psychological ... the hole can only be demarked independently of its
</em><br>
<em>&gt; S&gt; (physical) substrate by the naming of it (seeing it, pattern completion,
</em><br>
<em>&gt; S&gt; and formulating it as a linguistic/ conceptual entity). It has no
</em><br>
<em>&gt; &quot;matter&quot;
</em><br>
<em>&gt; S&gt; so isn't physical ..... but is observable ... an observer-related effect.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;Yes, but we must be careful not to overload the term &quot;psychological.&quot;
</em><br>
<em>&gt; &gt;Feelings are psychological, and so are &quot;holes,&quot; but they're
</em><br>
<em>&gt; &gt;psychological in very different ways.  Sadness, for example, has no
</em><br>
<em>&gt; &gt;physical place at all, by virtue of its purely mental character.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't disagree with this. We have infinite-state potential to experience
</em><br>
<em>&gt; any feeling imaginable.
</em><br>
<p>I'm not sure what your response had to do with my original claim.  I
<br>
just meant that feelings have no location.  Finite-state and
<br>
infinite-state doesn't seem to enter into that question.
<br>
<p>And being infinite-state certainly isn't an INTUITION I have.  What
<br>
would it feel like to be very-many-state?  Would that feel differently
<br>
from being infinite-state?
<br>
<p>You might say &quot;it doesn't feel like anything to be finite-state,&quot; but
<br>
I certainly don't see why *that* has to be true.  Why couldn't you
<br>
have one-state or two-state illusions?  Why not twenty?  Or twenty
<br>
million?  Why only infinite?
<br>
<p>Can you imagine checking on this, even internally?  You'd have one
<br>
imagining after another, again and again, until... what?  You halted?
<br>
Until you didn't halt?  Until you gave up?
<br>
<p><em>&gt; &gt;Holes are physical bits of space (or functions/components, ...) that
</em><br>
<em>&gt; &gt;we use our minds to demarcate.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Let me understand this correctly ... you claim that &quot;space&quot; or &quot;void&quot;
</em><br>
<em>&gt; is physical ... although it just has location and not any matter/ physical
</em><br>
<em>&gt; stuff? I think &quot;location&quot; is a dimension, much like &quot;time&quot; .. and as such
</em><br>
<em>&gt; isn't necessarily (or maybe isn't either probably, or even *possibly*)
</em><br>
<em>&gt; physical. Matter, time and space are assigned as different variants
</em><br>
<em>&gt; in physics  ... so can  these things be identical?
</em><br>
<p>I don't follow you.  I'd never said that matter, time and space are
<br>
identical.  I do think that they're all physical; that they share
<br>
that one property in common.  I take it that the correct move in a
<br>
phenomenological scenario is to be an anti-realist about physics: to
<br>
say &quot;when you say matter, you really mean such-and-such matter
<br>
qualia...&quot; or &quot;when you say physical, you really mean having
<br>
such-and-such sensations in common...&quot;
<br>
<p>Anyway, the very fact that &quot;holes&quot; have a &quot;location&quot; by definition
<br>
whereas &quot;feelings&quot; don't, is enough to show that &quot;holes&quot; are
<br>
analytically different from &quot;feelings,&quot; whatever other properties
<br>
these things have.
<br>
<p><em>&gt; I include &quot;possibly&quot; because of the possible that all is mental, and
</em><br>
<em>&gt; space, physical stuff, atoms and all the rest of it are just
</em><br>
<em>&gt; concepts combined with conscious perceptions (real virtuality in
</em><br>
<em>&gt; MVT-terms) plus self-generated imagination.
</em><br>
<p>Again, this doesn't bother me.  Even in a virtual reality, you have to
<br>
wonder how your sensations-of-brains are connected to other minds.
<br>
<p><em>&gt; Anyway, you are not consistent saying that &quot;we use our minds to
</em><br>
<em>&gt; demarcate&quot; if your system does not include &quot;minds&quot; ... conscious
</em><br>
<em>&gt; organs.
</em><br>
<p>We anti-realists get this a lot.  It's completely fallacious.
<br>
Anti-realists about Xs assert that there aren't really Xs, AND that we
<br>
should reinterpret claims about Xs to be claims about Ys.  So when
<br>
somebody says &quot;The anti-realist contradicts himself when he says
<br>
such-and-such about Xs, yet maintains that there are no Xs!&quot; they're
<br>
making a flat-out mistake.  It is not wrong to talk about
<br>
consciousness or pain or other feelings; all I ask is that we remember
<br>
that these are handy terms for physical phenomena.
<br>
<p>The way to avoid this mistake is to remember that it is *very* rare
<br>
that an intelligent person will assert an outright contradiction,
<br>
especially an intelligent philosopher; they're probably saying
<br>
something else similar.
<br>
<p>In this case, I could have said that &quot;holes are psychological only in
<br>
that we use our BRAINS to demarcate their boundaries&quot; without any loss
<br>
of meaning.  Indeed, I obviously should have said this: it would have been
<br>
clearer to you.
<br>
<p>But forgive me if I slip back into such handy phrases as &quot;Imagine that
<br>
...&quot; &quot;I feel differently ...&quot; or &quot;... they both feel the same.&quot;  I'm
<br>
being an anti-realist about these phrases.  We both get to say them,
<br>
but we get to say them for different reasons.
<br>
<p><em>&gt; &gt;Well, yes.  It's a philosophical problem which we resolve by pondering
</em><br>
<em>&gt; &gt;our intuitions on the matter, or which we refuse to resolve, since
</em><br>
<em>&gt; &gt;it's pointless.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why don't you do your Senior thesis (?) on MVT ... much less boring.
</em><br>
<em>&gt; I have a mass of publications on it.
</em><br>
<p>Well, it's because the science part isn't philosophy, and I don't
<br>
particularly agree with the philosophy part.
<br>
<p><em>&gt; S&gt; Your &quot;consciousness isn't real&quot; posture just doesn't cut it in workaday
</em><br>
<em>&gt; S&gt; reality.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;It works just as well as its opposing view, so long as one
</em><br>
<em>&gt; &gt;pro-actively reinterprets consciousness claims into something else.
</em><br>
<em>&gt; &gt;&quot;When you say you're in pain, you mean that your E fibers are firing,
</em><br>
<em>&gt; &gt;and that's a bad thing; better get you some ibuprofen.&quot;  In practice,
</em><br>
<em>&gt; &gt;we simply don't decide whether to re-interpret consciousness claims or
</em><br>
<em>&gt; &gt;not, since their reinterpretation does not affect our decisions about
</em><br>
<em>&gt; &gt;what to do about &quot;pain,&quot; whether pain is mental or purely physical.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But our senses, through which we interpret the world .. and our common
</em><br>
<em>&gt; sense, or &quot;how we&quot; combine and interpret sense data, can recognise
</em><br>
<em>&gt; the &quot;feel&quot; experience of *pain* because we KNOW what it is like ourselves.
</em><br>
<em>&gt; A torturer can soon change someone's mind (though not as elegantly as
</em><br>
<em>&gt; my new system of hypnosis arguably!)
</em><br>
<p>Sure.  Just be sure that you re-interpret all of those claims into
<br>
physical ones (when you intend to speak formally), and I agree with
<br>
all of that.
<br>
<p>Since your theory and anti-realism agree on truth values, and since
<br>
you don't actually have to re-interpret claims on the spot (or ever,
<br>
if you don't intend to speak formally) they're equally useful for
<br>
workaday practice.
<br>
<p><em>&gt; Yes, so are there some truth or empirical grounds which reinforce
</em><br>
<em>&gt; even the hypnosis, or make the hypnosis easier to take if experience
</em><br>
<em>&gt; is in agreement?
</em><br>
<p>Well, it doesn't matter to me whether there's a &quot;truth&quot; or not.  I'll
<br>
go about acting like my intuitions are pretty well (but not perfectly)
<br>
in touch with it, either way.
<br>
<p>I'd assume that hypnosis is harder to the extent that it disagrees with
<br>
my currently active beliefs/desires, but that there's nothing else
<br>
helping or hindering the matter.  Hypnotizing me to believe the truth
<br>
when I strongly believe a falsehood should be no harder than
<br>
hypnotizing me to believe a falsehood when I believe the truth, all
<br>
else being equal (which it so rarely is).
<br>
<p><em>&gt; And given that we could already be in trance or working on
</em><br>
<em>&gt; post-hypnotic suggestions, how do you make any truth claims for your
</em><br>
<em>&gt; own beliefs in determinism, epiphenobblyism and all that Turing
</em><br>
<em>&gt; machine rubbish?
</em><br>
<p>I make truth claims because I'm following my intuitions, and my
<br>
program.  Do I make justified truth claims?  I think I do, and that
<br>
has to be pretty much good enough for me.
<br>
<p><em>&gt; S&gt; No Turing machines of the sort you discuss have ever, not will ever,be
</em><br>
<em>&gt; S&gt; built.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;.Perhaps not, but only on account of their being too cumbersome, slow,
</em><br>
<em>&gt; &gt;expensive, and hard to build, not by virtue of their being different
</em><br>
<em>&gt; &gt;in principle.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, or in other words the idea of building them is daft! So why would
</em><br>
<em>&gt; evolution (infinitely pragmatic) have used such a daft design?
</em><br>
<p>Nobody's arguing that nature has actually designed a tape-reader, or
<br>
that the human brain has any tape.  But nature might be stuck using a
<br>
million tape-reader-equivalents instead of something better because
<br>
Turing machine equivalents (the collection of which, in turn, is one
<br>
big Turing machine equivalent) are all that are physically available.
<br>
<p><em>&gt; S&gt; The SHAPE of the brain effects its function, the shape evolved, and
</em><br>
<em>&gt; S&gt; (gestalt) can be described in terms of foreground OR background
</em><br>
<em>&gt; S&gt; (holes), or both.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;But holes are different from sadness; different in kind and in
</em><br>
<em>&gt; &gt;principle.  They may be linked, but they're not the same.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; No, you continue to misunderstand that &quot;holes&quot; are an analogy that I
</em><br>
<em>&gt; use to point out some shared attributes with the &quot;absent&quot; or
</em><br>
<em>&gt; &quot;abstract&quot; pineal eye .... but I by no means hold that this analogy
</em><br>
<em>&gt; is the whole story.
</em><br>
<p>Sure, I see where you're going here.  To say that something is
<br>
&quot;missing a certain function&quot; is just to state counterfactually that,
<br>
if you had a pineal eye, you'd act in such-and-such a way.  It is to
<br>
describe a certain possible state-of-affairs in which you had a pineal
<br>
eye, and you acted that way.  But that &quot;possible state-of-affairs&quot; is
<br>
just an idea, a non-physical if not purely mental object.  So &quot;missing
<br>
functions&quot; are psychological just like possibilities are.
<br>
<p>But still we're conflating &quot;psychological&quot; here, because even
<br>
possibilities, and thereby missing functions, are different in kind
<br>
from feelings, sensations, and other qualia.  A feeling is not a
<br>
possibility, not even a mental representation of a possibility.
<br>
<p>One common brand of anti-realism about consciousness is
<br>
&quot;functionalism,&quot; the view that &quot;being conscious&quot; is really nothing
<br>
more than the body's CAPACITY to have certain kinds of behavior, or to
<br>
be in a certain physical state.  Hilary Putnam, who, I believe,
<br>
originally coined the term, emphasized that one of functionalism's
<br>
most important characteristics was that it maintained that mental
<br>
properties were non-physical properties: although &quot;capacities&quot; are
<br>
properties of physical objects, the functionality itself was
<br>
non-physical: it was merely a statement of possibility, or, in
<br>
philosophical jargon, it was a modal property of a physical thing, a
<br>
way a thing could be.
<br>
<p>But this solution does not solve the mind/body problem, as even Putnam
<br>
himself now admits.  Because to say that you feel sad is not to say
<br>
anything about the way your body is OR about the way that your body
<br>
could possibly be.  All our old thought experiments come back.  It's
<br>
easy to imagine someone who had all of the functionality of a person
<br>
but doesn't have any feelings.  There's nothing about the (ordinary,
<br>
non-functionalist) definition of &quot;feelings&quot; implying that someone
<br>
who COULD ACT in a certain way feels in a certain way.
<br>
<p>Indeed, there are obvious counterexamples: actors act sad, but they
<br>
aren't sad.  A more refined functionalism can get around this
<br>
simplistic counterexample, but still suffers from the same old
<br>
objections: this is all talk about the PHYSICAL.  It's talk about
<br>
one's PHYSICAL functionality.  The mental is something more; something
<br>
else.  And functionalism provides us with no explanation for how or
<br>
why modal properties of physical things cause or imply mental
<br>
properties.
<br>
<p>Why this little parable about functionalism?  Because your view, that
<br>
being conscious just is to miss the functionality of the pineal eye,
<br>
and nothing more, amounts to a kind of anti-functionalism: it is to
<br>
say that being conscious means to have a MISSING physical
<br>
functionality, rather than a present physical functionality, as Putnam
<br>
had argued.  It's a modal property of a physical object either way.
<br>
<p>Your anti-functionalist view suffers from all the same problems as
<br>
functionalism; all the same objections.  Maybe it has all the same
<br>
intuitive support.  Certainly it's worth noting that missing
<br>
pineal-eye functionality seems to cause positive physical
<br>
functionality like the kind Putnam was interested in.  That's what led
<br>
us to conclude that the pineal eye was interesting: missing that
<br>
physical functionality seemed to grant us another functionality:
<br>
intelligent behavior.  But we can't really use this as a solution for
<br>
the mind/body problem, or even as intuitive support for a solution,
<br>
because you'd just be arguing for functionalism: you'd be using
<br>
functionalism to argue that you'd solved the mind/body problem.
<br>
<p>Modal properties are not mental properties.  &quot;Being sad&quot; says
<br>
something about the way my body is, but it says more than that.  &quot;Being
<br>
conscious&quot; says something about the way my body could be, but it says
<br>
more than that.  But unless we turn into dualists, (and probably
<br>
epiphenomenalists, at that,) we may never be able to quite put our
<br>
finger on what that might be.
<br>
<p>So... even if we put scare quotes around &quot;holes&quot; and remind ourselves
<br>
that we mean missing components/functions, still &quot;holes&quot; are
<br>
analytically different from feelings.  Functionality, even missing
<br>
functionality, is not enough to convert the dualists.  They want more.
<br>
<p>I argue that it's more than scientists can even give them.  But they
<br>
want more, all the same.
<br>
<p><em>&gt; &gt;Well, of course, there is a weak version of free-will, according to
</em><br>
<em>&gt; &gt;which we have free will if only we can make decisions independently of
</em><br>
<em>&gt; &gt;our genetics and our fellow man, but NOT necessarily independent of,
</em><br>
<em>&gt; &gt;say, the state of the Earth yesterday or last week or last year.  I
</em><br>
<em>&gt; &gt;must agree with that weaker version.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I will reciprocally agree with a weaker version of determinism: after
</em><br>
<em>&gt; all we cannot step outside this Universe (at least very easily!) and I
</em><br>
<em>&gt; accept that we do not have free will in all things. Perhaps by combining
</em><br>
<em>&gt; these weaker versions we can stop this tired old Free Will debate?
</em><br>
<p>Probably not, so long as philosophers assert that we CAN make
<br>
decisions wholly independent from how we were last week or laster
<br>
year, and so long as philosophers argue that the difference between us
<br>
a million Turing machines (or one big fast one) is that one is
<br>
free-willed and the other is not.
<br>
<p>In the weak sense we just defined, a Turing machine CAN be
<br>
free-willed, CAN make its decisions independently of what other people
<br>
&quot;tell&quot; it to do.  Highly self-modifying but deterministic Turing
<br>
programs can and regularly do surprise their creators.  Nobody told
<br>
Deep Blue to move the queen there.  No one knew that it would; not
<br>
even it, until it found out that it &quot;desired&quot; to do that.  (Scare
<br>
quotes again.)
<br>
<p><em>&gt; &gt;I never said that they did it in real time... they do it considerably
</em><br>
<em>&gt; &gt;slower than that.  But doing it at all is interesting.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; NO ... why go with a less good analogy, a less efficient proof,
</em><br>
<em>&gt; and with a daft imaginary (Turing) architecture when you would
</em><br>
<em>&gt; learn far more looking at neural (silicon) computation ... which
</em><br>
<em>&gt; sculpt themselves from experience rather than running code ...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The von Neumann and Turing analogies as to how a brain works
</em><br>
<em>&gt; are of as much use and out of date as the 1920's analogies between
</em><br>
<em>&gt; the brain and a telephone exchange.
</em><br>
<p>Because the Turing-Church thesis tells us of what we human beings are
<br>
capable (namely, nothing more than of what a bunch of Turing machines
<br>
are capable, and therefore nothing more than of what one great big
<br>
fast Turing machine is capable) and what can possibly act like us.
<br>
<p><em>&gt; &gt;In
</em><br>
<em>&gt; &gt;particular, if you had a slow person who still had REM, still claimed
</em><br>
<em>&gt; &gt;to have dreams and told me about them, still told me how they felt,
</em><br>
<em>&gt; &gt;still talked to me like an ordinary slow person, I'd be drawn to
</em><br>
<em>&gt; &gt;conclude that they were just like me, only slower, including having
</em><br>
<em>&gt; &gt;consciousness, only slower, assuming I have it in the first place.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This isn't a case of just &quot;equivalent but slower&quot; .... they would also be
</em><br>
<em>&gt; working in a completely different way from you. Neural computers
</em><br>
<em>&gt; are reverse engineered from brain circuits, so are a lot more
</em><br>
<em>&gt; convincing ... this ISN'T just an aesthetic matter either ... the neural
</em><br>
<em>&gt; computational model of the brain is BETTER than the older serial
</em><br>
<em>&gt; computational models ... sure a load of sluggard academics still use it
</em><br>
<em>&gt; but they are due for reduction by MVT pretty soon, I hope.
</em><br>
<p>But the fact that they'd do the same things at the end of a very long
<br>
day, I insist, IS interesting.  They WOULD behave the same way, though
<br>
one would do so much much slower (but that's all).
<br>
<p>-Dan
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-unless you love someone-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;-nothing else makes any sense-
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.e. cummings
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4783.html">Luke Howison: "RE: Beaming Up via Nanotech"</a>
<li><strong>Previous message:</strong> <a href="4781.html">John Clark: "Re: Beaming Up via Nanotech"</a>
<li><strong>In reply to:</strong> <a href="4706.html">Steve Nichols: "MVT: all-conquering philosophy?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4782">[ date ]</a>
<a href="index.html#4782">[ thread ]</a>
<a href="subject.html#4782">[ subject ]</a>
<a href="author.html#4782">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:43 MDT</em>
</em>
</small>
</body>
</html>
