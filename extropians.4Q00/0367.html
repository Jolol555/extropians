<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Eugene's nuclear threat</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Eugene's nuclear threat</h1>
<!-- received="Thu Oct  5 03:37:16 2000" -->
<!-- isoreceived="20001005093716" -->
<!-- sent="Thu, 05 Oct 2000 02:38:50 -0700" -->
<!-- isosent="20001005093850" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Eugene's nuclear threat" -->
<!-- id="39DC4C2A.1F4D69DF@objectent.com" -->
<!-- inreplyto="14808.28184.390840.207289@lrz.uni-muenchen.de" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39DC4C2A.1F4D69DF@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Thu Oct 05 2000 - 03:38:50 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0368.html">Samantha Atkins: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Previous message:</strong> <a href="0366.html">Eugene Leitl: "Re: Intelligence increase"</a>
<li><strong>In reply to:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0038.html">Spudboy100@aol.com: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#367">[ date ]</a>
<a href="index.html#367">[ thread ]</a>
<a href="subject.html#367">[ subject ]</a>
<a href="author.html#367">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eugene Leitl wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Samantha Atkins writes:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; Wrong.  The entire attitude is based so much on nothing but fear rather
</em><br>
<em>&gt;  &gt; than finding a positive approach to guide what is going to develop in
</em><br>
<em>&gt;  &gt; any case that this very attitude is more poisonous than what you fear.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What can be possibly more poisonous than the end of the world as we
</em><br>
<em>&gt; know it(tm) and death of all or most human beings?
</em><br>
<p><p>I have been positioning every thing I said against the likelihood for
<br>
all or most humans dying.  It is precisely this I want to avoid. 
<br>
Perhaps there was some mis-communication.  But the world as we know it
<br>
is in fact history.  There is no way that world will stick around except
<br>
in a VR.  We are in for much too much change much too quickly for
<br>
anything like the world today (in most respects) to be likely to stick
<br>
around for long.  But that doesn't mean the ecology gets ripped (it is
<br>
more likely to flourish long term) or that all humans die.  They most
<br>
likely will become more and more augmented and/or upload but they
<br>
needn't die.
<br>
<p>The most interesting period for me is the one between now and the first
<br>
SI or nanotech or uploading, all the stuff we need to get right in order
<br>
to get there without such massive breakdowns and freakouts that we do
<br>
something really stupid.  More positively I believe we need some really
<br>
good memetic engineering to set up a positive vision of the future and
<br>
driver for ethics that actually work to make the world a better, happier
<br>
and vastly more productive place (and yes, friendlier) place than it is
<br>
today.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;  &gt; You (and whoever else you can persuade to such a view) stand to one side
</em><br>
<em>&gt;  &gt; and act as if you can do the impossible.  You act as if you can grade
</em><br>
<em>&gt;  &gt; utterly what is safe and non-safe and keep the world safe by destroying
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Of course not, and I hope I don't make too many mistakes on the wrong
</em><br>
<em>&gt; side.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; all of what you see as non-safe.  Yet you yourself have argued this does
</em><br>
<em>&gt;  &gt; not work.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Relinquishment doesn't work sustainably, true. However, I don't
</em><br>
<em>&gt; propose 1) relinquishment 2) sustainably, just culling of the most
</em><br>
<em>&gt; dangerous branches using muscle (the old legislative/executive thing),
</em><br>
<em>&gt; for a limited period of time while we're passing the bottleneck of
</em><br>
<em>&gt; vulnerability.
</em><br>
<em>&gt;
</em><br>
<p>Without a vision of where we're going that enrolls most researchers and
<br>
a lot of the rest of us I don't think you can get to where you want to
<br>
go.  The business of culling without clear understanding of where we
<br>
want to go and without popular buy-in is itself quite dangerous to our
<br>
future (and present). 
<br>
<p>I'm not sure you can define a delimited period of time that we are
<br>
vulnerable.  It seems to me we would be very vulnerable up to the point
<br>
where we're all backed up fully in as failsafe a way as is imaginable.  
<br>
<p><p>&nbsp;
<br>
<em>&gt;  &gt; Those dead researchers were also a large part of the hope of humanity
</em><br>
<em>&gt;  &gt; transcending this mudball.  Thank you very much.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I want to achieve transcension by not dying, thankyouverymuch. A
</em><br>
<em>&gt; sterilized mudball, or mudball turned into supermachinery, stripping
</em><br>
<em>&gt; people in the process, that's not exactly my idea of progress.
</em><br>
<em>&gt;
</em><br>
<p>You have me confused with someone else.  I don't plan on any of those
<br>
scenarios.  
<br>
&nbsp;
<br>
<em>&gt;  &gt; That is a little more immediate and more directly aimed at destruction.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Duh. Do you think I'm a monster?
</em><br>
<em>&gt;
</em><br>
<p>Nope.  I think you, like most of us, can get frightened (rightfully so)
<br>
and can reach conclusions that aren't really likely to get you what you
<br>
want and have really nasty consequences of their own.
<br>
&nbsp;
<br>
<em>&gt;  &gt; I would suggest though that growing a positive future scenario that
</em><br>
<em>&gt;  &gt; gives bright babies something better to use their brains for than
</em><br>
<em>&gt;  &gt; figuring out how to exercise their own particular fears is probably the
</em><br>
<em>&gt;  &gt; most fruitful way to avoid or at least minimize such situations.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure, but no matter what you do, a few of the bright babies wound up
</em><br>
<em>&gt; pathological individuals (blame evolution), and would put their
</em><br>
<em>&gt; brightness to destroy themselves and us in the process.
</em><br>
<em>&gt;
</em><br>
<p>Yeah.  But you can at least make it a lot less likely by providing more
<br>
positive channels.  It also helps to have enough research openness for
<br>
the dangerous channels to get recognized early on (as well as the
<br>
near-psychotic researcher here and there).  
<br>
<p>I'm not saying we don't have any safeguards.  But we should exhaust
<br>
positive means first and be very careful what kinds of negative
<br>
safeguards we propose and implement.
<br>
&nbsp;
<br>
<em>&gt; To show you all how truly evil I am, I propose for an early screening
</em><br>
<em>&gt; program, identifying such people (thankfully, brilliant sickos are
</em><br>
<em>&gt; quite rare), and locking them up where they can't hurt themselves and
</em><br>
<em>&gt; others.
</em><br>
<em>&gt;
</em><br>
<p>That simply will not work.  Non-sick people sometimes make decisions
<br>
that are extremely dangerous and have very negative unforseen
<br>
consequences.  The occassional psychopath is not the main worry as I see
<br>
it.
<br>
<p>&nbsp;
<br>
<em>&gt;  &gt; It is not too hard to think up a variety of ways to destroy and fuck up
</em><br>
<em>&gt;  &gt; on a massive scale.  It is much harder to create and especially hard to
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There aren't that many self-constructed scenarious which end us
</em><br>
<em>&gt; sustainably, at least with our current state of knowledge. A large
</em><br>
<em>&gt; asteroid sneaking up, or a GRB in our neck of the woods would do, but
</em><br>
<em>&gt; they're not man-made.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; create an ovearching vision that our science and technology is used to
</em><br>
<em>&gt;  &gt; bring into reality and that can get buy-in from more than just us nerds.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sounds like a good plan. But people don't buy into delayed
</em><br>
<em>&gt; gratification, so it has to work in small increments.
</em><br>
<em>&gt;
</em><br>
<p>It depends on how it is sold.  Memes have been sold that delayed
<br>
gratification for generations (rightly or wrongly).  The former Soviet
<br>
Union is a case in point.  It wasn't a very healthy meme but it shows
<br>
that long-term goals can be sold well enough to counteract short-range
<br>
thinking.  But fortunately, things that benefit us short-term can be
<br>
aligned with policies and long term goals in many cases.  One of the
<br>
hardest jobs of meme hacking is to get people to really see more
<br>
globally and more at a system level.  It goes against a lot of
<br>
conditioning.  In the West we also have a lot of anti-intellectualism
<br>
and anti-science/technology memes to counteract and replace with
<br>
something more healthy.  
<br>
&nbsp;
<br>
<em>&gt;  &gt; The best way to be reasonably sure that we won't create our own
</em><br>
<em>&gt;  &gt; destroyer is for humanity to become the Power instead of trying to
</em><br>
<em>&gt;  &gt; create something separate from them.  Create SI as part of our own being
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure, I'm all for it. Notice that the positive self-enhancement
</em><br>
<em>&gt; autofeedback loop is still present. But in this case we start with a
</em><br>
<em>&gt; human, so here we can assume conservation of compassion at least for
</em><br>
<em>&gt; the few steps of the self-enhancement process, which will hopefully be
</em><br>
<em>&gt; also somewhat less fulminant.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; and growing edge.  Learn to care for and evolve the entire body instead
</em><br>
<em>&gt;  &gt; of just certain parts of the head.  Then we will have our best chance.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Since when did we wound up to be disembodied brains floating in the vats?
</em><br>
<em>&gt;
</em><br>
<p>We sometimes act like such.  We get way out into the tech and into the
<br>
wondrous future Mind that will be build and forget our roots, forget our
<br>
dreams, forget the real world and real people we are now that will
<br>
somehow have to be what we build from.  Too often we lay aside our
<br>
dreams of better, of better and happier life for ourselves and others
<br>
and get a bit lost in a hyper head trip.  But we can sell just the head
<br>
thing.  If you get the masses to grok the head thing at all they are
<br>
likely to be marching in the streets with torches because that story
<br>
doesn't say how they can take care of themselves and their kids and have
<br>
a viable and compelling future.  
<br>
&nbsp;
<br>
<em>&gt;  &gt; I think that all of us together are as smart as we get and that we need
</em><br>
<em>&gt;  &gt; to learn to work together really well if we are to make a difference.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Our firmware is not made to cooperate in large groups, and deal with
</em><br>
<em>&gt; extreme threats. We're not smart and rational enough for that. If
</em><br>
<em>&gt; there ever was a use for human germline engineering, it's to boost our
</em><br>
<em>&gt; EQ and IQ.
</em><br>
<p>Then we better learn to re-write and work around the firmware because we
<br>
haven't got a lot of choice if we wish to survive.  We don't have space
<br>
to wait for germline engineering.  It takes some powerful and compelling
<br>
memes to enable and sustain the types of efforts needed.  I don't know
<br>
in detail what those memes look like but I think coming up with them and
<br>
effectively planting them is crucial to our success as a species.
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0368.html">Samantha Atkins: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Previous message:</strong> <a href="0366.html">Eugene Leitl: "Re: Intelligence increase"</a>
<li><strong>In reply to:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0038.html">Spudboy100@aol.com: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#367">[ date ]</a>
<a href="index.html#367">[ thread ]</a>
<a href="subject.html#367">[ subject ]</a>
<a href="author.html#367">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:15 MDT</em>
</em>
</small>
</body>
</html>
