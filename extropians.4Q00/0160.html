<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Let's hear Eugene's ideas</title>
<meta name="Author" content="hal@finney.org (hal@finney.org)">
<meta name="Subject" content="Re: Let's hear Eugene's ideas">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Let's hear Eugene's ideas</h1>
<!-- received="Tue Oct  3 00:30:30 2000" -->
<!-- isoreceived="20001003063030" -->
<!-- sent="Mon, 2 Oct 2000 23:26:18 -0700" -->
<!-- isosent="20001003062618" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Let's hear Eugene's ideas" -->
<!-- id="200010030626.XAA05407@finney.org" -->
<!-- inreplyto="Let's hear Eugene's ideas" -->
<strong>From:</strong> <a href="mailto:hal@finney.org?Subject=Re:%20Let's%20hear%20Eugene's%20ideas&In-Reply-To=&lt;200010030626.XAA05407@finney.org&gt;"><em>hal@finney.org</em></a><br>
<strong>Date:</strong> Tue Oct 03 2000 - 00:26:18 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0161.html">Samantha Atkins: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0159.html">Brian Atkins: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Maybe in reply to:</strong> <a href="0114.html">Eliezer S. Yudkowsky: "Let's hear Eugene's ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0179.html">Spudboy100@aol.com: "Re: Let's hear Eugene's ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#160">[ date ]</a>
<a href="index.html#160">[ thread ]</a>
<a href="subject.html#160">[ subject ]</a>
<a href="author.html#160">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Brian wrote:
<br>
<em>&gt; On one hand you want to allow
</em><br>
<em>&gt; some research in order to get improved smart software packages, but on
</em><br>
<em>&gt; the other hand you want to prevent the &quot;bad&quot; software development that
</em><br>
<em>&gt; might lead to a real general intelligence?
</em><br>
<p>I was predicting, not recommending.  I was responding to your suggestion
<br>
to &quot;look around at the reality of the next 20 years (max). There are
<br>
likely to be no Turing Police tracking down and containing all these
<br>
AIs that all the hackers and scientists out there will dream up.&quot;
<br>
<p>My points were (a) that 20 years is not necessarily the right timeframe
<br>
because it is questionable whether AI can be developed that quickly,
<br>
(b) that we might well see increased restrictions on genetics, nanotech
<br>
and robotic research as called for by Joy, and (c) that if AI does make
<br>
progress, people are going to know about it and possibly be afraid of the
<br>
consequences.  See my earlier message for elaborations on these.
<br>
<p><em>&gt; Is the government going to sit
</em><br>
<em>&gt; and watch every line of code that every hacker on the planet types in?
</em><br>
<em>&gt; In an era of super-strong encryption and electronic privacy (we hope)?
</em><br>
<p>So you are arguing that even if Turing Police are authorized by the
<br>
public, they will not be effective?  If so I misunderstood your earlier
<br>
point.  I thought you were implying that AI would happen so quickly as
<br>
to be &quot;under the radar&quot; of a public which was ignorant of its dangers,
<br>
hence there would be no awareness of the threat.  It was that scenario
<br>
which I disagreed with.
<br>
<p>The question of efficacy is more difficult to judge.  If AI research
<br>
were controlled, would we really see bands of hackers, protected by
<br>
cryptographic anonymity, working together in networks scattered across
<br>
the planet to make new AI systems?  This would be a task orders of
<br>
magnitude more difficult than the closest thing I see today, the open
<br>
source programming projects.  And the reward is much more distant and
<br>
hypothetical.  You'd almost have to have an ideological commitment to
<br>
AI as the supreme goal of your life to stay motivated and involved in
<br>
a project like this.  This would limit participation considerably.
<br>
<p>I wouldn't rule out some efforts along these lines, but my guess is
<br>
that they would be relatively small and uncoordinated.  Progress would
<br>
be much slower than a scenario where AI research was done in the open.
<br>
Given that I think AI progress would be slow even in the best case, my
<br>
opinion is that the chances of anonymous hackers successfully producing
<br>
a super-AI is low.
<br>
<p>I am not recommending that we stop AI research.  I am offering an analysis
<br>
of whether restrictions would be effective against it, which is what I
<br>
understand to be the point you are raising.
<br>
<p>Hal
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0161.html">Samantha Atkins: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0159.html">Brian Atkins: "Re: Let's hear Eugene's ideas"</a>
<li><strong>Maybe in reply to:</strong> <a href="0114.html">Eliezer S. Yudkowsky: "Let's hear Eugene's ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0179.html">Spudboy100@aol.com: "Re: Let's hear Eugene's ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#160">[ date ]</a>
<a href="index.html#160">[ thread ]</a>
<a href="subject.html#160">[ subject ]</a>
<a href="author.html#160">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
