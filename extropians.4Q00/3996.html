<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<title>extropians: Re: transitional thinking</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: transitional thinking">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: transitional thinking</h1>
<!-- received="Wed Dec 13 22:23:09 2000" -->
<!-- isoreceived="20001214052309" -->
<!-- sent="Wed, 13 Dec 2000 21:23:11 -0800" -->
<!-- isosent="20001214052311" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: transitional thinking" -->
<!-- id="00cd01c0658d$fcbb47a0$40bc473f@jrmolloy" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="F1733Sv0YKpDS7hx27k0000e29c@hotmail.com" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20transitional%20thinking&In-Reply-To=&lt;00cd01c0658d$fcbb47a0$40bc473f@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Dec 13 2000 - 22:23:11 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3997.html">Dan Fabulich: "Re: Stalker Tricks was: Reason +/- Faith"</a>
<li><strong>Previous message:</strong> <a href="3995.html">Harvey Newstrom: "Re: Civilization and Enemies, was Re: CONFESSIONS OF A       CHEERFULLIBERTARIAN By David Brin"</a>
<li><strong>In reply to:</strong> <a href="3989.html">Justin Corwin: "Re: transitional thinking"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4001.html">Samantha Atkins: "Re: transitional thinking"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3996">[ date ]</a>
<a href="index.html#3996">[ thread ]</a>
<a href="subject.html#3996">[ subject ]</a>
<a href="author.html#3996">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Justin Corwin writes,
<br>
<em>&gt; i would argue, no offense intended at all towards the singularity folks,
</em><br>
<em>&gt; that it already is a religious meme. singularity is supposed to solve
</em><br>
every
<br>
<em>&gt; problem since the time you burnt your toast to cats and dogs living
</em><br>
together
<br>
<em>&gt; in harmony, which smacks of faith to me.
</em><br>
<p>Well then, technological singularity could also solve the problem of faith.
<br>
Rather like self-healing/faith-healing
<br>
too-smart-for-mere-mortals-to-comprehend SI, which provides the answer to
<br>
why anything exists. No Problem.
<br>
Nothing offensive in that (unless I'm expected to do something about it).
<br>
<p><em>&gt; not that i think greater than human intelligence wont' solve problems we
</em><br>
<em>&gt; can't on our own, but perhaps the singularity will not be the incredible
</em><br>
<em>&gt; force you're expecting.
</em><br>
<p>I cannot expect technological singularity to manifest as a force, unless
<br>
that force already operates in reality. As I understand extropy, it
<br>
qualifies as a pre-singularity force that fits the profile of
<br>
hyper-accelerated positive change, which has the potential to evolve into a
<br>
hyper-complex super-adaptive mega-system that will rip itself out of the
<br>
constraints of biology and boot itself into galactic commandeering like we
<br>
can't imagine. It's progeny shall eat universes for breakfast.
<br>
Nothing offensive in that (unless I'm expected to do something about it).
<br>
<p><em>&gt; what if self modifying humans with their patterned
</em><br>
<em>&gt; parallel processors are never overtaken by machine intelligences? it's
</em><br>
just
<br>
<em>&gt; as likely as a human who is self modifying has less far to go to become
</em><br>
more
<br>
<em>&gt; intelligent than a human, all he would have to do is become ANY smarter. a
</em><br>
<em>&gt; machine intelligence doesn't exist yet. going from 60 to 61 is easier than
</em><br>
0
<br>
<em>&gt; to 61, even with our design flaws.
</em><br>
<em>&gt; just a theory.
</em><br>
<p>I like the idea of self modifying humans. For starters, I'd modify myself so
<br>
that I could earn an enormous amount of money to pay for the operation that
<br>
made me self-modifying.
<br>
After that, I'd set about to teach the world that Democrats will not let
<br>
machine intelligence get out of control, even if they have to hand count
<br>
every ballot in the country.
<br>
<p><em>&gt; i do however, believe that expert systems and ultratech/ultrasoftware will
</em><br>
<em>&gt; play a role in improving us, as we're unlikely just to do it through
</em><br>
<em>&gt; biological manipulation(gene therapy, bioware, etc). although you could
</em><br>
just
<br>
<em>&gt; add a bunch of grey matter and see what happened.
</em><br>
<p>Yes, let's start with... uh, how 'bout me. Go ahead, strap me down and pour
<br>
some grey matter in there. Not too much though. I might start thinking about
<br>
the meaning of &quot;improving us&quot; and go haywire. Relax, I'm just kidding. What
<br>
I really want to do is work as hard as I can to become a real live
<br>
transitional-post-human. (I'll just die if I don't make it.)
<br>
<p><em>&gt; (a wonderful quote from a bad movie:
</em><br>
<em>&gt; &quot;....so, what does a 18 foot predator with a brain the size of a flat-head
</em><br>
<em>&gt; V12 engine think about?...&quot;
</em><br>
<em>&gt;    -Deep Blue Sea )
</em><br>
<p>What would such a predator _need_ to think about? I've been thinking about
<br>
the Global Brain lately. (Greg Stock used to call it &quot;Metaman.&quot;) Suppose a
<br>
super-intelligent super-organism were to solve all our problems for us. Then
<br>
what? Isn't that what people invented god for? So there you are, back with
<br>
religionism, and like a jack-in-the-box, here comes deus ex machina.
<br>
<p><em>&gt; the bottom line is that trancendant AI is cool, and massively
</em><br>
<em>&gt; useful(theoretically). but it's also not here. so we need to be careful
</em><br>
<em>&gt; where we put our trust(faith?). as long as we're not sitting on our butts
</em><br>
<em>&gt; waiting for momma AI to come and fix our problems, the religious nature of
</em><br>
<em>&gt; &quot;awaiting the singularity&quot; won't be an issue.
</em><br>
<p>You are right to advise caution, I think. Nevertheless, an SI that can solve
<br>
all my problems may not be worth the problems it creates by requiring me to
<br>
build it. I have no clue where to begin, which tempts me to stop right now.
<br>
Suddenly I feel as though I have no problems. Has the singularity happened,
<br>
or will even more unproblematical feelings herald its birth...
<br>
<p><em>&gt; my big question, is, when the singularity does occur, how do we keep
</em><br>
people
<br>
<em>&gt; from treating it like a GOD, or a Demon. no matter how logical and well
</em><br>
<em>&gt; constructed it is, being treated like a god would hamper both it's
</em><br>
<em>&gt; situation, it's flexibility, and it's psychology(assuming a general
</em><br>
<em>&gt; intelligence would have a similar psychology to other general
</em><br>
intelligences,
<br>
<em>&gt; such as humans, being given absolute worship and power has a tendency to
</em><br>
<em>&gt; mess with your head and hamper your effectiveness)
</em><br>
<p>I see no reason why people should _not_ treat an SI like a god. A benevolent
<br>
god would be nice, but a demon with the right answers would do fine. Don't
<br>
forget, the singularity is you... if you successfully self-modify.
<br>
Nothing offensive in that (unless I'm expected to do something about it).
<br>
<p>Stay hungry,
<br>
<p>--J. R.
<br>
3M TA3
<br>
<p>&quot;Truth is a pathless land.&quot;
<br>
--J. Krishnamurti
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3997.html">Dan Fabulich: "Re: Stalker Tricks was: Reason +/- Faith"</a>
<li><strong>Previous message:</strong> <a href="3995.html">Harvey Newstrom: "Re: Civilization and Enemies, was Re: CONFESSIONS OF A       CHEERFULLIBERTARIAN By David Brin"</a>
<li><strong>In reply to:</strong> <a href="3989.html">Justin Corwin: "Re: transitional thinking"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4001.html">Samantha Atkins: "Re: transitional thinking"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3996">[ date ]</a>
<a href="index.html#3996">[ thread ]</a>
<a href="subject.html#3996">[ subject ]</a>
<a href="author.html#3996">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:36 MDT</em>
</em>
</small>
</body>
</html>
