<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: &quot;Cybernetic Totalism?&quot;</title>
<meta name="Author" content="Anders Sandberg (asa@nada.kth.se)">
<meta name="Subject" content="Re: &quot;Cybernetic Totalism?&quot;">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: &quot;Cybernetic Totalism?&quot;</h1>
<!-- received="Fri Oct 13 12:12:00 2000" -->
<!-- isoreceived="20001013181200" -->
<!-- sent="13 Oct 2000 20:11:50 +0200" -->
<!-- isosent="20001013181150" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: &quot;Cybernetic Totalism?&quot;" -->
<!-- id="b498zrswqzd.fsf@sans04.nada.kth.se" -->
<!-- inreplyto="Thu, 12 Oct 2000 18:21:31 +0100&quot;" -->
<strong>From:</strong> Anders Sandberg (<a href="mailto:asa@nada.kth.se?Subject=Re:%20&quot;Cybernetic%20Totalism?&quot;&In-Reply-To=&lt;b498zrswqzd.fsf@sans04.nada.kth.se&gt;"><em>asa@nada.kth.se</em></a>)<br>
<strong>Date:</strong> Fri Oct 13 2000 - 12:11:50 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1073.html">Anders Sandberg: "Re: Incomplete Singularity"</a>
<li><strong>Previous message:</strong> <a href="1071.html">Ralph Lewis: "Re: IRS definition of religion (Was: Back off! I'm Navajo!)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1157.html">Anders Sandberg: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1072">[ date ]</a>
<a href="index.html#1072">[ thread ]</a>
<a href="subject.html#1072">[ subject ]</a>
<a href="author.html#1072">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Bryan Moss&quot; &lt;<a href="mailto:bryan.moss@btinternet.com?Subject=Re:%20&quot;Cybernetic%20Totalism?&quot;&In-Reply-To=&lt;b498zrswqzd.fsf@sans04.nada.kth.se&gt;">bryan.moss@btinternet.com</a>&gt; writes on Lanier's argument:
<br>
<p><em>&gt;     Autonomy has no technological benefit.  That is, we
</em><br>
<em>&gt; cannot *use* autonomous devices.  But the approaches we are
</em><br>
<em>&gt; currently taking towards the creation of autonomous devices
</em><br>
<em>&gt; are technological.  For example, *evolving* a brain is not
</em><br>
<em>&gt; science--it provides no understanding--and, if the goal is
</em><br>
<em>&gt; human equivalency, it's of no technological benefit either.
</em><br>
<em>&gt; (Imagine an automobile manufacturer that has not only fully
</em><br>
<em>&gt; automated their production and design process but only
</em><br>
<em>&gt; produces passenger-less self-driving vehicles.)  Given that
</em><br>
<em>&gt; AI has no apparent merit either as science or technology
</em><br>
<em>&gt; there must be another reason for adopting it as a goal, and
</em><br>
<em>&gt; that reason is the quasi-religious &quot;Cybernetic Totalism&quot;.
</em><br>
<p>I agree with this. Why uplift animals or make alife? Beside the pure
<br>
ego gratification of &quot;because they are/aren't there&quot;, there is likely
<br>
a kind of spiritual drive to be agent of evolution. I certainly feel
<br>
it. 
<br>
<p>But Lanier is not just attacking the idea of making AI (which is much
<br>
broader than autonomy - a smart house or software agent may not be
<br>
totally autonomous but *very* useful) but the overall idea that
<br>
Something Big is about to happend due to technological change, and
<br>
some of the information assumptions many make in relation to this.
<br>
<p><em>&gt; I think Lanier's mistake, like so many critics of technology, is the
</em><br>
<em>&gt; failure to recognise that technology does not create new problems it
</em><br>
<em>&gt; merely magnifies existing ones.
</em><br>
<p>Well, I would think most of them actually like to imply that it does
<br>
both. What they fail to notice is that it also solves many problems
<br>
and can be directed in useful ways.
<br>
<p><em>&gt;  In the case of AI it's that old favourite
</em><br>
<em>&gt; &quot;what are we and what are we doing here?&quot;  You can't
</em><br>
<em>&gt; question the purpose of fully autonomous systems without
</em><br>
<em>&gt; also questioning the purpose of our own society.
</em><br>
<p>Good point. 
<br>
<p><em>&gt; It may also be that Lanier is using AI's questionable
</em><br>
<em>&gt; application as a user interface to challenge the idea that
</em><br>
<em>&gt; AI could become integral to society rather than simply be
</em><br>
<em>&gt; used to automate facets of society into a kind of
</em><br>
<em>&gt; disconnectedness (as with my example of the automobile
</em><br>
<em>&gt; manufacturer).  If we want AI to form a part of society and
</em><br>
<em>&gt; do not simply accept AI as our mind children and &quot;hand over
</em><br>
<em>&gt; the reigns&quot; we have to find a niche in society that involves
</em><br>
<em>&gt; interaction rather than automated isolation.  By questioning
</em><br>
<em>&gt; this niche Lanier adds merit to his argument.
</em><br>
<p>It might be interesting to explore what kinds of interfaces to AI
<br>
would be useful. Would a animistic interface (everything is aware and
<br>
sentient to some extent) be useful, for example?
<br>
<p><em>&gt; &gt; [...] we should see how we can polish up transhumanist
</em><br>
<em>&gt; &gt; thinking in order not to fall into the traps he describes.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think Lanier makes some good points that are difficult to
</em><br>
<em>&gt; find in what is essentially a very confused essay.  The main
</em><br>
<em>&gt; thing we should take away from this is the questionable
</em><br>
<em>&gt; nature of AI as a goal, not because it is necessarily a bad
</em><br>
<em>&gt; goal but because, for me, it illuminates a bigger problem.
</em><br>
<em>&gt; After all, what is society but a fully autonomous system?
</em><br>
<em>&gt; And what external purpose does that system serve?  For me
</em><br>
<em>&gt; Lanier's essay was an affirmation of my own doubts about
</em><br>
<em>&gt; transhumanism.  Without a purpose we cannot architect our
</em><br>
<em>&gt; future, we need to discover the precise things we wish to
</em><br>
<em>&gt; preserve about ourselves and our society and only then can
</em><br>
<em>&gt; we go forward.  In my mind it is not enough to say &quot;I want
</em><br>
<em>&gt; to live forever&quot;; &quot;I&quot; is simply shorthand, I want to know
</em><br>
<em>&gt; what it is about me that I should preserve and why I should
</em><br>
<em>&gt; preserve it.  I think these problems run deep enough that
</em><br>
<em>&gt; we'll need more than polish.
</em><br>
<p>My thought also. I would gladly see more discussions about questions
<br>
like this, the philosophical foundations of transhumanism both on the
<br>
list and among transhumanists. Obviously there is more to it than
<br>
wanting to live forever and to play a bit with computers.
<br>
<p><pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<a href="mailto:asa@nada.kth.se?Subject=Re:%20&quot;Cybernetic%20Totalism?&quot;&In-Reply-To=&lt;b498zrswqzd.fsf@sans04.nada.kth.se&gt;">asa@nada.kth.se</a>                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1073.html">Anders Sandberg: "Re: Incomplete Singularity"</a>
<li><strong>Previous message:</strong> <a href="1071.html">Ralph Lewis: "Re: IRS definition of religion (Was: Back off! I'm Navajo!)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1157.html">Anders Sandberg: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1072">[ date ]</a>
<a href="index.html#1072">[ thread ]</a>
<a href="subject.html#1072">[ subject ]</a>
<a href="author.html#1072">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:17 MDT</em>
</em>
</small>
</body>
</html>
