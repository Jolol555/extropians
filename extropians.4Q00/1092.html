<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Web stuff (was Re: A plea for restraint)</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Web stuff (was Re: A plea for restraint)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Web stuff (was Re: A plea for restraint)</h1>
<!-- received="Sat Oct 14 00:34:59 2000" -->
<!-- isoreceived="20001014063459" -->
<!-- sent="Fri, 13 Oct 2000 23:35:49 -0700" -->
<!-- isosent="20001014063549" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Web stuff (was Re: A plea for restraint)" -->
<!-- id="39E7FEC5.BA0EBAF1@objectent.com" -->
<!-- inreplyto="14823.48039.637305.142456@lrz.uni-muenchen.de" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Web%20stuff%20(was%20Re:%20A%20plea%20for%20restraint)&In-Reply-To=&lt;39E7FEC5.BA0EBAF1@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sat Oct 14 2000 - 00:35:49 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1093.html">Amara Graps: "Re: Immortalism: The Epic of Gilgamesh"</a>
<li><strong>Previous message:</strong> <a href="1091.html">David Blenkinsop: "Re: Mars vs Rice (was Re: v2.5 vs v3.0)"</a>
<li><strong>In reply to:</strong> <a href="1069.html">Eugene Leitl: "Re: A plea for restraint"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1099.html">Alex Future Bokov: "Re: Web stuff (long message)"</a>
<li><strong>Reply:</strong> <a href="1099.html">Alex Future Bokov: "Re: Web stuff (long message)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1092">[ date ]</a>
<a href="index.html#1092">[ thread ]</a>
<a href="subject.html#1092">[ subject ]</a>
<a href="author.html#1092">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eugene Leitl wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt;Alex Future Bokov wrote:
</em><br>
<em>&gt;  &gt; Please direct your comments at how ExtroDot specifically can improve. I
</em><br>
<em>&gt; 
</em><br>
<p>One thing that bugs be about most web sites including slash types is
<br>
that most of these systems don't have an obvious way to send comments on
<br>
the site itself like a webmaster email link.  To me it is somewhat rude
<br>
and cowardly to not include a feedback button on a site, especially one
<br>
that expects thousands of hits. 
<br>
<p><p><p><em>&gt; 
</em><br>
<em>&gt; Nope, I was talking about /. clones in general. I believe it's slick,
</em><br>
<em>&gt; loads fast, and is about as mean and lean as webpages can
</em><br>
<em>&gt; get. Unfortunately, it's still a web page.
</em><br>
<em>&gt; 
</em><br>
<p>There isn't anything wrong with web pages per se that a bit of re-think
<br>
wouldn't fix.  We need imho something at the browser/client (dumb
<br>
distinction) end that is more like an interpreter and a bag of very
<br>
basic graphic capabilities but little more than that and a fairly simple
<br>
scripting language for invoking more capability.  What comes from the
<br>
server is model (data) plus requests on the views to apply to that data
<br>
(more data).  The browser constructs the view, loads the model into it
<br>
and provides some controller functionality for interpreting user
<br>
gestures within particular standard widgets.  It does what actions it
<br>
can against the data loaded to it from the server (or other peer if you
<br>
will) and only talks to the server (or other peer) when it needs
<br>
services not available in the browser or the local loadable software
<br>
module space.  This is much cleaner than having a server that concocts
<br>
the entire view, cramming in the model data as best it can with some
<br>
ungodly ugliness or other and then sends this thing as a dumb, dead file
<br>
that is nearly unreadable to a big fat browser that does its best to
<br>
render the thing locally even though most of the brains (what little
<br>
there were) have been left at the server end.  Almost all client
<br>
interaction causes another round-trip to the server for yet another dumb
<br>
page whose data is all collected by and at the server and whose
<br>
presentation is described and painfully built by the server. 
<br>
<p>Now I know that today there are a lot of people doing things a little
<br>
smarter.  Like sending XML data up and having it locally rendered.  Some
<br>
of them are even using Java or something better to do the rendering. 
<br>
Which gets a bit better.  But too many are using yet more layers of
<br>
obfuscation (XSLT, CSS) to get around to doing a half-assed job at
<br>
something Smalltalk  programmers did well (pluggable views) a long time
<br>
ago.  I used to subscribe to an XSL[T} list.  But it was much too
<br>
depressing reading endless posts about people attempting to do simple
<br>
programming tasks in something not at all made for it.  Why do people
<br>
buy some half-ass language or hype of the day and try to make it do
<br>
everything?  
<br>
<p>And exactly why is it that my 650Mhz+ machines with 10s of gigs of
<br>
storage are not being utilized for better UI experience, local caching
<br>
of data and code fragments and so on?  Treat me as a &quot;thin client&quot; when
<br>
I'm on a cell phone or my palm pilot but not when I have that kind of
<br>
local power.  It is a stupid waste.  We clog the internet with page
<br>
after page to be drawn on machines most of which could calculate their
<br>
own pages from data kept in synch with its remote sources with far less
<br>
traffic on the net and a far richer user experience and MUCH faster.  
<br>
<p>The Web as such is not the problem.  Falling for hype and forgetting to
<br>
think or to dream up better solutions using all the resources at your
<br>
disposal is.  I have no problem with something that does every
<br>
functional thing the web does.  I have a big problem with its
<br>
dysfunctional aspects and with people and companies literally refusing
<br>
to think outside of the box called the WEB.  &quot;The customers won't buy it
<br>
if we do anything but HTTP for our GUI.&quot;  &quot;The customer won't buy our
<br>
server if it isn't Microsoft.&quot; &quot;The customer definitely won't buy our
<br>
server if it isn't written in pure Java.&quot;  Balderdash.  Give a business
<br>
tools it can use to be many times more effective than its competitors at
<br>
a fraction of the cost and they will be lined up at your door.  Of
<br>
course you have to find the people in the business actually capable of
<br>
thinking vs. simply repeating what they read.
<br>
<p><em>&gt;  &gt;
</em><br>
<em>&gt;  &gt; Huh? Extodot sits on *our* drivespace, not yours. Unless you choose
</em><br>
<em>&gt;  &gt; to save a particular posting or article locally. It's *more* efficient
</em><br>
<em>&gt;  &gt; on disk space.
</em><br>
<em>&gt; 
</em><br>
<p>Let's see.  I can pick up  IDE space at around 40 gigs for $300 or
<br>
less.  My time runs around $80+/hour currently.  So about 4 hours net of
<br>
time wasted putting up with someone else's organization of the data and
<br>
waiting for them to render it in the ways their server knows how to and
<br>
to deliver it a piece at a time over the net to me vs. spending that
<br>
four hours of earnings for enough space to store huge libraries of
<br>
information locally.  I can see going to other machines (but much more
<br>
efficiently) for new fresh information.  But going to them to get stuff
<br>
that hasn't changed?  What for?  Disks are cheap, time is expensive.  A
<br>
remote database/repository is nice for sure but I want my own not little
<br>
links to everyone's own web-ified offerings of information. I'm sitting
<br>
right on top of a fiber installation at work and on 780K bi-directional
<br>
DSL at home.  I can afford to download all the original data and updates
<br>
I need.  On the road I could link to my own server and see things in the
<br>
form that I want it.  
<br>
<p><p><p><em>&gt; I'm a digital pack rat. I don't trust content to be there tomorrow
</em><br>
<em>&gt; when I see it today. Because, like, every third link I click is dead
</em><br>
<em>&gt; like, totally. Rather frustrating, this. Other people are solving this
</em><br>
<em>&gt; by running squid in total web trail mode, me, I don't have that much
</em><br>
<em>&gt; hard drive space. So I grab whatever I deem useful. Because web
</em><br>
<em>&gt; doesn't allow me to save the entire document, I have to resort to
</em><br>
<em>&gt; naked .html, txt, .ps.gz and .pdf
</em><br>
<em>&gt; 
</em><br>
<p>Excuse my ignorance but what is a &quot;squid&quot;?
<br>
<p><em>&gt; Actually, I'm running the leanest browser version I know, have a
</em><br>
<em>&gt; browser half life time of a week despite heavy use (abovementioned 100
</em><br>
<em>&gt; simultaneously open sessions) and system uptimes well in excess of a
</em><br>
<em>&gt; month (usually, due to creeping memory leaks (thanks again, Netscape
</em><br>
<em>&gt; programmers) lwhich et ran my swap space (256 MBytes) full, and when I
</em><br>
<em>&gt; forget to weekly kill and restart the browser, the system will sooner
</em><br>
<em>&gt; or later typically crash). It would sure help if I had a gig of core,
</em><br>
<em>&gt; but I'm not that rich.
</em><br>
<p>The Netscape crashes in Linux don't seem correlated with either number
<br>
of windows or amount of memory on the machine as far as I can tell.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Opera is not quite there yet when it comes to stability (but it is
</em><br>
<em>&gt; making good progress), nor is Galeon (also almost there). However, the
</em><br>
<em>&gt; problem is principal. You can't render complex content in a
</em><br>
<em>&gt; sustainably stable fashion, using state of the art software
</em><br>
<em>&gt; development. On the other hand, I can rely on the average software to
</em><br>
<em>&gt; render simple content (ASCII) reliably.
</em><br>
<em>&gt; 
</em><br>
<p>Actually you can come a lot closer if you keep the data (model)
<br>
relatively straightforward in terms of knows sets of meta protocols it
<br>
employs and have a stable set of widgets and view thingies that you
<br>
might add experimental things to now and then with fallbacks to simpler
<br>
ones plus some decent streamable scripting support (both to run
<br>
interpreters and embed code and support dynamic configuration).  The
<br>
rest of the complexity  in a mulit-user environment is in concurrency
<br>
and transaction type issues and in other goodies like failover,
<br>
replication and security.  Some parts of transactional processing
<br>
(especially long transactions and non-standard models of concurrency)
<br>
are research topics.  But the simpler things should not be what is
<br>
causing unpredictability as is the case largely today.  The simpler
<br>
things also should not be eating up ungodly amounts of bandwidth.  And
<br>
most of all the simpler things should be consuming the majority of the
<br>
programming talent.  When you see that happen something is obviously
<br>
wrong.
<br>
<p><p><em>&gt; I've never liked the web. When the CERN dudes came out with HTML, my
</em><br>
<em>&gt; first thoughts were 1) great, something new which totally ignores
</em><br>
<em>&gt; prior art (both TeX and PostScript) and is not a programming language
</em><br>
<em>&gt; 2) it doesn't do typography? uh-oh. In a few years they'll wind up
</em><br>
<em>&gt; reintroducing basic typographic capabilities, in dribs and drabs,
</em><br>
<em>&gt; until the thing breaks all over the place.
</em><br>
<p>Well, HTML is a bastardized subset of SGML (or was).  SGML does give the
<br>
real presentation and typography stuff.  It would have been really good
<br>
if actual display PostScript was used to model a lot of the rendering
<br>
stuff and dependably customize it.  At the time it came out HTML was a
<br>
reasonable compromise for getting people sharing a lot of content over
<br>
the internet.  But we lost sight of what was and wasn't good about it
<br>
and made it a matter of religion to do all things for all people through
<br>
HTTP.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; So we did have 4 major HTML revisions, now there's XML which is
</em><br>
<em>&gt; falling into complexity morass even before it is widely deployed, we
</em><br>
<em>&gt; have about five different, incompatible widely misused scripting
</em><br>
<em>&gt; languages which further increase browser instability and are a system
</em><br>
<em>&gt; security nightmare.
</em><br>
<em>&gt;
</em><br>
<p>XML is getting made to complex imho.  The basic idea is fairly simple. 
<br>
Except it ignored some simply facts in its early design like the fact
<br>
that most data exists in the form of a general graph rather than a
<br>
hierarchy.  It is taking a really long time for them to get over that
<br>
and fix it rather than conveniently ignoring it much of the time.  Then
<br>
the official standard parsers are braindead in that a 15 meg XML data
<br>
stream will blow up into 200 megs or so in memory using most
<br>
implementations of DOM (well, under Java anyway).  And people got so
<br>
hooked on human readability they didn't bother to take XML data
<br>
description or DTD and compress the actual data into some predictable
<br>
binary format that is more efficient to transmit and decipher given the
<br>
meta information and perhaps a bit of indexing at the front.  Worse of
<br>
all are the people who want to take perfectly good (well, maybe a bit
<br>
too bloated) RPC and CORBA and COM pipes and turn it all into XML.  
<br>
<p><p>&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; with this point in the first place. Tell me more about your filters.
</em><br>
<em>&gt;  &gt; They may already exist as features, or they may be relatively easy to
</em><br>
<em>&gt;  &gt; implement.
</em><br>
<em>&gt;  &gt;
</em><br>
<p>How about implementing general scripting based filters and let
<br>
half-clueful users provide their own filters written in the script?  I
<br>
would vote for Scheme or Python based scripting myself.  So you need an
<br>
interpreter and a sandbox and some reasonable API for getting at the
<br>
information on your site as information/data.  
<br>
<p><p><em>&gt;  &gt; I leave everybody with this question to ponder:
</em><br>
<em>&gt;  &gt;
</em><br>
<em>&gt;  &gt; Is there an inherent difference between push and pull media, or is this
</em><br>
<em>&gt;  &gt; difference arbitrary, artifactual, and potentially transparent to the
</em><br>
<em>&gt;  &gt; user in the same way as &quot;static location vs. search query&quot; or &quot;local
</em><br>
<em>&gt;  &gt; volume vs. distributed file system&quot;?
</em><br>
<em>&gt; 
</em><br>
<p>Push and pull aren't terribly relevant to me.  What I really want are
<br>
systems that make the walls disappear.  I would like to not need to
<br>
think much about whether the data, objects, functionality I am dealing
<br>
with is on my machine, your machine, all of our machines or what
<br>
computer language it is in or what database vendor product and on and on
<br>
it goes.  I would like to see information/objects/fucntionality helped
<br>
to be rearranged and duplicated and migrated to best balance the load
<br>
dynamically.  I think a big mistake &quot;server&quot; or &quot;website&quot; people make is
<br>
assuming they more or less own the information and are the determiners
<br>
of how others access it.  At most they give some particular views onto
<br>
information.  But this functionality should not make it impossible to
<br>
get to the informationa and bits of the functionality to use them in
<br>
other and new ways.  I'm probably not expressing that well.  Even after
<br>
15 years I haven't found a way to say it that will reach most people. 
<br>
And most of my time gets eaten doing something far less clueful to make
<br>
my daily bread.  
<br>
<p><p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1093.html">Amara Graps: "Re: Immortalism: The Epic of Gilgamesh"</a>
<li><strong>Previous message:</strong> <a href="1091.html">David Blenkinsop: "Re: Mars vs Rice (was Re: v2.5 vs v3.0)"</a>
<li><strong>In reply to:</strong> <a href="1069.html">Eugene Leitl: "Re: A plea for restraint"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1099.html">Alex Future Bokov: "Re: Web stuff (long message)"</a>
<li><strong>Reply:</strong> <a href="1099.html">Alex Future Bokov: "Re: Web stuff (long message)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1092">[ date ]</a>
<a href="index.html#1092">[ thread ]</a>
<a href="subject.html#1092">[ subject ]</a>
<a href="author.html#1092">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:17 MDT</em>
</em>
</small>
</body>
</html>
