<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Eugene's nuclear threat</title>
<meta name="Author" content="Eugene Leitl (eugene.leitl@lrz.uni-muenchen.de)">
<meta name="Subject" content="Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Eugene's nuclear threat</h1>
<!-- received="Mon Oct  2 03:10:47 2000" -->
<!-- isoreceived="20001002091047" -->
<!-- sent="Mon, 2 Oct 2000 01:06:52 -0700 (PDT)" -->
<!-- isosent="20001002080652" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene.leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Eugene's nuclear threat" -->
<!-- id="14808.16924.882912.189448@lrz.uni-muenchen.de" -->
<!-- inreplyto="39D7BD44.AEC7CC63@pobox.com" -->
<strong>From:</strong> Eugene Leitl (<a href="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;14808.16924.882912.189448@lrz.uni-muenchen.de&gt;"><em>eugene.leitl@lrz.uni-muenchen.de</em></a>)<br>
<strong>Date:</strong> Mon Oct 02 2000 - 02:06:52 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0066.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0064.html">Samantha Atkins: "Re: Why wouldn't friendly AI leave fundies in the dust?"</a>
<li><strong>In reply to:</strong> <a href="0036.html">Eliezer S. Yudkowsky: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0248.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0248.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#65">[ date ]</a>
<a href="index.html#65">[ thread ]</a>
<a href="subject.html#65">[ subject ]</a>
<a href="author.html#65">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eliezer S. Yudkowsky writes:
<br>
<p><em> &gt; Eugene Leitl thinks it's okay to murder
</em><br>
<em> &gt; scientists whose work he doesn't like.
</em><br>
<p>Sigh. Let's try it again.
<br>
<p>There must be lots of scientists I don't like personally (them and me
<br>
being only human, and all), but that hardly gives me mandate to snuff
<br>
them. Only those who *provably* engage into *Armageddon-class*
<br>
research (*not only according to my opinion* -- I would get second and
<br>
third and fourth opinions from independent experts in the area) and
<br>
*would not cease and desist* when confronted with what they do and
<br>
*given proper time to recant* would have to be prevented from what
<br>
they do, *preferably by locking them up*, or, failing that, by
<br>
*executing them*. I would expect this to be handled by a (state or
<br>
private) authority representing a substantial amount of people. Only
<br>
if this machinery is not there or fails to handle the problem (which I
<br>
must be 100% sure is for real), and I'm in the position of handling it
<br>
(fat chance) I will be compelled to terminate these people with
<br>
whatever means are at my disposal. Buck Rogers saving the world with a
<br>
toothpick, etc.
<br>
<p>Now compare above passage with what you just said.
<br>
<p>If you confuse that with what Ted Kaczynski did when he blew
<br>
Gelernter's hands off, then you ought to have your head examined.
<br>
<p>According to you, people disposing sarine in Japanese subways should
<br>
be apparently allowed to proceed, in the name of freedom of
<br>
science. Or how about Dr. Mengele, surely he did some valuable
<br>
research on identical twins, the dream control group? Or those WWII
<br>
Japanese bioweapon researchers, who tested their weapons on POWs,
<br>
causing them to slowly die of gangrene? Or those French military
<br>
surgeons, who -- of course without asking them -- transplanted heads
<br>
of terminally wounded asian POWs in Indochina? Or these nameless
<br>
German engineers who calculated the size of crematorium ovens for
<br>
sustained criticality? Or the IG Farben producing HCN absorbed on
<br>
silica, for a rather radical concentration camp delousing?  Or Chinese
<br>
medics extracting and selling organs of executed prisoners on the
<br>
transplantation market? Or these people who contaminated whole Utah
<br>
with nuke airbursts, resulting in hundreds of additional deaths due to
<br>
cancer? Freedom of science, my ass. If you condone any of this I
<br>
indeed would like to see you locked up for good.
<br>
<p>Right now I'm aware of only three potential instances of Armageddon
<br>
class research: bioweapons of a certain design and modus of deployment
<br>
(your garden-variety anthrax and Ebola obviously don't qualify),
<br>
free-environment-capable molecular autoreplicators and positive-
<br>
autofeedback-capable superhuman AI. Possible future candidates would
<br>
be devices based on new physics, which can destroy this planet (say,
<br>
allowing you to create a stable singularity, and dropping it into
<br>
Earth's core, or something which dislodges our false vacuum, etc.).
<br>
<p><em>&gt;From what you said before, I assume you're not quite cool with grey
</em><br>
goo gobbling up the global biosphere, and I'm pretty sure you don't
<br>
like you and 95% of humanity dying painfully from some engineered
<br>
disease as well as a radically compacted Earth with lots of hard gamma
<br>
pyrotechnics. I presume -- freedom of science or no -- you would want
<br>
these people stopped, by whatever means possible, even if it involves
<br>
you personally stepping up and capping them from behind. I would
<br>
really like to hear your response to this one.
<br>
<p>Now assuming you're mistaken about your superhuman AI, and, if you
<br>
indeed happen to produce a critical core, and it will indeed explode
<br>
right into your face into a positive autofeedback selfimprovement
<br>
runaway, and eat us all, starting with you first, would you allow you
<br>
to proceed?
<br>
<p>But, of course, you can't be possibly mistaken. Never, ever. These
<br>
divine voices in my head telling me I'm right, etc.
<br>
<p>Enough of this crap.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0066.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0064.html">Samantha Atkins: "Re: Why wouldn't friendly AI leave fundies in the dust?"</a>
<li><strong>In reply to:</strong> <a href="0036.html">Eliezer S. Yudkowsky: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0248.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0248.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#65">[ date ]</a>
<a href="index.html#65">[ thread ]</a>
<a href="subject.html#65">[ subject ]</a>
<a href="author.html#65">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
