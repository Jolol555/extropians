<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Market failure to sufficently weigh the future</title>
<meta name="Author" content="Nick Bostrom (nick@nickbostrom.com)">
<meta name="Subject" content="Re: Market failure to sufficently weigh the future">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Market failure to sufficently weigh the future</h1>
<!-- received="Tue Oct 31 18:22:28 2000" -->
<!-- isoreceived="20001101012228" -->
<!-- sent="Tue, 31 Oct 2000 20:21:35 -0400" -->
<!-- isosent="20001101002135" -->
<!-- name="Nick Bostrom" -->
<!-- email="nick@nickbostrom.com" -->
<!-- subject="Re: Market failure to sufficently weigh the future" -->
<!-- id="4.3.2.7.2.20001031185302.057bfe68@nlb28.mail.yale.edu" -->
<!-- inreplyto="4.2.0.58.20001031140445.00b9f100@mason.gmu.edu" -->
<strong>From:</strong> Nick Bostrom (<a href="mailto:nick@nickbostrom.com?Subject=Re:%20Market%20failure%20to%20sufficently%20weigh%20the%20future&In-Reply-To=&lt;4.3.2.7.2.20001031185302.057bfe68@nlb28.mail.yale.edu&gt;"><em>nick@nickbostrom.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 31 2000 - 17:21:35 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<li><strong>Previous message:</strong> <a href="1835.html">J. R. Molloy: "ROBOT: Aesthetically Evolved Virtual Pets"</a>
<li><strong>In reply to:</strong> <a href="1824.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<li><strong>Reply:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1836">[ date ]</a>
<a href="index.html#1836">[ thread ]</a>
<a href="subject.html#1836">[ subject ]</a>
<a href="author.html#1836">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Robin Hanson wrote:
<br>
<p><em>&gt;Hal Finney wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;evolution, ... The authors' argument does not seem to address the
</em><br>
<em>&gt;&gt;possibility that discounting is rational and appropriate.  They view
</em><br>
<em>&gt;&gt;the effect as purely psychological or even philosophical.  Discounting
</em><br>
<em>&gt;&gt;the future can be modelled as a fully rational process.
</em><br>
<em>&gt;
</em><br>
<em>&gt;It is standard practice to describe the discount rate in simple
</em><br>
<em>&gt;examples where there is no uncertainty, but I'm very sure the authors
</em><br>
<em>&gt;are well aware that real decisions have uncertainty, and that they
</em><br>
<em>&gt;intended their discount rate to be used in the standard expected
</em><br>
<em>&gt;utility framework when there is uncertainty.
</em><br>
<p>A few possibly clarifying points:
<br>
1. As Robin points out above, we factor out uncertainty, growth etc. and 
<br>
focus on the remaining tendency that people have to discount the future.
<br>
2. What we are looking at is what a benevolent social planner who is a 
<br>
preference utilitarian would do. I.e. the task of the planner is to 
<br>
maximize total preference-satisfaction.
<br>
3. Preference-satisfaction is distinct from pleasure. On the preference 
<br>
utilitarian's view, it is good that a preference be satisfied even if the 
<br>
person who has the preference never finds out about it and thus never 
<br>
experiences any pleasure as a result.
<br>
4. Preferences of future and past people count for as much as current 
<br>
preferences of existing people.
<br>
5. Although the authors end up drawing policy conclusions, we can set that 
<br>
aside, temporarily at least. The step from what the ideal social planner 
<br>
would choose to recommending certain kinds of government intervention 
<br>
requires extra arguments that take into account practicalities of 
<br>
implementation.
<br>
<p>Now, the authors argue that we discount the future but that we don't have a 
<br>
corresponding inverse tendency to &quot;over-appreciate&quot; the past. Although I 
<br>
may have some preference that my past was happy, I tend to prefer to have 
<br>
current or near-future felicity rather than felicity in the past. This 
<br>
seems a plausible claim to me. If one argues that we haven't evolved to 
<br>
have any strong preferences about the past, this would only strengthen the 
<br>
authors' claim.
<br>
<p>&nbsp;From this, it is then shown that if each observer-moment makes choices 
<br>
according to its own preferences, then less total preference-satisfaction 
<br>
results than if a benevolent social planner could subsidize resource 
<br>
transfer to later observer-moments (saving).
<br>
<p>Another consequence is that if we consider an individual who lives for 10 
<br>
time units, and has the same kind of preferences throughout his life and 
<br>
has identical past and future discount rates, then it is more important 
<br>
that the preferences he had in his mid-life be satisfied than that those he 
<br>
had at the beginning and end of his life are. For by satisfying a 
<br>
preference he had during t=5, you satisfy both that preference and the 
<br>
preferences he had at t=4 that his preference at t=5 would be satisfied, 
<br>
and his preference at t=6 that his preference at t=5 be satisfied, etc. By 
<br>
contrast, satisfying a preference at t=10 only satisfies preference at t=10 
<br>
and t=9 and preferences at earlier times which are more heavily discounted 
<br>
since they are more distant from t=10.
<br>
<p>Here are two further ruminations that I haven't thought through carefully:
<br>
<p>A. Yet another consequence is that if you want the social planner to give 
<br>
you what you want, you may create lots of individuals who have as their 
<br>
main preference in life that your preferences be satisfied. (This is 
<br>
somewhat analogous to paying people to pray for your soul after you're dead 
<br>
in the hope that a preference-satisfying God will choose not to ignore so 
<br>
many peoples' wishes.) If this seems counterintuitive, one should bear in 
<br>
mind that maybe it's not ethical to create individuals for that purpose. 
<br>
But once they are there, their preferences count. Yet suppose you are 
<br>
ethically entitled to use your capital for such purposes. Then one thing 
<br>
you could do if you were very rich is to create a sufficient number of 
<br>
individuals whose only wish were that your wishes should be granted. The 
<br>
preferences of all these wishers could then dominate counter-wishes by 
<br>
other people, so that you would get the right e.g. to have somebody else's 
<br>
spaceship since that would satisfy so many more preferences. It seems 
<br>
wasteful to require the rich guy to actually create all the wishers, so 
<br>
maybe he has a right to take your spaceship simply in virtue of being so 
<br>
rich and having the potential to create the wishers. That seems rather 
<br>
absurd, so we should conclude that you don't have a generic ethical right 
<br>
to use your capital to create new individuals with whatever preferences you 
<br>
fancy.
<br>
<p>B. Presumably you don't have to be actively aware of a desire for X in 
<br>
order to have a preference for X (otherwise we'd have much fewer 
<br>
preferences than economists ascribe to us. But do we also have preferences 
<br>
while we sleep (dreamlessly)? While cryonically suspended? Or in the case 
<br>
of an upload, during the time when you are not running? That would seem to 
<br>
have the counterintuitive consequence that by just suspending your mind for 
<br>
a sufficiently long period, you would get an ethical entitlement to 
<br>
whatever you want.
<br>
<p><p><p>Dr. Nick Bostrom
<br>
Department of Philosophy
<br>
Yale University
<br>
Homepage: <a href="http://www.nickbostrom.com">http://www.nickbostrom.com</a>
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<li><strong>Previous message:</strong> <a href="1835.html">J. R. Molloy: "ROBOT: Aesthetically Evolved Virtual Pets"</a>
<li><strong>In reply to:</strong> <a href="1824.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<li><strong>Reply:</strong> <a href="1837.html">Robin Hanson: "Re: Market failure to sufficently weigh the future"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1836">[ date ]</a>
<a href="index.html#1836">[ thread ]</a>
<a href="subject.html#1836">[ subject ]</a>
<a href="author.html#1836">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:19 MDT</em>
</em>
</small>
</body>
</html>
