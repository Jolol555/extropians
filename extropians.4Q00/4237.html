<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Sentience</title>
<meta name="Author" content="Steve Nichols (steve@multisell.com)">
<meta name="Subject" content="Re: Sentience">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Sentience</h1>
<!-- received="Mon Dec 18 10:58:22 2000" -->
<!-- isoreceived="20001218175822" -->
<!-- sent="Sun, 17 Dec 2000 00:22:29 -0000" -->
<!-- isosent="20001217002229" -->
<!-- name="Steve Nichols" -->
<!-- email="steve@multisell.com" -->
<!-- subject="Re: Sentience" -->
<!-- id="002701c067bf$8ab97bc0$efb1403e@i6x7m6" -->
<!-- inreplyto="Sentience" -->
<strong>From:</strong> Steve Nichols (<a href="mailto:steve@multisell.com?Subject=Re:%20Sentience&In-Reply-To=&lt;002701c067bf$8ab97bc0$efb1403e@i6x7m6&gt;"><em>steve@multisell.com</em></a>)<br>
<strong>Date:</strong> Sat Dec 16 2000 - 17:22:29 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4238.html">Ziana Astralos: "Re: Yahoo Technical Support for DEFINE.COM"</a>
<li><strong>Previous message:</strong> <a href="4236.html">Barbara Lamar: "another Texas clone"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4261.html">Dan Fabulich: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4261.html">Dan Fabulich: "Re: Sentience"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4237">[ date ]</a>
<a href="index.html#4237">[ thread ]</a>
<a href="subject.html#4237">[ subject ]</a>
<a href="author.html#4237">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Date: Sun, 17 Dec 2000 21:11:11 -0500 (EST)
<br>
From: Dan Fabulich &lt;<a href="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Sentience&In-Reply-To=&lt;002701c067bf$8ab97bc0$efb1403e@i6x7m6&gt;">daniel.fabulich@yale.edu</a>&gt;
<br>
Subject: Re: Immortality
<br>
<p>Steve Nichols wrote:
<br>
<p><em>&gt; Exactly ..... whereas evolvable circuitry machines (silicon or biological)
</em><br>
<em>&gt; can be or approach infinite-state. The mammalian brain is infinite-state
</em><br>
<em>&gt; in a way that a simple thermostat, or even a massive Turing machine,
</em><br>
<em>&gt; cannot.
</em><br>
<p><em>&gt;I had not heard the news that brains were infinite-state.  Last I
</em><br>
<em>&gt;heard, atoms were all finite-state, so a finite clump of atoms must
</em><br>
<em>&gt;necessarily be finite-state.
</em><br>
<p><em>&gt;The brain has very very many possible states, but it is no more
</em><br>
<em>&gt;infinite state than a hundred billion thermostats would be
</em><br>
<em>&gt;infinite-state, if you wired them all together in an interesting way.
</em><br>
<p>@ But the brain can self-organise and forge new neuronal patterns.
<br>
@ Furthermore, it is  a massively parallel distributed system, and
<br>
@ *not* a Turing machine or von Neumann computer. Cite Kohonnen &amp;c.
<br>
<p>@ I doubt that it is ever in the same state twice!
<br>
<p>@ Any thought is possible, there are no boundaries to imagination.
<br>
@ Apparently there are more possible moves in a game of chess than
<br>
@ there are atoms in the universe, and there are presumably an (infinite)
<br>
@ different possible games of chess. This is because we are talking of
<br>
@ dynamic potentials. The thing with MVT is that we recognise a non-
<br>
@ physical component ... this is true infinite-state!
<br>
<p>Date: Sun, 17 Dec 2000 22:33:47 -0500 (EST)
<br>
From: Dan Fabulich &lt;<a href="mailto:daniel.fabulich@yale.edu?Subject=Re:%20Sentience&In-Reply-To=&lt;002701c067bf$8ab97bc0$efb1403e@i6x7m6&gt;">daniel.fabulich@yale.edu</a>&gt;
<br>
Subject: Re: Sentience
<br>
<p>Steve Nichols wrote:
<br>
<p><em>&gt; Date: Thu, 14 Dec 2000 12:56:40 -0500
</em><br>
<em>&gt; From: &quot;John Clark&quot; &lt;<a href="mailto:jonkc@worldnet.att.net?Subject=Re:%20Sentience&In-Reply-To=&lt;002701c067bf$8ab97bc0$efb1403e@i6x7m6&gt;">jonkc@worldnet.att.net</a>&gt;
</em><br>
<em>&gt; Subject: Re: Immortality
</em><br>
<em>&gt;
</em><br>
<p><em>&gt;A bald assertion.  I get the sense that you're not aware of the bigger
</em><br>
<em>&gt;picture John Clark has in mind (and with which I largely agree).
</em><br>
<p><em>&gt;John and I actually DO think that the human brain is (analogous to) an
</em><br>
<em>&gt;oversized Turing machine.  We think that it's programmed, and that we
</em><br>
<em>&gt;make &quot;decisions&quot; the same way that Deep Blue &quot;decides&quot; to move its
</em><br>
<em>&gt;bishop.
</em><br>
<p>How does such (unsubstantiable) conjecture even begin to explain
<br>
consciousness? How can any Turing machine, a glorified card-reader,
<br>
have experience? Anyway, big blue is a CPU machine, not even a
<br>
neural computer, so is absolutely nothing like a brain. Are you saying
<br>
the DNA is the &quot;program&quot; or what other medium are you identifying?
<br>
<p><em>&gt;&quot;But,&quot; you reply, &quot;Deep Blue was programmed to do that!&quot; and we reply:
</em><br>
<em>&gt;SO ARE WE.  We just have a very complex program, given to us by
</em><br>
<em>&gt;millions of years of evolution.  We &quot;change our own logic&quot; the same
</em><br>
<em>&gt;way Deep Blue alters its play style, the same way a thermostat adjusts
</em><br>
<em>&gt;the gas on your heater.  We're all programmed to do that.  Some of us
</em><br>
<em>&gt;have a more complex program than others.
</em><br>
<p>Hang about, Deep Blue is an extremely limited program that just plays
<br>
common chess. It is so dumb it can't even play other chess-like games, let
<br>
alone &quot;learn&quot; ... it cannot even start to cope with natural language.
<br>
<p>What about extrapolation abilities, how can programs alter themselves
<br>
to deal with entirely new circumstances? Complexity (more depth) is
<br>
not any sort of answer. Learning abilities are needed.
<br>
<p><em>&gt; &gt;based on its internal state and
</em><br>
<em>&gt;
</em><br>
<em>&gt; A digital switch does not have an &quot;internal state&quot;
</em><br>
<p>Yes, it does.  It has an &quot;desired&quot; temperature, which it must
<br>
&quot;remember&quot; in order to work properly.  The &quot;desired&quot; temperature isn't
<br>
a property of anything else in the thermostat-heater-room system, so
<br>
it must be an internal state of the thermostat.
<br>
<p>But precisely my point is it has not control over any &quot;memory&quot; of
<br>
the temperature setting, this is made EXTERNALLY and is not
<br>
within the thermostat's remit. So you are completely wrong in
<br>
anthromorphising that the thermostat &quot;desires&quot; a setting. A digital
<br>
switch is On or OFF, there is no intermediate or internal state, either
<br>
current goes through it or not. It cannot override its programming.
<br>
<p><p><em>&gt;These differ only in complexity, not in kind.  Deep Blue is a Turing
</em><br>
<em>&gt;machine: it differs only in complexity from a simple adder.  Our
</em><br>
<em>&gt;brains are just a finite arrangement of simple finite-state machines
</em><br>
<em>&gt;which do simple things, like thermostats.
</em><br>
<p><em>&gt;     &gt; Turing machines are neither conscious,
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;How do you know?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Well, they would fail the Turing test for starters.
</em><br>
<p>&lt;blink blink&gt; ALL Turing machines???  This is to say that we'll never
<br>
have a computer that will pass the Turing test, that we can never
<br>
write a program so complex that it could trick people into believing
<br>
that it acted like us.  Were you thinking about this when you said
<br>
that?
<br>
<p>Even passing the Turing test does not suggest consciousness, just AI.
<br>
The very fact that every aspect of Turing machines actions can be
<br>
predicted, I would say, might even preclude them from consciousness.
<br>
<p><em>&gt; You have rather foolishly missed the whole point that ANALOG is the
</em><br>
<em>&gt; abbreviation of &quot;analogous to infinite-state&quot; ... since true infinity
</em><br>
<em>&gt; is a conjecture ......
</em><br>
<p><em>&gt;But that's just the point.  Very-many-state is still finite-state, is
</em><br>
<em>&gt;still predictable, is still programmed, in an important sense.  It is
</em><br>
<em>&gt;difficult to predict the behaviour of complex very-many-state hardware,
</em><br>
<em>&gt;but obviously possible in principle.
</em><br>
<p>Yes, but as I try to point out, what MVT brings to table is *absent* or
<br>
non-physical, phantom components that complete the circuit!
<br>
<p>A cathode ray tube is infinite-state in that it is fully variable, scalar,
<br>
but because it operates within boundaries it is ANALOG. This stuff
<br>
is fairly rudimentary solid-state physics, you have no grounds to be
<br>
obfusticating here.
<br>
<p><em>&gt; Are you actually claiming the Turing machines exhibit phasic
</em><br>
<em>&gt; transients? Cite evidence please, you are utterly lost on this.
</em><br>
<p><em>&gt;There's no evidence to cite; this is a purely philosophical problem.
</em><br>
<p>No, your problem is that these Turing machines you talk about do not
<br>
exist, and probably never will. Unlike brains and silicon RGA circuits
<br>
(reconfigurable hardware), and all the many designs of neural computers,
<br>
your ideas are mere armchair theorising and of no relevance to anything.
<br>
<p><p><em>&gt;I can obviously get a Turing machine to exhibit periodic behaviour.  If
</em><br>
<em>&gt;I hooked a Turing machine up to a set of motors hooked up to some
</em><br>
<em>&gt;eyes, I could program it to go into REM.  If you had some other
</em><br>
<em>&gt;requirements, you could tack those on to a kind of Turing Test for
</em><br>
<em>&gt;Phasic Transient Behaviour.  The point is that an adequately complex
</em><br>
<em>&gt;Turing machine could pass that test.
</em><br>
<p>No, phasic transients occur simply because a circuit is undergoing
<br>
transformation from finite-state (lock step) to self-organising ....
<br>
and they happen after the removal of an external clock (whether
<br>
electronic or organic pineal eye). Aren't Turing machines always
<br>
lock-stepped?
<br>
<p><em>&gt; &gt;Seems to me all you've done is conjure up a black box, call it the
</em><br>
<em>&gt; &gt;phantom median eye and say consciousness comes from there.
</em><br>
<em>&gt; &gt;Not very helpful.
</em><br>
<em>&gt;
</em><br>
<em>&gt; No, the conceptual &quot;black box&quot; which was a problem before MVT
</em><br>
<em>&gt; now has a complete description, in actual terms and as an evolutionary
</em><br>
<em>&gt; narrative, as the phantom media eye. I have done away with mere
</em><br>
<em>&gt; &quot;black box&quot; conjecture!
</em><br>
<p><em>&gt;How good of you to say so.  But just saying THAT doesn't convince
</em><br>
<em>&gt;anyone.
</em><br>
<p><em>&gt;Look, you're overlooking the very simple point that in order to make
</em><br>
<em>&gt;any kind of induction, you need to first NOTICE a correlation.
</em><br>
<p>Absolutely. The main body of MVT concerns comparative brain
<br>
anatomy and behavioural difference between E-2 and E-1 animals.
<br>
<p><em> &gt;You
</em><br>
<em>&gt;can't justify any scientific inference to &quot;consciousness&quot; unless you
</em><br>
<em>&gt;can observe a few cases where the phantom median eye and consciousness
</em><br>
<em>&gt;go together.  You have to *observe* that, say, wherever you find
</em><br>
<em>&gt;consciousness, the pineal eye is less developed, and then posit that
</em><br>
<em>&gt;wherever the pineal eyes is underdeveloped, you'll find consciousness.
</em><br>
<p>You obviously haven't read anything of MVT. All mammals and birds
<br>
are E-1, and have REM. No cold-blooded animals have REM. The
<br>
pineal eye atrophied across all species during the reptilian/mammalian
<br>
boundary, and during the emergence of endothermy (internal or warm-
<br>
blooded strategies). There is a clear experimental correlation between
<br>
absence of pineal input (after pinealectomy, or when pineal eye has
<br>
been covered by metal foil and subject reptiles compared with a control
<br>
group) and intelligent behaviour ... *awareness* ... I don't really like to
<br>
use the &quot;C&quot; word!
<br>
<p><p><em>&gt;But you can't observe any such cases, thanks to the problem of other
</em><br>
<em>&gt;minds.
</em><br>
<p>Yes, as I mention above, there are about 130 years of records of such
<br>
experiments.  Other minds is an artificial lingoistic problem, it
<br>
doesn't stop  consciousness (sentience) happening, just gives philosophers
<br>
something to argue amongst themselves about.
<br>
<p><em>&gt;I know I have feelings, and that I smile, cry, scream, etc. as
</em><br>
<em>&gt;I have them.  But all I see you do is smile, cry, scream, etc.  How
</em><br>
<em>&gt;can I tell whether you're having feelings, or whether you're just
</em><br>
<em>&gt;going through the motions?  How do I know you're actually conscious,
</em><br>
<em>&gt;rather than just passing the Turing Test?
</em><br>
<p>Newborn infants seem to have empathic abilities, plus abilities
<br>
to monitor and judge emotions in others. It is a fair bet that if someone
<br>
is screaming in pain, particularly if they have correlating signs such
<br>
as a red-hot poker sticking up their arse, that they are actually feeling
<br>
pain, in much the same way you would. I really fail to see the problem here,
<br>
other than that you cannot be the other person so have to rely on reports.
<br>
<p>The median eye (template for E-1 consciousness) cannot be swapped
<br>
between animals, so a phantom equivalent of it likewise is non-transferable.
<br>
<p><em>&gt;Maybe you have something simpler in mind.  Maybe you're just positing
</em><br>
<em>&gt;MVT as a theory to explain how and when things can pass the Turing
</em><br>
<em>&gt;Test.  But you fail on THOSE grounds, too: you provide no *mechanism*
</em><br>
<em>&gt;by which the phantom pineal eye causes people to be conscious, or to
</em><br>
<em>&gt;act conscious, or, well, anything.  You only claim that consciousness
</em><br>
<em>&gt;DOES happen, and you tell us WHEN, but you don't explain HOW.
</em><br>
<p>On the contrary, MVT takes Melzack's neuromatrix theory of self (and
<br>
gateway theory of pain) a step further, and does explain how experiences
<br>
are identified by the brain as being self-originating (neurosignatures &amp;c)
<br>
or not. The deep structures of the brain evolved concurrently in early
<br>
evolution with their main sensory information supplier, the median or
<br>
*primal* eye (not &quot;third eye&quot; ... it predates lateral eyes). The brain
<br>
expects
<br>
information from the median eye ... and when it doesn't come from external
<br>
light, generates phantom information instead.
<br>
<p><em>&gt;That's a black box.
</em><br>
<p>NO. Fodorian modules and central executive theories, supervenience and
<br>
all the other philosophical lingoistic drivel are not physiology based, nor
<br>
do
<br>
they give a clear account of the *evolution* of consciousness.
<br>
<p><em>&gt; Solipsism is simply one (admissible) viewpoint. It isn't &quot;refutable&quot; since
</em><br>
<em>&gt; I do not deny that people have this thought. Infinite-state capability
</em><br>
<em>&gt; allows
</em><br>
<em>&gt; *any possible thoughts* including the solipsistic ones. Likewise you
</em><br>
cannot
<br>
<em>&gt; prove it &quot;correct.&quot;
</em><br>
<p><em>&gt;Another miscommunication.  The solipsist you DO have to deal with is
</em><br>
<em>&gt;someone who's a realist about matter but worries about the problem of
</em><br>
<em>&gt;other minds; you really MUST claim to have dealt with it if you have
</em><br>
<em>&gt;a scientific theory of consciousness.  You should be able to say:
</em><br>
<em>&gt;&quot;Look Clark, you can measure my phantom median eye, so you know that I
</em><br>
<em>&gt;MUST be conscious.&quot;  Or whatever.
</em><br>
<p><em>&gt;But you offer nothing like that.  That's why you're offering a black box.
</em><br>
<p>Experimental evidence can only observe behaviour .... would that be
<br>
acceptable to you? If so, MVT has it in abundance. However, if as
<br>
I suspect you are not happy with circumstantial evidence (correlation
<br>
between
<br>
REM and dream mentation, even in humans, cannot be absolutely proven
<br>
since it relies on reports of the dreamer) then YOU have a problem, because
<br>
you
<br>
can never accept any account of consciousness, MVT or not.
<br>
<p>Look Clark, you can measure the parietal foramen in a human infant and
<br>
correlate the span of its clore with emerging indicators of self-awareness
<br>
(tests involving self-recognition mirrors), and you can measure the degree
<br>
of atrophy of the pineal eye across species (most atrophied in primates
<br>
where pineal gland is much more deep in the brain because of the subsequent
<br>
development of the cortex). But what I, or nobody, can prove is that
<br>
behaviour +
<br>
correlating brain activity shows their MUST be consciousness. This is a
<br>
problem
<br>
with your MUST (100% certainty) criteria, and not with MVT.
<br>
<p>No-one has come up with a better idea than MVT, which explains both
<br>
walking and sleeping consciousness (24/7). Your Turing machine idea
<br>
doesn't even reach first base, it only models intelligence.
<br>
<p>Perhaps I should develop new and irresistible hypnotic applications
<br>
from MVT and enforce belief in it ... would this satisfy you?
<br>
<p>Level Up
<br>
www.steve-nichols.com
<br>
The Physician of Souls
<br>
Posthuman Organisation
<br>
<p><em>&gt; Then (whether you believe that I exist independently, or am just
</em><br>
<em>&gt; another facet of *your* consciousness - the solipsistic claim) by
</em><br>
<em>&gt; accepting that at least your dreams exist, you allow a conscious
</em><br>
<em>&gt; phenomenon, and defeat your previous claim that consciousness
</em><br>
<em>&gt; doesn't occur.
</em><br>
<p>I *know* he didn't say that.  He knows that HE'S conscious, but he's
<br>
worried about YOU (and everyone else).
<br>
<p><em>&gt; Do you still deny &quot;consciousness&quot;? I argue the idealist stance that in
</em><br>
<em>&gt; fact the world can be said to exist in consciousness, and not that
</em><br>
<em>&gt; consciousness (phantom pineal eye) is located in space.
</em><br>
<p>Idealism is good and well.  (Not my bag, but, hey.)  But the question
<br>
you STILL need to ask yourself, even as an idealist, is: are those
<br>
other people in the world conscious?  It doesn't matter whether the
<br>
world is in consciousness or not to answer this question; the answer
<br>
could turn out to be &quot;yes&quot; or &quot;no&quot; whether or not we accept idealism.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4238.html">Ziana Astralos: "Re: Yahoo Technical Support for DEFINE.COM"</a>
<li><strong>Previous message:</strong> <a href="4236.html">Barbara Lamar: "another Texas clone"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4261.html">Dan Fabulich: "Re: Sentience"</a>
<li><strong>Reply:</strong> <a href="4261.html">Dan Fabulich: "Re: Sentience"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4237">[ date ]</a>
<a href="index.html#4237">[ thread ]</a>
<a href="subject.html#4237">[ subject ]</a>
<a href="author.html#4237">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:37 MDT</em>
</em>
</small>
</body>
</html>
