<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Eugene's nuclear threat</title>
<meta name="Author" content="Eugene Leitl (eugene.leitl@lrz.uni-muenchen.de)">
<meta name="Subject" content="Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Eugene's nuclear threat</h1>
<!-- received="Mon Oct  2 06:18:16 2000" -->
<!-- isoreceived="20001002121816" -->
<!-- sent="Mon, 2 Oct 2000 04:14:32 -0700 (PDT)" -->
<!-- isosent="20001002111432" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene.leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Eugene's nuclear threat" -->
<!-- id="14808.28184.390840.207289@lrz.uni-muenchen.de" -->
<!-- inreplyto="39D79736.DC872890@objectent.com" -->
<strong>From:</strong> Eugene Leitl (<a href="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;14808.28184.390840.207289@lrz.uni-muenchen.de&gt;"><em>eugene.leitl@lrz.uni-muenchen.de</em></a>)<br>
<strong>Date:</strong> Mon Oct 02 2000 - 05:14:32 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0078.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0076.html">KPJ: "Re: Why would AI want to be friendly?"</a>
<li><strong>In reply to:</strong> <a href="0025.html">Samantha Atkins: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0088.html">Brian Atkins: "Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0088.html">Brian Atkins: "Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0136.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0367.html">Samantha Atkins: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#77">[ date ]</a>
<a href="index.html#77">[ thread ]</a>
<a href="subject.html#77">[ subject ]</a>
<a href="author.html#77">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Samantha Atkins writes:
<br>
<p><em> &gt; Wrong.  The entire attitude is based so much on nothing but fear rather
</em><br>
<em> &gt; than finding a positive approach to guide what is going to develop in
</em><br>
<em> &gt; any case that this very attitude is more poisonous than what you fear. 
</em><br>
<p>What can be possibly more poisonous than the end of the world as we
<br>
know it(tm) and death of all or most human beings?
<br>
<p><em> &gt; You (and whoever else you can persuade to such a view) stand to one side
</em><br>
<em> &gt; and act as if you can do the impossible.  You act as if you can grade
</em><br>
<em> &gt; utterly what is safe and non-safe and keep the world safe by destroying
</em><br>
<p>Of course not, and I hope I don't make too many mistakes on the wrong
<br>
side.
<br>
<p><em> &gt; all of what you see as non-safe.  Yet you yourself have argued this does
</em><br>
<em> &gt; not work. 
</em><br>
&nbsp;
<br>
Relinquishment doesn't work sustainably, true. However, I don't
<br>
propose 1) relinquishment 2) sustainably, just culling of the most
<br>
dangerous branches using muscle (the old legislative/executive thing),
<br>
for a limited period of time while we're passing the bottleneck of
<br>
vulnerability.
<br>
<p><em> &gt; Those dead researchers were also a large part of the hope of humanity
</em><br>
<em> &gt; transcending this mudball.  Thank you very much.
</em><br>
<p>I want to achieve transcension by not dying, thankyouverymuch. A
<br>
sterilized mudball, or mudball turned into supermachinery, stripping
<br>
people in the process, that's not exactly my idea of progress.
<br>
<p><em> &gt; That is a little more immediate and more directly aimed at destruction. 
</em><br>
<p>Duh. Do you think I'm a monster?
<br>
<p><em> &gt; I would suggest though that growing a positive future scenario that
</em><br>
<em> &gt; gives bright babies something better to use their brains for than
</em><br>
<em> &gt; figuring out how to exercise their own particular fears is probably the
</em><br>
<em> &gt; most fruitful way to avoid or at least minimize such situations.  
</em><br>
&nbsp;
<br>
Sure, but no matter what you do, a few of the bright babies wound up
<br>
pathological individuals (blame evolution), and would put their
<br>
brightness to destroy themselves and us in the process.
<br>
<p>To show you all how truly evil I am, I propose for an early screening
<br>
program, identifying such people (thankfully, brilliant sickos are
<br>
quite rare), and locking them up where they can't hurt themselves and
<br>
others.
<br>
<p><em> &gt; It is not too hard to think up a variety of ways to destroy and fuck up
</em><br>
<em> &gt; on a massive scale.  It is much harder to create and especially hard to
</em><br>
<p>There aren't that many self-constructed scenarious which end us
<br>
sustainably, at least with our current state of knowledge. A large
<br>
asteroid sneaking up, or a GRB in our neck of the woods would do, but
<br>
they're not man-made.
<br>
<p><em> &gt; create an ovearching vision that our science and technology is used to
</em><br>
<em> &gt; bring into reality and that can get buy-in from more than just us nerds.
</em><br>
&nbsp;
<br>
Sounds like a good plan. But people don't buy into delayed
<br>
gratification, so it has to work in small increments.
<br>
<p><em> &gt; The best way to be reasonably sure that we won't create our own
</em><br>
<em> &gt; destroyer is for humanity to become the Power instead of trying to
</em><br>
<em> &gt; create something separate from them.  Create SI as part of our own being
</em><br>
<p>Sure, I'm all for it. Notice that the positive self-enhancement
<br>
autofeedback loop is still present. But in this case we start with a
<br>
human, so here we can assume conservation of compassion at least for
<br>
the few steps of the self-enhancement process, which will hopefully be 
<br>
also somewhat less fulminant.
<br>
<p><em> &gt; and growing edge.  Learn to care for and evolve the entire body instead
</em><br>
<em> &gt; of just certain parts of the head.  Then we will have our best chance.
</em><br>
&nbsp;
<br>
Since when did we wound up to be disembodied brains floating in the vats?
<br>
<p><em> &gt; I think that all of us together are as smart as we get and that we need
</em><br>
<em> &gt; to learn to work together really well if we are to make a difference.
</em><br>
&nbsp;
<br>
Our firmware is not made to cooperate in large groups, and deal with
<br>
extreme threats. We're not smart and rational enough for that. If
<br>
there ever was a use for human germline engineering, it's to boost our 
<br>
EQ and IQ. 
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0078.html">Eugene Leitl: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0076.html">KPJ: "Re: Why would AI want to be friendly?"</a>
<li><strong>In reply to:</strong> <a href="0025.html">Samantha Atkins: "Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0088.html">Brian Atkins: "Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0088.html">Brian Atkins: "Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0136.html">J. R. Molloy: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0367.html">Samantha Atkins: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#77">[ date ]</a>
<a href="index.html#77">[ thread ]</a>
<a href="subject.html#77">[ subject ]</a>
<a href="author.html#77">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
