<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: `friendly AI' research (was: Re: JOIN THE EXI)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: `friendly AI' research (was: Re: JOIN THE EXI)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: `friendly AI' research (was: Re: JOIN THE EXI)</h1>
<!-- received="Tue Oct 24 23:15:21 2000" -->
<!-- isoreceived="20001025051521" -->
<!-- sent="Wed, 25 Oct 2000 01:17:32 -0400" -->
<!-- isosent="20001025051732" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: `friendly AI' research (was: Re: JOIN THE EXI)" -->
<!-- id="39F66CEC.41E8878D@pobox.com" -->
<!-- inreplyto="39F65E15.2E26406E@posthuman.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20`friendly%20AI'%20research%20(was:%20Re:%20JOIN%20THE%20EXI)&In-Reply-To=&lt;39F66CEC.41E8878D@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 24 2000 - 23:17:32 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1551.html">Michael S. Lorrey: "Re: Fermi Paradox in the news"</a>
<li><strong>Previous message:</strong> <a href="1549.html">Brian Atkins: "Re: Congratulations to Brian and Sabine Atkins!"</a>
<li><strong>In reply to:</strong> <a href="1548.html">Brian Atkins: "Re: `friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1552.html">Damien Broderick: "Re: `friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1550">[ date ]</a>
<a href="index.html#1550">[ thread ]</a>
<a href="subject.html#1550">[ subject ]</a>
<a href="author.html#1550">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Brian Atkins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Hmm well you've obviously got Eliezer thinking about such stuff, that's
</em><br>
<em>&gt; one. He is working on Ben Goertzel of webmind.com, so hopefully he will
</em><br>
<em>&gt; start thinking about this more. And you definitely have people like Minsky
</em><br>
<em>&gt; thinking about these issues since he was there at the recent foresight senior
</em><br>
<em>&gt; associates gathering, and attended Eliezer's talk on friendly AI.
</em><br>
<p>Minsky may be thinking about these issues, but he hasn't gotten very far. 
<br>
Still at the subgoal-stomping-on-a-supergoal stage - his phrase went something
<br>
along the line of &quot;If you ask the AI to solve the Goldbach Conjecture, it
<br>
might wipe us all out to prevent us from interfering with its solution of the
<br>
Goldbach Conjecture.&quot;  If he picked up anything at all from my talk, it didn't
<br>
show, and he doesn't appear to be interested in discussing the matter with
<br>
anyone.  I've written him off unless something new pops up.
<br>
<p>Ben Goertzel has read _Coding a Transhuman AI 2.2_ and we've traded comments
<br>
on Friendly AI on the SL4 mailing list, but we're delaying a more complex
<br>
discussion until I can read the newly released docs on Webmind's design and he
<br>
can read the not-yet-published &quot;Friendly AI&quot; section of CaTAI.  I will say
<br>
that Ben Goertzel currently seems to be thinking in terms of a transhuman
<br>
Friendly AI that increases in intelligence slowly and still operates within
<br>
the context of a human economy.  I hope to either persuade Goertzel that the
<br>
very-rapid-transcendence scenario is more likely, or get Goertzel to agree
<br>
that it makes sense to overdesign for that scenario.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1551.html">Michael S. Lorrey: "Re: Fermi Paradox in the news"</a>
<li><strong>Previous message:</strong> <a href="1549.html">Brian Atkins: "Re: Congratulations to Brian and Sabine Atkins!"</a>
<li><strong>In reply to:</strong> <a href="1548.html">Brian Atkins: "Re: `friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1552.html">Damien Broderick: "Re: `friendly AI' research (was: Re: JOIN THE EXI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1550">[ date ]</a>
<a href="index.html#1550">[ thread ]</a>
<a href="subject.html#1550">[ subject ]</a>
<a href="author.html#1550">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:18 MDT</em>
</em>
</small>
</body>
</html>
