<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: transitional thinking</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: transitional thinking">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: transitional thinking</h1>
<!-- received="Thu Dec 14 01:16:55 2000" -->
<!-- isoreceived="20001214081655" -->
<!-- sent="Thu, 14 Dec 2000 00:16:21 -0800" -->
<!-- isosent="20001214081621" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: transitional thinking" -->
<!-- id="3A3881D5.28ED8EBD@objectent.com" -->
<!-- inreplyto="F1733Sv0YKpDS7hx27k0000e29c@hotmail.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20transitional%20thinking&In-Reply-To=&lt;3A3881D5.28ED8EBD@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 14 2000 - 01:16:21 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4002.html">Samantha Atkins: "Re: what an old &quot;c&quot;"</a>
<li><strong>Previous message:</strong> <a href="4000.html">Dan Fabulich: "Re: Stalker Tricks was: Reason +/- Faith"</a>
<li><strong>In reply to:</strong> <a href="3989.html">Justin Corwin: "Re: transitional thinking"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4001">[ date ]</a>
<a href="index.html#4001">[ thread ]</a>
<a href="subject.html#4001">[ subject ]</a>
<a href="author.html#4001">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Justin Corwin wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; JR sez:
</em><br>
<em>&gt; &gt;Good question. Also, how do we keep the idea of a transcendent
</em><br>
<em>&gt; &gt;machine from becoming a religious meme?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; i would argue, no offense intended at all towards the singularity folks,
</em><br>
<em>&gt; that it already is a religious meme. singularity is supposed to solve every
</em><br>
<em>&gt; problem since the time you burnt your toast to cats and dogs living together
</em><br>
<em>&gt; in harmony, which smacks of faith to me.
</em><br>
<p>Improving things, even broadly, &quot;smacks of faith&quot;?  How so?  Technology
<br>
in general and human freedom have improved things on this earth beyond
<br>
many of the dreams of even the most hopeful pious folks.  Does this mean
<br>
that science/technology and human freedom are religious memes?
<br>
<p>Now, that said, there is an element of &quot;we will fix everything and make
<br>
everything perfect&quot; in some of our thinking some of the time.  That is
<br>
probably unrealistic.  We will be able to do an almost (not almost,
<br>
actual) unimaginable amount of things good and ill but I think expecting
<br>
utopia is going too far.  I expect things to get a lot more interesting
<br>
and a lot less limited in a variety of ways and a lot more joyous but I
<br>
also expect there will still be a whole slew of ills and stupidities
<br>
still present.  
<br>
<p>On the other hand, I have nothing against religious memes judiciously
<br>
applied with a good helping of common sense and plenty of real-world
<br>
science.  It may be that such a mix is precisely what is required to
<br>
move enough of humanity quickly enough to make the singularity not only
<br>
real sooner but far less cataclysmic than it may otherwise be.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; not that i think greater than human intelligence wont' solve problems we
</em><br>
<em>&gt; can't on our own, but perhaps the singularity will not be the incredible
</em><br>
<em>&gt; force you're expecting. what if self modifying humans with their patterned
</em><br>
<em>&gt; parallel processors are never overtaken by machine intelligences? it's just
</em><br>
<em>&gt; as likely as a human who is self modifying has less far to go to become more
</em><br>
<em>&gt; intelligent than a human, all he would have to do is become ANY smarter. a
</em><br>
<em>&gt; machine intelligence doesn't exist yet. going from 60 to 61 is easier than 0
</em><br>
<em>&gt; to 61, even with our design flaws.
</em><br>
<em>&gt; just a theory.
</em><br>
<p>Not sure I see where you're going sith that in context.  Humans will
<br>
eventually become quite different than human as we think of it today. 
<br>
At least the ones with enough flexibility will.  I am more than a little
<br>
worried about our raw intelligence, strength and durability increasing
<br>
drastically without us changing some of our less desirable and largely
<br>
inherited from our merely-meat-days traits.  Some of those are far less
<br>
appropriate and are downright dangerous for post-humans.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; i do however, believe that expert systems and ultratech/ultrasoftware will
</em><br>
<em>&gt; play a role in improving us, as we're unlikely just to do it through
</em><br>
<em>&gt; biological manipulation(gene therapy, bioware, etc). although you could just
</em><br>
<em>&gt; add a bunch of grey matter and see what happened.
</em><br>
<em>&gt;
</em><br>
<p>Not much of anything if you don't add a lot of other stuff to support,
<br>
organize and integrate that additional grey matter.
<br>
&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt; the bottom line is that trancendant AI is cool, and massively
</em><br>
<em>&gt; useful(theoretically). but it's also not here. so we need to be careful
</em><br>
<em>&gt; where we put our trust(faith?). as long as we're not sitting on our butts
</em><br>
<em>&gt; waiting for momma AI to come and fix our problems, the religious nature of
</em><br>
<em>&gt; &quot;awaiting the singularity&quot; won't be an issue.
</em><br>
<em>&gt; 
</em><br>
<p>Faith?  Working our butts off to produce the future doesn't leave a lot
<br>
of time for faith except maybe the kind that is simply belief that what
<br>
one is doing is really important and for the good of everyone (more or
<br>
less) if it can be produced.  
<br>
<p><em>&gt; my big question, is, when the singularity does occur, how do we keep people
</em><br>
<em>&gt; from treating it like a GOD, or a Demon. no matter how logical and well
</em><br>
<em>&gt; constructed it is, being treated like a god would hamper both it's
</em><br>
<em>&gt; situation, it's flexibility, and it's psychology(assuming a general
</em><br>
<em>&gt; intelligence would have a similar psychology to other general intelligences,
</em><br>
<em>&gt; such as humans, being given absolute worship and power has a tendency to
</em><br>
<em>&gt; mess with your head and hamper your effectiveness)
</em><br>
<p><p>The singularity is not a thing per se, much less a candidate for God or
<br>
Devil.   An SI might be seen to be.  Humans really aren't that general
<br>
an intelligent compared to an SI.  We are highly specialized and quite
<br>
inefficient and getting beyond our specialities except by building other
<br>
systems to do what we can't.  We have very little idea what a true AI
<br>
psychology will be like.  But I doubt seriously that the AI would bask
<br>
in the worship of masses of humans.  What for?  It might accidentally
<br>
come to believe it is infallible or that it can find an answer to any
<br>
question it can formulate.  It is possible that it would go down a
<br>
worrisome path of considering humans a collosal bore and bother at best. 
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4002.html">Samantha Atkins: "Re: what an old &quot;c&quot;"</a>
<li><strong>Previous message:</strong> <a href="4000.html">Dan Fabulich: "Re: Stalker Tricks was: Reason +/- Faith"</a>
<li><strong>In reply to:</strong> <a href="3989.html">Justin Corwin: "Re: transitional thinking"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4001">[ date ]</a>
<a href="index.html#4001">[ thread ]</a>
<a href="subject.html#4001">[ subject ]</a>
<a href="author.html#4001">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:36 MDT</em>
</em>
</small>
</body>
</html>
