<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Why would AI want to be friendly?</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Why would AI want to be friendly?">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Why would AI want to be friendly?</h1>
<!-- received="Fri Oct  6 18:52:52 2000" -->
<!-- isoreceived="20001007005252" -->
<!-- sent="Fri, 6 Oct 2000 17:53:35 -0700" -->
<!-- isosent="20001007005335" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Why would AI want to be friendly?" -->
<!-- id="01f101c02ff9$11363020$abbc473f@jrmolloy" -->
<!-- inreplyto="14804.30480.354543.180747@lrz.uni-muenchen.de" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Why%20would%20AI%20want%20to%20be%20friendly?&In-Reply-To=&lt;01f101c02ff9$11363020$abbc473f@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Fri Oct 06 2000 - 18:53:35 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0511.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0509.html">J. R. Molloy: "Re: Some thoughts on Politics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0511.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#510">[ date ]</a>
<a href="index.html#510">[ thread ]</a>
<a href="subject.html#510">[ subject ]</a>
<a href="author.html#510">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
[Just cleaning up unread messages]
<br>
Eugene Leitl has written,
<br>
<p><em>&gt; J. R. Molloy writes:
</em><br>
<em>&gt;
</em><br>
<em>&gt;  &gt; That's because you are an intelligent entity. The AI, in contrast, must
</em><br>
conform
<br>
<em>&gt;  &gt; to the program that coders give it. &lt;grrrin&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Such as the atoms in your body must conform to the natural laws
</em><br>
<em>&gt; governing their behaviour. Or as the neurons in a biologically
</em><br>
<em>&gt; realistic (such as lobster gastric ganglion) simulation produce their
</em><br>
<em>&gt; spikes according to the program codifying their behaviour. Or as an
</em><br>
<em>&gt; NP-complete problem of a nontrivial size is being solved by a computer
</em><br>
<em>&gt; program.
</em><br>
<p>No, as the AI must conform to the program that coders give it.
<br>
<p><em>&gt; These are all true statements, but they're also rather irrelevant,
</em><br>
<em>&gt; because they do not impose any noticeable constraints on system
</em><br>
<em>&gt; state. In all these cases, you can't prove that system A in state B
</em><br>
<em>&gt; reaches state C after N steps, without traversing every single state
</em><br>
<em>&gt; leading from B to C.
</em><br>
<p>These are all true statements, and they're also irrelevant.
<br>
<p><em>&gt; Because behaviour is phenotype of above state changes over time, the
</em><br>
<em>&gt; problem of predicting behaviour with absolute certainty is impossible
</em><br>
<em>&gt; for a class of observers less than omniscient. All assuming, of
</em><br>
<em>&gt; course, that you can cleanly classify all behaviour into &quot;desireable&quot;
</em><br>
<em>&gt; and &quot;undesireable&quot; bins.
</em><br>
<p>Right. So even if an AI becomes &quot;unfriendly&quot; that doesn't necessarily make it
<br>
&quot;undesirable.&quot;
<br>
<p>--J. R.
<br>
<p><p><p><p>&quot;Lord, grant me the serenity to accept the things I cannot change,
<br>
the courage to change the things I can, and the wisdom to hide the bodies
<br>
of the people I had to kill because they pissed me off.&quot;
<br>
--U. Biquitous
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0511.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0509.html">J. R. Molloy: "Re: Some thoughts on Politics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0511.html">J. R. Molloy: "Re: Why would AI want to be friendly?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#510">[ date ]</a>
<a href="index.html#510">[ thread ]</a>
<a href="subject.html#510">[ subject ]</a>
<a href="author.html#510">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:15 MDT</em>
</em>
</small>
</body>
</html>
