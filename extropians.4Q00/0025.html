<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Eugene's nuclear threat</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Eugene's nuclear threat</h1>
<!-- received="Sun Oct  1 13:55:57 2000" -->
<!-- isoreceived="20001001195557" -->
<!-- sent="Sun, 01 Oct 2000 12:57:42 -0700" -->
<!-- isosent="20001001195742" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Eugene's nuclear threat" -->
<!-- id="39D79736.DC872890@objectent.com" -->
<!-- inreplyto="14807.7292.928179.472937@lrz.uni-muenchen.de" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D79736.DC872890@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Oct 01 2000 - 13:57:42 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0026.html">Barbara Lamar: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0024.html">Spudboy100@aol.com: "Re: FreakyLinks"</a>
<li><strong>In reply to:</strong> <a href="0004.html">Eugene Leitl: "Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#25">[ date ]</a>
<a href="index.html#25">[ thread ]</a>
<a href="subject.html#25">[ subject ]</a>
<a href="author.html#25">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eugene Leitl wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Eliezer S. Yudkowsky writes:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; Are you so very, very sure that you know better than the people running the
</em><br>
<em>&gt;  &gt; facilities?  If the people with enough understanding and experience to have
</em><br>
<em>&gt; 
</em><br>
<em>&gt; No.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But if I make a mistake, we've got a bunch of dead researchers who
</em><br>
<em>&gt; wouldn't listen. If they make a mistake, we've got millions of
</em><br>
<em>&gt; lightyears of planets full of dead people. (Aliens are also people, of
</em><br>
<em>&gt; course). Dunno, these odds sound good to me.
</em><br>
<em>&gt; 
</em><br>
<p>Wrong.  The entire attitude is based so much on nothing but fear rather
<br>
than finding a positive approach to guide what is going to develop in
<br>
any case that this very attitude is more poisonous than what you fear. 
<br>
You (and whoever else you can persuade to such a view) stand to one side
<br>
and act as if you can do the impossible.  You act as if you can grade
<br>
utterly what is safe and non-safe and keep the world safe by destroying
<br>
all of what you see as non-safe.  Yet you yourself have argued this does
<br>
not work. 
<br>
<p>Those dead researchers were also a large part of the hope of humanity
<br>
transcending this mudball.  Thank you very much.
<br>
<p><p><em>&gt; On a less galactic scale, there is this crazy molecular biologist down
</em><br>
<em>&gt; the street, who subscribes to the &quot;Green Planet, Death to the People&quot;
</em><br>
<em>&gt; church. (Man, these people are sure not Friendly). Funded by fellow
</em><br>
<em>&gt; billionaire church members, he has managed to engineer a
</em><br>
<em>&gt; long-symptomless-latency high-infectivity high-delayed-mortality
</em><br>
<em>&gt; bioweapon, consisting from a dozen of diverse virus families. You know
</em><br>
<em>&gt; he has made successful tests on primates and people (bums snatched off
</em><br>
<em>&gt; the street), and intends to start releasing the stuff in all major
</em><br>
<em>&gt; airports and subways as well in stratospheric bursts (properly
</em><br>
<em>&gt; packaged). All numerical epidemic models they've ran predict &gt;99%
</em><br>
<em>&gt; infection and &gt;95% mortality rate. In other words, the threat is
</em><br>
<em>&gt; rather believable. Because they're rather paranoid, they've got a
</em><br>
<em>&gt; device to reliably (they're very good engineers) self-destruct the
</em><br>
<em>&gt; entire facility, triggerable from a room you just managed to
</em><br>
<em>&gt; penetrate. (Well, I've seen an old James Bond movie yesterday).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Would you press the big red button, instantly killing all people on
</em><br>
<em>&gt; property and safely destroying all virus cultures and information on
</em><br>
<em>&gt; how make them?
</em><br>
<em>&gt; 
</em><br>
<p>That is a little more immediate and more directly aimed at destruction. 
<br>
I would suggest though that growing a positive future scenario that
<br>
gives bright babies something better to use their brains for than
<br>
figuring out how to exercise their own particular fears is probably the
<br>
most fruitful way to avoid or at least minimize such situations.  
<br>
<p>It is not too hard to think up a variety of ways to destroy and fuck up
<br>
on a massive scale.  It is much harder to create and especially hard to
<br>
create an ovearching vision that our science and technology is used to
<br>
bring into reality and that can get buy-in from more than just us nerds.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; I'm just smart enough to know no one can be that smart to predict what
</em><br>
<em>&gt; a superhuman Power is going to do. At the same time, Turing, Goedel &amp;
</em><br>
<em>&gt; footnotes to them say you can't, and game theory and evolution theory
</em><br>
<em>&gt; say it won't be a smart thing to try, since offering some constraints
</em><br>
<em>&gt; on behaviour of Powers, which don't look too pretty if you happen to
</em><br>
<em>&gt; be at the human receiving end of it.
</em><br>
<em>&gt;
</em><br>
<p>The best way to be reasonably sure that we won't create our own
<br>
destroyer is for humanity to become the Power instead of trying to
<br>
create something separate from them.  Create SI as part of our own being
<br>
and growing edge.  Learn to care for and evolve the entire body instead
<br>
of just certain parts of the head.  Then we will have our best chance.
<br>
<p>&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt; Thankfully, you will never have authority over enough resources for a
</em><br>
<em>&gt; SI project likely to succeed, but even so, just saying those words can
</em><br>
<em>&gt; make life less pleasant for all of us. You should know better.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Seriously, who's playing the architect of humankind's future destiny
</em><br>
<em>&gt; here? You think you're smart enough for that?
</em><br>
<em>&gt;
</em><br>
<p>I think that all of us together are as smart as we get and that we need
<br>
to learn to work together really well if we are to make a difference.
<br>
<p>&nbsp;
<br>
<em>&gt; Instead of trying to persuade people to pull over into a high enough
</em><br>
<em>&gt; fitness regime by dangling enough of juicy carrots in front of their
</em><br>
<em>&gt; noses before embarking on a project to end all projects, or ending up
</em><br>
<em>&gt; there spontaneously, you say &quot;people no good, I'm also only human, but
</em><br>
<em>&gt; I know what is good for the rest of them, so I'll just go ahead, and
</em><br>
<em>&gt; will do it, the faster, the better&quot;. That sounds smart, for sure.
</em><br>
<em>&gt;
</em><br>
<p>This is a good point.  
<br>
&nbsp;
<br>
- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0026.html">Barbara Lamar: "Re: Why would AI want to be friendly?"</a>
<li><strong>Previous message:</strong> <a href="0024.html">Spudboy100@aol.com: "Re: FreakyLinks"</a>
<li><strong>In reply to:</strong> <a href="0004.html">Eugene Leitl: "Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0077.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#25">[ date ]</a>
<a href="index.html#25">[ thread ]</a>
<a href="subject.html#25">[ subject ]</a>
<a href="author.html#25">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
