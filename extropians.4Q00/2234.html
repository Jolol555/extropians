<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>extropians: MIT Dreams</title>
<meta name="Author" content="Spudboy100@aol.com (Spudboy100@aol.com)">
<meta name="Subject" content="MIT Dreams">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>MIT Dreams</h1>
<!-- received="Sat Nov 11 20:40:41 2000" -->
<!-- isoreceived="20001112034041" -->
<!-- sent="Sat, 11 Nov 2000 22:40:45 EST" -->
<!-- isosent="20001112034045" -->
<!-- name="Spudboy100@aol.com" -->
<!-- email="Spudboy100@aol.com" -->
<!-- subject="MIT Dreams" -->
<!-- id="2f.cc18d37.273f6b3d@aol.com" -->
<!-- charset="UTF-8" -->
<strong>From:</strong> <a href="mailto:Spudboy100@aol.com?Subject=Re:%20MIT%20Dreams&In-Reply-To=&lt;2f.cc18d37.273f6b3d@aol.com&gt;"><em>Spudboy100@aol.com</em></a><br>
<strong>Date:</strong> Sat Nov 11 2000 - 20:40:45 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<li><strong>Previous message:</strong> <a href="2233.html">CurtAdams@aol.com: "Re: Buchanan Palm Beach Statistics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<li><strong>Reply:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2234">[ date ]</a>
<a href="index.html#2234">[ thread ]</a>
<a href="subject.html#2234">[ subject ]</a>
<a href="author.html#2234">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="http://www.nytimes.com/2000/11/07/science/07FOER.html">http://www.nytimes.com/2000/11/07/science/07FOER.html</a>
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt;&gt; A CONVERSATION WITH / Anne Foerst
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Do Androids Dream? M.I.T. Is Working on It
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; &lt;By CLAUDIA DREIFUS&lt;&gt;&gt; 
</em><br>
<em>&gt;&gt; Rick Friedman for The New York Times 
</em><br>
<em>&gt;&gt; Dr. Anne Foerst outside her office at the Artificial Intelligence 
</em><br>
<em>&gt;&gt; Laboratory. 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Related Articles
</em><br>
<em>&gt;&gt; &lt;• &lt;A HREF=&quot;<a href="http://www.nytimes.com/library/tech/00/08/biztech/articles/31robot.html">http://www.nytimes.com/library/tech/00/08/biztech/articles/31robot.html</a>&quot;&gt;&lt;Aping Biology, Computer Guides Automated Evolution of a Robot &lt;/A&gt;(Aug. 31, 
</em><br>
<em>&gt;&gt; 2000)
</em><br>
<em>&gt;&gt; &lt;• &lt;A HREF=&quot;<a href="http://www.nytimes.com/library/tech/00/06/circuits/articles/22next.html">http://www.nytimes.com/library/tech/00/06/circuits/articles/22next.html</a>&quot;&gt;&lt;Trying to Give Bomb Squad Robots Brains to Match Their Brawn &lt;/A&gt;(June 22, 
</em><br>
<em>&gt;&gt; 2000)
</em><br>
<em>&gt;&gt; &lt;• &lt;A HREF=&quot;<a href="http://www.nytimes.com/library/tech/00/06/circuits/articles/15fish.html">http://www.nytimes.com/library/tech/00/06/circuits/articles/15fish.html</a>&quot;&gt;&lt;Team Links Brain Cells With a Robot&lt;/A&gt; (June 15, 2000)
</em><br>
<em>&gt;&gt; &lt;• &lt;A HREF=&quot;<a href="http://www.nytimes.com/library/tech/00/03/circuits/articles/09next.html">http://www.nytimes.com/library/tech/00/03/circuits/articles/09next.html</a>&quot;&gt;&lt;Shape-Shifting Robots From Xerox&lt;/A&gt; (March 9, 2000)
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; &lt;&gt; 
</em><br>
<em>&gt;&gt; Rick Friedman for The New York Times 
</em><br>
<em>&gt;&gt; &quot;Cute&quot; robots with social skills, like Kismet, are in favor at the M.I.T. 
</em><br>
<em>&gt;&gt; lab. 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; &lt;&gt;AMBRIDGE, Mass. — Dr. Anne Foerst, 34, a researcher at the Artificial 
</em><br>
<em>&gt;&gt; Intelligence Laboratory at the Massachusetts Institute of Technology and 
</em><br>
<em>&gt;&gt; the director of M.I.T.'s God and Computers project, apologized on a recent 
</em><br>
<em>&gt;&gt; afternoon that a certain robot named Kismet wouldn't be joining our 
</em><br>
<em>&gt;&gt; interview.
</em><br>
<em>&gt;&gt; &quot;Cynthia Breazeal, who built Kismet, is away in Japan right now and 
</em><br>
<em>&gt;&gt; there's no getting her going,&quot; Dr. Foerst said in her German accent, &quot;but 
</em><br>
<em>&gt;&gt; you'd love her. She's oh so cute.&quot; A cute robot? Well, yes. At the 
</em><br>
<em>&gt;&gt; Artificial Intelligence Laboratory, engineers are trying to build robots 
</em><br>
<em>&gt;&gt; with social skills and humanlike experiences, and so, as an experiment, 
</em><br>
<em>&gt;&gt; they've created creatures that they think humans will relate to.
</em><br>
<em>&gt;&gt; Dr. Foerst, a Lutheran minister who supported herself by repairing 
</em><br>
<em>&gt;&gt; computers during eight years of higher education in Germany, serves as 
</em><br>
<em>&gt;&gt; theological adviser to the scientists building Kismet and the robot's 
</em><br>
<em>&gt;&gt; brother, Cog.
</em><br>
<em>&gt;&gt; Q. What exactly do people do here at this laboratory?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. We are trying to build robots that are social and embodied. 
</em><br>
<em>&gt;&gt; We have four projects. I am the theological adviser for two of them: the 
</em><br>
<em>&gt;&gt; building of the humanoid machines, Cog and Kismet.
</em><br>
<em>&gt;&gt; Cog is a robot built in analogy to a human infant. He has a torso, two 
</em><br>
<em>&gt;&gt; arms, a head, ears and eyes. He, it, learns to coordinate those limbs to 
</em><br>
<em>&gt;&gt; explore its environment, just as newborn babies do. Kismet is a robot who 
</em><br>
<em>&gt;&gt; interacts with humans through her body posture and facial expressions. The 
</em><br>
<em>&gt;&gt; aim of this project is to explore social interactions between humans and 
</em><br>
<em>&gt;&gt; robots and also between the humans themselves.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. Why a theologian here in this particular laboratory?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Two reasons. The first is when you build machines in analogy to humans, 
</em><br>
<em>&gt;&gt; you make assumptions about humans. Theologians explore the cultural and 
</em><br>
<em>&gt;&gt; spiritual dimensions of that very question, What does it mean to be human? 
</em><br>
<em>&gt;&gt; The idea is that as these robots are built, we can use the wisdom of 
</em><br>
<em>&gt;&gt; religious studies to enlarge our understanding of humans, and thus what 
</em><br>
<em>&gt;&gt; you build into the humanoid machines.
</em><br>
<em>&gt;&gt; The other reason is that when we build social interactive robots that 
</em><br>
<em>&gt;&gt; force people to treat them as if they were persons, tricky moral questions 
</em><br>
<em>&gt;&gt; come up. For instance, Who are we, really? Are all our reactions actually 
</em><br>
<em>&gt;&gt; developed in a very mechanistic, functionalist way? Or is there a 
</em><br>
<em>&gt;&gt; dimension to social interaction that goes beyond that? What are ethics 
</em><br>
<em>&gt;&gt; here? Why should I treat someone else like a human, with dignity, when it 
</em><br>
<em>&gt;&gt; is just a mechanistic thing?
</em><br>
<em>&gt;&gt; For instance, one question we discuss quite frequently is, What would be 
</em><br>
<em>&gt;&gt; the threshold when the robots are developed to a certain point that you 
</em><br>
<em>&gt;&gt; couldn't switch them off anymore? The question really is, When does a 
</em><br>
<em>&gt;&gt; creature deserve to be treated as intrinsically valuable?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. When do you think a robot should be treated as intrinsically valuable?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Well, that moment is 50 years down the road. At least. But it's pretty 
</em><br>
<em>&gt;&gt; clear that when it comes, those who built the robot will have to make that 
</em><br>
<em>&gt;&gt; decision because they won't be blinded by their fears of the seemingly 
</em><br>
<em>&gt;&gt; human qualities of the machines. They'll know what's inside. And if it 
</em><br>
<em>&gt;&gt; ever got to the point where the builders felt, Oops, now that has become 
</em><br>
<em>&gt;&gt; something, the builders could become the creature's strongest advocates.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. What make the robots Cog and Kismet different from previous ones?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Previous attempts put very abstract features of human intelligence into 
</em><br>
<em>&gt;&gt; a machine: chess playing, mathematical theorem-proving and natural 
</em><br>
<em>&gt;&gt; language processing. The idea now is, In order for a machine to really be 
</em><br>
<em>&gt;&gt; intelligent, it has to be embodied. We say intelligence cannot be 
</em><br>
<em>&gt;&gt; abstracted from the body. We feel that the body — the way it moves, grows, 
</em><br>
<em>&gt;&gt; digests food, gets older, all have an influence on how a person thinks. 
</em><br>
<em>&gt;&gt; That's why we've built Cog and Kismet to have humanoid features.
</em><br>
<em>&gt;&gt; Cog moves and experiences the world the way someone who can walk upright 
</em><br>
<em>&gt;&gt; might. He experiences balance problems, friction problems, weight, 
</em><br>
<em>&gt;&gt; gravity, all the stuff that we do, so that he can have a body feeling that 
</em><br>
<em>&gt;&gt; is similar to ours. The humanoid features are also crafted into the 
</em><br>
<em>&gt;&gt; machines in order to trigger social responses from the people interacting 
</em><br>
<em>&gt;&gt; with them.
</em><br>
<em>&gt;&gt; The other thing we believe is that humans are human because we are social. 
</em><br>
<em>&gt;&gt; Thus, we try to treat Cog and Kismet something like the way most of us 
</em><br>
<em>&gt;&gt; treat babies, as if they have intentionality, emotion, desires and 
</em><br>
<em>&gt;&gt; intelligence. We give them as much social interaction as we can.
</em><br>
<em>&gt;&gt; Cog is a whole body and Kismet is mostly a head and facial expression. Our 
</em><br>
<em>&gt;&gt; work with Cog concentrates more on the embodiment stuff and Kismet more on 
</em><br>
<em>&gt;&gt; emotional-social learning.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. Is the robot Kismet a she?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Robots are its. But I can't help but think of her as a she. If you were 
</em><br>
<em>&gt;&gt; to see Kismet, you would be taken by her enormously expressive face: long 
</em><br>
<em>&gt;&gt; eyelashes, big blue eyes, movable brow, cute, kissy mouth. When Kismet 
</em><br>
<em>&gt;&gt; puts her eyes on you and looks sad, you want to make her happy. Of course, 
</em><br>
<em>&gt;&gt; part of you thinks, It's just a stupid machine. But you do react and you 
</em><br>
<em>&gt;&gt; can't help it.
</em><br>
<em>&gt;&gt; The point of reacting to Kismet is the same as reacting to a baby. We 
</em><br>
<em>&gt;&gt; believe that only when you treat the machines as if they have all these 
</em><br>
<em>&gt;&gt; social characteristics, will they ever get them. If you want to have an 
</em><br>
<em>&gt;&gt; intelligent being, you need to create that circle. So we react here to 
</em><br>
<em>&gt;&gt; Kismet's emotional displays. When she's bored, you want to make her happy. 
</em><br>
<em>&gt;&gt; When she seems scared, you back off.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. Has the very social robot Kismet done anything yet that has astonished 
</em><br>
<em>&gt;&gt; you? 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Kismet has not yet learned. Cog is the one who learns. A former 
</em><br>
<em>&gt;&gt; graduate student, Matt Williamson, the guy who built Cog's arms, taught 
</em><br>
<em>&gt;&gt; the robot how to control his arm.
</em><br>
<em>&gt;&gt; To coordinate the arms, Matt had to touch a part of Cog's body and then, 
</em><br>
<em>&gt;&gt; the arm would touch that part, too. After he did that for the first time, 
</em><br>
<em>&gt;&gt; Matt ran into my office and said, &quot;You've got to come to look at this.&quot; It 
</em><br>
<em>&gt;&gt; looked so eerily human. It's not so much that Cog does something that's 
</em><br>
<em>&gt;&gt; unexpected, it's more the human reaction, like, it's alive!
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. People often talk about humans having some indefinable extra above life 
</em><br>
<em>&gt;&gt; that makes for humanness — some call it &quot;spirit.&quot; Can a robot have spirit? 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Rod calls it &quot;juice.&quot; He says, &quot;Even though I get it all right, might 
</em><br>
<em>&gt;&gt; there not be some juice I'm missing?&quot; I would say from a religious 
</em><br>
<em>&gt;&gt; perspective, the juice is that which comes from the outside world and 
</em><br>
<em>&gt;&gt; emerges in social interaction.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. Some people might complain that in building humanoid robots, you are 
</em><br>
<em>&gt;&gt; trying to supplant God.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Yes. I know. They say, &quot;Do you want to be like God?&quot; Actually, if you 
</em><br>
<em>&gt;&gt; use biology as your inspiration in your robot-building and focus on 
</em><br>
<em>&gt;&gt; embodiment and environment, you get much more humble instead of arrogant. 
</em><br>
<em>&gt;&gt; Suddenly, you realize that even the most brilliant robot that the most 
</em><br>
<em>&gt;&gt; brilliant engineers have worked on for years and years is still dumber 
</em><br>
<em>&gt;&gt; than an insect. 
</em><br>
<em>&gt;&gt; Q. So, in your view, God is, as the Latin Americans say, the &quot;intellectual 
</em><br>
<em>&gt;&gt; author&quot; of everything?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. No. The creative author. When we are creative, the power of creation is 
</em><br>
<em>&gt;&gt; from God. 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. In the many plays, novels and movies about robots, the dramatic climax 
</em><br>
<em>&gt;&gt; of the story always comes at moment when the machine achieves sentience. 
</em><br>
<em>&gt;&gt; Why do you think that is?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. Well, I think it's the search to feel and to be treated like something 
</em><br>
<em>&gt;&gt; more than the sum of the parts that's inherently dramatic. This is the 
</em><br>
<em>&gt;&gt; moment when the robots start to participate in the all-too-human quest of 
</em><br>
<em>&gt;&gt; what does it mean to be me?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. In the movie &quot;2001: A Space Odyssey,&quot; HAL becomes a danger to humans 
</em><br>
<em>&gt;&gt; once he's sentient.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. In &quot;Frankenstein,&quot; too. But in both cases, there is an explanation. 
</em><br>
<em>&gt;&gt; When you look at Frankenstein, he is never part of a community. His 
</em><br>
<em>&gt;&gt; creator left him right away. The people hated him, feared him, ran away 
</em><br>
<em>&gt;&gt; from him. The only person who ever loved him was a blind man who couldn't 
</em><br>
<em>&gt;&gt; see what he looked like. Frankenstein was never treated as a valuable 
</em><br>
<em>&gt;&gt; being, a person with dignity. He had to turn against the society that 
</em><br>
<em>&gt;&gt; shunned him. Where should the goodness come from when he never experienced 
</em><br>
<em>&gt;&gt; it himself?
</em><br>
<em>&gt;&gt; HAL is the same thing. And he's disembodied. There is no body with which 
</em><br>
<em>&gt;&gt; to experience the world. I would even say that in such a setting a robot 
</em><br>
<em>&gt;&gt; couldn't even become sentient. In the movie, HAL becomes sentient at some 
</em><br>
<em>&gt;&gt; point and nobody notices. No one treats him properly and he's isolated and 
</em><br>
<em>&gt;&gt; what happens? He becomes psychotic.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Q. What's your favorite robot movie?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; A. &quot;Blade Runner.&quot; I teach it in my classes. The robots have this absolute 
</em><br>
<em>&gt;&gt; search for meaning, and when their quest is not taken seriously, it 
</em><br>
<em>&gt;&gt; becomes fatal. The movie raises this wonderful question: how do humanoid 
</em><br>
<em>&gt;&gt; creatures feel about having been created by us and how do they deal with 
</em><br>
<em>&gt;&gt; their human-made limitations?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt; 
</em><br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&lt;/HTML&gt;
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<li><strong>Previous message:</strong> <a href="2233.html">CurtAdams@aol.com: "Re: Buchanan Palm Beach Statistics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<li><strong>Reply:</strong> <a href="2235.html">Michael M. Butler: "Re: MIT Dreams"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2234">[ date ]</a>
<a href="index.html#2234">[ thread ]</a>
<a href="subject.html#2234">[ subject ]</a>
<a href="author.html#2234">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:20 MDT</em>
</em>
</small>
</body>
</html>
