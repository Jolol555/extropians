<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Attacks (was Re: Why would AI want to be friend</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Attacks (was Re: Why would AI want to be friendly?)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Attacks (was Re: Why would AI want to be friendly?)</h1>
<!-- received="Sun Oct  1 14:22:19 2000" -->
<!-- isoreceived="20001001202219" -->
<!-- sent="Sun, 01 Oct 2000 13:24:05 -0700" -->
<!-- isosent="20001001202405" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Attacks (was Re: Why would AI want to be friendly?)" -->
<!-- id="39D79D65.9701FCA4@objectent.com" -->
<!-- inreplyto="200010011926.PAA12797@panix5.panix.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Attacks%20(was%20Re:%20Why%20would%20AI%20want%20to%20be%20friendly?)&In-Reply-To=&lt;39D79D65.9701FCA4@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Oct 01 2000 - 14:24:05 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0031.html">Eliezer S. Yudkowsky: "Re: Why wouldn't friendly AI leave fundies in the dust?"</a>
<li><strong>Previous message:</strong> <a href="0029.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<li><strong>In reply to:</strong> <a href="0021.html">James Wetterau: "Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0264.html">Emlyn: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#30">[ date ]</a>
<a href="index.html#30">[ thread ]</a>
<a href="subject.html#30">[ subject ]</a>
<a href="author.html#30">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
James Wetterau wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; J. R. Molloy says:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; ... Uploading criminals and the Amish might be the best way to get rid
</em><br>
<em>&gt; &gt; of them. Make video games out of them. ...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I just want to register my extreme dissent from this idea, and
</em><br>
<em>&gt; whatever motivates it.  I find it revolting to see transhumanist
</em><br>
<em>&gt; concepts discussed as weapons against religious people.
</em><br>
<em>&gt; 
</em><br>
<p><p>If that was what it was then I would also find it revolting.  But I
<br>
think a more interesting set of possibilities might be present.  Today
<br>
we kill or lock away for life those we consider irredeemably criminal. 
<br>
Putting the person instead in a VR with karmic consequence mode turned
<br>
on would a) not involve the irreversible destruction of the individual;
<br>
b) give them a chance to learn and grow without harming other people.
<br>
<p>Other persons who simply cannot abide what 21st century real-world
<br>
brings and who fervently wish to live in a different sort of world can
<br>
only have their heart's desire within a tailored VR.  Again, they get to
<br>
live as they want and experience the consequences of their choices
<br>
without being forced to abandon their heart's desire or limiting the
<br>
freedom of others.  When they change their minds about what they want
<br>
they get to move into whatever that new thing is.
<br>
<p>Looked at this way the VR might be the best choice that preserves the
<br>
most diversity and freedom with the least amount of conflict.  It's a
<br>
thought anyway. 
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0031.html">Eliezer S. Yudkowsky: "Re: Why wouldn't friendly AI leave fundies in the dust?"</a>
<li><strong>Previous message:</strong> <a href="0029.html">Eugene Leitl: "Re: Eugene's nuclear threat"</a>
<li><strong>In reply to:</strong> <a href="0021.html">James Wetterau: "Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0037.html">Eliezer S. Yudkowsky: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<li><strong>Reply:</strong> <a href="0264.html">Emlyn: "Re: Attacks (was Re: Why would AI want to be friendly?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#30">[ date ]</a>
<a href="index.html#30">[ thread ]</a>
<a href="subject.html#30">[ subject ]</a>
<a href="author.html#30">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
