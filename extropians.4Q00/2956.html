<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: [&gt;Htech] The Age on Cyborgology</title>
<meta name="Author" content="Samantha Atkins (samantha@isis.aurinia.com)">
<meta name="Subject" content="Re: [&gt;Htech] The Age on Cyborgology">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: [&gt;Htech] The Age on Cyborgology</h1>
<!-- received="Sun Nov 26 12:45:25 2000" -->
<!-- isoreceived="20001126194525" -->
<!-- sent="Sun, 26 Nov 2000 11:49:08 -0800" -->
<!-- isosent="20001126194908" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@isis.aurinia.com" -->
<!-- subject="Re: [&gt;Htech] The Age on Cyborgology" -->
<!-- id="3A216934.B9CB6043@isis.aurinia.com" -->
<!-- inreplyto="Pine.UW2.4.20.0011210854480.19789-100000@www.aeiveos.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@isis.aurinia.com?Subject=Re:%20[&gt;Htech]%20The%20Age%20on%20Cyborgology&In-Reply-To=&lt;3A216934.B9CB6043@isis.aurinia.com&gt;"><em>samantha@isis.aurinia.com</em></a>)<br>
<strong>Date:</strong> Sun Nov 26 2000 - 12:49:08 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2957.html">J. R. Molloy: "Re: 137: Sheer blank-minded stupidity"</a>
<li><strong>Previous message:</strong> <a href="2955.html">Samantha Atkins: "Re: Two great articles on ignoring government"</a>
<li><strong>In reply to:</strong> <a href="2780.html">Robert J. Bradbury: "Re: [&gt;Htech] The Age on Cyborgology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3962.html">Robert J. Bradbury: "Re: [&gt;Htech] The Age on Cyborgology"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2956">[ date ]</a>
<a href="index.html#2956">[ thread ]</a>
<a href="subject.html#2956">[ subject ]</a>
<a href="author.html#2956">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<p><em>&gt;However as work by de Garis
</em><br>
<em>&gt; and Doug Lenat (@ Cyccorp) have shown, the problem is *not* hardware equivalence.
</em><br>
<em>&gt; Its figuring out good ways of programming the net.  You have to bear in
</em><br>
<em>&gt; mind that it takes 2-6 *years* of full time learning for a human brain
</em><br>
<em>&gt; &quot;net&quot; to program itself so it is interesting to interact with.  Even if you
</em><br>
<em>&gt; had lots of human equivalent desktop machines by 2010, it is a very open
</em><br>
<em>&gt; question at this point how long it would take them to &quot;learn&quot; enough to
</em><br>
<em>&gt; be considered &quot;intelligent&quot;.  
</em><br>
<p>Yes.  Finding and duplicating human learning programs, much less
<br>
radically improving on them for machine use, is likely to take far
<br>
longer than merely matching raw hardware.   Arguably, AIs should not
<br>
think or learn quite like humans have evolved to.  But that does not
<br>
make the problem more tractable. 
<br>
<p><em>&gt; Now, the interesting thing about resident
</em><br>
<em>&gt; computer intelligence is that you can copy it from machine to machine
</em><br>
<em>&gt; much faster than you can propagate it among humans.
</em><br>
<em>&gt; 
</em><br>
<p><p>Maybe, maybe not.  If the intelligence is actually learning in a similar
<br>
way as humans do then the very act of learning consists of integrating
<br>
the new information within the net of information already possessed and
<br>
binding it up with such already present information and mind-state.  It
<br>
is quite possible that information so integrated is no more seperable
<br>
and easily transmitted to another machine than it is from human to
<br>
human.  This would be ironic but not unexpected.  Since the AI operates
<br>
at higher speed it might still learn and teach much faster than we do
<br>
however. 
<br>
<p><em>&gt; The second thing about quantum computing that people MUST remember is
</em><br>
<em>&gt; that I have seen nothing that says it can be used for &quot;general purpose&quot;
</em><br>
<em>&gt; computing.  Charles H. Bennet from IBM Research who is one of the world's
</em><br>
<em>&gt; leading experts on the physics of computation, wrote a paper in 1994
</em><br>
<em>&gt; entitled &quot;Strengths and Weaknesses of Quantum Computing&quot;.  People should
</em><br>
<em>&gt; listen to the *experts* in a field such as leading physicists, not the
</em><br>
<em>&gt; popularizers such as Kurzweil (a programmer), or worse yet newspaper reporters.
</em><br>
<em>&gt; 
</em><br>
<p>I think it can be proved that a general purpose computer (a Turing
<br>
equivalent) can be constructed using quantum computing techniques. But I
<br>
don't have the time or expertise to work it out.
<br>
<p>Don't put down non-experts.  Too many advances have come from them
<br>
including deep theoretical advances.  
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; It requires discipline not to use buzz terms like &quot;quantum computers&quot;
</em><br>
<em>&gt; in an area where they may be inappropriate.
</em><br>
<em>&gt;
</em><br>
<p>Sure.  And it is certainly true that quantum computing is not required
<br>
to produce true AIs.
<br>
&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt; Love, hate &amp; compassion are hard-wired into humans at the genetic,
</em><br>
<em>&gt; neurological and biochemical levels.  I believe the leading candidate
</em><br>
<em>&gt; for the &quot;love&quot; drug currently may be oxytocin but other factors are
</em><br>
<em>&gt; probably involved.  If we &quot;program in&quot; or &quot;select for&quot; traits that
</em><br>
<em>&gt; create human or &quot;mind&quot; like characteristics in our computers, cyborgs
</em><br>
<em>&gt; or robots, the answer is *yes* they will have minds.
</em><br>
<em>&gt;
</em><br>
<p>And that wiring is nothing much more than programs burned into these
<br>
levels.  There is no reason I see that an Artificial Intelligence could
<br>
not run and even auto-generate similar programs.  There are also quite
<br>
logical components to many of the named &quot;human&quot; qualities above that any
<br>
sufficiently intelligent consciousness interacting with others is likely
<br>
to come up with in some form or other.   
<br>
<p><p><em>&gt; &gt;Ray Kurzweil, another eminent American technologist, is more gloomy. He
</em><br>
<em>&gt; &gt;predicts that human identity will be called into question by the massive
</em><br>
<em>&gt; &gt;computers of the future.
</em><br>
<p>Ray Kurzweil is not in the least gloomy.  Closer to the opposite.  
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Human &quot;minds&quot; can evolve and adapt.  Human bodies will become irrelevant
</em><br>
<em>&gt; in the long term.  Because human bodies cannot avoid local hazards
</em><br>
<em>&gt; (earthquakes, floods, hurricanes, etc.) bodies will eventually be
</em><br>
<em>&gt; irreparably damaged.  The interim period, which could well last
</em><br>
<em>&gt; thousands of years depending on how &quot;attached&quot; we remain to our
</em><br>
<em>&gt; bodies, will be one of gradual uploading as human minds expand
</em><br>
<em>&gt; within computer hardware (perhaps not unlike how the developing
</em><br>
<em>&gt; brain of a fetus or young baby expands within its growing head).
</em><br>
<em>&gt;
</em><br>
<p>Notions about the coming irrelevance of human minds are vastly
<br>
premature. What it is to be human will shift and evolve as the machines
<br>
shift and evolve.   
<br>
<p><em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;About 2050 or so, says Mr Kurzweil, the computers, by then capable of
</em><br>
<em>&gt; &gt;reasoning for themselves, could decide we humans are too slow, too
</em><br>
<em>&gt; &gt;ignorant, too petty and too argumentative to be tolerated.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Poppycock again.  If you link the humans to the computers using the
</em><br>
<em>&gt; technologies discussed (neural implants and high bandwidth radio
</em><br>
<em>&gt; or fiber connections), then you can't create such a simple dividing
</em><br>
<em>&gt; line between artificial minds and human minds.
</em><br>
<em>&gt; 
</em><br>
<p>I could see that faster intelligences would at least regard unagumented
<br>
humans as too slow to be competitive or sufficiently capable in some
<br>
areas.  It is already obvious to many of us that humans (as currently
<br>
existing) are quite inefficient and inadequate at some types of tasks
<br>
increasingly required by even current circumstances.  I predict that
<br>
within 10 years no human not highly wired into the computer nets will be
<br>
able to compete in many white collar jobs.
<br>
<p>I also predict that within 10 years of getting
<br>
human-equivalent-processing-power machines that many white collar jobs
<br>
will be off-loaded to specialized machine intelligences.  The economic
<br>
incentives are high.  
<br>
<p><p><em>&gt; &gt;Why would a computer wish to associate with us?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why would a human want a frail human body if it could do away with it?
</em><br>
<em>&gt;
</em><br>
<p>Because this squishy body also has its exceedingly pleasurable aspects
<br>
and because much of our intelligence, our mind-stuff seems strongly
<br>
rooted in this particularly type of physical embodiment.
<br>
<p>&nbsp;
<br>
<em>&gt; &gt; Just as we have allowed the information age to create increasingly
</em><br>
<em>&gt; &gt; divided societies of haves and have-nots, so will it be
</em><br>
<em>&gt; &gt;we humans who will create a future of cyborgs and mega-computers.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Self-replicating systems based on biotechnology will solve much of the
</em><br>
<em>&gt; &quot;have-not&quot; problem.  Full blown molecular nanotechnology is not required.
</em><br>
<em>&gt;
</em><br>
<p>Without a change in human consciousness from scarcity to abundance-based
<br>
thinking and acting, I don't beleieve that any amount of technology will
<br>
fundamentally change the have/have-not polarity.  We do need full
<br>
nanotech to fully escape the &quot;limits of the flesh&quot;.
<br>
&nbsp;
<br>
<em>&gt; &gt;Mr Kurzweil quotes Daniel Hillis, a noted computer engineer: &quot;I'm as fond
</em><br>
<em>&gt; &gt;of my body as anyone else, but if I can be 200 with a body of silicon, I'll
</em><br>
<em>&gt; &gt;take it.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If the problem of aging is resolved through the clever application
</em><br>
<em>&gt; of first biotechnology and then nanotechnology, then the average
</em><br>
<em>&gt; lifespan determined by the U.S. present day accident rate would
</em><br>
<em>&gt; be ~2000 years.  Who would want to live 2000 years without being
</em><br>
<em>&gt; able to grow and evolve beyond the limitations of a standard-issue
</em><br>
<em>&gt; human brain?
</em><br>
<em>&gt; 
</em><br>
<p>This is a strawman.  Let me live 2000 years with at least the mental
<br>
capacity I possess now and I will find more than enough to do and enjoy
<br>
and plentiful ways to effectively multiply that capacity.  There is no
<br>
way you could stop me from growing and evolving.
<br>
<p><em>&gt; &gt;Then, are you a human or a computer, and who's side are you on?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Its always easy to cast as &quot;us&quot; vs. &quot;them&quot;.  Instead we merge as the
</em><br>
<em>&gt; humans who are not too afraid to evolve, do so, perhaps in the
</em><br>
<em>&gt; end choosing to leave the planet to those who choose not to do so.
</em><br>
<em>&gt; 
</em><br>
<p>Actually, I predict that the only way to eventually keep the peace and
<br>
allow everyone maximum freedom is to pop the more coercive (of others)
<br>
elements into a VR where they can live out whatever reality they choose
<br>
until such time as they choose differently.  A sort of high-tech karma
<br>
system.  Some days I am not convinced we aren't already in such a
<br>
system.
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2957.html">J. R. Molloy: "Re: 137: Sheer blank-minded stupidity"</a>
<li><strong>Previous message:</strong> <a href="2955.html">Samantha Atkins: "Re: Two great articles on ignoring government"</a>
<li><strong>In reply to:</strong> <a href="2780.html">Robert J. Bradbury: "Re: [&gt;Htech] The Age on Cyborgology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3962.html">Robert J. Bradbury: "Re: [&gt;Htech] The Age on Cyborgology"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2956">[ date ]</a>
<a href="index.html#2956">[ thread ]</a>
<a href="subject.html#2956">[ subject ]</a>
<a href="author.html#2956">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:31 MDT</em>
</em>
</small>
</body>
</html>
