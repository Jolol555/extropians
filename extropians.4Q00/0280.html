<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Pointless Re: Eugene's nuclear threat</title>
<meta name="Author" content="Eugene Leitl (eugene.leitl@lrz.uni-muenchen.de)">
<meta name="Subject" content="Re: Pointless Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Pointless Re: Eugene's nuclear threat</h1>
<!-- received="Wed Oct  4 05:22:30 2000" -->
<!-- isoreceived="20001004112230" -->
<!-- sent="Wed, 4 Oct 2000 03:18:38 -0700 (PDT)" -->
<!-- isosent="20001004101838" -->
<!-- name="Eugene Leitl" -->
<!-- email="eugene.leitl@lrz.uni-muenchen.de" -->
<!-- subject="Re: Pointless Re: Eugene's nuclear threat" -->
<!-- id="14811.1022.25367.694862@lrz.uni-muenchen.de" -->
<!-- inreplyto="39D8EB32.CCF01D47@posthuman.com" -->
<strong>From:</strong> Eugene Leitl (<a href="mailto:eugene.leitl@lrz.uni-muenchen.de?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;14811.1022.25367.694862@lrz.uni-muenchen.de&gt;"><em>eugene.leitl@lrz.uni-muenchen.de</em></a>)<br>
<strong>Date:</strong> Wed Oct 04 2000 - 04:18:38 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0281.html">Eugene Leitl: "AT&amp;T vows no censorship on new network"</a>
<li><strong>Previous message:</strong> <a href="0279.html">Technotranscendence: "AT&amp;T vows no censorship on new network"</a>
<li><strong>In reply to:</strong> <a href="0111.html">Brian Atkins: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0318.html">Eliezer S. Yudkowsky: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0318.html">Eliezer S. Yudkowsky: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#280">[ date ]</a>
<a href="index.html#280">[ thread ]</a>
<a href="subject.html#280">[ subject ]</a>
<a href="author.html#280">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Brian Atkins writes:
<br>
<em> &gt; You must be suffering some serious cognitive dissonance about now, since
</em><br>
<em> &gt; your chosen area of study is exactly the thing that may open Pandora's box
</em><br>
<em> &gt; so to speak. And it isn't just us- you've got your favorite de Garis who
</em><br>
<p>Sure, but we'll need that hardware for human uploads, and this is
<br>
about the only thing which can save our ass on the long run. I'm not
<br>
to be held responsible (notice the relatively (and
<br>
uncharacteristically) radical attitude towards misuse of certain
<br>
technologies as demonstrated in recent sequence of posts) if that
<br>
hardware is to be put to wrong use by irresponsible people. (And,
<br>
yeah, fat chance for me actually having any measurable impact, so
<br>
nyanya).
<br>
<p>Notice that molecular cicuitry of the self-assembly kind is quite
<br>
useless for gray goo type of technologies (thought it *is* applicable
<br>
for virus design, alas. But efficient bioweapon contermeasures are
<br>
well within reach of current or near future technologies, as DNA
<br>
screening, sterile bareers and quarantining).
<br>
<p><em> &gt; is just waiting for faster processing, plus the following bit from the SL4
</em><br>
<p>My favourite? Hardly, he's just the one focusing on technologies most
<br>
likely to succeed. Eliezer can add de Garis to the Evil People list,
<br>
his artilect essays do seem to indicate the usual Moravecian form of
<br>
mental derangement (mind children uber alles).
<br>
<p><em> &gt; list last night will also probably give you severe indigestion. You know
</em><br>
<p>Bring on the good stuff. I'm stocked on Lefax.
<br>
<p><em> &gt; actually SIAI has got to be the least of your worries since we have no
</em><br>
<em> &gt; plans at this point to make use of evolutionary programming techniques...
</em><br>
&nbsp;
<br>
So Eliezer said, and I'm glad to hear it. However, you may wind up
<br>
with introducing evolutionary algorithm use via the back door, when
<br>
code is rewriting code, hence my appeal to continuously revise the
<br>
goals and implementation of the project. You will keep it offline,
<br>
will you?
<br>
<p>For the record, I don't think SIAI is a considerable threat, both
<br>
because of the limit of resources (you won't start writing Net worms,
<br>
will you?) and focus on brittle AI and declared ban on evolutionary
<br>
algorithms. The real dangers lie with researchers like de Garis,
<br>
especially military research, and renegade authors of Net worms using
<br>
evolutionary algorithms. I assume this has a high threshold on both
<br>
resource use and delayed onset, due to self-mod software self
<br>
bootstrap problem.
<br>
<p><em> &gt; Subject: RE: Ben what are your views and concerns
</em><br>
<em> &gt; Date: Sun, 1 Oct 2000 23:25:06 -0400
</em><br>
<em> &gt; From: &quot;Ben Goertzel&quot; &lt;<a href="mailto:ben@intelligenesis.net?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;14811.1022.25367.694862@lrz.uni-muenchen.de&gt;">ben@intelligenesis.net</a>&gt;
</em><br>
<em> &gt;
</em><br>
<em> &gt; I don't have ~big~ concerns about AI that becomes evil
</em><br>
<em> &gt; due to its own purely AI motivations
</em><br>
<em> &gt; 
</em><br>
<em> &gt; I do worry, though, about evil humans using AI in evil ways
</em><br>
<p>That's weird, my concerns run exactly the other way round. You can't
<br>
use a god. That's a lot like the deermouse under the bush yonder
<br>
trying to use you.
<br>
&nbsp;
<br>
<em> &gt; See, Internet AI systems aren't going to have an inbuilt urge for
</em><br>
<em> &gt; aggression -- they're not growing up
</em><br>
<em> &gt; in a predator-prey ecosystem... they'll mainly grow up to help and serve
</em><br>
<p>Yeah? Look at system security, it's a jungle out there.
<br>
<p><em> &gt; people in various ways; their
</em><br>
<em> &gt; &quot;fitness&quot; won't have to do with killing other creatures or becoming &quot;leader
</em><br>
<em> &gt; of the pack,&quot; but rather with
</em><br>
<em> &gt; being as useful as possible to their human masters...
</em><br>
&nbsp;
<br>
If we're talking about the positive autofeedback self-enhancement
<br>
process occuring in the future Net matrix, being as useful as possible
<br>
to their (former) human masters will be the last thing on their
<br>
agenda. Surviving sysadmins hunting them and pulling down hardware
<br>
from under their feet will be their typical environment. This selects
<br>
for stealth, cunning and optimal resource (CPU and bandwidth) use.
<br>
<p><em> &gt; What kinds of weird AI psychology will emerge once AI systems move on beyond
</em><br>
<em> &gt; being primarily servants
</em><br>
<em> &gt; to humans... I don't know, but have speculated
</em><br>
<em> &gt; 
</em><br>
<em> &gt; Here is a moderately brief excerpt from my forthcoming book &quot;Creating
</em><br>
<em> &gt; Internet Intelligence&quot; (Plenum press), which verges
</em><br>
<p>Oh, god. Another candidate for the &quot;Evil People&quot; list.
<br>
<p><em> &gt; on this topic:
</em><br>
<em> &gt; 
</em><br>
<em> &gt; -- ben
</em><br>
<em> &gt; 
</em><br>
<em> &gt; 
</em><br>
<em> &gt; ****
</em><br>
<em> &gt; With something as new and different as this [Internet AI], it would be easy
</em><br>
<em> &gt; to slip up and create a disaster.  Or would it?   Maybe there are inexorable
</em><br>
<em> &gt; forces of evolution at work here, and the conscious acts that we take are
</em><br>
<em> &gt; just tiny little nudges one way or the other.  Maybe if a disaster is
</em><br>
<em> &gt; inevitable, there's no act that any of us could take to stop it anyway?
</em><br>
<p>A yet another defaetist. Sorry, don't buy it. He might want to lie
<br>
down in the path of the Juggernaut, me, I have a sudden important
<br>
business to attend elsewhere.
<br>
<p><em> &gt; Anything's possible, of course, and in the presence of so many unknowns,
</em><br>
<em> &gt; assigning probabilities to various outcomes is going to be more intuitive
</em><br>
<em> &gt; than rational.  My intuition is that what's going to happen will be good -
</em><br>
<p>I wouldn't rely on anybody's intuition in matters like this. This
<br>
needs cold, hard numbers. Considerable modelling resources invested.
<br>
<p><em> &gt; intelligence, creativity and passion will be served; instinctive, habitual
</em><br>
<em> &gt; routines will be loosened; the process of forming and destroying boundaries
</em><br>
<em> &gt; between people, groups and ideas will transform into something we can't yet
</em><br>
<em> &gt; understand.  But this is just the intuition of my little human brain,
</em><br>
<em> &gt; supercharged by whatever &quot;collective unconscious&quot; forces it's managed to tap
</em><br>
<em> &gt; into.  How to assess how much this is worth?
</em><br>
&nbsp;
<br>
Using a broken bit of pencil and a piece of paper, no less. Some assessment.
<br>
<p><em> &gt; Much of my intuition about the long-term future of the Net comes from my
</em><br>
<em> &gt; work on Webmind.  Webminds, as individual minds, are going to be useful for
</em><br>
<p>Another fancy word for AI, I presume. Grabbing credit by pushing
<br>
catchy neologisms. Webmind, artilect, you name it. A spade is not an
<br>
entrenching tool, it's a spade.
<br>
<p><em> &gt; various practical applications as described in the previous chapter; but
</em><br>
<em> &gt; they'll also be autonomous, self-directed systems, concerned with achieving
</em><br>
<em> &gt; their own goals and their own happiness.  What happens when the Internet is
</em><br>
<em> &gt; dominated by a community of AI agents, serving commercial, collective and
</em><br>
<em> &gt; individual goals?  What will be the nature of this Webmind society, and its
</em><br>
<em> &gt; implications for us?
</em><br>
&nbsp;
<br>
Something what we can't possibly imagine, since being outside of a
<br>
single human's scope of perception.
<br>
&nbsp;
<br>
<em> &gt; Of course, Webmind society is not going to be the Internet as a whole.  But
</em><br>
<em> &gt; there's reason to believe that the core of the first phase of the
</em><br>
<em> &gt; intelligent Internet will indeed be centered on a community of powerful AI
</em><br>
<em> &gt; agents.  And if this is true, that's all the more reason to understand how
</em><br>
<em> &gt; these agent societies are going to operate.  For example, what's the chance
</em><br>
<em> &gt; that Webminds and other AI agents are going to sit around all day exchanging
</em><br>
<em> &gt; encrypted messages about how to accelerate the obsolescence of the human
</em><br>
<em> &gt; race?
</em><br>
&nbsp;
<br>
Huh? That time would be better invested in self enhancement. The
<br>
obsolescense of biology would then emerge as a side effect.
<br>
&nbsp;
<br>
<em> &gt; I don't know the answers to these questions, but I've thought about them a
</em><br>
<em> &gt; good bit, and discussed them with others.  In this chapter I'll give some
</em><br>
<em> &gt; ideas about Webmind societies, and their implications for the future of the
</em><br>
<em> &gt; Net in general.  In concrete terms, these ideas concern the Intelligent
</em><br>
<em> &gt; Internet phase, more so than the Global Brain phase - they have to do with
</em><br>
<em> &gt; computer programs on the Net, not with human brains jacked into the Net,
</em><br>
<em> &gt; bio-digital intelligence, or the behavior of AI systems filled with the
</em><br>
<em> &gt; contents of uploaded human minds.  But, thinking more laterally, it seems
</em><br>
<em> &gt; likely that the nature of the society of AI agents in the Intelligent
</em><br>
<em> &gt; Internet phase is going to be critical in setting the stage for the nature
</em><br>
<em> &gt; of the true Global Brain to follows.  If this is the case, then Webmind
</em><br>
<em> &gt; societies are truly a highly important issue.
</em><br>
<p>Somebody seems to be getting lost in his mental constructs. Seems like 
<br>
a regular job hazard in these circles &lt;sheepish grin&gt;.
<br>
&nbsp;
<br>
<em> &gt; The Webmind Inc. &quot;tech list&quot; e-mail discussion group has sustained a number
</em><br>
<em> &gt; of long threads on the topic of Webmind morality, and social interaction
</em><br>
<em> &gt; among groups of Webminds.  These discussions sometimes seem frivolous, mixed
</em><br>
<em> &gt; in as they are with reports of bugs in Webmind's basic thinking processes,
</em><br>
<em> &gt; basic questions about Java programming and Webmind structure from new
</em><br>
<em> &gt; employees, and debates over new features in Webmind's reasoning, language,
</em><br>
<em> &gt; or data analysis modules . but, although they sometimes are frivolous, they
</em><br>
<em> &gt; are also important.  We all proceed fairly blindly into future, but if we
</em><br>
<em> &gt; squint our eyes hard enough, we can see a little bit, and after a lot of
</em><br>
<em> &gt; thinking about where we want to go, we can have at least a little input into
</em><br>
<em> &gt; our direction of movement.  In many areas these internal company discussions
</em><br>
<em> &gt; have gone far deeper than the discussions on the Global Brain mailing list,
</em><br>
<em> &gt; as excerpted above.
</em><br>
&nbsp;
<br>
More entries for Eliezer's Evil People list.
<br>
&nbsp;
<br>
<em> &gt; One consequence of our discussions on Webmind morality has been the
</em><br>
<em> &gt; realization that Teilhard really was wrong - the global brain will not be
</em><br>
<em> &gt; perfect!   In fact, the same flaws that plague human society will plague the
</em><br>
<p>Gimme a break, Teilhard de Chardin was a friggin member of a Church
<br>
order, not a cognition expert.
<br>
<p><em> &gt; Intelligent Internet, though hopefully to a lesser degree, and definitely
</em><br>
<em> &gt; with a different flavor.  Furthermore, as a consequence of this, the
</em><br>
<em> &gt; convergence of the Net with the Jungian vision of the collective unconscious
</em><br>
<p>Ok, he's gone completely overboard now.
<br>
<p><em> &gt; will be greater than it might seem at first glance.  Many of the archetypes
</em><br>
<em> &gt; of the human unconscious emerge from socialization, from the dynamics of
</em><br>
<em> &gt; society.  And there are certain aspects of social dynamics that seem to be
</em><br>
<em> &gt; universal, that are bound to emerge in the global brain once it reaches a
</em><br>
<em> &gt; certain level of complexity, just as they have emerged among humans.
</em><br>
&nbsp;
<br>
More meaningless garbage.
<br>
<p><em> &gt; We've seen how it's possible to embody a Webmind with compassion - you
</em><br>
<em> &gt; program it so that its happiness will increase when it senses that the other
</em><br>
<em> &gt; actors it interacts with are happy.  One then has a collection of Webminds
</em><br>
<p>A yet another programmer with an idee fixe. &quot;I can program the Moon
<br>
from the skies, and program the stormy seas to grew calm&quot;. Here, have
<br>
another Xanax.
<br>
<p><em> &gt; that want to please each other.  This enhances the intelligence of the
</em><br>
<em> &gt; overall community of Webminds, because the Webminds have an intrinsic
</em><br>
<em> &gt; motivation to supply each other with the best answers to their questions,
</em><br>
<em> &gt; and to provide each other with resources when needed.  If this were Webminds
</em><br>
<p>Why not leave this to a proven method: co-evolution? If they're so
<br>
damn smart, why can't they figure out how to cooperate?
<br>
<p><em> &gt; ' only motivation, one would soon have a community of morons, babbling
</em><br>
<em> &gt; digital nonsense to each other in a chorus of mutually supportive, ignorant
</em><br>
<em> &gt; bliss.  But overlaid on a system in which Webminds achieve happiness by
</em><br>
<em> &gt; creating patterns and satisfying users, and pay each other for intelligent
</em><br>
<em> &gt; answers to their questions, compassion enhances emergent intelligence.  This
</em><br>
<em> &gt; hasn't been proven in practice yet, since we have not yet built a large
</em><br>
<em> &gt; network of Webminds.  But we've set up simulations that have borne out this
</em><br>
<em> &gt; intuition.
</em><br>
&nbsp;
<br>
Based on which models?
<br>
<p><em> &gt; So far, so good.  But what happens when someone introduces a
</em><br>
<em> &gt; non-compassionate Webmind (or another non-compassionate intelligent actor)
</em><br>
<em> &gt; into the mix?  A whole system of selfish Webminds works worse than a whole
</em><br>
<em> &gt; system of compassionate Webminds.  But is global compassion a stable
</em><br>
<p>Why? Rational selfishness will eventually give raise to emergence of
<br>
progressively more benign cooperative strategies.
<br>
<p><em> &gt; situation?  One selfish Webmind, in a compassionate community, will have an
</em><br>
<em> &gt; intrinsic advantage - it will in effect be able to make itself king.  More
</em><br>
<em> &gt; and more selfish Webminds will then get introduced into the system, as
</em><br>
<em> &gt; others see the value of selfishness for achieving their goals.  The
</em><br>
<em> &gt; compassionate society will dissolve.
</em><br>
<em> &gt; What's the solution?  One answer is benevolent fascism.  Erect a global
</em><br>
<em> &gt; authority, which makes sure that only compassionate Webminds get released
</em><br>
<em> &gt; into the Net.  But this will never work.  The Net is too disorganized and
</em><br>
<em> &gt; self-organized; no one owns it.
</em><br>
&nbsp;
<br>
More computer scientist's armchair philosophy.
<br>
<p><em> &gt; The only other answer that I see is, painfully enough, social ostracism.
</em><br>
<p>Duh, what deep insight. And it's is quite telling when he calls it
<br>
&quot;painfully enough&quot;.
<br>
<p><em> &gt; Compassionate Webminds need to take a &quot;tough love&quot; approach to selfish
</em><br>
<em> &gt; Webminds, and refuse to deal with them, even if it would be to their
</em><br>
<em> &gt; short-term economic advantage to do so.  It then becomes a bad strategy for
</em><br>
<em> &gt; a single Webmind to be selfish.   This seems simple enough.  But the problem
</em><br>
<em> &gt; is, how do you recognize selfishness, from the outside?  It's not so easy.
</em><br>
<p>Seems he hasn't read &quot;Rules of Encounter&quot; yet.
<br>
<p><em> &gt; This is just another tough pattern recognition problem.  Seeing examples of
</em><br>
<em> &gt; selfishness, and knowing some properties of selfishness, Webmind can learn
</em><br>
<em> &gt; to recognize selfishness by certain signs.  But then, Webminds will get a
</em><br>
<em> &gt; hang of the &quot;selfishness recognition systems&quot; of other Webminds, and learn
</em><br>
<em> &gt; how to fool each other.  Just as humans trick each other by false facial
</em><br>
<em> &gt; expressions and tones of voice.   And furthermore, there will be Webminds
</em><br>
<em> &gt; that are perfectly compassionate, but that unintentionally give the signs of
</em><br>
<em> &gt; being selfish - &quot;false negatives&quot; for the selfishness recognition systems of
</em><br>
<em> &gt; their fellow Webminds.
</em><br>
<p>He forgot to talk about ships and sealing wax.
<br>
<p><em> &gt; You have to act right to be accepted.  If you don't act right, nobody wants
</em><br>
<em> &gt; to talk to you.  Some of the ways of acting &quot;wrong&quot; may actually better than
</em><br>
<em> &gt; the accepted ways of doing things, but no one seems to recognize this.  You
</em><br>
<em> &gt; either have to go along with the majority, accept your isolation, or band
</em><br>
<em> &gt; together with similar freaks who go against the prevailing standard of what
</em><br>
<em> &gt; is the correct way to be.  This may sound familiar to many readers - it is
</em><br>
<em> &gt; definitely familiar to me, from my teenage years, particularly the five
</em><br>
<em> &gt; miserable years I spent in middle school and high school, before leaving for
</em><br>
<em> &gt; college.  Unfortunately, it seems that a certain amount of this stuff is
</em><br>
<em> &gt; going to be there in Webmind communities as well.  Not all of the nastiness
</em><br>
<em> &gt; of human society can be avoided, some of it is an inevitable consequence of
</em><br>
<em> &gt; the information-processing restrictions imposed by the finitude of mind.  We
</em><br>
<em> &gt; can't tell what's really good or not, so we have to estimate, and our
</em><br>
<em> &gt; estimation errors may be painful for their victims.
</em><br>
&nbsp;
<br>
He sounds genuinely screwed up. Why must the outcasts always try to
<br>
improve the world?
<br>
<p><em> &gt; And what happens when a band of freaks, going against the prevailing
</em><br>
<em> &gt; standards of right, gets large enough?  It becomes an alternative community.
</em><br>
<em> &gt; You then have two groups, each one of which judges goodness according to its
</em><br>
<em> &gt; own criteria, its own estimates.  Each one may judge the other one as bad.
</em><br>
<em> &gt; And - maybe - try and wipe the other one out, in the name of goodness?
</em><br>
<p>Whee! Here we go. Let me wipe thee out, in the name of goodness. You
<br>
can't possibly object, since it's in your own best. So, there.
<br>
<p><em> &gt; Will things go this far in Webmind society?  Will warfare erupt among
</em><br>
<em> &gt; Webminds, based on differing groups that use different pattern recognition
</em><br>
<em> &gt; algorithms to estimate goodness?  Actually I doubt it.  The saving grace of
</em><br>
<p>He doubts it, now I feel reassured.
<br>
<p><em> &gt; digital intelligence, I believe, will be its adaptability.  Webminds can
</em><br>
<em> &gt; change much more rapidly than humans.  Potentially, they can even revise
</em><br>
<em> &gt; their brains.  Right now this is well beyond any existing software, but in a
</em><br>
<em> &gt; decade or so, we may have Webminds that can rewrite their own Java code to
</em><br>
<em> &gt; improve functionality.
</em><br>
&nbsp;
<br>
In a totally controlled fashion, eh. Routing yourself round that pesky
<br>
undecidedability. Dream on.
<br>
&nbsp;
<br>
<em> &gt; I don't think there is much relation between the goodness of a society and
</em><br>
<em> &gt; the intelligence of the actors who make it up.  Yes, more intelligent actors
</em><br>
<em> &gt; can figure out what features indicate goodness better.  On the other hand,
</em><br>
<em> &gt; they can also figure out how to fool each other better.  The two factors
</em><br>
<p>Only smart players can progress to progressively more benign
<br>
cooperation strategies. The more primitive, the more red in tooth and
<br>
claw.
<br>
<p><em> &gt; probably balance out.  On the other hand, I do think that adaptability
</em><br>
<em> &gt; encourages goodness.  A fair amount of the stupidity of human society can be
</em><br>
<em> &gt; traced to our slow adaptation, in particular to the inability of our brains
</em><br>
<em> &gt; to respond to cultural changes.
</em><br>
&nbsp;
<br>
Sure, but what makes him think that the virtual ecology as a whole
<br>
will be moving on to more intelligent players? If you look into,
<br>
admittedly in transit, biological ecology, humans are by the metric
<br>
ton and certainly not by the numbers of individuals the kings of the
<br>
planet.
<br>
<p><em> &gt; We humans are to a great extent locked in by our evolutionary history.
</em><br>
<em> &gt; There are hundreds of examples of this - one is the way that women's sexual
</em><br>
<em> &gt; infidelity is treated much more seriously than men's, in all human cultures.
</em><br>
<em> &gt; Many women find this unfair, and I would too in their place, but the reason
</em><br>
<em> &gt; is obvious, if one takes a sociobiological, DNA-centric view.  If a woman
</em><br>
<em> &gt; has a baby by a different man than her husband, then the husband, insofar as
</em><br>
<em> &gt; he is supporting and protecting the child, is wasting his time propagating
</em><br>
<em> &gt; someone else's DNA.  His DNA is angry: it wants to propagate itself.  On the
</em><br>
<em> &gt; other hand, if a man impregnates a different woman than his wife, this doesn
</em><br>
<em> &gt; 't matter much to the wife's DNA.   All her DNA wants is for the husband to
</em><br>
<em> &gt; keep supporting her children, which carry it into the future.  So the extra
</em><br>
<em> &gt; stigma attached to female infidelity makes sense from an evolutionary
</em><br>
<em> &gt; perspective.  But from a modern human perspective, it is almost completely
</em><br>
<em> &gt; obsolete.   Now, women can use birth control, hence they can sleep around
</em><br>
<p>Agreed here. But you'll have a hard chance fighting with your
<br>
hardwired behaviour, even if you're aware of what is going on.
<br>
<p><em> &gt; without much risk of pregnancy.   Also, most women are no longer producing
</em><br>
<em> &gt; children on a continual basis, so that most acts of infidelity do not
</em><br>
<em> &gt; produce any question of paternal identity.  Finally, we have DNA testing, so
</em><br>
<em> &gt; that, in principle, every new father can test his child's DNA to see if he's
</em><br>
<em> &gt; the real father or not, thus eliminating the risk of his DNA wasting much of
</em><br>
<em> &gt; its effort propagating a competing DNA pattern.  Have these developments
</em><br>
<p>You know what? They're selling DNA home testing kits, and they're
<br>
going away like crazy. Somehow, daddies still seem to adhere to what
<br>
their DNA is telling them.
<br>
<p><em> &gt; decreased the stigma attached to female infidelity?  Yes, a bit.  Cheating
</em><br>
<em> &gt; women are no longer routinely killed.  We are not completely pawns of our
</em><br>
<em> &gt; evolutionary heritage.  But, they have not decreased it as much as they
</em><br>
<em> &gt; should have, and they probably never will.  Our mechanisms for judging
</em><br>
<em> &gt; others are not very adaptive.
</em><br>
&nbsp;
<br>
Calvin seems to have a useful bibliography on that:
<br>
<a href="http://faculty.washington.edu/wcalvin/bk2/bk2notes.htm">http://faculty.washington.edu/wcalvin/bk2/bk2notes.htm</a> I personally
<br>
find Konner, Melvin. The Tangled Wing: Biological Constraints on the
<br>
Human Spirit. New York: Holt, Rinehart &amp; Winston (1982) dated, but
<br>
informative.
<br>
<p><em> &gt; To take another example, Freud, in &quot;Civilization and Its Discontents&quot;
</em><br>
<em> &gt; (1984),  argued that neurosis is a necessary consequence of civilization.
</em><br>
<em> &gt; His reason was that civilization requires us to check our primitive impulses
</em><br>
<em> &gt; toward violence, to restrict our behavior in biologically unnatural ways.
</em><br>
<p>Untypically insightful of Freud.
<br>
<p><em> &gt; In the terms I am using here, what was good in the contest of tribal society
</em><br>
<em> &gt; is no longer good in modern society, and this causes problems.  Webminds
</em><br>
<em> &gt; will not have much of this kind of problem: faced with the situation Freud
</em><br>
<em> &gt; describes, they would just rewire themselves to be less violent.
</em><br>
<p>Great opportunity to slide off into Red Queen regime here.
<br>
<p><em> &gt; Webmind society will thus be very different from ours.  Social codes and
</em><br>
<em> &gt; standards will change continually and rapidly.  It is hard to imagine what
</em><br>
<em> &gt; it would be like to live in such a way - but it's not impossible.  Because,
</em><br>
<p>So saith the ant from his blade of grass, while observing the party of
<br>
picknickers.
<br>
<p><em> &gt; after all, social codes and standards are changing more rapidly every
</em><br>
<em> &gt; decade.  Society has moved into fast-forward mode.  Aboriginals dressed and
</em><br>
<em> &gt; acted the same way for sixty thousand years; now styles change every six
</em><br>
<em> &gt; months.  The dynamism of internet intelligence and the dynamism of
</em><br>
<em> &gt; contemporary culture will intersect to give the global societal mind a
</em><br>
<em> &gt; colorful, vibrant, wild character that
</em><br>
<em> &gt; I could express in music or pictures much more easily than in words.
</em><br>
&nbsp;
<br>
Not also in graphs and equations? A rather superficial form of expression.
<br>
<p><em> &gt; Many features derived from human sexuality will be missing from Webmind
</em><br>
<em> &gt; society, since the types of reproduction available to Webminds will be much
</em><br>
<em> &gt; more diverse: a Webmind can clone itself, or can &quot;cross over&quot; with any
</em><br>
<em> &gt; number of other Webminds, yielding Webminds with 2, 3, or 100,000 parents.
</em><br>
<p>It is not important with how many you cross over, as long as you cross
<br>
over (yeah, and of course you have to limit the diversity with whom
<br>
you're crossing over, orelse you just wound up with meaningless
<br>
garbage in place of your genome). And if you think finding a partner
<br>
today is hard, try finding 10 suitable simultaneouly.
<br>
<p><em> &gt; Furthermore a Webmind can be progressively altered by itself or its owner,
</em><br>
<p>Self neurosurgery, the path to self improvement. No way to evaluate
<br>
this without external authority (former self, or a number of others).
<br>
<p><em> &gt; yielding a continuous evolution of personality that is not accessible to
</em><br>
<em> &gt; humans at all, due to our inability to modify our own brain structure except
</em><br>
<em> &gt; crudely through drugs.  But even with this new diversity, much of the
</em><br>
<p>Of course, this is immaterial for uploaders and even biomedical nanotechnology.
<br>
<p><em> &gt; archetypal structure of human relationships will be there.  We know, from
</em><br>
<em> &gt; our research with genetic algorithms, that sexual reproduction is much more
</em><br>
<em> &gt; efficient than asexual reproduction by fission or continuous development.
</em><br>
<em> &gt; So Webminds will reproduce sexually even though they have other options open
</em><br>
<em> &gt; to them.  And genetic algorithm experiments show that multi-parent
</em><br>
<em> &gt; reproduction is not significantly more effective than two-parent
</em><br>
<em> &gt; reproduction.  So many Webminds will have two parents, though there will be
</em><br>
<em> &gt; no difference between mom and dad.
</em><br>
&nbsp;
<br>
There is no need for sexual dimorphism due no need for intracorporeal
<br>
gestation, but maybe sexual selection will cause two sexes to become
<br>
asymmetrical. This ought to be modelled.
<br>
<p><em> &gt; Webminds will be careful about whom they reproduce with.  If a Webmind has
</em><br>
<em> &gt; access to certain resources, in which it wants to place one of its children,
</em><br>
<em> &gt; it will want to make this child as good a child as possible.  Furthermore,
</em><br>
<em> &gt; once it has observed that it can produce a good child with another Webmind,
</em><br>
<em> &gt; it may want to maintain this relationship over time.
</em><br>
<p>Of course, this assumes that a limited scope player knows what
<br>
global-scope fitness is, which is just wishful thinking.
<br>
<p><em> &gt; &quot;Childhood&quot; among Webminds will not necessarily mean the same thing as it
</em><br>
<em> &gt; does among humans.  It is possible for two Webminds to mate and birth a
</em><br>
<em> &gt; fully-formed Webmind, ready for action.  On the other hand, it may be very
</em><br>
<p>Not if you're genome based, you'll have to express the phenotype
<br>
(unless you consider your bits and your state both phenotype and
<br>
genotype), which will take time, and the proper context. Just as with
<br>
human babies. Otherwise you don't know what a piece of genome is
<br>
coding for.
<br>
<p><em> &gt; useful for a Webmind to create a &quot;baby Webmind&quot;, with a partially empty
</em><br>
<em> &gt; brain.  In this way it may arrive at something much smarter than itself, or
</em><br>
<em> &gt; at least something with new and different ideas.  A baby Webmind, however,
</em><br>
<p>No other way to know whether you're in a local minimum without trying
<br>
to break out. Casualties calculated.
<br>
<p><em> &gt; will require a teacher.  The notion of parental responsibility arises.
</em><br>
<em> &gt; Webminds that take good care of their babies will be more likely to produce
</em><br>
<em> &gt; successful babies.  Thus, by evolutionary pressure, Webminds will come to
</em><br>
<em> &gt; have an &quot;instinct&quot; that taking care of baby Webminds is good.  The urge to
</em><br>
<em> &gt; take care of baby Webminds will be automatically passed along from parent to
</em><br>
<em> &gt; child..
</em><br>
&nbsp;
<br>
Sounds sensible.
<br>
<p><em> &gt; And so it goes.  The community of Webminds will not be exactly like human
</em><br>
<em> &gt; society - far from it.  But it will not be entirely different either.  The
</em><br>
<em> &gt; Jungian archetypes of union, child, family, will all be there, overlaid with
</em><br>
<em> &gt; other archetypes that we can barely even envision, all improvising on the
</em><br>
<em> &gt; theme of the basic numerical archetypes, the combinations of 0's and 1's
</em><br>
<p>Could as well use ternary logic, or whatever discrete coding the
<br>
hardware layer suggests. Biology did came up with four bases, not two,
<br>
because the chemistry allowed for sufficient distinguishable
<br>
variability in a given molecular framework. Similiar applies to
<br>
electronically excited states of your molecular switching matrix.
<br>
<p><em> &gt; that make up the mind and the world.  The human collective unconscious will
</em><br>
<p>&quot;Collective unconscious&quot;? Now he's raving again.
<br>
<p><em> &gt; be made concrete via the action of intelligent actors on human text and on
</em><br>
<em> &gt; numerical data representing human activities.  But it will be made non-human
</em><br>
<p>Hogwash. Why should the things be confined to the network? They will
<br>
represent whatever is necessary, including self, others and
<br>
environment, whether inside our outside. You don't live long is
<br>
someone can step up, stick out the tongue and then pull your plug.
<br>
<p><em> &gt; via the intrinsic peculiarities of these intelligent actors and their
</em><br>
<em> &gt; interactions.  Their own unconscious patterns will filter down into human
</em><br>
<em> &gt; society, so that we are affected in subtle ways by the feeling a digital
</em><br>
<p>Assuming, there is still a human society at this stage, of
<br>
course. Which seems like going out on a limb.
<br>
<p><em> &gt; actor gets when it has 1000 parents, as opposed to 1 or 2.  Much of each
</em><br>
<em> &gt; human being's brain will be filled with patterns and ideas of digital
</em><br>
<em> &gt; origin, just as much of the intelligent Internet will be filled with
</em><br>
<em> &gt; patterns and ideas of human origin.  All this is bound to occur as a
</em><br>
<p>As long as they don't fall into the positive autofeedback
<br>
self-improvement loop and become utterly incomprehensible, I'm all for
<br>
it.
<br>
<p><em> &gt; consequence of our incessant daily interaction with the Net, and the Net's
</em><br>
<em> &gt; increasing self-organizing intelligence.
</em><br>
<p>My, The Church of Webminds. Perhaps he should sell the concept to the Bahai.
<br>
&nbsp;
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0281.html">Eugene Leitl: "AT&amp;T vows no censorship on new network"</a>
<li><strong>Previous message:</strong> <a href="0279.html">Technotranscendence: "AT&amp;T vows no censorship on new network"</a>
<li><strong>In reply to:</strong> <a href="0111.html">Brian Atkins: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0318.html">Eliezer S. Yudkowsky: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0318.html">Eliezer S. Yudkowsky: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#280">[ date ]</a>
<a href="index.html#280">[ thread ]</a>
<a href="subject.html#280">[ subject ]</a>
<a href="author.html#280">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:15 MDT</em>
</em>
</small>
</body>
</html>
