<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: &quot;Cybernetic Totalism?&quot;</title>
<meta name="Author" content="Michael S. Lorrey (retroman@turbont.net)">
<meta name="Subject" content="Re: &quot;Cybernetic Totalism?&quot;">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: &quot;Cybernetic Totalism?&quot;</h1>
<!-- received="Thu Oct 12 12:52:12 2000" -->
<!-- isoreceived="20001012185212" -->
<!-- sent="Thu, 12 Oct 2000 15:00:12 -0400" -->
<!-- isosent="20001012190012" -->
<!-- name="Michael S. Lorrey" -->
<!-- email="retroman@turbont.net" -->
<!-- subject="Re: &quot;Cybernetic Totalism?&quot;" -->
<!-- id="39E60A3C.1B2BE9CF@turbont.net" -->
<!-- inreplyto="000f01c03471$06159380$8b14073e@mossbtinternet.com" -->
<strong>From:</strong> Michael S. Lorrey (<a href="mailto:retroman@turbont.net?Subject=Re:%20&quot;Cybernetic%20Totalism?&quot;&In-Reply-To=&lt;39E60A3C.1B2BE9CF@turbont.net&gt;"><em>retroman@turbont.net</em></a>)<br>
<strong>Date:</strong> Thu Oct 12 2000 - 13:00:12 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1036.html">Jason Joel Thompson: "Re: Please throttle back your posting!"</a>
<li><strong>Previous message:</strong> <a href="1034.html">matthew gream: "Good reading material - books on global history"</a>
<li><strong>In reply to:</strong> <a href="1029.html">Bryan Moss: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1110.html">xgl: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1035">[ date ]</a>
<a href="index.html#1035">[ thread ]</a>
<a href="subject.html#1035">[ subject ]</a>
<a href="author.html#1035">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Bryan Moss wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I think Lanier makes some good points that are difficult to
</em><br>
<em>&gt; find in what is essentially a very confused essay.  The main
</em><br>
<em>&gt; thing we should take away from this is the questionable
</em><br>
<em>&gt; nature of AI as a goal, not because it is necessarily a bad
</em><br>
<em>&gt; goal but because, for me, it illuminates a bigger problem.
</em><br>
<em>&gt; After all, what is society but a fully autonomous system?
</em><br>
<em>&gt; And what external purpose does that system serve?  For me
</em><br>
<em>&gt; Lanier's essay was an affirmation of my own doubts about
</em><br>
<em>&gt; transhumanism.  Without a purpose we cannot architect our
</em><br>
<em>&gt; future, we need to discover the precise things we wish to
</em><br>
<em>&gt; preserve about ourselves and our society and only then can
</em><br>
<em>&gt; we go forward.  In my mind it is not enough to say &quot;I want
</em><br>
<em>&gt; to live forever&quot;; &quot;I&quot; is simply shorthand, I want to know
</em><br>
<em>&gt; what it is about me that I should preserve and why I should
</em><br>
<em>&gt; preserve it.  I think these problems run deep enough that
</em><br>
<em>&gt; we'll need more than polish.
</em><br>
<p>This is a very good analysis. I hope you send your comments to Lanier to see
<br>
what he thinks. 
<br>
<p><em>&gt;From my own point of view, this falls hand in hand with what I was saying in
</em><br>
another thread, questioning the preservation of life as the highest ethic.
<br>
Without both a purpose, and a standard of quality, life, society, and the
<br>
universe are pretty meaningless things. Modern liberal thinking typically posits
<br>
that there is no meaning or purpose to life as the basis for its moral
<br>
relativism, and this core conflict, I think, is why old and current day issues
<br>
are repeatedly debated and argued over here and in society in general. Others
<br>
say we shouldn't talk about current day issues, that this list is about making
<br>
the future, to which I reply that in order for us to make that future we need to
<br>
come to agreement over core facts and issues.
<br>
<p>If we accept that honest intelligent people will continue to disagree about
<br>
these things, then we do need to accept that while some people like Lanier many
<br>
not share OUR purposes or values, should they be allowed to oppress our
<br>
expression of our purpose and values?
<br>
<p>Essentially what Lanier is advocating for the future is technofascism (which is
<br>
also the goal of those in the Turningpoint Project), where one group gets to use
<br>
the government monopoly of force to force other groups from attaining their
<br>
technological goals merely because those in power fear those goals, not because
<br>
there is any actual threat. His implicit acceptance of the concept that AI
<br>
technology will replace 'real humanity' indicates the fearful root of this
<br>
fascism, they cannot conceive that AI will BE us. 
<br>
<p><em>&gt;From my own conversations with many common people about extropic and &gt;H
</em><br>
concepts, it seems to be universally accepted that an intelligent machine is not
<br>
'human', cannot be, and never will or should be regarded as 'human', even if the
<br>
intelligence once resided in a human body. This innate xenophobia I think is the
<br>
prime drive against transhuman technological trends. 
<br>
<p>Greg Bear's _Darwin's Radio_ got the level of this fear portrayed pretty good.
<br>
While his plot relied on endogenous retroviruses to trigger the next stage of
<br>
human evolution, and were confused for epidemic diseases, development of AI
<br>
technology will trigger a similar level of fear among the population. I feel
<br>
pretty secure predicting some sort of a 'Butlerian Jihad' (see Dune) against AI
<br>
technology. The only question is how significant and widespread it will be.
<br>
This, I think, will be determined memetically in the media by a propaganda war,
<br>
a war that is already started and which most transhumanists are blithely unaware
<br>
is now raging.
<br>
<p>Mike Lorrey
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1036.html">Jason Joel Thompson: "Re: Please throttle back your posting!"</a>
<li><strong>Previous message:</strong> <a href="1034.html">matthew gream: "Good reading material - books on global history"</a>
<li><strong>In reply to:</strong> <a href="1029.html">Bryan Moss: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1110.html">xgl: "Re: &quot;Cybernetic Totalism?&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1035">[ date ]</a>
<a href="index.html#1035">[ thread ]</a>
<a href="subject.html#1035">[ subject ]</a>
<a href="author.html#1035">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:17 MDT</em>
</em>
</small>
</body>
</html>
