<!-- received="Fri Sep 25 15:32:43 1998 MDT" -->
<!-- sent="Fri, 25 Sep 1998 16:39:49 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: AI big wins" -->
<!-- id="360C0D90.4C5F866A@pobox.com" -->
<!-- inreplyto="3.0.3.32.19980910101936.00b29c90@econ.berkeley.edu" -->
<!-- version=1.10, linesinbody=53 -->
<html><head><title>extropians: Re: AI big wins</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: AI big wins</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Fri, 25 Sep 1998 16:39:49 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2649">[ date ]</a><a href="index.html#2649">[ thread ]</a><a href="subject.html#2649">[ subject ]</a><a href="author.html#2649">[ author ]</a>
<!-- next="start" -->
<li><a href="2650.html">[ Next ]</a><a href="2648.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2645.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2653.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
Robin Hanson wrote:
<br>
<i>&gt; </i><br>
<a href="2645.html#2649qlink1">&gt; Eliezer S. Yudkowsky writes:</a><br>
<a name="2653qlink1"><i>&gt; &gt;&gt; Mere mention of the work "feedback" is not sufficient to argue for a sudden</i><br>
<i>&gt; &gt;&gt; and sustained acceleration in growth rates, which is what you seem to claim.</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt;I didn't just "mention" it; I talked about the behavior of the sum of the</i><br>
</a>
<i>&gt; &gt;series of I'1 = C(O, P, I), I'2 = C(P, O, I + I'1), I'3 = C(P, O, I + I'1 +</i><br>
<i>&gt; &gt;I'2), etc.  I don't see any realistic way to get steady progress from this</i><br>
<i>&gt; &gt;model.  Flat, yes, jumps, yes, but not a constant derivative.</i><br>
<i>&gt; </i><br>
<i>&gt; You just keep repeating your claim about the behavior of the sum, without</i><br>
<i>&gt; elaborating why one thing is more "realistic" than another.  If C is concave</i><br>
<i>&gt; in its third argument, you get subexponential growth.  If C is convex instead,</i><br>
<i>&gt; you get superexponential growth (which may still be very slow for a long time).</i><br>
<i>&gt; And lots of functions are neither concave nor convex.  Why is a strongly</i><br>
<i>&gt; convex C more realistic?</i><br>

<p>
You can't apply the same optimization trick over and over again; that's like
the old joke about compressing Usenet down to one byte with lossless
compression.  If optimization yields a small jump, then the next increment of
optimization is likely to be zero, since much the same method is being used. 
If optimization yields a big jump, one that translates into a substantial
amount of power freed up for intelligence, the AI is likely to redesign itself
in a fairly major way - from 1.1 to 2.0, or at least 1.0 to 1.1.  Major
repartitioning of the computational modules, and whatnot, which in turn is
likely to lead to a large jump in intelligence and optimization.

<p>
Now either these large steps keep repeating to superintelligence, or at some
point the AI can't redesign or optimize itself.  I don't believe in slow,
steady, improvement.  Debugging, yes.  But if you're talking about the slow
reworking of code, line by line, you're really talking about a large jump in
slow motion because the AI is slow - if the AI can rework a line of code well
enough to get improvement, without needing to add more intelligence, it's all
part of the same "increment", the same I' or O'.  If the partial reworking
adds even more intelligence, then the equation runs even faster.

<p>
Final remark:  Given the relative computational requirements of consciousness
and algorithmic thinking, and given the Principle of Mediocrity, and given the
relative linear speeds and the relative processing power compared to the human
brain, I would find it to be a remarkable coincidence if a major jump was
slowed down exactly enough that it looked like slow and steady improvement on
the human timescale, and not flat or vertical.  It might happen, because the
human programmers could be unable to work on things that happened on other
scales, but it wouldn't happen by coincidence.
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2650.html">[ Next ]</a><a href="2648.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2645.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2653.html">Robin Hanson</a>
</ul>
</body></html>
