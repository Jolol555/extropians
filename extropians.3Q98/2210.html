<!-- received="Mon Sep  7 22:22:32 1998 MDT" -->
<!-- sent="Mon, 07 Sep 1998 23:22:10 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="SITE:  Singularity Analysis" -->
<!-- id="35F4B0E8.9BBFB3A9@pobox.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=40 -->
<html><head><title>extropians: SITE:  Singularity Analysis</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>SITE:  Singularity Analysis</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 07 Sep 1998 23:22:10 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2210">[ date ]</a><a href="index.html#2210">[ thread ]</a><a href="subject.html#2210">[ subject ]</a><a href="author.html#2210">[ author ]</a>
<!-- next="start" -->
<li><a href="2211.html">[ Next ]</a><a href="2209.html">[ Previous ]</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>

<p>
Singularity Analysis
<br>
A Series of Educated Guesses

<p>
A few conclusions drawn from "Coding A Transhuman AI".
About 65K.

<p>
I tried to summarize from _Coding_, so you can hopefully follow along if
you're willing to take my word for a few summarized assertions.  Deep
understanding or persuasion probably requires that you bite the bullet and
read _Coding_.

<p>
I will post highlights as my response to some comments.

<p>
Current Table of Contents:


<OL>
  <li>  AI:  Human-equivalence and transhumanity. 
     Trajectory analysis:  Does human AI imply superhuman AI? 
     In response to:  Max More, Hanson. 
  <li>  Zone Barriers. 
     A canonical list of shields from the Singularity. 
     In response to:  Vernor Vinge, Nielsen. 
  <li>  Superintelligent motivations. 
     Mostly summarizes _Coding_'s sections on goals.  Some arguments. 
     Necessary to item 4. 
  <li>  Unknowability:  Evaporation of the human ontology. 
     The complexity barrier and the simplicity barrier. 
     In response to:  Damien Sullivan, Bostrum, Hanson, More, Nielsen.


</OL>
<p>
I don't plan to post from _Motivations_ or _Unknowability_.
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2211.html">[ Next ]</a><a href="2209.html">[ Previous ]</a>
<!-- nextthread="start" -->
</ul>
</body></html>
