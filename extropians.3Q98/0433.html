<!-- received="Wed Jul  8 11:24:06 1998 MDT" -->
<!-- sent="Wed, 8 Jul 1998 17:23:24 +0100" -->
<!-- name="Bryan Moss" -->
<!-- email="bryan.moss@dial.pipex.com" -->
<!-- subject="Re: The Singularity" -->
<!-- id="000001bdaa95$35f5eb80$d45995c1@bungle" -->
<!-- inreplyto="The Singularity" -->
<!-- version=1.10, linesinbody=83 -->
<html><head><title>extropians: Re: The Singularity</title>
<meta name=author content="Bryan Moss">
<link rel=author rev=made href="mailto:bryan.moss@dial.pipex.com" title ="Bryan Moss">
</head><body>
<h1>Re: The Singularity</h1>
Bryan Moss (<i>bryan.moss@dial.pipex.com</i>)<br>
<i>Wed, 8 Jul 1998 17:23:24 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#433">[ date ]</a><a href="index.html#433">[ thread ]</a><a href="subject.html#433">[ subject ]</a><a href="author.html#433">[ author ]</a>
<!-- next="start" -->
<li><a href="0434.html">[ Next ]</a><a href="0432.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0411.html">Dan Clemmensen</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0788.html">Eugene Leitl</a>
</ul>
<!-- body="start" -->

<p>
Dan Clemmensen wrote:

<p>
<a href="0411.html#0433qlink1">&gt; &gt; 2) Artificial Intelligence speeds up the</a><br>
<i>&gt; &gt; creation of more powerful computers and</i><br>
<i>&gt; &gt; intelligence’s. This seems wrong because</i><br>
<i>&gt; &gt; hardware and software power is already a major</i><br>
<i>&gt; &gt; factor in the increase of hardware and</i><br>
<i>&gt; &gt; software power. There is no reason to suggest</i><br>
<i>&gt; &gt; this trend would suddenly change.</i><br>
<i>&gt;</i><br>
<a name="0450qlink1"><i>&gt; Yes, computer hardware and software have been</i><br>
<i>&gt; contributing to the development of the next</i><br>
<i>&gt; generation of computre hardware and software,</i><br>
<i>&gt; but this is a relatively recent trend. Software</i><br>
<i>&gt; and hardware development productivity is</i><br>
<i>&gt; horrible, and IMO we are still taking baby</i><br>
<i>&gt; steps. A breakthrough is not unreasonable.</i><br>

<p>
But since the contribution is there it suggests
that catchall technologies like "artificial
intelligence" will be needed for software
developers to keep the current rate of growth in
software complexity. Where do you think a
breakthrough might come from?</a>

<p>
<a href="0411.html#0433qlink2">&gt; &gt; 3) A Super Intelligence emerges from a</a><br>
<i>&gt; &gt; distributed  network, such as the Internet.</i><br>
<i>&gt; &gt; I think this goes against current</i><br>
<i>&gt; &gt; network/software/hardware models and that a</i><br>
<i>&gt; &gt; distributed intelligence would only emerge</i><br>
<i>&gt; &gt; under certain (possibly engineered)</i><br>
<i>&gt; &gt; circumstances that current trends in hardware,</i><br>
<i>&gt; &gt; software and the economy would not support.</i><br>
<i>&gt;</i><br>
<i>&gt; In my personal model, the SI is not purely an</i><br>
<i>&gt; emergent phenomenon of the net. The net serves</i><br>
<i>&gt; as the raw material for a directed augmentation</i><br>
<i>&gt; of an initial proto-SI that first emerges as the</i><br>
<i>&gt; result of a catenation of a set of development</i><br>
<i>&gt; tools and a human programmer.</i><br>

<p>
<a name="0451qlink1">Creating any kind of universal intelligence would
be a massive task, even with genetic</a> algorithms
(which haven't had much success on large projects,
let alone human level intelligence). And if you're
expecting such an SI to "evolve" in the network
you would need to have a very specific environment
to get to display human-like qualities. This is
unlikely to happen without a large co-operative
effort to build the SI, which is unlikely due to
<a name="0451qlink2">risk factors, etc. Anyone with the kind of money
and resources necessary to pull off such a project
would have no obvious reason to do so.</a>

<p>
<a href="0411.html#0433qlink3">&gt; OK, let's take something very simple: Moore's</a><br>
<i>&gt; law. We all know that Moore's law is simply an</i><br>
<i>&gt; observation of a historical trend and cannot</i><br>
<i>&gt; be assumed to have any predictive power, but the</i><br>
<i>&gt; trend is quite robust and has already survived</i><br>
<i>&gt; through several technological generations.</i><br>
<i>&gt; Furthemore, it's fairly easy to see the next</i><br>
<i>&gt; several steps, getting us through the next 20</i><br>
<i>&gt; years without recourse to fundamental</i><br>
<i>&gt; breakthroughs.<a name="0450qlink2"> 20 years of Moore's law gains us</i><br>
<i>&gt; another factor of a million in each of several</i><br>
<i>&gt; computer capability parameters.</i><br>
<i>&gt;</i><br>
<i>&gt; Instead of asking a radical singulatarian such</i><br>
<i>&gt; as myself to comment, please allow me to ask you</i><br>
<i>&gt; to predict the effect of this level of computing</i><br>
<i>&gt; capacity on society.</i><br>

<p>
People will have smaller faster more intelligent
computers.</a>

<p>
<a name="0450qlink3">I think my real objection with the SI scenario is
the idea that people think intelligence must also
mean the ability to wake up one morning and decide
to wreak havoc on the mortals.

</a>
<p>
BM
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0434.html">[ Next ]</a><a href="0432.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0411.html">Dan Clemmensen</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0788.html">Eugene Leitl</a>
</ul>
</body></html>
