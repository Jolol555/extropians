<!-- received="Wed Sep 16 11:15:07 1998 MDT" -->
<!-- sent="Wed, 16 Sep 1998 10:11:06 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Singularity: Vinge responds" -->
<!-- id="3.0.3.32.19980916101106.00b76090@econ.berkeley.edu" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Singularity: Vinge responds</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Singularity: Vinge responds</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Wed, 16 Sep 1998 10:11:06 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2441">[ date ]</a><a href="index.html#2441">[ thread ]</a><a href="subject.html#2441">[ subject ]</a><a href="author.html#2441">[ author ]</a>
<!-- next="start" -->
<li><a href="2442.html">[ Next ]</a><a href="2440.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2437.html">Robin Hanson</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="2446qlink1">Vernor Vinge writes:
<br>
<a href="2437.html#2441qlink1">&gt;Notions of great change raise the vision of all sorts of things that</a><br>
<i>&gt;might be called a singularity. In the past, discussions of what I've</i><br>
<i>&gt;written about have more often than not spread out to things quite</i><br>
<i>&gt;different.</a></i><br>
<i>&gt;</i><br>
<i>&gt;Early on in this discussion I got my point distilled down to:</i><br>
<i>&gt;1. The creation of superhuman intelligence appears to be a plausible</i><br>
<i>&gt;   eventuality if our technical progress proceeds for another few</i><br>
<i>&gt;   years.</i><br>
<i>&gt;2. The existence of superhuman intelligence would yield forms of </i><br>
<i>&gt;   progress that are qualitatively less understandable than advances</i><br>
<i>&gt;   of the past.</i><br>
<i>&gt;</i><br>
<i>&gt;Given that, however, the form of the post-human environment is</i><br>
<i>&gt;not at all specified or restricted! I like speculation about it,</i><br>
<i>&gt;and I like to speculate about it (usually after acknowledging</i><br>
<i>&gt;that I shouldn't have any business doing so :-). The speculation</i><br>
<i>&gt;often leads to conflicting scenarios; some I regard as more</i><br>
<i>&gt;likely than others. But if they arise from the original point,</i><br>
<i>&gt;I feel they are relevant. ...</i><br>

<p>
O.K. Uncle.  It seems I was mistaken in my attempt to create a 
focused discussion on singularity by focusing on Vinge's concept
and analysis.  I incorrectly assumed that Vinge had in mind a specific 
enough concept of and analysis of singularity to hold discussants' 
attention.  In fact, by "singularity" Vinge seems to just mean 
"big changes will come when we get superhumans."  And while Vinge
has dramatic opinions about how soon this will happen and how fast
those changes will come afterward, these opinions are not part of 
his concept of "singularity", and he is not willing to elaborate
on or defend them.  

<p>
This seems analogous to Eric Drexler, who written extensively on 
nanotech, and privately expressed dramatic opinions about how soon 
nanotech will come and how fast change will then be, but who
has not to my knowledge publicly defended these opinions.  


<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-8614
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2442.html">[ Next ]</a><a href="2440.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2437.html">Robin Hanson</a>
<!-- nextthread="start" -->
</ul>
</body></html>
