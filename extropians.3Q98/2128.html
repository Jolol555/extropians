<!-- received="Fri Sep  4 16:11:04 1998 MDT" -->
<!-- sent="Fri, 04 Sep 1998 18:12:53 -0400" -->
<!-- name="Dan Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Beg your pardon? (Was: Teach the hungry)" -->
<!-- id="3.0.5.32.19980904181253.00a098b0@dgf4.mail.yale.edu" -->
<!-- inreplyto="35EFAE49.D4444763@ihug.co.nz" -->
<!-- version=1.10, linesinbody=239 -->
<html><head><title>extropians: Re: Beg your pardon? (Was: Teach the hungry)</title>
<meta name=author content="Dan Fabulich">
<link rel=author rev=made href="mailto:daniel.fabulich@yale.edu" title ="Dan Fabulich">
</head><body>
<h1>Re: Beg your pardon? (Was: Teach the hungry)</h1>
Dan Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Fri, 04 Sep 1998 18:12:53 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2128">[ date ]</a><a href="index.html#2128">[ thread ]</a><a href="subject.html#2128">[ subject ]</a><a href="author.html#2128">[ author ]</a>
<!-- next="start" -->
<li><a href="2129.html">[ Next ]</a><a href="2127.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2104.html">J. Maxwell Legg</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2131.html">J. Maxwell Legg</a>
</ul>
<!-- body="start" -->

<p>
J. Maxwell Legg wrote:
<br>
<a href="2104.html#2128qlink1">&gt;&gt; How is the existing ruler's Achilles heel exposed by m-w???</a><br>
<i>&gt;</i><br>
<i>&gt;Ask not "How" but "What". Is their reliance on figures and their notion that</i><br>
<i>&gt;effects always follow causes the limited creation of a future m-w magician?</i><br>

<p>
Many-worlds is deterministic, and accepts cause-and-effect.  The scientist
opens the box containing Schroedinger's cat and that *causes* the worlds to
split, then and there.

<p>
Here's relevant quotes from the FAQ you sent me:

<hr>

<p>
Q8   When does Schrodinger's cat split?
<hr>
<br>
Consider Schrodinger's cat.  A cat is placed in a sealed box with a
device that releases a lethal does of cyanide if a certain radioactive
decay is detected.  For simplicity we'll imagine that the box, whilst
closed, completely isolates the cat from its environment.  After a while
an investigator opens the box to see if the cat is alive or dead. 
According to the Copenhagen Interpretation the cat was neither alive nor
dead until the box was opened, whereupon the wavefunction of the cat
collapsed into one of the two alternatives (alive or dead cat).  The
paradox, according to Schrodinger, is that the cat presumably knew if
it was alive *before* the box was opened.  According to many-worlds the
device was split into two states (cyanide released or not) by the
radioactive decay, which is a thermodynamically irreversible process
(See "When do worlds split?" and "Why do worlds split?").  As the
cyanide/no-cyanide interacts with the cat the cat is split into two
states (dead or alive).  From the surviving cat's point of view it
occupies a different world from its deceased copy.  The onlooker is
split into two copies only when the box is opened and they are altered
by the states of the cat.

<p>
The cat splits when the device is triggered, irreversibly.  The
investigator splits when they open the box.  The alive cat has no idea
that investigator has split, any more than it is aware that there is a
dead cat in the neighbouring split-off world.  The investigator can
deduce, after the event, by examining the cyanide mechanism, or the
cat's memory, that the cat split prior to opening the box.

<p>
[snip]

<p>
Q19  Do worlds differentiate or split?
<hr>
<br>
Can we regard the separate worlds that result from a measurement-like
interaction (See "What is a measurement?") as having previous existed
distinctly and merely differentiated, rather than the interaction as
having split one world into many?  This is definitely not permissable
in many-worlds or any theory of quantum theory consistent with
experiment.  Worlds do not exist in a quantum superposition
independently of each other before they decohere or split.  The
splitting is a physical process, grounded in the dynamical evolution of
the wave vector, not a matter of philosophical, linguistic or mental
convenience (see "Why do worlds split?" and "When do worlds split?") 
If you try to treat the worlds as pre-existing and separate then the
maths and probabilistic behaviour all comes out wrong.  Also the
differentiation theory isn't deterministic, in contradiction to the wave
equations which are deterministic, since many-minds says that:

<pre>
  AAAAAAAAAAAAAAABBBBBBBBBBBBBBB         --------------&amp;#62; time
                                         (Worlds differentiate)
</pre>
  AAAAAAAAAAAAAAACCCCCCCCCCCCCCC

<p>
occurs, rather than:
<pre>
                 BBBBBBBBBBBBBBB
                B
  AAAAAAAAAAAAAA                         (Worlds split)
                C
                 CCCCCCCCCCCCCCC

</pre>
<p>
according to many-worlds.

<p>
This false differentiation model, at the mental level, seems favoured
by adherents of many-minds.  (See "What is many-minds?")

<p>
Q20  What is many-minds?
<hr>
<br>
Many-minds proposes, as an extra fundamental axiom, that an infinity of
separate minds or mental states be associated with each single brain
state.  When the single physical brain state is split into a quantum
superposition by a measurement (See "What is a measurement?") the
associated infinity of minds are thought of as differentiating rather
than splitting.  The motivation for this brain-mind dichotomy seems
purely to avoid talk of minds splitting and talk instead about the
differentiation of pre-existing separate mental states.  There is no
physical basis for this interpretation, which is incapable of an
operational definition.  Indeed the differentiation model for physical
systems is specifically not permitted in many-worlds.  Many-minds seems
to be proposing that minds follow different rules than matter.  (See "Do
worlds differentiate or split?")

<p>
In many-minds the role of the conscious observer is accorded special
status, with its fundamental axiom about infinities of pre-existing
minds, and as such is philosophically opposed to many-worlds, which
seeks to remove the observer from any privileged role in physics. 
(Many-minds was co-invented by David Albert, who has, apparently, since
abandoned it.  See Scientific American July 1992 page 80 and contrast
with Albert's April '94 Scientific American article.)

<p>
The two theories must not be confused.

<hr>

<p>
<a name="2137qlink1">What's more, unless you're proposing massively improbable violations of
thermodynamic laws, m-w doesn't allow for magicians: the worlds will remain
so far split that there is no chance that they will fuse in any way a
magician could use reliably.  Similarly, no magician in the future can
influence events in the past using many-worlds.
</a>

<p>
<a name="2137qlink2"><a href="2104.html#2128qlink2">&gt;I read accusations that S&amp;B operates in secret and assume this causes</a><br>
information
<br>
<a href="2104.html#2128qlink3">&gt;loss designed to stymie AI development.</a><br>

<p>
I'm actually beginning to understand you here, but not quite.  Does an AI
need *all* of our information in order to run a neuronomy?  Or just lots?
Why isn't lots sufficient?
</a>

<p>
<a name="2137qlink3"><a href="2104.html#2128qlink4">&gt;Why do I feel that your agenda is S&amp;B's?</a><br>

<p>
The Skull and Bones building is about a block away from where I live here
at Yale.  It is closed to outsiders.  Though you have no reason to believe
me, I happen to be fundamentally opposed to secret societies and their ilk,
for reasons that don't relate to this conversation.

</a>
<p>
<a href="2104.html#2128qlink5">&gt;&gt; Your view on how and why AI will be implemented will be my chance to have a</a><br>
<i>&gt;&gt; say in the making of new global politics?  Or will the AI itself and its</i><br>
<i>&gt;&gt; implementation be my chance to have a say in the making of global politics?</i><br>
<i>&gt;&gt;  You're not making any sense!  Please, I beg of you, for your sake and</i><br>
<i>&gt;&gt; mine, clearly identify your position in a way that doesn't allude to</i><br>
<i>&gt;&gt; another idea that you haven't already explained!</i><br>
<i>&gt;&gt;</i><br>
<i>&gt;</i><br>
<i>&gt;Answering a question with a question is your style not mine.</i><br>

<p>
To begin with, I didn't assert that you answered questions with questions,
so I don't understand why you're raising this point.  Moreover, this is an
abuse of the phrase.  I have replied to almost all of your questions with a
very particular question:  "I didn't understand your question.  Would you
please explain it?"

<p>
<i>&gt;Take the simpler</i><br>
<a href="2104.html#2128qlink6">&gt;proposition and see if it happens. Any AI that's better than what I</a><br>
foresee as a
<br>
<a href="2104.html#2128qlink7">&gt;global realization of a parallel implementation of Ingrid</a><br>
(grids-in-motion) would
<br>
<a href="2104.html#2128qlink8">&gt;get my support so either way you'll have your chance. BTW, do you know how</a><br>
many AI
<br>
<a href="2104.html#2128qlink9">&gt;implementations has S&amp;B scuttled? </a><br>

<p>
I don't know about *any* AI implementations that S&amp;B has scuttled.  They're
a secret society, for crying out loud!  They make it their prime objective
to prevent me (and you) from finding out about stuff like this.  :)

<p>
<a href="2104.html#2128qlink10">&gt;Why is Zapata making its move on the net?</a><br>

<p>
Cursed if I know.  A search for "zapata AND conspiracy" turned up nothing.  ;)

<p>
Anyway, if I were to take a wild flaming guess: it's because they think
that's where the money is.

<p>
<a href="2104.html#2128qlink11">&gt;Try "George Kelly Ingrid" or better still search for a course on how to</a><br>
search.
<br>
<a href="2104.html#2128qlink12">&gt;(Sorry, but you're asking for trouble by not doing enough for yourself.)</a><br>

<p>
I do *plenty* for myself.  There's a limited amount of effort I'm willing
to exert in order to understand what you happen to think, however.  :)

<p>
<a name="2137qlink4">Anyway, if I follow you correctly, Ingrid is an attempt to automate and
coordinate the distribution of personal construct grids, yes?  In doing so,
a simply written program could coordinate the whole of human behavior if it
had access to enough/ the right grids.  Am I on the right track?
</a>

<p>
<a href="2104.html#2128qlink13">&gt;Since I first used Ingrid, I can't express how hard it is to put my</a><br>
vaporware into
<br>
<a href="2104.html#2128qlink14">&gt;english. My brain now rapidly construes in grids and as yet has no user</a><br>
friendly
<br>
<a href="2104.html#2128qlink15">&gt;semantic interface, but don't worry, I'm getting closer to finding a way</a><br>
out of
<br>
<a href="2104.html#2128qlink16">&gt;this high dimensional dilemma.</a><br>

<p>
I can see how this would pose problems. :)  Might I reccomend Strunk &amp;
White's _Elements of Style_?  The rules laid out there are a little bit too
difficult for most of today's AI but aren't too difficult for most people I
know.

<p>
<a href="2104.html#2128qlink17">&gt;&gt; Here's my essential problem: I have no idea what sort of system you're</a><br>
<i>&gt;&gt; proposing.  The impression I get is that it involves neural nets</i><br>
<i>&gt;&gt; intimately, but you haven't yet explained how, beyond the idea that the net</i><br>
<i>&gt;&gt; itself would be running the show.</i><br>
<i>&gt;</i><br>
<i>&gt;I didn't ever say the net would be running the show; - you did.</i><br>

<p>
And you tentatively affirmed what I said.

<p>
<a href="2104.html#2128qlink18">&gt;In practice the</a><br>
<i>&gt;adopted set of decentralized plans will be running the show and continuos</i><br>
feedback
<br>
<a href="2104.html#2128qlink19">&gt;will adjust those plans without today's delays and incompatibilities. Only</a><br>
private
<br>
<a href="2104.html#2128qlink20">&gt;plotting that keeps destroying the messengers can stop the development of</a><br>
a global
<br>
<a href="2104.html#2128qlink21">&gt;governance based on artificial intelligence.</a><br>

<p>
You continue to assert that AI needs all the info, or as much as possible
in order to work.  We humans function alright (if suboptimally) with
incomplete information; it seems to me that an AI that required complete
information before it would work would be effectively crippled, spending
its time on a quixotic quest for all the information it needs to solve the
problem.

<p>
Indeed, I'm now beginning to see some of those paralells between capitalism
and thermodynamics that Clark was alluding to: simply the act of trying to
find out everything costs money; trying to improve the efficiency of the
whole economy by observing the whole economy and dictating its behavior
leads to less efficiency than just letting the people organize themselves
and remaining in rational ignorance.

<p>
<a name="2153qlink1"><a href="2104.html#2128qlink22">&gt;Let's look at something else for a change. Caesar, Lincoln and Kennedy</a><br>
according
<br>
<a href="2104.html#2128qlink23">&gt;to what I know were assassinated for wanting to print debt free money; - a</a><br>
big
<br>
<a href="2104.html#2128qlink24">&gt;mistake. Will a simple treaty proposal calling for synaptic links to be</a><br>
mandatory
<br>
<a href="2104.html#2128qlink25">&gt;in all new software releases usher in a new round of assassinations? I am</a><br>
making
<br>
<a href="2104.html#2128qlink26">&gt;such a proposal right now.</a><br>
<i>&gt;</i><br>
<a name="2137qlink5"><i>&gt;<a href="http://listen.to/jimekus">http://listen.to/jimekus</a></i><br>

<p>
The link to assassination politics on this page is broken...  Do you know
of any mirrors?
</a>

<p>
<a name="2153qlink2">As to the point about assassinations, I'd not heard this particular theory
before.  From whom/where did you hear this?
</a>
</a>

<p>
              -TODAY IS A GOOD DAY TO LIVE-
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2129.html">[ Next ]</a><a href="2127.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2104.html">J. Maxwell Legg</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2131.html">J. Maxwell Legg</a>
</ul>
</body></html>
