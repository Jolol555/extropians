<!-- received="Thu Jul  2 09:44:46 1998 MDT" -->
<!-- sent="02 Jul 1998 17:44:41 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: The AI revolution" -->
<!-- id="b497m1ww93q.fsf@void.nada.kth.se" -->
<!-- inreplyto="Thu, 2 Jul 1998 09:19:39 -0600" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Re: The AI revolution</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: The AI revolution</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>02 Jul 1998 17:44:41 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#69">[ date ]</a><a href="index.html#69">[ thread ]</a><a href="subject.html#69">[ subject ]</a><a href="author.html#69">[ author ]</a>
<!-- next="start" -->
<li><a href="0070.html">[ Next ]</a><a href="0068.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0067.html">Brent Allsop</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0168.html">Hara Ra</a>
</ul>
<!-- body="start" -->

<p>
Brent Allsop &lt;allsop@swttools.fc.hp.com&gt; writes:

<p>
<a href="0067.html#0069qlink1">&gt; Hara Ra &lt;harara@shamanics.com&gt; commented about Anders reference to</a><br>
<i>&gt; Asimov's laws for robots:</i><br>
<i>&gt; </i><br>
<i>&gt; &gt; So, what if a robot has this choice:</i><br>
<i>&gt; &gt; </i><br>
<i>&gt; &gt;         Kill someone, and allow 100 others to live, or</i><br>
<i>&gt; &gt;         not kill, and allow the 100 others to die.</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt; This would probably immobilize the robot, which is the worst choice,</i><br>
<i>&gt; &gt; so the Zero'th Law is:</i><br>
<i>&gt; </i><br>
<i>&gt; 	I would think that robots simply be subject to the same laws</i><br>
<i>&gt; (or law) that we all try to adhear to.  And that is simply to do the</i><br>
<i>&gt; best possible.  Part of that law is, to rationally reason and figure</i><br>
<i>&gt; out what that best possible is as best as is possible.</i><br>

<p>
<a name="0168qlink1">But what is best? You have to supply the robot with valuations in
order to have this kind of reasoning. Asimov's laws have the advantage
of being clear what a robot may and may not do, and do not require
open ended reasoning ("... but if I save him, what if he is a killer?
But if he is a killer...").</a> 

<p>
<a href="0067.html#0069qlink2">&gt;  I think a</a><br>
<a name="0168qlink2"><i>&gt; robot could logically calculate that a person living is better than a</i><br>
<i>&gt; person dieing and by induction that 100 people living and only one</i><br>
<i>&gt; dieing is better than one person living and 100 dieing.</i><br>

<p>
This kind of reasoning was most likely too unconstrained for Asimov or
his contemporaries - or anybody building a robot today. Imagine the
litigation if your robot does something that leads to the death of
somebody, and it is not possible to show that this was a clear logical
results of the laws of robotics. People would feel much more at home
with a robot that simply couldn't harm them due to the first law, than
a robot that just *might* harm them because it had deduced that it was
for the best due to some obscure twist of logic.</a>

<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0070.html">[ Next ]</a><a href="0068.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0067.html">Brent Allsop</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0168.html">Hara Ra</a>
</ul>
</body></html>
