<!-- received="Fri Sep 11 17:11:57 1998 MDT" -->
<!-- sent="Fri, 11 Sep 1998 18:18:50 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Singularity: Human AI to superhuman" -->
<!-- id="35F9AFAE.474A4C4D@pobox.com" -->
<!-- inreplyto="Singularity: Human AI to superhuman" -->
<!-- version=1.10, linesinbody=65 -->
<html><head><title>extropians: Re: Singularity: Human AI to superhuman</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Singularity: Human AI to superhuman</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Fri, 11 Sep 1998 18:18:50 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2311">[ date ]</a><a href="index.html#2311">[ thread ]</a><a href="subject.html#2311">[ subject ]</a><a href="author.html#2311">[ author ]</a>
<!-- next="start" -->
<li><a href="2312.html">[ Next ]</a><b>In reply to:</b> <a href="2310.html">Robin Hanson</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Robin Hanson wrote:
<br>
<i>&gt; </i><br>
<a href="2310.html#2311qlink1">&gt; The idea was to have Vinge here to flesh out and defend his claims.</a><br>
<i>&gt; If he can't or won't, then I would be content to at least create a consensus</i><br>
<i>&gt; that he hasn't supported his vision with a coherent analysis.</i><br>

<p>
Vinge is _busy_.  If _I_ support his vision with a coherent analysis, that
counts too.  One of the ideas behind a colloquium is that you don't have to
defend every single tiny point someone else doesn't like, just the ones that
stump your supporters or for which your supporters give unsatisfactory arguments.

<p>
<a href="2310.html#2311qlink2">&gt; Your analysis seems to me to be based on unusual enough assumptions that it</a><br>
<i>&gt; can't really stand for what Vinge probably meant, but didn't get around to</i><br>
<i>&gt; saying.  It also seems opaque enough that in discussing it, one spends more</i><br>
<i>&gt; time trying to understand Eliezer's concept of singularity, rather than</i><br>
<i>&gt; Vinge's.</i><br>

<p>
Ah, now we come to a major point of dispute.  For you, the Singularity is a
concept in Vinge's mind.  It gets analyzed as a concept.  The criteria of
discussion is how neat a concept it is.  Coherent discussion requires that we
discuss only Vinge's concept and not everyone else's, because a controversial
concept becomes incoherent when spread across multiple minds.

<p>
For me, the Singularity is a real event that happens to a civilization.  Our
conceptions of it are irrelevant except insofar as they accurately describe
real events.  My description of a seed AI is detailed, but if the Singularity
actually occurs via neurological enhancement, then both my description and the
conclusions I draw are totally irrelevant, no matter how rational they may
have seemed at the time.  To me, Vinge isn't the person who invented the
Singularity, he's the person who noticed it.  And the Singularity certainly
isn't just a concept in Vinge's mind!

<p>
<a href="2310.html#2311qlink3">&gt; &gt;... what _you_ (Hanson) originally</a><br>
<i>&gt; &gt;asked is whether the concept of a Singularity was flawed.</i><br>
<i>&gt; </i><br>
<i>&gt; I asked about *Vinge's* singularity concept, exactly to avoid this elephant</i><br>
<i>&gt; that becomes all things to all people.</i><br>

<p>
Well, there you go.  I'm asking about *Earth's* Singularity.

<p>
Facts about Earth are accessible to this discussion.  Facts about Vinge aren't
accessible unless he wants to waste a lot of time.  What wouldst thou of me? 
That I present a detailed deconstruction of Vinge's mind when he thinks about
the Singularity?  Supposing that I succeeded and supposing that Vinge didn't
punch me in the nose, how would we have significantly advanced the knowledge
of humanity?

<p>
My conception of the Singularity is recognizably an instance of Vinge's
concept:  It has unknowability, greater than human intelligence, and changes
in the basic rules - with positive feedback as a fourth principle.  If this
instance is rationally acceptable, so is the Singularity.  If this instance is
rationally flawed, the reasons (e.g. "no big wins in intelligence") will
probably generalize to any version of the Singularity.  Most high-level flaws
in Vinge's Singularity would apply to Eliezer's Singularity, and maybe even
vice versa.  So again, what's the problem?

<p>
I'm not sure what you're asking me to say or do.  I mean, specifically.  I
think you're asking for debate on a level that can't be rationally debated.
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2312.html">[ Next ]</a>
<b>In reply to:</b> <a href="2310.html">Robin Hanson</a>
<!-- nextthread="start" -->
</ul>
</body></html>
