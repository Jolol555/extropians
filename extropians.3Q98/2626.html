<!-- received="Thu Sep 24 18:33:55 1998 MDT" -->
<!-- sent="Thu, 24 Sep 1998 19:41:07 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: AI big wins" -->
<!-- id="360AE685.8E13721F@pobox.com" -->
<!-- inreplyto="3.0.3.32.19980910101936.00b29c90@econ.berkeley.edu" -->
<!-- version=1.10, linesinbody=54 -->
<html><head><title>extropians: Re: AI big wins</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: AI big wins</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Thu, 24 Sep 1998 19:41:07 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2626">[ date ]</a><a href="index.html#2626">[ thread ]</a><a href="subject.html#2626">[ subject ]</a><a href="author.html#2626">[ author ]</a>
<!-- next="start" -->
<li><a href="2627.html">[ Next ]</a><a href="2625.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2624.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2636.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
Robin Hanson wrote:
<br>
<i>&gt; </i><br>
<a name="2636qlink1"><a href="2624.html#2626qlink1">&gt; "I think a more realistic model is" is not a sufficiently detailed argument.</a><br>
<i>&gt; for t' = a*e^(b*(t+c)).  And even accepting this form, substantial growth</i><br>
<i>&gt; could still take centuries, depending on the values of a,b,c.</i><br>
<i>&gt; </i><br>
<i>&gt; Your argument here seems awfully close to the claim that "the doubling time</i><br>
<i>&gt; of computer hardware efficiency is proportional to the computer operations</i><br>
<i>&gt; per second devoted to R&amp;D in computer hardware, or within all of computer-aided</i><br>
<i>&gt; `humanity.'"</i><br>

<p>
If you mean with the t' = e^t, I agree absolutely that it's just as worthless
as the Argument from Moore's Law; it's a simple analogy, having none of the
reductionistic detail that's needed for a realistic discussion of AI
trajectories.  As you recall, my actual analysis clamped power at an arbitrary
value and treated strictly with optimization and intelligence.  Obviously, I
don't think that Moore's Law, or for that matter any simple equation for
growth rates, is of real value.

<p>
Can we return to the ABC/POI discussion now?  Focus on the technical
discussion, not the immoderate speculations &lt;grin&gt;.  But seriously, what about
the feedback into the system, which is my main argument?
</a>

<p>
<a href="2624.html#2626qlink2">&gt; If you recall, this was my summary of the assumption behind an</a><br>
<i>&gt; analysis from a web page of yours, and I gave specific empirical criticisms</i><br>
<i>&gt; of it.  You have not yet responded to them.</i><br>

<p>
Sure I did.  I responded by saying that I renounced, repented, and abjured the
substance if not the spirit - that the whole Argument from Moore's Law was
fundamentally worthless - which didn't seem to be exactly what you wanted.  Sigh.

<p>
<a name="2636qlink2"><a href="2624.html#2626qlink3">&gt; There really is a rich economic growth literature on when various equations</a><br>
<i>&gt; like this describe different growing systems, including intelligent systems.</i><br>
<i>&gt; Growth depends on many factors, and just because a previously fixed factor is</i><br>
<i>&gt; allowed to grow, that doesn't mean growth suddenly explodes.</i><br>

<p>
"Intelligence is not a factor, it is the equation itself."  You've never
responded to my basic assertion, which is that sufficient intelligence (which
is probably achievable) suffices for nanotech; which in turn suffices to turn
the planet into a computer; which in turn counts as "explosive growth" by my
standards.  It's difficult to see how the literature on the rise of
agriculture relates...

<pre>
"Sufficient" = Wili Wachendon with a headband.
"Achievable" = The end of my seed AI's trajectory, running on 10^13 ops.
"Nanotech"   = What Drexler said in _Engines of Creation_.
</a>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
</pre>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2627.html">[ Next ]</a><a href="2625.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2624.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2636.html">Robin Hanson</a>
</ul>
</body></html>
