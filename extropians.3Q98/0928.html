<!-- received="Tue Jul 21 17:34:51 1998 MDT" -->
<!-- sent="Tue, 21 Jul 1998 16:30:58 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: The Singularity" -->
<!-- id="3.0.3.32.19980721163058.0072e618@econ.berkeley.edu" -->
<!-- inreplyto="199807212058.NAA00546@hal.sb.rain.org" -->
<!-- version=1.10, linesinbody=43 -->
<html><head><title>extropians: Re: The Singularity</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: The Singularity</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Tue, 21 Jul 1998 16:30:58 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#928">[ date ]</a><a href="index.html#928">[ thread ]</a><a href="subject.html#928">[ subject ]</a><a href="author.html#928">[ author ]</a>
<!-- next="start" -->
<li><a href="0929.html">[ Next ]</a><a href="0927.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0921.html">Hal Finney</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0929.html">Damien R. Sullivan</a>
</ul>
<!-- body="start" -->

<p>
Hal Finney writes:
<br>
<a href="0921.html#0928qlink1">&gt;On reflection, though, it seems that it may be an oversimplification</a><br>
<i>&gt;to say that insects have no understanding of humans.  The issue is</i><br>
<i>&gt;complicated by the fact that insects probably have no "understanding"</i><br>
<i>&gt;at all, as we use the term.  They may not even be conscious, ...</i><br>
<i>&gt;Obviously insects do not predict many aspects of human behavior.  Still,</i><br>
<i>&gt;in terms of the level of detail that they attempt to capture, I'd say</i><br>
<i>&gt;they are reasonably effective.  ...</i><br>
<i>&gt;We may be as ants to the post singularity intelligences, but even so,</i><br>
<i>&gt;we may be able to successfully predict some aspects of their behavior,</i><br>
<i>&gt;just as ants are able to do with humans.</i><br>

<p>
A nice analysis Hal.  

<p>
What seems more disturbing about the human ant analogy is that humans have
little use for ants, usually killing them off when feasible, exactly 
because of limited expressiveness of ant models.   If we could tell ants
"If you pick up the dust within this chalked area, we'll give you this 
cup of syrup," we'd love ants, and their future would be assured for a 
long time to come.  It's not that ants couldn't do this, but more that
they don't have an interface that let's us ask them to do it.

<p>
Pieces of software code are usually much dummer than ants, but their
future seems brighter because they have relatively general interfaces. 
They can sit in libraries, and much smarter creatures can put them to use
as desired, flexibly connecting them to other code chunks.  We can know
what they do and tell them to do it when desired.  They rarely have 
problems understanding what we tell them, because we don't bother to tell
them anything we don't think they can understand.

<p>
It seems to me that human interfaces are flexible and general enough
that if transhumans find them useless, it wouldn't be because someone 
couldn't tell us what it is they wanted done that we could do.  It would
more likely be because we just couldn't do it, or couldn't do it as 
cheaply as some competitor.  



<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-2627
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0929.html">[ Next ]</a><a href="0927.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0921.html">Hal Finney</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0929.html">Damien R. Sullivan</a>
</ul>
</body></html>
