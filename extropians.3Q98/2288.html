<!-- received="Thu Sep 10 22:58:29 1998 MDT" -->
<!-- sent="Fri, 11 Sep 1998 00:55:56 -0400" -->
<!-- name="John Clark" -->
<!-- email="jonkc@worldnet.att.net" -->
<!-- subject="Re: Singularity: Human AI to superhuman" -->
<!-- id="001901bddd40$b1aa10c0$13934d0c@flrjs" -->
<!-- inreplyto="Singularity: Human AI to superhuman" -->
<!-- version=1.10, linesinbody=58 -->
<html><head><title>extropians: Re: Singularity: Human AI to superhuman</title>
<meta name=author content="John Clark">
<link rel=author rev=made href="mailto:jonkc@worldnet.att.net" title ="John Clark">
</head><body>
<h1>Re: Singularity: Human AI to superhuman</h1>
John Clark (<i>jonkc@worldnet.att.net</i>)<br>
<i>Fri, 11 Sep 1998 00:55:56 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2288">[ date ]</a><a href="index.html#2288">[ thread ]</a><a href="subject.html#2288">[ subject ]</a><a href="author.html#2288">[ author ]</a>
<!-- next="start" -->
<li><a href="2289.html">[ Next ]</a><a href="2287.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2271.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2305.html">Robin Hanson</a>
</ul>
<!-- body="start" -->

<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1

<p>
 Robin Hanson &lt;hanson@econ.berkeley.edu&gt; Wrote:

<p>
<a href="2271.html#2288qlink1">&gt;If most of AI progress comes from a half dozen big win insights, then you</a><br>
<i>&gt;should be able to write them all down on one short page.  Anyone who read and</i><br>
<i>&gt;understood that page would be nearly as good an AI programmer as anyone else.</i><br>
<i>&gt;This is very far from the case, suggesting the importance of lots of little</i><br>
<a name="2305qlink1"><i>&gt;insights which require years of reading and experience to accumulate.</i><br>


<p>
That's a good point but the question remains,  even if a billion small
insights are needed what happens if their rate of discovery increases
astronomically?

</a>
<p>
By the way, does anybody know how Lenat is doing on his CYC project?
I haven't heard much about it lately?


<p>
<a href="2271.html#2288qlink2">&gt;there hasn't been much human genetic evolution over the last 50K years!</a><br>

<p>
True.

<p>
<a name="2305qlink2"><a href="2271.html#2288qlink3">&gt;There has been *cultural* evolution, but cultural evolution is Lamarkian.</a><br>

<p>
Yes but the distinction between physical and cultural evolution would
evaporate for an AI, it would all be Lamarkian and that's why it would
change so fast.</a> And artificial intelligence is only one path toward the
singularity, another is Nanotechnology, perhaps another is Quantum
Computers, and you only need one path to go somewhere.


<p>
<a href="2271.html#2288qlink4">&gt;There many have been breakthroughs within "short" times, though these times</a><br>
<i>&gt;were only "short" when compared to a million years.</i><br>


<p>
And the singularity may seem like a slow steady deliberate process when our
super fast electronic successors look back on it, but that's not the way it will
seem to us when we live through it, or die in it.

<p>
    John K Clark     jonkc@att.net





<p>
-----BEGIN PGP SIGNATURE-----
<br>
Version: PGP for Personal Privacy 5.5.5

<p>
iQA/AwUBNfitXN+WG5eri0QzEQK0jACgry3TY7i3x8q+SzkxFjPv/7V32sAAnAhp
ztb+nH+h4uMXDPe72uhUWI/n
<br>
=ydx2
<br>
-----END PGP SIGNATURE-----
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2289.html">[ Next ]</a><a href="2287.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2271.html">Robin Hanson</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2305.html">Robin Hanson</a>
</ul>
</body></html>
