<!-- received="Tue Jul 14 19:16:45 1998 MDT" -->
<!-- sent="Tue, 14 Jul 1998 21:16:34 -0400 (EDT)" -->
<!-- name="Daniel Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Ethics" -->
<!-- id="Pine.GSO.3.94.980714203801.21919B-100000@mars.its.yale.edu" -->
<!-- inreplyto="19980714194430.22354.rocketmail@send1e.yahoomail.com" -->
<!-- version=1.10, linesinbody=64 -->
<html><head><title>extropians: Re: Ethics</title>
<meta name=author content="Daniel Fabulich">
<link rel=author rev=made href="mailto:daniel.fabulich@yale.edu" title ="Daniel Fabulich">
</head><body>
<h1>Re: Ethics</h1>
Daniel Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Tue, 14 Jul 1998 21:16:34 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#684">[ date ]</a><a href="index.html#684">[ thread ]</a><a href="subject.html#684">[ subject ]</a><a href="author.html#684">[ author ]</a>
<!-- next="start" -->
<li><a href="0685.html">[ Next ]</a><a href="0683.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0677.html">Joe Jenkins</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
On Tue, 14 Jul 1998, Joe Jenkins wrote:

<p>
<a href="0677.html#0684qlink1">&gt; We both agree that the best known strategy for iterated Prisoners</a><br>
<i>&gt; Dilemma is "tit for tat" for both egoism and utilitarianism.  I know</i><br>
<i>&gt; Prisoners Dilemma is a well developed field of study and we both agree</i><br>
<i>&gt; it can be a useful tool for evaluating ethics philosophies.  Although,</i><br>
<i>&gt; I never understood what Richard Dawkins was getting at in "The Selfish</i><br>
<i>&gt; Gene" when he commented that he does not advocate the use of Prisoners</i><br>
<i>&gt; Dilemma to develop a system of ethics.  Maybe he was referring to the</i><br>
<i>&gt; mismatch with a lot of real word situations.  Anyway, if ethics is to</i><br>
<i>&gt; be rational, IMHO game theoretics allows a more critical evaluation</i><br>
<i>&gt; than any other I know of.  We must have a leg to stand on even if it</i><br>
<i>&gt; is a little shaky.  Thats why its still a philosophy.</i><br>

<p>
In general, this is referred to as the "naturalistic" fallacy.  Basically,
it is a fallacy to presume that just because we have evolved some system
of ethics, it must be right.  By this argument, we could just as easily
operate entirely on instinct, which is more evolved (in the biological
sense) than logic, which may only have been around since Aristotle.  I
must agree, however, that he has made a mistake when he associates game
theory and the naturallistic fallacy: it is an entirely different argument
to say that we should agree on an ethical system which HAS evolved and to
say that we should agree on an ethical system which MUST evolve given
certain realistic presumptions. 

<p>
I personally see such simulations as part of the practical part the
answer, telling us more about what we ought to do within an ethical system
than defining the system itself.  I only mention it here because it is not
intuitively obvious that the game should have such a successful strategy
in the iterated version (which is what most of us play most of the time)
and the non-iterated version.  As I've already noted, consequentialism and
the generalization principle, which states that a rational system for one
person must also be rational for another person, together provide an
excellent argument for utilitarianism without these simulations. 
 
<p>
<a href="0677.html#0684qlink2">&gt; You have stated that non-iterated Prisoners dilemma does not render</a><br>
<i>&gt; evolutionarily stable systems.  Intuitively, this does not play well</i><br>
<i>&gt; between my ears.  But even if so (assuming you've seen the results of</i><br>
<i>&gt; some computer simulation), again intuitively, would not some</i><br>
<i>&gt; strategies be better than others in this game.  I would bet on a "tit</i><br>
<i>&gt; for tat" strategy before going all out with "always cooperate"</i><br>
<i>&gt; (utilitarianism) or "always defect" (egoism) even if I'm</i><br>
<i>&gt; non-rationally "tit"ing this guy because that other guy "tat"ed me.  I</i><br>
<i>&gt; can see "always cooperate" as the best strategy only in utopia which</i><br>
<i>&gt; we both agree does not exist. Oh logic where have I failed thee.</i><br>

<p>
They will all become Defectors if you try it.  Think: If a Tit for Tat
(TfT) plays against a Defector, TfT will defect on the next round.  If it
happens to defect against another TfT, the first TfT will cooperate on the
next round, but the second TfT will defect on the next round.  No matter
how many TfTs there are, one of them will always defect on the next round.
Worse, the number of TfTs who will defect on the next round increases
every time a TfT who intends to cooperate plays against a Defector.  When
any number of Defectors play against x TfTs, all x of the TfTs will always
defect after x games between a TfT and a Defector in which the TfT
cooperates while the Defector defects. 

<p>
<a name="0727qlink1">Anyway, this game is especially obvious in the version I originally
posted, the situation under which the prisoners, though known to each
other, will never play again.  In that case egoism absolutely</a> demands that
<a name="0727qlink2">both players defect; despite the fact that it results in suboptimal
consequences.
</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0685.html">[ Next ]</a><a href="0683.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0677.html">Joe Jenkins</a>
<!-- nextthread="start" -->
</ul>
</body></html>
