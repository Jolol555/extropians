<!-- received="Thu Jul  2 01:02:10 1998 MDT" -->
<!-- sent="Wed, 01 Jul 1998 23:32:19 -0700" -->
<!-- name="Hara Ra" -->
<!-- email="harara@shamanics.com" -->
<!-- subject="Re: The AI revolution" -->
<!-- id="Version.32.19980701232254.00e4fea0@mail.scruznet.com" -->
<!-- inreplyto="b49g1gtdfqr.fsf@void.nada.kth.se" -->
<!-- version=1.10, linesinbody=47 -->
<html><head><title>extropians: Re: The AI revolution</title>
<meta name=author content="Hara Ra">
<link rel=author rev=made href="mailto:harara@shamanics.com" title ="Hara Ra">
</head><body>
<h1>Re: The AI revolution</h1>
Hara Ra (<i>harara@shamanics.com</i>)<br>
<i>Wed, 01 Jul 1998 23:32:19 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#55">[ date ]</a><a href="index.html#55">[ thread ]</a><a href="subject.html#55">[ subject ]</a><a href="author.html#55">[ author ]</a>
<!-- next="start" -->
<li><a href="0056.html">[ Next ]</a><b>Maybe in reply to:</b> <a href="0055.html">Hara Ra</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0056.html">Anders Sandberg</a>
</ul>
<!-- body="start" -->

<p>
Anders:
<br>
<i>&gt;(This reminds me of the "zeroth law of robotics" some of Asimov's</i><br>
<i>&gt;robots came up with, although the logical reasoning behind it remains</i><br>
<i>&gt;unclear to me).</i><br>

<p>
<a name="0056qlink1">Asimov invented the Three Laws as a device by which conflicts could be
created for his robot stories. A case of simple statements leading to
impossibly complex results.</a> The Laws (as I remember them 30 years later,
feel free to correct me) are:


<OL>
  <li>  A robot may not harm a human being, nor through inaction
   cause a human being to come to harm.

  <li>  A robot must obey all orders from a human being except those
   which conflict with the First Law.

  <li>  A robot must protect its existence except when it conflicts
   with the First or Second Laws.


</OL>
<p>
<a name="0068qlink1"><a name="0067qlink1"><a name="0056qlink2">So, what if a robot has this choice:</a>

<pre>
	Kill someone, and allow 100 others to live, or
	not kill, and allow the 100 others to die.

</pre>
<p>
<a name="0068qlink2">This would probably immobilize the robot, which is the worst choice,
so the Zero'th Law</a> is:
</a>

<p>
<a name="0068qlink3">0. A robot, when faced with a choice which results in harm,</a>
<p>
   chooses the one resulting in the least harm.</a>

<p>
<a name="0056qlink3">Implied is that this Law overrides the other three; that the phrase
"except when in conflict with the Zero'th Law" is added to the first
3 Laws.</a>



<pre>
O--------------------------------O 
| Hara Ra &lt;harara@shamanics.com&gt; | 
| Box 8334 Santa Cruz, CA 95061  |
|                                |
| Death is for animals;          |
| immortality for gods.          |
| Technology is the means by     |
</pre>
<br>
| which we make the transition.  |
<pre>
O--------------------------------O
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0056.html">[ Next ]</a><b>Maybe in reply to:</b> <a href="0055.html">Hara Ra</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0056.html">Anders Sandberg</a>
</ul>
</body></html>
