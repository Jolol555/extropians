<!-- received="Mon Aug 10 22:12:21 1998 MDT" -->
<!-- sent="11 Aug 1998 04:11:52 -0000" -->
<!-- name="edward worthington" -->
<!-- email="edwardworth@supernews.com" -->
<!-- subject="Re: 5,000,000,000 transhumans?" -->
<!-- id="19980811041152.24492.qmail@usenet63.supernews.com" -->
<!-- inreplyto="5,000,000,000 transhumans?" -->
<!-- version=1.10, linesinbody=13 -->
<html><head><title>extropians: Re: 5,000,000,000 transhumans?</title>
<meta name=author content="edward worthington">
<link rel=author rev=made href="mailto:edwardworth@supernews.com" title ="edward worthington">
</head><body>
<h1>Re: 5,000,000,000 transhumans?</h1>
edward worthington (<i>edwardworth@supernews.com</i>)<br>
<i>11 Aug 1998 04:11:52 -0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1367">[ date ]</a><a href="index.html#1367">[ thread ]</a><a href="subject.html#1367">[ subject ]</a><a href="author.html#1367">[ author ]</a>
<!-- next="start" -->
<li><a href="1368.html">[ Next ]</a><a href="1366.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1297.html">Max More</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
I do not belive that all humans will become transhumans, I belive that the population will not allow power hungry egotistical maniacs to have transhuman benefits. I know I would not like having Sadam Heussian have life extenstion and super intelligance, that would make him an even more threat. So I belive that only Over Intelligant Responsiable Healthy people will be able to become Transhuman because people will not want having anyone abuse there transhuman power.


<p>
On Sun, 09 Aug 1998 12:09:06 -0700, extropians@extropy.com wrote:
<br>
<a href="1297.html#1367qlink1">&gt; At 01:37 PM 8/9/98 +0200, Den Otter wrote:&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;Yes, but this is fundamentally different; godhood isn't something&lt;br&gt;&gt; &gt;that one would sell (or give away) like one would do with minor&lt;br&gt;&gt; &gt;technological advances such as phones, TVs cars etc. Just like nukes&lt;br&gt;&gt; &gt;were (and are) only for a select few, so will hyperintelligence, &lt;br&gt;&gt; &gt;nanotech, uploading etc. initially be only available to a select&lt;br&gt;&gt; &gt;group, which will most likely use them to become gods. There is&lt;br&gt;&gt; &gt;no rational reason to distribute this kind of power once you have&lt;br&gt;&gt; &gt;it. &lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;Powerful businessmen still need others to make and buy their products,&lt;br&gt;&gt; &gt;and dictators and presidents still need their people to stay in power&lt;br&gt;&gt; &gt;&amp; to keep the country running, but a SI needs NO-ONE, it's&lt;br&gt;&gt; &gt;supremely autonomous. I can't imagine why it would share its &lt;br&gt;&gt; &gt;awesome power with creatures that are horribly primitive from its point &lt;br&gt;&gt; &gt;of view. Would *we* uplift ants/mice/dogs/monkeys to rul</a><br>
e the world&lt;br&gt;&gt; &gt;as our equals? I think not.&lt;br&gt;&gt; &lt;br&gt;&gt; "No rational reason" is a strong claim. I doubt your claim. First, your&lt;br&gt;&gt; view surely depends on a Singularitarian view that superintelligence will&lt;br&gt;&gt; come all at once, with those achieving it pulling vastly far away from&lt;br&gt;&gt; everyone else. I don't expect things to work out that way. I've explained&lt;br&gt;&gt; some of my thinking in the upcoming Singularity feature that Robin Hanson&lt;br&gt;&gt; is putting together for Extropy Online.&lt;br&gt;&gt; &lt;br&gt;&gt; Second, I also doubt that the superintelligence scenario is so radically&lt;br&gt;&gt; different from today's powerful business people. [I don't say "businessmen"&lt;br&gt;&gt; since this promotes an unfortunate assumption about gender and business.]&lt;br&gt;&gt; You could just as well say that today's extremely wealthy and powerful&lt;br&gt;&gt; business should have no need to benefit poor people. Yet, here we have oil&lt;br&gt;&gt; companies building hospitals and providing income in central Africa. I just&lt;br&gt;&gt; don't buy the idea that ea
<pre>
ch single SI will do everyone alone.&lt;br&gt;&gt; Specialization and division of labor will still apply. at some SI's will&lt;br&gt;&gt; want to help the poor humans upgrade because that will mean adding to the&lt;br&gt;&gt; pool of superintelligences with different points of view and different&lt;br&gt;&gt; interests.&lt;br&gt;&gt; &lt;br&gt;&gt; Let me put it this way: I'm pretty sure your view is incorrect, because I&lt;br&gt;&gt; expect to be one of the first superintelligences, and I intend to uplift&lt;br&gt;&gt; others. Or, are you planning on trying to stop me from bringing new members&lt;br&gt;&gt; into the elite club of SIs?&lt;br&gt;&gt; &lt;br&gt;&gt; &gt; In any case, we&lt;br&gt;&gt; &gt;should all work hard to be among the first SIs, that's the only&lt;br&gt;&gt; &gt;reasonably sure way to live long and prosper.&lt;br&gt;&gt; &lt;br&gt;&gt; No disagreement there. Make money, invest it, and keep on integrating&lt;br&gt;&gt; advances as they happen.&lt;br&gt;&gt; &lt;br&gt;&gt; Max&lt;br&gt;&gt;  &lt;br&gt;&gt; --------------------------------------------------------------------------&lt;br&gt;&gt; Max More, Ph.D.&lt;br&gt;&gt; more@extropy.org  (soon also: &lt;max@maxmore.com
&gt;)&lt;br&gt;&gt; &lt;br&gt;<a href="http://www.primenet.com/~maxmore" target=_blank>http://www.primenet.com/~maxmore</a>&lt;br&gt;&gt; Consulting services on the impact of advanced technologies&lt;br&gt;&gt; President, Extropy Institute: &lt;br&gt;<a href="http://www.extropy.org" target=_blank>http://www.extropy.org</a>&lt;br&gt;&gt; --------------------------------------------------------------------------&lt;br&gt;

</pre>
<pre>
---
Free and Private email from Supernews(TM) &lt;<a href="http://www.supernews.com">http://www.supernews.com</a>&gt;
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1368.html">[ Next ]</a><a href="1366.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1297.html">Max More</a>
<!-- nextthread="start" -->
</ul>
</body></html>
