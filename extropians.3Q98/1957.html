<!-- received="Fri Aug 28 11:46:05 1998 MDT" -->
<!-- sent="Fri, 28 Aug 1998 10:42:02 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: Doomsday Example" -->
<!-- id="3.0.3.32.19980828104202.007649d0@econ.berkeley.edu" -->
<!-- inreplyto="199808281608.RAA02684@andromeda.hosts.netdirect.net.uk" -->
<!-- version=1.10, linesinbody=84 -->
<html><head><title>extropians: Re: Doomsday Example</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: Doomsday Example</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Fri, 28 Aug 1998 10:42:02 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1957">[ date ]</a><a href="index.html#1957">[ thread ]</a><a href="subject.html#1957">[ subject ]</a><a href="author.html#1957">[ author ]</a>
<!-- next="start" -->
<li><a href="1958.html">[ Next ]</a><a href="1956.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1953.html">Nick Bostrom</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Nick Bostrom writes:
<br>
<a href="1953.html#1957qlink1">&gt;&gt; &gt;Let me put it like this. The amnesia heuristic sets a lower bound for </a><br>
<i>&gt;&gt; &gt;what should be included in the reference class.</i><br>
<i>&gt;&gt; &gt;</i><br>
<i>&gt;&gt; &gt;For example, it clearly makes sense to say that you might not have </i><br>
<i>&gt;&gt; &gt;known (indeed you may not know) the exact hour of your birth. If you </i><br>
<i>&gt;&gt; &gt;didn't know that, then you would use some probability distribution </i><br>
<i>&gt;&gt; &gt;over possible birth hours compatible with what else you know. If you </i><br>
<i>&gt;&gt; &gt;conditionalize this distribution on your exact birth hour, you should </i><br>
<i>&gt;&gt; &gt;get back the distribution you held before you forgot the birth hour. </i><br>
<i>&gt;&gt; &gt;If you don't get back the original distribution then that indicates </i><br>
<i>&gt;&gt; &gt;that you had forgot to take account of some effect. The doomsday </i><br>
<i>&gt;&gt; &gt;argument claims that there is such an effect that you have neglected </i><br>
<i>&gt;&gt; &gt;to take into account.</i><br>
<i>&gt;&gt; </i><br>
<i>&gt;&gt; Well if you're going to rest the whole DA on a mismatch between these</i><br>
<i>&gt;&gt; two calculations, you have do a lot better convincing me there *is* </i><br>
<i>&gt;&gt; a mismatch.  I thought Dieks did a reasonable job of calculating what </i><br>
<i>&gt;&gt; the person with amnesia should calculate according to the usual view.</i><br>
<i>&gt;</i><br>
<i>&gt;Dieks calculation rests on the self-indication axiom: that finding </i><br>
<i>&gt;that you are an observer indicates that there are many </i><br>
<i>&gt;observers. Only yourself can answer whether that is what you </i><br>
<i>&gt;believed before you heard about the DA. Speaking for myself, I </i><br>
<i>&gt;didn't believe that, ...</i><br>

<p>
I don't see what timing has to do with anything.  We've had a standard
approach to modeling things like doom for a long time.  What is new is 
asking what this standard approach implies for a creature with amnesia.
Perhaps you find counterintuitive the result that amnesiacs should be 
especially optimistic about humanity as a whole surprising.  But it is
DA advocates who are using this surprise to argue for a change in the 
standard approach, a change which eliminates this surprise at the 
expense of making other surprises elsewhere. 

<p>
<a href="1953.html#1957qlink2">&gt;believed that either, since it was not generally accepted that by </a><br>
<i>&gt;just sitting back in your armchair you could decide that the universe </i><br>
<i>&gt;is infinite with probability one, unless it is impossible that it is </i><br>
<i>&gt;infinite. Most people did, and presumably still do, believe that </i><br>
<i>&gt;there is some finite probability that the universe is infinite and a </i><br>
<i>&gt;finite probability that it is finite. If that is what you believe, </i><br>
<i>&gt;then your prior was certainly not the one Dieks presupposes.</i><br>

<p>
Can you *prove* that under the standard approach, one cannot coherently 
believe with probability in (0,1) that the universe has a finite number of 
humans?  I'd guess that doing so would require a rather subtle analysis,
as things get messy when probabilities and infinities collide.  

<p>
<a href="1953.html#1957qlink3">&gt;&gt; Let me repeat as forcefully as I can: There are standard approaches</a><br>
<i>&gt;&gt; to formally modeling our propects for doom, and which don't imply doom </i><br>
<i>&gt;&gt; soon.  To disagree with them, you must dispute some aspect of those </i><br>
<i>&gt;&gt; models, either their state spaces, priors, or information partitions.</i><br>
<i>&gt;</i><br>
<i>&gt;I don't know what "standard approaches" you are referring to. If </i><br>
<i>&gt;you mean the one you outlined, I have already said that I think your </i><br>
<i>&gt;specification of the state space is incoherent, since it presupposes </i><br>
<i>&gt;that in a world with just one apple and one pear, there is a fact of </i><br>
<i>&gt;the matter as to weather you are the apple and I'm the pear, or vice </i><br>
<i>&gt;versa. I simply can't make any sense of that.</i><br>

<p>
No that isn't the standard approach.  That is my attempt to create a 
hybrid of the standard approach and what I understand to be the DA
approach.  

<p>
I've tried to explain this at length in my paper:
<a href="http://hanson.berkeley.edu/nodoom.html">http://hanson.berkeley.edu/nodoom.html</a>

<p>
A standard approach to calculating the chance of doom would be to
assume that human population grows exponentially, that doom happens when 
the population reaches 10^d, and then to choose a prior over d based on 
our understanding of the sorts of processes that might cause doom.
A typical choice might be to have d be uniformly distributed between 0 
and 20.  One then interprets our information that today's population is 
about 10^10 as just telling us that d is at least ten, and so obtains
a posterior that d is uniformly distributed between 10 and 20.  
This implies a median future growth factor of 10^5 before doom, which is 
far from "doom soon." 


<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-8614
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1958.html">[ Next ]</a><a href="1956.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1953.html">Nick Bostrom</a>
<!-- nextthread="start" -->
</ul>
</body></html>
