<!-- received="Mon Sep  7 12:38:08 1998 MDT" -->
<!-- sent="07 Sep 1998 20:37:49 +0200" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Life in an Open Universe" -->
<!-- id="b49emtnydj6.fsf@void.nada.kth.se" -->
<!-- inreplyto="Fri, 28 Aug 1998 20:21:56 +0100" -->
<!-- version=1.10, linesinbody=96 -->
<html><head><title>extropians: Re: Life in an Open Universe</title>
<meta name=author content="Anders Sandberg">
<link rel=author rev=made href="mailto:asa@nada.kth.se" title ="Anders Sandberg">
</head><body>
<h1>Re: Life in an Open Universe</h1>
Anders Sandberg (<i>asa@nada.kth.se</i>)<br>
<i>07 Sep 1998 20:37:49 +0200</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2191">[ date ]</a><a href="index.html#2191">[ thread ]</a><a href="subject.html#2191">[ subject ]</a><a href="author.html#2191">[ author ]</a>
<!-- next="start" -->
<li><a href="2192.html">[ Next ]</a><a href="2190.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1961.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"Bryan Moss" &lt;bryan.moss@dial.pipex.com&gt; writes:

<p>
<a href="1961.html#2191qlink1">&gt; Few questions about life in an open universe as</a><br>
<i>&gt; described by Dyson in TIME WITHOUT END: PHYSICS</i><br>
<i>&gt; AND BIOLOGY IN AN OPEN UNIVERSE.</i><br>
<i>&gt; </i><br>
<i>&gt; Dyson chooses a model in which "human-sized</i><br>
<i>&gt; objects will disappear [within 10^(10^26) years],</i><br>
<i>&gt; but dust grains with diameter less than about</i><br>
<i>&gt; 100mu will last for ever". He later proposes that</i><br>
<i>&gt; if this is true life may have to exist as "a large</i><br>
<i>&gt; assemblage of dust grains". Does this mean that</i><br>
<i>&gt; after the elapsed 10^(10^26) years anything over a</i><br>
<i>&gt; 100mu diameter would be unable to exist, or merely</i><br>
<i>&gt; that such an object would take that many years to</i><br>
<i>&gt; decay? His later statement about the biology of</i><br>
<i>&gt; future life (the "assemblage of dust grains")</i><br>
<i>&gt; suggests the former, but I'm not sure.</i><br>

<p>
It should be noted that other decay processes like proton decay are
much faster, if they exist. The process Dyson studies is essentilly
random, quantum fluctuations making the drifting pieces of matter
implode into black holes which then evaporate. This means the numbers
are half-lives rather than exact ages; in the dust scenario matter
will vanish with a half life of 10^10^26 years.

<p>
However, it all depends on how small black holes can be. If they must
be fairly large, then small pieces of matter are safe. My
understanding of Hawking evaporation and small black holes is
rudimentary, but it seems to point to alternative (ii) in the paper.

<p>
Another paper looking at the situation but reaching a different
conclusion (through proton decay) is

<p>
@Article{Adams97,
<pre>
  author = 	 {Fred C. Adams and Gregory Laughlin},
  title = 	 {A dying universe: the long-term fate and evolution of astrophysical objects},
  journal = 	 {Reviews of Modern Physics},
  year = 	 1997,
  volume =	 69,
  number =	 2,
  pages =	 {337--372},
  month =	 {April}
</pre>
<br>
}

<p>
<a href="2073.html#2191qlink2">&gt; The most interesting thing about Dyson's scenario</a><br>
<i>&gt; is that it imposes a number of limits. These</i><br>
<i>&gt; limits make it easier to predict what life could</i><br>
<i>&gt; `evolve' into. (Tipler's Omega Point in a closed</i><br>
<i>&gt; universe relies on omniscience and is therefore an</i><br>
<i>&gt; omniboring area of conversation.) For instance,</i><br>
<i>&gt; the need for an infinite amount of memory storage</i><br>
<i>&gt; (Dyson suggests analog memory) "will put severe</i><br>
<i>&gt; constraints on the rate of acquisition of</i><br>
<i>&gt; permanent new knowledge". </i><br>

<p>
Here is a fun question: what is the slowest rate of memory growth that
doesn't get into an infinite loop? It seems to be logarithmic if we
measure time by computational steps:

<p>
If the system has N(t) bits of memory at timestep t, it can be in
2^N(t) different states. Suppose it traverses all of them without
increasing N, then it would have to recur to a previous state and
would get trapped in an infinite loop. So at time t+2^N(t) the system
has to increase N by at least one bit. Hence N(t) will grow as log(t).

<p>
So the system radius must grow faster than (log(t))^1/3, and slower
(due to lightspeed) than t.

<p>
<a href="1961.html#2191qlink3">&gt; He also proposes scaling</a><br>
<i>&gt; laws, the need for hibernation, and limits to</i><br>
<i>&gt; communication. I'm sure an even better model of</i><br>
<i>&gt; future life could be created. </i><br>

<p>
Yes, for example he doesn't take reversible computing (or
near-reversible computing) into account, and his derivation of the
entropy needs of life seems a bit aged; this can likely be improved
now.

<p>
<a href="1961.html#2191qlink4">&gt; For instance, are</a><br>
<i>&gt; there any fundamental limits to complexity that</i><br>
<i>&gt; would stop *really big* Jupiter Brains from</i><br>
<i>&gt; functioning (increased complexity generally means</i><br>
<i>&gt; more errors and more redundancy)? Will limits to</i><br>
<i>&gt; communication (speed of light, background</i><br>
<i>&gt; radiation) and size (spread of matter in the</i><br>
<i>&gt; universe, rate of decay) insure individuality?</i><br>

<p>
I have a paper on that, which by now is eons old. I'll try to finish it.

<pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
asa@nada.kth.se                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2192.html">[ Next ]</a><a href="2190.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1961.html">Bryan Moss</a>
<!-- nextthread="start" -->
</ul>
</body></html>
