<!-- received="Fri Sep 25 10:40:24 1998 MDT" -->
<!-- sent="Fri, 25 Sep 1998 09:36:21 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: AI big wins" -->
<!-- id="3.0.3.32.19980925093621.007295b0@econ.berkeley.edu" -->
<!-- inreplyto="360AE685.8E13721F@pobox.com" -->
<!-- version=1.10, linesinbody=70 -->
<html><head><title>extropians: Re: AI big wins</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: AI big wins</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Fri, 25 Sep 1998 09:36:21 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2636">[ date ]</a><a href="index.html#2636">[ thread ]</a><a href="subject.html#2636">[ subject ]</a><a href="author.html#2636">[ author ]</a>
<!-- next="start" -->
<li><a href="2637.html">[ Next ]</a><a href="2635.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2626.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2639.html">Eliezer S. Yudkowsky</a>
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky writes:
<br>
<a href="2626.html#2636qlink1">&gt;&gt; "I think a more realistic model is" is not a sufficiently detailed argument.</a><br>
<i>&gt;&gt; for t' = a*e^(b*(t+c)).  And even accepting this form, substantial growth</i><br>
<i>&gt;&gt; could still take centuries, depending on the values of a,b,c.</i><br>
<i>&gt;&gt; </i><br>
<i>&gt;&gt; Your argument here seems awfully close to the claim that "the doubling time</i><br>
<i>&gt;&gt; of computer hardware efficiency is proportional to the computer operations</i><br>
<i>&gt;&gt; per second devoted to R&amp;D in computer hardware, or within all of computer-aided</i><br>
<i>&gt;&gt; `humanity.'"</i><br>
<i>&gt;</i><br>
<i>&gt;If you mean with the t' = e^t, I agree absolutely that it's just as worthless</i><br>
<i>&gt;as the Argument from Moore's Law; it's a simple analogy, having none of the</i><br>
<i>&gt;reductionistic detail that's needed for a realistic discussion of AI</i><br>
<i>&gt;trajectories.  As you recall, my actual analysis clamped power at an arbitrary</i><br>
<i>&gt;value and treated strictly with optimization and intelligence.  Obviously, I</i><br>
<i>&gt;don't think that Moore's Law, or for that matter any simple equation for</i><br>
<i>&gt;growth rates, is of real value.</i><br>
<i>&gt;</i><br>
<i>&gt;Can we return to the ABC/POI discussion now?  Focus on the technical</i><br>
<i>&gt;discussion, not the immoderate speculations &lt;grin&gt;.  But seriously, what about</i><br>
<i>&gt;the feedback into the system, which is my main argument?</i><br>

<p>
<a name="2639qlink1">Mere mention of the work "feedback" is not sufficient to argue for a sudden 
and sustained acceleration in growth rates, which is what you seem to claim.</a>

<p>
I'm not saying your claim is false, just that you haven't presented a coherent
*argument* for it.  Lots of systems have feedback without having explosive 
growth.  Granted, some abstract differential equation systems do have explosive 
growth, but such systems are very rare in practice, so your job is to present 
some argument why we should think our future growth is more like those systems 
than other systems.  

<p>
I searched for such an argument in your volumous web pages, and finding the 
Moore's law argument, I tried to critique it.  But you say you "renounced, 
repented, and abjured" that argument (though one can't tell from your web 
pages).  Just yesterday you offer t' = e^t apparently as an argument in support
of "Why is a sharp jump upwards plausible at any given point?", but a few 
hours later you say it's just as worthless.  

<p>
<a name="2640qlink1">I am happy to consider simplified models of systems as a means to understanding.
My complain with your simple models isn't that they are too simple, it is that
it is not clear why they are better models than equally simple models without 
explosive growth.</a>

<p>
<a href="2626.html#2636qlink2">&gt;&gt; There really is a rich economic growth literature on when various equations</a><br>
<i>&gt;&gt; like this describe different growing systems, including intelligent systems.</i><br>
<i>&gt;&gt; Growth depends on many factors, and just because a previously fixed factor is</i><br>
<i>&gt;&gt; allowed to grow, that doesn't mean growth suddenly explodes.</i><br>
<i>&gt;</i><br>
<a name="2640qlink2"><i>&gt;"Intelligence is not a factor, it is the equation itself."  You've never</i><br>
<i>&gt;responded to my basic assertion, which is that sufficient intelligence (which</i><br>
<i>&gt;is probably achievable) suffices for nanotech; which in turn suffices to turn</i><br>
<i>&gt;the planet into a computer; which in turn counts as "explosive growth" by my</i><br>
<i>&gt;standards.  It's difficult to see how the literature on the rise of</i><br>
<i>&gt;agriculture relates...</i><br>
<i>&gt;</i><br>
<i>&gt;"Sufficient" = Wili Wachendon with a headband.</i><br>
<i>&gt;"Achievable" = The end of my seed AI's trajectory, running on 10^13 ops.</i><br>
<i>&gt;"Nanotech"   = What Drexler said in _Engines of Creation_.</i><br>

<p>
</a>(Intelligence is an equation?)
<br>
<a name="2640qlink3">The question is *how fast* a nanotech enabled civilization would turn the
planet into a computer.  You have to make an argument about *rates* of change,
not about eventual consequences.</a>  

<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-8614
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2637.html">[ Next ]</a><a href="2635.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2626.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2639.html">Eliezer S. Yudkowsky</a>
</ul>
</body></html>
