<!-- received="Mon Jul 13 12:08:45 1998 MDT" -->
<!-- sent="Mon, 13 Jul 1998 14:08:31 -0400" -->
<!-- name="Harvey Newstrom" -->
<!-- email="harv@gate.net" -->
<!-- subject="Re: [UPLOADING]  Is an exact duplicate "me"?" -->
<!-- id="1dc3rm5.137qafr10l2apaM@mlbfl2-21.gate.net" -->
<!-- inreplyto="199807130240.TAA05277@hal.sb.rain.org" -->
<!-- version=1.10, linesinbody=107 -->
<html><head><title>extropians: Re: [UPLOADING]  Is an exact duplicate "me"?</title>
<meta name=author content="Harvey Newstrom">
<link rel=author rev=made href="mailto:harv@gate.net" title ="Harvey Newstrom">
</head><body>
<h1>Re: [UPLOADING]  Is an exact duplicate "me"?</h1>
Harvey Newstrom (<i>harv@gate.net</i>)<br>
<i>Mon, 13 Jul 1998 14:08:31 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#646">[ date ]</a><a href="index.html#646">[ thread ]</a><a href="subject.html#646">[ subject ]</a><a href="author.html#646">[ author ]</a>
<!-- next="start" -->
<li><a href="0647.html">[ Next ]</a><a href="0645.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0620.html">Hal Finney</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Hal Finney &lt;hal@rain.org&gt; wrote:
<br>
<a href="0620.html#0646qlink1">&gt; Suppose we take some intermediate case, such as being an upload on a</a><br>
<i>&gt; relatively slow computer.  Are you dead then?  Is there some threshold</i><br>
<i>&gt; of speed such that you are literally dead if the computer runs slower</i><br>
<i>&gt; than that, because the rest of the universe is going on without you,</i><br>
<i>&gt; while you are still alive if the computer runs faster?</i><br>

<p>
My fear is never waking up again.  Being slow, or being temporarily dead
is not so bad.  It is when you get to the point that you stretch the
metaphor of sleep or suspension to permanency that it becomes too much
for me.

<p>
<a href="0620.html#0646qlink2">&gt; Can you imagine discovering that you are running on a timesharing computer</a><br>
<i>&gt; and there are occasional delays of up to 1 millisecond during which</i><br>
<i>&gt; you are suspended?  Would you then view yourself as constantly dying</i><br>
<i>&gt; and being reborn?  Does this frighten you and activate your instincts</i><br>
<i>&gt; which fear death?</i><br>

<p>
No, because I would perceive a continuous consciousness.  When I watch a
movie at 60 frames per second, I perceive continuous movement.  The
knowledge that it is really stopping and starting does not bother me.
If you were to perceptibly turn the movie on and off while I am trying
to watch it, then I would be bothered.  If you shut the movie off
completely so that I never get to see any more, that would be the worst
case.



<p>
<a href="0620.html#0646qlink3">&gt; I want to emphasize here that we are not arguing any semantic issues about</a><br>
<i>&gt; sameness or anything else.  All I want to know is whether the scenarios</i><br>
<i>&gt; frighten you and make you fear that you will die.  Would you be afraid</i><br>
<i>&gt; to run on a multiprocessor system because you know that it would switch</i><br>
<i>&gt; you among its internal processors, even though the switching would be</i><br>
<i>&gt; undetectable to you?  If you found that you were running on such a system,</i><br>
<i>&gt; would you conclude that you were constantly dying and being reborn, and</i><br>
<i>&gt; feel alarmed and upset as a result?</i><br>

<p>
The strange part is that a bullet through my brain would also be
undetectable to me.  I would not feel it or detect it in any way.  So I
could not argue that the resulting dead body would object to being dead.
I can only argue that if I had foreknowledge of the event, I would
object.

<p>
When you propose switching processors, you terminate one program and
start up another.  The newly started program experiences activity and
therefore does not consider itself dead.  The shut down program is dead.
It is not experiencing anything.  Yes, I might consider this death if
the original program is deleted from memory after the new program is
copied.

<p>
These examples are fuzzy because we don't know enough about future
computers or how life would be in them.  What you are asking is the same
as if you brainwashed my twin brother to "think like me" and then
pointed a gun at me and pulled the trigger.

<p>
<a href="0620.html#0646qlink4">&gt; What if it were discovered that the human brain occasionally switches among</a><br>
<i>&gt; its neurons, letting some neurons rest and using other nearby neurons</i><br>
<i>&gt; while those first ones recover.  Would you conclude that you are constantly</i><br>
<i>&gt; dying, because the site of processing in your brain is constantly shifting</i><br>
<i>&gt; around and not staying with the same set of neurons?</i><br>

<p>
You seem to be trying to prove that individual components of my brain
can be shut down without affecting the whole.  If you make a copy of me,
you have not modified my brain in any way.  Then when you kill the
original, you destroy the entire brain just as if you killed the
individual without making a copy.  What difference is there to the
original in these two scenarios?  I don't see any difference or basis
for different reactions.

<p>
<a name="0662qlink1"><a href="0620.html#0646qlink5">&gt; What if the redundancy is obtained by using double-thick wires and</a><br>
<i>&gt; double-sized transistors in the circuit design?  Now someone proposes</i><br>
<i>&gt; to save costs by shaving away half of this circuitry, while leaving the</i><br>
<i>&gt; logic alone.  Would this bother you?</i><br>

<p>
You keep asking the same question over and over in different ways.  I'm
not sure why you expect to get a different answer at some point.  As
long as the original object/function that I define as "me" ceases to
exist, I object on the grounds that I don't want to cease to exist.  For
me to find a procedure acceptable, you must convince me that the
original definition of "me" is no longer valid, and that a new
definition of "me" has replaced it.  You then will destroy the old "me"
and replace me with a new person who has been redefined to be "me".</a>

<p>
<a href="0620.html#0646qlink6">&gt; I appreciate you taking the time to attempt to answer these rather</a><br>
<i>&gt; exotic thought experiments.</i><br>

<p>
I enjoy these kinds of discussions.  There obviously are two different
camps of thought here.  I'm not sure that either has converted members
of the other.  

<p>
<i>&gt; My instinct is that the nature of electronic</i><br>
<a href="0620.html#0646qlink7">&gt; circuits is such that the notion of "how many circuits" there are is not</a><br>
<i>&gt; well defined, yet it appears to be central to your idea of identity.</i><br>

<p>
Actually, I am not interested in the number of circuits, but in the
number of distinct individuals with differing points of view, even if
they differ only by location.  I don't care about removing a single
circuit, but when you reduce the total number of viewpoints in the
universe, then I believe there has been a death.  If the viewpoint being
terminated is the original one where I am now, then I believe that I
will be the one who is dead.

<pre>
-- 
Harvey Newstrom                                   &lt;<a href="mailto:harv@gate.net">mailto:harv@gate.net</a>&gt;
Author, Engineer, Entrepreneur,              &lt;<a href="http://www.gate.net/~harv">http://www.gate.net/~harv</a>&gt;
Consultant, Researcher, Scientist.           &lt;ldap://certserver.pgp.com&gt;
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0647.html">[ Next ]</a><a href="0645.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0620.html">Hal Finney</a>
<!-- nextthread="start" -->
</ul>
</body></html>
