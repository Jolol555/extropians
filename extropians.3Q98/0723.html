<!-- received="Wed Jul 15 21:11:50 1998 MDT" -->
<!-- sent="Wed, 15 Jul 1998 23:11:41 -0400 (EDT)" -->
<!-- name="Daniel Fabulich" -->
<!-- email="daniel.fabulich@yale.edu" -->
<!-- subject="Re: Ethics" -->
<!-- id="Pine.GSO.3.94.980715224755.6633A-100000@mars.its.yale.edu" -->
<!-- inreplyto="35AD122E.50C4@piclab.com" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Re: Ethics</title>
<meta name=author content="Daniel Fabulich">
<link rel=author rev=made href="mailto:daniel.fabulich@yale.edu" title ="Daniel Fabulich">
</head><body>
<h1>Re: Ethics</h1>
Daniel Fabulich (<i>daniel.fabulich@yale.edu</i>)<br>
<i>Wed, 15 Jul 1998 23:11:41 -0400 (EDT)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#723">[ date ]</a><a href="index.html#723">[ thread ]</a><a href="subject.html#723">[ subject ]</a><a href="author.html#723">[ author ]</a>
<!-- next="start" -->
<li><a href="0724.html">[ Next ]</a><a href="0722.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0711.html">Lee Daniel Crocker</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
On Wed, 15 Jul 1998, Lee Daniel Crocker wrote:

<p>
<a href="0711.html#0723qlink1">&gt; DF&gt; &lt;sigh&gt; As I've already said many times before, this is true</a><br>
<i>&gt; &gt; when the game is iterated, which is most of the time. I'd say</i><br>
<i>&gt; &gt; utilitarianism and egoism coincide at least 80% of the time,</i><br>
<i>&gt; &gt; if not more. However, egoism leaves us worse off in that</i><br>
<i>&gt; &gt; remaining 20% region, representing games where you don't know</i><br>
<i>&gt; &gt; who your opponent is or in which one or more players will not</i><br>
<i>&gt; &gt; play again. </i><br>
<i>&gt; </i><br>
<i>&gt; 2) That "20%" speculation of yours is absurd in the real world.</i><br>
<i>&gt; In my 35 years on the planet, I have yet to encounter a single</i><br>
<i>&gt; situation where my interaction with someone else would not have</i><br>
<i>&gt; consequences later in life.  For me, then, the percentage of</i><br>
<i>&gt; non-iterated prisoner's dilemma situations in real life is zero.</i><br>
<i>&gt; I'd like to hear a convincing example of such a situation, but</i><br>
<i>&gt; even if one or two could be contrived--just as I'm sure I could</i><br>
<i>&gt; contrive an example or two of utilitarian atrocities--one should</i><br>
<i>&gt; live by principles that reflect how life is in general, not by</i><br>
<i>&gt; contrived examples.</i><br>

<p>
So here's what it boils down to.  You can't think of a single situation in
which you could hurt someone for your own long term profit.

<p>
Unfortunately, there are lots.  Any and all situations in which you could
commit a crime against a victim (ie theft, fraud, murder, etc.) and not
get caught are examples for my argument.  If you steal and no one finds
out who it was, you have hurt someone for your own long term profit; if we
exploited all such situations, indeed, even sought out these sitautions as
egoism demands, we would all find ourselves worse off.

<p>
Another perfect example: tax credits for special interests.  This moronic
practice drags down the economy and makes everybody worse off in the long
run, but any individual special interest would be worse off
if they chose not to lobby Congress for its extra break.  Only when
OTHERS choose not to take special tax credits am I made better off; since
only I get to determine my choice, egoism demands that I choose to get a
tax credit, despite the fact that it hurts others more than it benefits
me.

<p>
<a name="0765qlink1">If you can't think of at least fifty other ways in which you could hurt
people for your own gain, you're just not thinking hard enough.
</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0724.html">[ Next ]</a><a href="0722.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0711.html">Lee Daniel Crocker</a>
<!-- nextthread="start" -->
</ul>
</body></html>
