<!-- received="Thu Sep 24 15:53:16 1998 MDT" -->
<!-- sent="Thu, 24 Sep 1998 14:49:10 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: AI big wins" -->
<!-- id="3.0.3.32.19980924144910.0076f39c@econ.berkeley.edu" -->
<!-- inreplyto="360A9ABC.4812706E@pobox.com" -->
<!-- version=1.10, linesinbody=50 -->
<html><head><title>extropians: Re: AI big wins</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: AI big wins</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Thu, 24 Sep 1998 14:49:10 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2621">[ date ]</a><a href="index.html#2621">[ thread ]</a><a href="subject.html#2621">[ subject ]</a><a href="author.html#2621">[ author ]</a>
<!-- next="start" -->
<li><a href="2622.html">[ Next ]</a><a href="2620.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2618.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2626.html">Eliezer S. Yudkowsky</a>
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky writes:
<br>
<a href="2596.html#2621qlink1">&gt;&gt;&gt;Well, my other reason for expecting a breakthrough/bottleneck architecture,</a><br>
<i>&gt;&gt;&gt;even if there are no big wins, is that there's positive feedback involved,</i><br>
<i>&gt;&gt;...</i><br>
<i>&gt;&gt;Let me repeat my call for you to clarify what appears to be a muddled argument.</i><br>
<i>&gt;...</i><br>
<i>&gt;Sigh.  Okay, one more time:  The total trajectory is determined by the</i><br>
<i>&gt;relation between power (raw teraflops), optimization (the speed and size of</i><br>
<i>&gt;code) and intelligence (the ability to do interesting things with code or</i><br>
<i>&gt;invent fast-infrastructure technologies).</i><br>
<i>&gt;Given constant power, the trajectory at time T is determined by whether the AI</i><br>
<i>&gt;can optimize itself enough to get an intelligence boost which further</i><br>
<i>&gt;increases the ability at optimization enough for another intelligence boost. </i><br>

<p>
Can I translate you so far as follows?
<br>
Let P = power, O = optimization, I = intelligence.
For any X, let X' = time derivative of X.
The AI can work on improving itself, its success given by functions A,B,C.
<pre>
If the AI devoted itself to improving P, it would get P' = A(P,O,I), O'=I'=0.
If the AI devoted itself to improving O, it would get O' = B(P,O,I), P'=I'=0.
If the AI devoted itself to improving I, it would get I' = C(P,O,I), P'=O'=0.
</pre>
(If it devotes fractions a,b,c of its time to improving P,O,I, it presumably
<p>
   gets P' = a*A, O' = b*B, I' = c*C.)

<p>
<a href="2618.html#2621qlink2">&gt;Presumably the sum of this series converges to a finite amount.  </a><br>

<p>
Sum?  Of what over what?  Do you mean that for the AIs choice of a,b,c, that 
P,O, and I converge to some limit as time goes to infinity?  

<p>
<i>&gt;If the amount</i><br>
<a href="2618.html#2621qlink3">&gt;is small, we say the trajectory bottlenecks; if the amount is large, we say a</a><br>
<i>&gt;breakthrough has occurred.  The key question is whether the intelligence</i><br>
<i>&gt;reached is able to build fast-infrastructure nanotechnology and the like, or</i><br>
<i>&gt;of exhibiting unambiguously better-than-human abilities in all domains.</i><br>

<p>
I thought you had an argument for why "breakthrough" is plausible, rather than 
just listing it as one of many logical possibilities.

<p>
<a href="2618.html#2621qlink4">&gt;... At this point, the key question for me is "How much of _Coding a </a><br>
<i>&gt;Transhuman AI_ did you actually read?"  </i><br>

<p>
All of it.



<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-8614
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2622.html">[ Next ]</a><a href="2620.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2618.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2626.html">Eliezer S. Yudkowsky</a>
</ul>
</body></html>
