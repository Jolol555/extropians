<!-- received="Mon Sep  7 22:27:45 1998 MDT" -->
<!-- sent="Mon, 07 Sep 1998 22:17:50 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="SITE:  Coding A Transhuman AI (temp)" -->
<!-- id="35F4A1D9.F591C605@pobox.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=51 -->
<html><head><title>extropians: SITE:  Coding A Transhuman AI (temp)</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>SITE:  Coding A Transhuman AI (temp)</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 07 Sep 1998 22:17:50 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2212">[ date ]</a><a href="index.html#2212">[ thread ]</a><a href="subject.html#2212">[ subject ]</a><a href="author.html#2212">[ author ]</a>
<!-- next="start" -->
<li><a href="2213.html">[ Next ]</a><a href="2211.html">[ Previous ]</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>

<p>
Coding a Transhuman AI
<p>
    also known as
<br>
Notes on the Design of Self-Enhancing Intelligences
The Art of Seed AIs
<br>
How to Build a Power in 3 Easy Steps and 35 Hard Steps
Applied Theology 101:  Fast Burn Transcendence

<p>
A fairly massive tome, about halfway complete at 210K.
This is a temporary version for use in the Singularity Colloquium, in case the
completed page takes another two weeks.  The completed version will be reannounced.

<p>
     Table Of Contents:      (Implemented sections only.)

<p>
Paradigms 

<OL>
  <li>  Pragmatism and allowable methods. 
  <li>  Seed AIs. 
  <li>  Grounding (vs. symbols and stochastics). 
Principles 
  <li>  Self-enhancement and domino enhancement. 
  <li>  Domain modules:  Domdules. 
  <li>  World-model:  Integration of domdules. 
  <li>  RNUI:  Representing, Noticing, Understanding, and Inventing. 
  <li>  Symbols and memory. 
  <li>  Adaptive code and self-organization. 
  <li>  Reflexive reasoning:  Self-awareness and will. 
  <li>  Causality and goals. 
View from multiple levels 
  <li>  Meet the AI. 
  <li>  Sample thought.  (Internal TOC.) 
  <li>  The AI Advantage. 
Details 
  <li>  Self-swallowing compilers. 
  <li>  Interim Goal Systems. 
Precautions
  <li>  The Prime Directive:  No Asimov Laws. 


</OL>
<p>
Credit goes to Max More for stimulating this by challenging the assertion that
human AI implies transhuman AI.  I tried to specify all the principles that
would affect the AI's trajectory, and at about 3 AM realized it should
probably be a separate page...
<pre>
-- 
        sentience@pobox.com         Eliezer S. Yudkowsky
         <a href="http://pobox.com/~sentience/AI_design.temp.html">http://pobox.com/~sentience/AI_design.temp.html</a>
          <a href="http://pobox.com/~sentience/sing_analysis.html">http://pobox.com/~sentience/sing_analysis.html</a>
Disclaimer:  Unless otherwise specified, I'm not telling you
everything I think I know.
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2213.html">[ Next ]</a><a href="2211.html">[ Previous ]</a>
<!-- nextthread="start" -->
</ul>
</body></html>
