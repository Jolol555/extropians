<!-- received="Wed Sep 23 17:20:27 1998 MDT" -->
<!-- sent="Wed, 23 Sep 1998 16:16:19 -0700" -->
<!-- name="Robin Hanson" -->
<!-- email="hanson@econ.berkeley.edu" -->
<!-- subject="Re: Punctuated Equilibrium Theory" -->
<!-- id="3.0.3.32.19980923161619.00772558@econ.berkeley.edu" -->
<!-- inreplyto="3609763F.4675F46B@pobox.com" -->
<!-- version=1.10, linesinbody=35 -->
<html><head><title>extropians: Re: Punctuated Equilibrium Theory</title>
<meta name=author content="Robin Hanson">
<link rel=author rev=made href="mailto:hanson@econ.berkeley.edu" title ="Robin Hanson">
</head><body>
<h1>Re: Punctuated Equilibrium Theory</h1>
Robin Hanson (<i>hanson@econ.berkeley.edu</i>)<br>
<i>Wed, 23 Sep 1998 16:16:19 -0700</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2595">[ date ]</a><a href="index.html#2595">[ thread ]</a><a href="subject.html#2595">[ subject ]</a><a href="author.html#2595">[ author ]</a>
<!-- next="start" -->
<li><a href="2596.html">[ Next ]</a>
<b>In reply to:</b> <a href="2594.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2596.html">Eliezer S. Yudkowsky</a>
</ul>
<!-- body="start" -->

<p>
Eliezer S. Yudkowsky writes: 
<br>
<a href="2594.html#2595qlink1">&gt;&gt; and the key assumption is that "the phenotypic optimum changes suddenly and</a><br>
<i>&gt;&gt; then remains fixed during the bout of adaptation studied."  ...</i><br>
<i>&gt;</i><br>
<i>&gt;Punctuated equilibrium, as the fossil-record phenomenon, neither requires nor</i><br>
<i>&gt;prohibits single big-win mutations.  ...</i><br>

<p>
Yes, and this theory paper doesn't help settle the question.  If the enviroment
changes very very quickly, then the first few changes can be very big wins. 
But if the environment just changes a hundred times as fast some times as others,
then you just get a distrubution of small vs. itsy-bitsy wins, with no big wins.

<p>
<a name="2596qlink1"><i>&gt;I noticed that paper because it explained punctuated equilibrium in a way </i><br>
<a href="2594.html#2595qlink2">&gt;that exported fairly well to breakthrough/bottleneck AI trajectories.  </a><br>
<i>&gt;It was the first explanation I had seen with that property.</i><br>

<p>
I can describe my sense of AI progress in terms of this model as well.  Early
on in AI research people came across the big win concepts, and the rate of 
discovery of such big wins then declined with time.   The main way in which the
environment for AI programs is changing now is hardware improvement.  Some big 
wins have to await enough compute power to verify/study them, and these sort 
continue to show themselves more steadly with time.  But none of these are so 
huge as to create an average factor of ten productivity win for AI programs.</a>    

<p>
<a name="2596qlink2">As best I can tell, your reason for expecting big future wins seems to be that 
you, Eliezer, have personally come up with great (largely untested) designs 
for AI programs, and you're sure they're enough to change everything.  Are you
aware of how stereotypical this is of young people when they first get into AI?</a>


<p>
Robin Hanson  
<br>
hanson@econ.berkeley.edu    <a href="http://hanson.berkeley.edu/">http://hanson.berkeley.edu/</a>   
RWJF Health Policy Scholar, Sch. of Public Health   510-643-1884  
140 Warren Hall, UC Berkeley, CA 94720-7360    FAX: 510-643-8614
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2596.html">[ Next ]</a>
<b>In reply to:</b> <a href="2594.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2596.html">Eliezer S. Yudkowsky</a>
</ul>
</body></html>
