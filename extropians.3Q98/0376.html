<!-- received="Tue Jul  7 11:12:25 1998 MDT" -->
<!-- sent="Tue, 7 Jul 1998 17:30:11 +0100" -->
<!-- name="Bryan Moss" -->
<!-- email="bryan.moss@dial.pipex.com" -->
<!-- subject="The Singularity" -->
<!-- id="000101bda9ca$66893d40$395a95c1@bungle" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=39 -->
<html><head><title>extropians: The Singularity</title>
<meta name=author content="Bryan Moss">
<link rel=author rev=made href="mailto:bryan.moss@dial.pipex.com" title ="Bryan Moss">
</head><body>
<h1>The Singularity</h1>
Bryan Moss (<i>bryan.moss@dial.pipex.com</i>)<br>
<i>Tue, 7 Jul 1998 17:30:11 +0100</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#376">[ date ]</a><a href="index.html#376">[ thread ]</a><a href="subject.html#376">[ subject ]</a><a href="author.html#376">[ author ]</a>
<!-- next="start" -->
<li><a href="0377.html">[ Next ]</a><a href="0375.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0704.html">Eugene Leitl</a>
</ul>
<!-- body="start" -->

<p>
<a name="0411qlink1">I’m always hearing the Singularity mentioned on
this list but I’m not sure if I understand the
concept fully. There are several different
scenarios I’ve heard:


<OL>
  <li>  The point where population growth apparently
goes infinite and that *something* must happen at
this point. For instance, we all upload and we
really can have an infinite population. This, I
</a>
think, is stretching statistics a little too far.

<a name="0411qlink2">  <li>  Artificial Intelligence speeds up the creation
of more powerful computers and intelligence’s.
This seems wrong because hardware and software
power is already a major factor in the increase of
hardware and software power. There is no reason to
suggest this trend would suddenly change.</a>

<a name="0411qlink3">  <li>  A Super Intelligence emerges from a distributed
network, such as the Internet. I think this goes
against current network/software/hardware models
and that a distributed intelligence would only
emerge under certain (possibly engineered)
circumstances that current trends in hardware,
software and the economy would not support.</a>


</OL>
<p>
<a name="0411qlink4">Otherwise it is just treated as the point beyond
which we cannot predict (sometimes called the
Horizon). Although the curves are certainly moving
upwards I see no evidence that we should get ready
for a sudden surge in power, the collapse of world
government, the onslaught of Super Intelligence’s,</a>
etc.

<p>
Anyone care to fill me in?

<p>
BM
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0377.html">[ Next ]</a><a href="0375.html">[ Previous ]</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="0704.html">Eugene Leitl</a>
</ul>
</body></html>
