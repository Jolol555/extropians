<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Can Pure Lookup Tables Be Conscious?</title>
<meta name="Author" content="Lee Corbin (lcorbin@ricochet.net)">
<meta name="Subject" content="Can Pure Lookup Tables Be Conscious?">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Can Pure Lookup Tables Be Conscious?</h1>
<!-- received="Tue Apr 24 21:46:11 2001" -->
<!-- isoreceived="20010425034611" -->
<!-- sent="Tue, 24 Apr 2001 20:46:01 -0700" -->
<!-- isosent="20010425034601" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@ricochet.net" -->
<!-- subject="Can Pure Lookup Tables Be Conscious?" -->
<!-- id="200104250344.WAA26371@dal-mail2.ricochet.net" -->
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@ricochet.net?Subject=Re:%20Can%20Pure%20Lookup%20Tables%20Be%20Conscious?&In-Reply-To=&lt;200104250344.WAA26371@dal-mail2.ricochet.net&gt;"><em>lcorbin@ricochet.net</em></a>)<br>
<strong>Date:</strong> Tue Apr 24 2001 - 21:46:01 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3031.html">Damien Broderick: "TRANSCENSION"</a>
<li><strong>Previous message:</strong> <a href="3029.html">John Marlow: "Re: CRYO: &quot;Ischemia&quot; vs. &quot;Reversibly dead&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3050.html">Anders Sandberg: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Reply:</strong> <a href="3050.html">Anders Sandberg: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3093.html">hal@finney.org: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3190.html">Lee Corbin: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3192.html">Lee Corbin: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3030">[ date ]</a>
<a href="index.html#3030">[ thread ]</a>
<a href="subject.html#3030">[ subject ]</a>
<a href="author.html#3030">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Have I been wrong for twenty years, and is it possible that a
<br>
pure lookup table can be conscious?  This post is a continuation
<br>
of a discussion in &quot;Re: How To Live In A Simulation&quot;, which ended
<br>
in late March 2001.
<br>
<p>In my opinion, a number of people made some very interesting and
<br>
significant contributions---so many per day that I was unable to
<br>
keep up.  Most significant however, was the submission by
<br>
Hal Finney (28 Mar 2001 21:59:28 -0800) that read in part:
<br>
<p><em>&gt; The index into a lookup table, if expressed as a binary address,
</em><br>
<em>&gt; presumably carries as much information as is in your own brain.
</em><br>
<em>&gt; And each successive change of that index is a transformation
</em><br>
<em>&gt; every bit as causal and dependent upon experience as the changes
</em><br>
<em>&gt; in your own brain from one moment to the next.
</em><br>
<p>Yes, it is causal all right.  To outward appearances it does
<br>
resemble the cherished causality that drives forward our own
<br>
conscious experiences.  But I will attempt a valid reductio
<br>
ad absurdum.
<br>
<p>A note of caution: some attack mechanism by an unacceptable
<br>
reductio ad absurdum that always goes something like this:
<br>
&quot;Clearly one atom is not intelligent; now if N atoms are not
<br>
intelligent, it is surely the case that N+1 atoms are not
<br>
intelligent, since it is inconceivable that that addition
<br>
of a single atom is significant.  Therefore, no collection
<br>
of atoms can be intelligent.&quot;  The reader is encouraged to
<br>
ferret out any similar reasoning in what follows.
<br>
<p>Suppose that by the laws of physics there turn out to be
<br>
N_QUANTUM states that an ordinary human brain goes through
<br>
<p>in the course of a few minutes.  I wish I had a good idea
<br>
of what the minimum size of N_QUANTUM is, but it has to be
<br>
10^54, or less, according to Tipler (p. 31).
<br>
<p>The ultimate question may emerge as &quot;does the activity
<br>
driven by a lookup table that completely duplicates a
<br>
few minutes of physics for a human brain also generate
<br>
consciousness?&quot;  But if I am lucky, this question can
<br>
be approached gradually without loss of resolution.
<br>
<p>The argument that a super-enormous lookup table is able
<br>
to generate the same experience, regardless of input, is
<br>
a part of Hal's argument's assumptions above.  This
<br>
&quot;complete table&quot; has the characteristic of being able to
<br>
pass the Turing Test, for example, or any other test of
<br>
flexibility that we have come to associate with genuinely
<br>
feeling programs or people.  But let's focus on the
<br>
abbreviated table that is just one possible thread through
<br>
the table.  In other words, &quot;playback&quot; as Hal says:
<br>
<p><em>&gt; You are saying that [for someone's experience] you could write
</em><br>
<em>&gt; down the series of states, and then play them back in a simple
</em><br>
<em>&gt; way?  Which of course you could do with your own brain as well,
</em><br>
<em>&gt; right?  You could write down the sequence of your own neural
</em><br>
<em>&gt; brain states and then &quot;play them back&quot;.
</em><br>
<p><em>&gt; The question is, are such playbacks conscious?  Your initial
</em><br>
<em>&gt; experience was conscious; [The original experience of the
</em><br>
<em>&gt; individual you made it from] was at least conscious when you
</em><br>
<em>&gt; created the lookup table, and possibly when you jumped around in
</em><br>
<em>&gt; it again later. Now you are playing back some of that experience.
</em><br>
<p>The rest of Hal's well-written post argues persuasively that
<br>
we would have to make a number of strong assumptions about 
<br>
the nature of consciousness in order to answer the question,
<br>
assumptions that we are in no position to make.
<br>
<p>But apart from the theoretical question &quot;Are Lookups Conscious&quot;,
<br>
there is the (perhaps soon-to-be-practical) question of the
<br>
value of playbacks, or as I called it in a thread here five years
<br>
ago, the value of &quot;Repeated Experience&quot;.  Uploaded entities
<br>
may have to soon decide what to do in real situations involving these
<br>
values.  So something of practical importance, in my opinion, does hinge
<br>
on the outcome of these discussions.
<br>
<p>To assist visualization of what is going on here and which may
<br>
facilitate the discussion, consider Conway's Game of Life.
<br>
Played on an nxn grid, it can implement fundamental logic and
<br>
so emulate any computer program.  (For a great, animated
<br>
introduction, see <a href="http://www.math.com/students/wonders/life/life.html">http://www.math.com/students/wonders/life/life.html</a>.)
<br>
<p><p>The advantage to Life is that the &quot;generations&quot; are discrete. 
<br>
Suppose that we visualize a gigantic Life Board made up of electric
<br>
lights, together with simple, underlying causal circuitry beneath
<br>
the board which takes any generation as input, and outputs---again
<br>
in a display of lights on the Board---the next generation.  Because
<br>
the machinery beneath the board (and in fact the whole board)
<br>
operates in accordance with quantum physics, (even classical physics),
<br>
we surely by means of this substitution have not yet crossed any
<br>
significant boundaries:  a human---or a civilization---that executes
<br>
on a Life Board is no different in any significant respect from our
<br>
own.  Importantly, entities on the Life Board must also possess
<br>
exactly the same kind of consciousness and feelings that we do.
<br>
(Apologies to the non-functionalists on this list.  But this isn't
<br>
the thread to debate those fundamentals.)
<br>
<p>Now &quot;playback&quot; in its crudest form is and never has been anything
<br>
significant, if it's merely the portrayal of computation or experience. 
<br>
Suppose that you watch a television &quot;re-creation&quot; of some terrible
<br>
episode in which people are being depicted as tortured.  If the
<br>
apparatus is really doing nothing more than arranging photons in
<br>
certain patterns and aiming them towards you, no important moral
<br>
and behavior problem really arises.  We would be doing an immense
<br>
disservice to entities undergoing genuine suffering were we to
<br>
confuse portrayals and emulations here.  
<br>
<p>It is now easy and instructive to visualize such &quot;playback&quot; on
<br>
a Life Board.  Rather than the next generation being actively
<br>
computed, we may simply have an automatic arm reach into a
<br>
sequenced table of gels, each with bright spots in fluorescent
<br>
paint, and place the next gel in sequence on the Life Board.
<br>
This gives every bit the appearance of a civilization developing,
<br>
or of an entity having an experience, but in reality has no
<br>
content.  Indeed, the lights are on, but no one is home.
<br>
<p>Therefore, giant lookup tables are not conscious.
<br>
<p>(To suppose the contrary---that moral weight applies to
<br>
the question of whether this portrayal should be run,
<br>
brings us back to the Theory of Dust, and to a (valid)
<br>
reduction to the assertion that all experiences are really
<br>
happening in the nebulae of dust (when looked at the right
<br>
way) and thereby to the nihilistic conclusion that nothing
<br>
matters anyway.  Details of this reduction can be found at
<br>
www.leecorbin.com/SFS.html.)
<br>
<p>This post leaves aside the deeper question of whether a complete
<br>
lookup table---one that has all the possibilities embedded
<br>
within it, not just a single thread---is conscious.  Nothing
<br>
above yet explicitly rebuts Hal's claim, which I quote again:
<br>
<p><em>&gt; The index into a lookup table, if expressed as a binary address,
</em><br>
<em>&gt; presumably carries as much information as is in your own brain.
</em><br>
<em>&gt; And each successive change of that index is a transformation
</em><br>
<em>&gt; every bit as causal and dependent upon experience as the changes
</em><br>
<em>&gt; in your own brain from one moment to the next.
</em><br>
<p>I hope that for the sake of the simplicity of my own world-view,
<br>
that this point also can be refuted.  Maybe later.
<br>
<p>Lee Corbin
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3031.html">Damien Broderick: "TRANSCENSION"</a>
<li><strong>Previous message:</strong> <a href="3029.html">John Marlow: "Re: CRYO: &quot;Ischemia&quot; vs. &quot;Reversibly dead&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3050.html">Anders Sandberg: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Reply:</strong> <a href="3050.html">Anders Sandberg: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3093.html">hal@finney.org: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3190.html">Lee Corbin: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<li><strong>Maybe reply:</strong> <a href="3192.html">Lee Corbin: "Re: Can Pure Lookup Tables Be Conscious?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3030">[ date ]</a>
<a href="index.html#3030">[ thread ]</a>
<a href="subject.html#3030">[ subject ]</a>
<a href="author.html#3030">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:56 MDT</em>
</em>
</small>
</body>
</html>
