<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Engaging Bioethics</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Engaging Bioethics">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Engaging Bioethics</h1>
<!-- received="Fri Mar  2 11:12:29 2001" -->
<!-- isoreceived="20010302181229" -->
<!-- sent="Fri, 02 Mar 2001 13:12:33 -0500" -->
<!-- isosent="20010302181233" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Engaging Bioethics" -->
<!-- id="3A9FE291.CCDC2062@pobox.com" -->
<!-- inreplyto="4.2.0.58.20010302105630.00b9b9c0@mail.gmu.edu" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Engaging%20Bioethics&In-Reply-To=&lt;3A9FE291.CCDC2062@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Fri Mar 02 2001 - 11:12:33 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0066.html">James Rogers: "Re: extropians-digest V6 #61"</a>
<li><strong>Previous message:</strong> <a href="0064.html">Chris Rasch: "HUMOR: Telephone line cleaning"</a>
<li><strong>In reply to:</strong> <a href="0061.html">Robin Hanson: "Engaging Bioethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0075.html">Robin Hanson: "Re: Engaging Bioethics"</a>
<li><strong>Reply:</strong> <a href="0075.html">Robin Hanson: "Re: Engaging Bioethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#65">[ date ]</a>
<a href="index.html#65">[ thread ]</a>
<a href="subject.html#65">[ subject ]</a>
<a href="author.html#65">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Robin Hanson wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; To appear, Summer 2002, Social Philosophy &amp; Policy 19(2).
</em><br>
<em>&gt; Current version at <a href="http://hanson.gmu.edu/bioerror.pdf">http://hanson.gmu.edu/bioerror.pdf</a> or .ps
</em><br>
<p>This is a really fascinating paper... from a Friendly AI standpoint.  A
<br>
lot of the concepts introduced in the opening sections sound like the sort
<br>
of thing a maturing AI would formulate to learn and quantify human
<br>
ethics.  Is the paper likely to stick around on your website, and is it
<br>
available for linkery and/or citation?
<br>
<p>I'm surprised at the degree of useful analysis that ethics would seem to
<br>
have undergone, in particular the concept of reflective equilibria.  Are
<br>
there any moderately technical works you would care to recommend on the
<br>
subject?
<br>
<p><p>I have a few objections to the way you phrase your evolutionary reasoning,
<br>
in particular:
<br>
<p>&quot;Often a moral intuition about the worthiness of some action comes
<br>
packaged with a rationale that its purpose is to benefit some third party,
<br>
even though a careful study of the details and origin of that intuition
<br>
suggests that it functions primarily to benefit the actor or his close
<br>
associates.  Such moral intuitions are commonly considered to be
<br>
especially likely to be in error, all else equal, through some complex
<br>
process of self-deception.&quot;
<br>
<p>It is an error to characterize the political emotions as being &quot;complex
<br>
processes of self-deception&quot;.  Political emotions are not self-deceptions;
<br>
they are evolved biases in systems of honestly held beliefs.  Political
<br>
emotions evolve in imperfectly deceptive social organisms; all else being
<br>
equal, the actor is more likely to convince others of a given statement if
<br>
he believes it himself.  The evolutionary rationale is real, but is
<br>
nowhere represented in cognition.  A slave-owner who believes that slaves
<br>
cannot be trusted with freedom is not deceiving himself; he is rather
<br>
being deceived by evolution - he is making cognitive errors which have
<br>
adaptive value (for him).
<br>
<p><p>Some other minor but evolutionarily-bothersome errors scattered through
<br>
the document:
<br>
<p>&quot;When people want to signal their health, wealth, and intelligence to
<br>
potential mates, they still use the ancient signals of physique, sports,
<br>
fancy clothes, and witty conversation.  They do not use the plausibly more
<br>
reliable modern substitutes of medical tests, bank statements, educational
<br>
degrees, and IQ scores.&quot;
<br>
<p>This presumes that the female of the species is seeking health, wealth,
<br>
and intelligence as declarative goals, rather than responding to cues
<br>
which were adaptive cues in the ancestral environment; similarly, that the
<br>
male is executing a consciously reasoned mate-acquisition strategy rather
<br>
than acting on instincts for &quot;how to acquire mates&quot; which were adaptive in
<br>
the ancestral environment.  However, these errors are comparatively
<br>
trivial.
<br>
<p><p>&quot;Infrequent large costs, in contrast, can signal long term allegiance. 
<br>
[...]  Health care is thus our one remaining ancient strong signal of
<br>
long-term loyalty to associates, a signal that has likely stuck even as
<br>
the world has changed.&quot;
<br>
<p>Health care is not just a signal for loyalty because of its sparse
<br>
temporal distribution, but because of its context-insensitivity.  Someone
<br>
who is sick or injured has apparently decreased in value as an ally; thus,
<br>
caring for such an ally sends a signal to nearby observers that the carer
<br>
is someone who can be relied on to remain allied even under extreme
<br>
circumstances.  Again, this motive does not need to be declaratively
<br>
represented to become enshrined as an adaptive type of reasoning; indeed,
<br>
it is evolutionarily more adaptive if the ulterior motive is *not*
<br>
represented - if the carer *genuinely* cares about the recipient.  An
<br>
unconditional ally is substantially more valuable than a conditional ally;
<br>
thus, humans are evolved to admire unconditionality and be disgusted at
<br>
conditionality; thus, humans are now evolved to have and display
<br>
unconditional emotions, in defiance of short-term payoffs and penalties. 
<br>
(For the record, please do not interpret the above as a statement that I
<br>
believe unconditionality to be irrational.  More the reverse; there are
<br>
some emotionally buried forms of context-sensitivity that I regard as
<br>
naturalistic infringements on valued moral principles.)
<br>
<p><p>&quot;If we think of status as having many good allies, then you want them to
<br>
act as if they were sure to be of high status.&quot;
<br>
<p>Why?
<br>
<p>&quot;So if investing in one’s health is more attractive when one has many
<br>
allies,&quot;
<br>
<p>Why?
<br>
<p>&quot;then you will want your ally to invest more in health than he or she
<br>
would choose for himself or herself.&quot;
<br>
<p>This conclusion follows from the premises, but both premises strike me as
<br>
non sequiturs.  I do not see why either premised behavior is adaptive, or
<br>
how the final conclusion is adaptive.
<br>
<p>Personally, I would conclude the reverse; in terms of evolutionary
<br>
rationale, a patron is more likely to want the ally to expend resources on
<br>
group ventures, while the ally is more likely to expend resources on
<br>
increasing context-insensitive personal effectiveness, which includes
<br>
health care.  A person is much more likely to rationalize the group
<br>
utility of personal health care than a third-party observer.  But the main
<br>
thing I'm objecting to is that you went *way* too fast in that paragraph
<br>
and totally lost me.
<br>
<p><p>&quot;Thus your allies should care more about your health than about your
<br>
happiness.&quot;
<br>
<p>*This* makes perfect sense, and you don't need the earlier stuff to lead
<br>
up to it.  Health makes someone a more valuable ally.  Happiness may or
<br>
may not.  If an ally wants to be happy at the expense of their health, it
<br>
is adaptive for you if they don't take that action.  This is a valued part
<br>
of friendship!  Some people want to resist temptation, but they can't
<br>
resist temptation in contexts where giving in to temptation was adaptive
<br>
in the ancestral environment.  Thus it's the role of the friend to counsel
<br>
the befriended against eating too many cookies or committing adultery.  An
<br>
elegant and symbiotic relationship.
<br>
<p><p>&quot;While we believe that our apparent paternalism is a response to the
<br>
ignorance of those we are supposedly helping, it seems to actually be the
<br>
direct result of an ancient fear that such people will not remain in our
<br>
group of allies.&quot;
<br>
<p>I have to say that I found this totally unconvincing.  It looks to me like
<br>
it's just standard paternalism, the political emotion whereby gaining
<br>
power over others (context-insensitive, adaptive power) is rationalized as
<br>
a group benefit.
<br>
<p>I see no domain specificity for health care; it is a special case of
<br>
paternalism on the group scale, and &quot;friends help you resist temptation&quot;
<br>
on the individual scale.
<br>
<p><p>&quot;Also, while many believe they want NHI to deal with some internal market
<br>
failure, the actual function of NHI appears to be to promote national
<br>
solidarity.&quot;
<br>
<p>Very shaky.  Again, I see no reason to hypothesize domain specificity for
<br>
health care; as far as I can tell, advocacy of NHI is generated by the
<br>
same set of causes that generate advocacy of Welfare.  (Social Security
<br>
does plausibly have domain specificity with respect to our instincts about
<br>
how to treat elders.)  To be specific, both Welfare and NHI derive
<br>
argumentary force from our intuitions about how to treat tribal members
<br>
who are the victims of unpredictable, major, temporally sparse
<br>
catastrophes.  Opponents of both Welfare and NHI invoke mental imagery
<br>
regarding &quot;savings&quot; or &quot;insurance&quot;, i.e. that the catastrophes are
<br>
predictable and preventable.
<br>
<p>But your point about why people don't seek information about quality
<br>
provided to others, despite their declared concern, is probably correct.
<br>
<p><p>Page 19 and 20 struck me as very hard to follow - you seemed to keep
<br>
switching between individual definitions of benefit, evolutionary
<br>
definitions of benefit, and morally normative definitions of benefit.  And
<br>
I didn't understand how any of it was relevant to health care.
<br>
<p><p>In the appendix... well, basically I disagreed with just about everything
<br>
you said about health care and status, for the reasons given above.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0066.html">James Rogers: "Re: extropians-digest V6 #61"</a>
<li><strong>Previous message:</strong> <a href="0064.html">Chris Rasch: "HUMOR: Telephone line cleaning"</a>
<li><strong>In reply to:</strong> <a href="0061.html">Robin Hanson: "Engaging Bioethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0075.html">Robin Hanson: "Re: Engaging Bioethics"</a>
<li><strong>Reply:</strong> <a href="0075.html">Robin Hanson: "Re: Engaging Bioethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#65">[ date ]</a>
<a href="index.html#65">[ thread ]</a>
<a href="subject.html#65">[ subject ]</a>
<a href="author.html#65">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:39 MDT</em>
</em>
</small>
</body>
</html>
