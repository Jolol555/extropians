<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Chunking intelligence functions</title>
<meta name="Author" content="Anders Sandberg (asa@nada.kth.se)">
<meta name="Subject" content="Re: Chunking intelligence functions">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Chunking intelligence functions</h1>
<!-- received="Thu May 10 02:40:47 2001" -->
<!-- isoreceived="20010510084047" -->
<!-- sent="Thu, 10 May 2001 10:40:38 +0200" -->
<!-- isosent="20010510084038" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Chunking intelligence functions" -->
<!-- id="01051010403800.20121@akira" -->
<!-- inreplyto="3AFA2DC1.72DA9AD4@pobox.com" -->
<strong>From:</strong> Anders Sandberg (<a href="mailto:asa@nada.kth.se?Subject=Re:%20Chunking%20intelligence%20functions&In-Reply-To=&lt;01051010403800.20121@akira&gt;"><em>asa@nada.kth.se</em></a>)<br>
<strong>Date:</strong> Thu May 10 2001 - 02:40:38 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4084.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<li><strong>Previous message:</strong> <a href="4082.html">Eliezer S. Yudkowsky: "Re: Chunking intelligence functions"</a>
<li><strong>In reply to:</strong> <a href="4074.html">Eliezer S. Yudkowsky: "Re: Chunking intelligence functions"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4085.html">Francois-Rene Rideau: "Re: Chunking intelligence functions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4083">[ date ]</a>
<a href="index.html#4083">[ thread ]</a>
<a href="subject.html#4083">[ subject ]</a>
<a href="author.html#4083">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
torsdagen den 10 maj 2001 07:57 Eliezer S. Yudkowsky wrote:
<br>
<em>&gt; Spike Jones wrote:
</em><br>
<em>&gt; &gt; &gt; &quot;Eliezer S. Yudkowsky&quot; wrote: ...Minsky and
</em><br>
<em>&gt; &gt; &gt; Papert killing off the entire field of neural networks...
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Elizer, Im not up to speed on the state of the art in
</em><br>
<em>&gt; &gt; neural nets, but I did notice there was not much said
</em><br>
<em>&gt; &gt; about it in recent years after it seemed so promising
</em><br>
<em>&gt; &gt; 12 yrs ago.  Could you give us a one paragraph
</em><br>
<em>&gt; &gt; summary on your comment?
</em><br>
<em>&gt;
</em><br>
<em>&gt; No, this was long before then.  I think there was a paper in 1967 and a
</em><br>
<em>&gt; book in 1969, if I recall correctly.  Essentially, Minsky and Papert
</em><br>
<em>&gt; proved that a two-layer Perceptron (which was what a neural network was
</em><br>
<em>&gt; called back then) couldn't compute the XOR function.  Which killed off the
</em><br>
<em>&gt; entire, then-nascent field of neural networks.  Eventually someone noticed
</em><br>
<em>&gt; that a three-layer neural network (with a total of five neurons) could
</em><br>
<em>&gt; easily compute the XOR function and the entire field came back to life.
</em><br>
<p>Yes. the book _Perceptrons_ was published in 1969 and really put a damper on 
<br>
the hype. However, Minsky and Papert did show that three-layer networks could 
<br>
do XOR in the book, it was just that they were pessimistic about finding a 
<br>
training rule for such networks.  
<br>
<p>(Why care for XOR? Because it demonstrated that there were simple operations 
<br>
the networks could not perform; the book gives several other examples of more 
<br>
behaviorally relevant things like parity and pattern recognition simple 
<br>
perceptrons cannot do).
<br>
<p><em>&gt; I am oversimplifying slightly - what really brought the field back was
</em><br>
<em>&gt; backpropagation, which is what enabled the training of multilayer networks
</em><br>
<em>&gt; - but the fact still remains that Minsky and Papert's eulogy was
</em><br>
<em>&gt; incredibly premature and did a lot of damage.  Nothing remotely on the
</em><br>
<em>&gt; scale of Margaret Mead, though.
</em><br>
<p>Actually, I think it did a good thing. It made the field more cautious and 
<br>
less hyped. The book is good science and hence far from the claims of Mead. 
<br>
It was the rest of the field that should be blamed: in the face of adversity 
<br>
it just caved in, and did not meet the challenge posed by Minsky in finding a 
<br>
multilayer training algorithm. 
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4084.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<li><strong>Previous message:</strong> <a href="4082.html">Eliezer S. Yudkowsky: "Re: Chunking intelligence functions"</a>
<li><strong>In reply to:</strong> <a href="4074.html">Eliezer S. Yudkowsky: "Re: Chunking intelligence functions"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4085.html">Francois-Rene Rideau: "Re: Chunking intelligence functions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4083">[ date ]</a>
<a href="index.html#4083">[ thread ]</a>
<a href="subject.html#4083">[ subject ]</a>
<a href="author.html#4083">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:04 MDT</em>
</em>
</small>
</body>
</html>
