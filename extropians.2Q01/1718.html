<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Emulation vs. Simulation</title>
<meta name="Author" content="hal@finney.org (hal@finney.org)">
<meta name="Subject" content="Re: Emulation vs. Simulation">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Emulation vs. Simulation</h1>
<!-- received="Thu Mar 29 01:11:06 2001" -->
<!-- isoreceived="20010329081106" -->
<!-- sent="Thu, 29 Mar 2001 00:07:39 -0800" -->
<!-- isosent="20010329080739" -->
<!-- name="hal@finney.org" -->
<!-- email="hal@finney.org" -->
<!-- subject="Re: Emulation vs. Simulation" -->
<!-- id="200103290807.AAA08085@finney.org" -->
<!-- inreplyto="Emulation vs. Simulation" -->
<strong>From:</strong> <a href="mailto:hal@finney.org?Subject=Re:%20Emulation%20vs.%20Simulation&In-Reply-To=&lt;200103290807.AAA08085@finney.org&gt;"><em>hal@finney.org</em></a><br>
<strong>Date:</strong> Thu Mar 29 2001 - 01:07:39 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1719.html">J. R. Molloy: "Re: Antidepressants: Happiness is only a drug?"</a>
<li><strong>Previous message:</strong> <a href="1717.html">Spudboy100@aol.com: "Re: 70s trivia, was Re: Antidepressants: Happiness is only a drug?"</a>
<li><strong>Maybe in reply to:</strong> <a href="1120.html">Lee Corbin: "Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1755.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<li><strong>Reply:</strong> <a href="1755.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1718">[ date ]</a>
<a href="index.html#1718">[ thread ]</a>
<a href="subject.html#1718">[ subject ]</a>
<a href="author.html#1718">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Jim Fehlinger, &lt;<a href="mailto:fehlinger@home.com?Subject=Re:%20Emulation%20vs.%20Simulation&In-Reply-To=&lt;200103290807.AAA08085@finney.org&gt;">fehlinger@home.com</a>&gt;, writes:
<br>
<em>&gt; Here's what McCrone has to say about this in _Going Inside_:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;With hindsight, it seems odder and odder that mainstream psychologists
</em><br>
<em>&gt; were so intent on studying the mind without also studying the brain.
</em><br>
<em>&gt; Even if they could not do actual experiments, there was already
</em><br>
<em>&gt; enough known about neurology to help frame their theories.  However,
</em><br>
<em>&gt; a generation of researchers had grown up in the belief that
</em><br>
<em>&gt; information processing was all about programs.  It did not really
</em><br>
<em>&gt; matter what kind of hardware a program was running on -- whether it
</em><br>
<em>&gt; was flesh and blood or silicon -- so long as the underlying logic
</em><br>
<em>&gt; was preserved.  The brain was simply a particular implementation
</em><br>
<em>&gt; of something more general.
</em><br>
<p>Makes sense up to this point.
<br>
<p><em>&gt; So how the brain might choose to arrange
</em><br>
<em>&gt; its circuits was of marginal interest at best.
</em><br>
<p>Thud.
<br>
<p>This final sentence does not follow.  It is slipping between levels
<br>
of understanding.  Philosophically, a computer can be conscious.
<br>
But psychologically, the only conscious systems around are brains.
<br>
While the details of brain structure are irrelevant to the abstract
<br>
philosopher, to the psychologists (which is what this paragraph is about)
<br>
they are highly relevant.
<br>
<p>I, like most of us, adopt a position which is basically functionalism;
<br>
anyone who believes that uploading is possible (even gradual uploading)
<br>
believes in it.  Yet do any of us agree that how a brain arranges its
<br>
circuits is of only marginal interest?  I don't see how.  This is of
<br>
crucial interest in understanding brain behavior.
<br>
<p>It's certainly true that, once this understanding is gained, the same
<br>
functional properties can be realized in other media, such as computer
<br>
circuits.  But the paragraph is discussion how theories of consciousness
<br>
are created and tested.  The most devout, strict functionalist will find
<br>
his philosophy fully supportive of the notion that his theories of mind
<br>
must be consistent with the physical properties that implement the mind,
<br>
which is the structure of the brain.
<br>
<p><em>&gt; In 1960, one of the founders of cognitive science, the Princeton
</em><br>
<em>&gt; philosopher Hilary Putnam, seized on Turing's proof to argue
</em><br>
<em>&gt; that it meant brains did not matter.  If the processes of the
</em><br>
<em>&gt; human mind could be expressed in computational form, then any
</em><br>
<em>&gt; old contraption could be used to recreate what brains did.
</em><br>
<p>Of course.  You could make a computer capable of running a conscious
<br>
program out of tin cans and string, in principle.
<br>
<p>But this says NOTHING that implies that we should ignore the brain in
<br>
trying to understand how it works.  All it means is that, once that
<br>
understanding is gained, we can at least in principle implement the
<br>
same functional relationships on a computer.
<br>
<p><em>&gt; And here's what Edelman has to say about functionalism:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;A persuasive set of arguments states that if I can describe
</em><br>
<em>&gt; an effective mathematical procedure (technically called an
</em><br>
<em>&gt; algorithm...), then that procedure can be carried out by a
</em><br>
<em>&gt; Turing machine.  More generally, we know that **any**
</em><br>
<em>&gt; algorithm or effective procedure may be executed by any
</em><br>
<em>&gt; universal Turing machine.  The existence of universal
</em><br>
<em>&gt; machines implies that the **mechanism** of operation of
</em><br>
<em>&gt; any one of them is unimportant.  This can be shown in the
</em><br>
<em>&gt; real world by running a given program on two digital computers
</em><br>
<em>&gt; of radically different construction or hardware design and
</em><br>
<em>&gt; successfully obtaining identical results...
</em><br>
<p>Sure, keeping in mind that the details are unimportant only in the
<br>
philosophical sense.  In terms of learning what the program is, being
<br>
able to dump out the memory requires understanding how the data is stored
<br>
in memory in the first place.  So to learn about the program and how it
<br>
works, understanding these details is of crucial importance.  This is
<br>
the distinction which the anti-functionalists seem eager to overlook.
<br>
<p><em>&gt; More damaging is the fact that an analysis of ecological
</em><br>
<em>&gt; and environmental variation and of the categorization
</em><br>
<em>&gt; procedures of animals and humans... makes it unlikely
</em><br>
<em>&gt; that the world (physical and social) could function
</em><br>
<em>&gt; as a tape for a Turing machine...  The brain and
</em><br>
<em>&gt; nervous system cannot be considered in isolation from
</em><br>
<em>&gt; states of the world and social interactions.  But
</em><br>
<em>&gt; such states, both environmental and social, are
</em><br>
<em>&gt; indeterminate and open-ended.  They cannot be simply
</em><br>
<em>&gt; identified by any software description...
</em><br>
<p>There is a germ of truth in this critique.  Technically a TM does not
<br>
interact with a changing environment.  It has a static set of input and
<br>
output tapes.  As a model for some forms of computation, this is adequate,
<br>
but to model a physical system which is not fully self-contained it is
<br>
not enough.
<br>
<p>I don't view this as of crucial importance, because the basic idea
<br>
still holds.  Modern computers are open systems just like brains; they
<br>
interact with their environments.  I don't know if anyone has formalized
<br>
this notion of &quot;open&quot; computation.  But the general idea is still valid,
<br>
that a computer interacting with an environment is every bit as powerful
<br>
in its information-processing capabilities as a brain interacting with
<br>
that environment.
<br>
<p>We should also note that the recent discoveries of quantum computers
<br>
suggest that it may be possible for physical systems to be more powerful
<br>
than Turing Machines.  However we can fix this by simply positing a
<br>
Universal Quantum Computer in place of the Universal Turing Machine.
<br>
The basic point remains true, that information processing is a fundamental
<br>
physical process which can be carried out by many kinds of systems,
<br>
from brains to computer chips.
<br>
<p><em>&gt; Now we begin to see why digital computers are a false
</em><br>
<em>&gt; analogue to the brain.  The facile analogy with
</em><br>
<em>&gt; digital computers breaks down for several reasons.
</em><br>
<em>&gt; The tape read by a Turing machine is marked unambiguously
</em><br>
<em>&gt; with symbols chosen from a finite set; in contrast,
</em><br>
<em>&gt; the sensory signals available to nervous systems are
</em><br>
<em>&gt; truly analogue in nature and therefore are neither
</em><br>
<em>&gt; unambiguous nor finite in number.
</em><br>
<p>Nonsense!  If sensory signals were truly analog they would have an
<br>
infinite amount of precision and therefore carry an infinite amount
<br>
of information.  This is fundamentally impossible by quantum theory
<br>
if nothing else.  Any measuring device, whether a retinal cell or a
<br>
magnetometer, has a finite precision.
<br>
<p><em>&gt; Turing machines
</em><br>
<em>&gt; have by definition a finite number of internal states,
</em><br>
<em>&gt; while there are no apparent limits on the number of
</em><br>
<em>&gt; states the human nervous system can assume (for example,
</em><br>
<em>&gt; by analog modulation of large numbers of synaptic
</em><br>
<em>&gt; strengths in neuronal connections).
</em><br>
<p>Further nonsense!  Are brains immune to the Bekenstein Bound?  Does
<br>
Edelman really think the information storage capacity of the human brain
<br>
is INFINITE?
<br>
<p><em>&gt; The transitions
</em><br>
<em>&gt; of Turing machines between states are entirely
</em><br>
<em>&gt; deterministic, while those of humans give ample appearance
</em><br>
<em>&gt; of indeterminacy.  Human experience is not based on
</em><br>
<em>&gt; so simple an abstraction as a Turing machine; to get
</em><br>
<em>&gt; our 'meanings' we have to grow and communicate in
</em><br>
<em>&gt; a society.&quot;
</em><br>
<p>Here I think he has a technical point, but first, Turing machines can
<br>
approximate indeterminacy, and second, we might use quantum computers
<br>
in place of TMs if it should turn out that quantum uncertainty plays a
<br>
fundamental role in brain behavior.
<br>
<p>I am surprised that these quotes (which I appreciate Jim taking the
<br>
time to find and present) are what passes for intelligent commentary on
<br>
these issues.  There are arguments against functionalism which are far
<br>
more profound than what McCrone and Edelman offer.  They focus on one
<br>
weak point, which is that there is no agreed-upon way to unambiguously
<br>
describe what consitutes an implementation of a given computation.
<br>
<p>This is an issue which we have debated on this list at length over the
<br>
years, and it is discussed in many other forums as well.  Chalmers has
<br>
done a good job of tackling this problem head-on (and it nearly bounced
<br>
him into dualism).  Such arguments are much more difficult to deal with
<br>
than claiming that brains have more power than TMs because they are
<br>
analog, for Pete's sake.
<br>
<p>Hal
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1719.html">J. R. Molloy: "Re: Antidepressants: Happiness is only a drug?"</a>
<li><strong>Previous message:</strong> <a href="1717.html">Spudboy100@aol.com: "Re: 70s trivia, was Re: Antidepressants: Happiness is only a drug?"</a>
<li><strong>Maybe in reply to:</strong> <a href="1120.html">Lee Corbin: "Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1755.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<li><strong>Reply:</strong> <a href="1755.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1718">[ date ]</a>
<a href="index.html#1718">[ thread ]</a>
<a href="subject.html#1718">[ subject ]</a>
<a href="author.html#1718">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:44 MDT</em>
</em>
</small>
</body>
</html>
