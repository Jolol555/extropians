<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Risk vs. Payoff</title>
<meta name="Author" content="Emlyn (emlyn@one.net.au)">
<meta name="Subject" content="Re: Risk vs. Payoff">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Risk vs. Payoff</h1>
<!-- received="Thu May 10 18:37:44 2001" -->
<!-- isoreceived="20010511003744" -->
<!-- sent="Fri, 11 May 2001 10:00:31 +0930" -->
<!-- isosent="20010511003031" -->
<!-- name="Emlyn" -->
<!-- email="emlyn@one.net.au" -->
<!-- subject="Re: Risk vs. Payoff" -->
<!-- id="003401c0d9b1$9ac95b20$3c0120c2@squashy2000" -->
<!-- inreplyto="002501c0d989$5d5e9340$3562f9c2@xxxx" -->
<strong>From:</strong> Emlyn (<a href="mailto:emlyn@one.net.au?Subject=Re:%20Risk%20vs.%20Payoff&In-Reply-To=&lt;003401c0d9b1$9ac95b20$3c0120c2@squashy2000&gt;"><em>emlyn@one.net.au</em></a>)<br>
<strong>Date:</strong> Thu May 10 2001 - 18:30:31 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4130.html">Lee Corbin: "Re: Reversible Computation and Experience"</a>
<li><strong>Previous message:</strong> <a href="4128.html">Eliezer S. Yudkowsky: "Re: Iconoclasm (was: Chunking intelligence functions)"</a>
<li><strong>In reply to:</strong> <a href="4114.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4257.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<li><strong>Reply:</strong> <a href="4257.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4129">[ date ]</a>
<a href="index.html#4129">[ thread ]</a>
<a href="subject.html#4129">[ subject ]</a>
<a href="author.html#4129">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Aleks wrote:
<br>
<em>&gt; &gt; More seriously, you have an implicit assumption here that survival of
</em><br>
the
<br>
<em>&gt; &gt; species, or survival of intelligent life, or some otherwise defined
</em><br>
class,
<br>
<em>&gt; &gt; is our &quot;supergoal&quot; (to borrow some jargon). Many here would argue that
</em><br>
this
<br>
<em>&gt;
</em><br>
<em>&gt; I was referring to the most fundamental class, namely life. It's perhaps
</em><br>
the
<br>
<em>&gt; only one which is not abstract.
</em><br>
<p>How so? In what way is life a non-abstract grouping? More importantly, it's
<br>
not even clearly defined, and will become harder to pin down as we venture
<br>
further into nanotech, and begin to make all kinds of interesting
<br>
self-directed &amp; self-replicating greeblies.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; is fundamentally at odds with extropianism, which has a more
</em><br>
individualistic
<br>
<em>&gt; &gt; outlook... we would save ourselves, at the cost of the long term good of
</em><br>
the
<br>
<em>&gt; &gt; species perhaps. Although it is not at all clear that this is a required
</em><br>
<em>&gt; &gt; tradeoff.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Individualism and selfishness are just other evolved heuristics. Can you
</em><br>
<em>&gt; transcend your &quot;naturally selected&quot; impulses and comprehend with the mind
</em><br>
alone?
<br>
<p>Yes, they certainly are. I don't think that we can pick any motivation, and
<br>
call it anything other than arbitrary. When you get right down to it, there
<br>
is no purely rational basis for doing anything at all, which does not rest
<br>
on some arbitrary axioms, like &quot;it is good for me to survive&quot;. As an
<br>
example, can you present a purely rational case that our prefered objective
<br>
should be the continuance of the class of living things, in preference to
<br>
other goals such as continuance of the self? Some redundance for the sake of
<br>
clarity... I don't claim to be able to present a rational argument for the
<br>
continuance of self as the fundamental goal.
<br>
<p>Your question is an interesting one... &quot;Can you transcend your &quot;naturally
<br>
selected&quot; impulses and comprehend with the mind alone?&quot;
<br>
<p>I think this comes up especially when we contemplate changing fundamental
<br>
aspects of our minds, like extending our intellectual or emotional
<br>
capacities, gaining &quot;direct control&quot; over emotional states, being able to
<br>
fiddle with our primary motivations. It always begs the question &quot;How do you
<br>
decide how to change yourself?&quot; The implication being that such a decision
<br>
to alter your mental makeup is firmly rooted in your mental makeup; thus you
<br>
cannot escape your biological, historical inheritance.
<br>
<p>There is not an entirely strong position, however. It falls down when we can
<br>
see that the process of mental modification is an iterative one. We begin
<br>
with an un-altered mind, call it M0. M0 decides to alter itself, to become
<br>
M1 (which is indeed determined by the drives of M0). M1 then alters to M2,
<br>
and so on, ... at any point in the future we have mental infrastructure Mn,
<br>
where n can be an arbitrarily large positive integer.
<br>
<p>You would agree that decisions made by the human mind are extremely complex,
<br>
and though we can say that they are driven by our biological history, the
<br>
derivational path is messy, to say the least. Chaotic, some might say.
<br>
<p>When we add a re-entrant iteration to such a complex system as the mind, it
<br>
becomes clear that the basis of our decisions as being entirely rooted in
<br>
biology, after a short number of iterations, is meaningless. Although it is
<br>
technically true that we are still wholy derived from our environment, there
<br>
is no way that, given the biological past of  a being, one could derive Mn
<br>
for n greater than some fairly small constant. The system is too dynamic,
<br>
unpredictable. So, in effect, our biology is lost to time.
<br>
<p>What replaces our biology, our evolved motivations and desires, as the
<br>
driver for that change? It's not an easy question to answer, and I suspect
<br>
it is highly dependent on initial conditions, and the kind of attractors
<br>
that exist in the space of mental modification. I strongly suspect that
<br>
there is a relatively rational attractor, into whose thrall some minds would
<br>
fall; that modification would be primarily driven by rational choices based
<br>
on needs in a given environment. But there are probably others, eg: I
<br>
imagine there could be a fairly coarse &quot;self-indulgent&quot;/pleasure seeking
<br>
attractor, where minds are driven by increasing narcissism and sensualism.
<br>
It sounds like fun, actually :-) I'd suspect that could be fairly unstable,
<br>
especially where a mind modified itself into the region of a different
<br>
attractor on some fleeting whim.
<br>
<p>There are likely a lot of other examples, and those I've given above are
<br>
hopelessly crude. The point, however, is that we absolutely can escape our
<br>
biology. We can even be in control of that process in some important sense,
<br>
eventually. Beings who modifiy their mental state to become something new,
<br>
will do it purposefully. We would expect that they (we?) will be rather
<br>
intelligent people... they will not be blind to the dynamic nature of
<br>
themselves, and to the rather tricky topology of the space that they
<br>
traverse. The whole idea of &quot;self&quot; may come to change it's meaning somewhat
<br>
(for the better, in my opinion).
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; I think the point that you are wanting to make is that natural selection
</em><br>
is
<br>
<em>&gt; &gt; more efficient than the alternative, whatever that may be. I don't think
</em><br>
<em>&gt; &gt; that's necessarily so. The idea of becoming transhuman is that we can
</em><br>
shape
<br>
<em>&gt; &gt; ourselves as we see fit, and as is best to meet the challenges of our
</em><br>
<em>&gt;
</em><br>
<em>&gt; We are already not subject solely to natural selection. For example, if
</em><br>
you like
<br>
<em>&gt; green eyes, you will choose a partner with green eyes, and a certain
</em><br>
proportion
<br>
<em>&gt; of your offspring will have green eyes. You don't have to wait for a
</em><br>
random
<br>
<em>&gt; mutation. You just pick it off the shelf, be that reason or impulse, and
</em><br>
mix it
<br>
<em>&gt; in your own genomic stew. It's Lamarckism, just that the iteration is a
</em><br>
<em>&gt; generation, and that the scalpel is a bit blunt. Surely we'll fix that.
</em><br>
<em>&gt;
</em><br>
<em>&gt; But my point is not to exemplify natural selection, as I have stressed
</em><br>
before. I
<br>
<em>&gt; agree with most of your objections to it. I'm just pointing out that
</em><br>
design and
<br>
<em>&gt; selection, without exploration, is dangerous.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p>No arguments there. One of the grounding concepts of extropy is dynamism...
<br>
no one is interested in a centrally controlled sculpting of humanity. The
<br>
idea is yet again that individualism reigns... self modification will be
<br>
diverse, and performed according to the desires of each person upon his or
<br>
her own self. Thus, while any individual can choose to risk exploratory
<br>
behaviour, or else to shun it, the whole space of self modifying individuals
<br>
will tend to be incredibly diverse and interesting. Without a central
<br>
organising factor, it cannot help but be exploratory, and evolutionary as a
<br>
whole, in a pretty fascinating way.
<br>
<p>Emlyn
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4130.html">Lee Corbin: "Re: Reversible Computation and Experience"</a>
<li><strong>Previous message:</strong> <a href="4128.html">Eliezer S. Yudkowsky: "Re: Iconoclasm (was: Chunking intelligence functions)"</a>
<li><strong>In reply to:</strong> <a href="4114.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4257.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<li><strong>Reply:</strong> <a href="4257.html">Aleks Jakulin: "Re: Risk vs. Payoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4129">[ date ]</a>
<a href="index.html#4129">[ thread ]</a>
<a href="subject.html#4129">[ subject ]</a>
<a href="author.html#4129">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:04 MDT</em>
</em>
</small>
</body>
</html>
