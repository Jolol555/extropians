<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Emulation vs. Simulation</title>
<meta name="Author" content="Jim Fehlinger (fehlinger@home.com)">
<meta name="Subject" content="Re: Emulation vs. Simulation">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Emulation vs. Simulation</h1>
<!-- received="Mon Mar 26 23:45:27 2001" -->
<!-- isoreceived="20010327064527" -->
<!-- sent="Mon, 26 Mar 2001 23:32:05 -0500" -->
<!-- isosent="20010327043205" -->
<!-- name="Jim Fehlinger" -->
<!-- email="fehlinger@home.com" -->
<!-- subject="Re: Emulation vs. Simulation" -->
<!-- id="3AC017C5.B3CD94D9@home.com" -->
<!-- inreplyto="200103270337.VAA13636@dal-mail2.ricochet.net" -->
<strong>From:</strong> Jim Fehlinger (<a href="mailto:fehlinger@home.com?Subject=Re:%20Emulation%20vs.%20Simulation&In-Reply-To=&lt;3AC017C5.B3CD94D9@home.com&gt;"><em>fehlinger@home.com</em></a>)<br>
<strong>Date:</strong> Mon Mar 26 2001 - 21:32:05 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1572.html">James Rogers: "Re: Emulation vs. Simulation"</a>
<li><strong>Previous message:</strong> <a href="1570.html">Damien Broderick: "Re: Emulation vs. Simulation"</a>
<li><strong>In reply to:</strong> <a href="1577.html">Lee Corbin: "Re: Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1579.html">hal@finney.org: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1571">[ date ]</a>
<a href="index.html#1571">[ thread ]</a>
<a href="subject.html#1571">[ subject ]</a>
<a href="author.html#1571">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Lee Corbin wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Functionalism&quot; is the name usually associated with the
</em><br>
<em>&gt; doctrine that if it quacks like a duck, walks like a
</em><br>
<em>&gt; duck, and acts like a duck in every way, then it's a
</em><br>
<em>&gt; duck.  Functionalists believe that anything that acts
</em><br>
<em>&gt; like a human, etc., really does have human awareness,
</em><br>
<em>&gt; intelligence, and feelings.
</em><br>
<p>Well, not exactly.  My reading suggests that &quot;functionalism&quot; is
<br>
the (fading) cognitive science assumption that imagines that the
<br>
brain, like an electronic computer, instantiates algorithms
<br>
that are independent of hardware substrate.
<br>
<p>In George Lakoff's words
<br>
( <a href="http://www.ex.ac.uk/~PErnest/pome10/art21.htm">http://www.ex.ac.uk/~PErnest/pome10/art21.htm</a> )
<br>
&quot;Functionalism, first formulated by philosopher
<br>
Hilary Putnam and since repudiated by him, is the theory that
<br>
all aspects of mind can be characterized adequately without
<br>
looking at the brain, as if the mind worked via the manipulation
<br>
of abstract formal symbols as in a computer program designed
<br>
independent of any particular hardware, but which happened to be
<br>
capable of running on the brain's wetware. This computer program
<br>
mind is not shaped by the details of the brain.&quot;
<br>
<p>A lot of neuroscientists are dubious about functionalism,
<br>
so defined, without having rejected down-to-earth
<br>
scientific materialism.  For example, in the discussion about
<br>
Gerald Edelman I posted here a year ago
<br>
( <a href="http://www.lucifer.com/exi-lists/extropians.2Q00/5580.html">http://www.lucifer.com/exi-lists/extropians.2Q00/5580.html</a> ),
<br>
I wrote:
<br>
<p>&quot;This contrast between the role of stochastic variation in the 
<br>
brain and the absence of such a role in electronic devices such 
<br>
as computers is one of the distinctions between what Edelman 
<br>
calls &quot;instructionism&quot; in his own terminology (RP p. 30), but has 
<br>
also been called &quot;functionalism&quot; or &quot;machine functionalism&quot; (RP 
<br>
p. 30; BABF p. 220); and &quot;selectionism&quot; (UoC p. 16; RP 
<br>
pp. 30-33). Up to the present, all human artifacts and machines 
<br>
(including computers and computer programs) have been based on 
<br>
functionalist or instructionist design principles. In these 
<br>
devices, the parts and their interactions are precisely specified 
<br>
by a designer, and precisely matched to expected inputs and 
<br>
outputs. This is a construction approach based on cost 
<br>
consciousness, parsimonious allocation of materials, and limited 
<br>
levels of manageable complexity in design and manufacture. The 
<br>
workings of such artifacts are &quot;held to be describable in a 
<br>
fashion similar to that used for algorithms&quot;. 
<br>
<p>By analogy to the hardware-independence of computer programs, 
<br>
functionalist models of neural &quot;algorithms&quot; underlying cognition 
<br>
and behavior have attempted to separate these functions from 
<br>
their physical instantiation in the brain: &quot;In the functionalist 
<br>
view, what is ultimately important for understanding psychology 
<br>
are the algorithms, not the hardware on which they are 
<br>
executed... Furthermore, the tissue organization and composition 
<br>
of the brain shouldn't concern us as long as the algorithm 'runs' 
<br>
or comes to a successful halt.&quot; (BABF p. 220). In Edelman's 
<br>
view, the capabilities of the human brain are much more 
<br>
intimately dependent on its morphology than the functionalist 
<br>
view admits, and any attempt to minimize the contribution of the 
<br>
brain's biological substrate by assuming functional equivalence 
<br>
with the sort of impoverished and rigid substrates characteristic 
<br>
of modern-day computers is bound to be misleading.&quot;
<br>
<p>And ( <a href="http://www.lucifer.com/exi-lists/extropians.2Q00/5578.html">http://www.lucifer.com/exi-lists/extropians.2Q00/5578.html</a> )
<br>
<p>&quot;In a biological system, much of the physical complexity needed to 
<br>
support primary consciousness is inherent in the morphology of 
<br>
biological cells, tissues, and organs, and it isn't clear that 
<br>
this morphology can be easily dismissed: &quot;[Are] artifacts 
<br>
designed to have primary consciousness... **necessarily** 
<br>
confined to carbon chemistry and, more specifically, to 
<br>
biochemistry (the organic chemical or chauvinist position)[?] 
<br>
The provisional answer is that, while we cannot completely 
<br>
dismiss a particular material basis for consciousness in the 
<br>
liberal fashion of functionalism, it is probable that there will 
<br>
be severe (but not unique) constraints on the design of any 
<br>
artifact that is supposed to acquire conscious behavior. Such 
<br>
constraints are likely to exist because there is every indication 
<br>
that an intricate, stochastically variant anatomy and synaptic 
<br>
chemistry underlie brain function and because consciousness is 
<br>
definitely a process based on an immensely intricate and unusual 
<br>
morphology&quot; (RP pp. 32-33).&quot;
<br>
<p><em>&gt; ...I am also a functionalist, and it seems that practically
</em><br>
<em>&gt; all extropians are too.
</em><br>
<p>Not me.  (But am I an Extropian, I wonder?) ;-&gt;
<br>
<p>Jim F.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1572.html">James Rogers: "Re: Emulation vs. Simulation"</a>
<li><strong>Previous message:</strong> <a href="1570.html">Damien Broderick: "Re: Emulation vs. Simulation"</a>
<li><strong>In reply to:</strong> <a href="1577.html">Lee Corbin: "Re: Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1579.html">hal@finney.org: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1571">[ date ]</a>
<a href="index.html#1571">[ thread ]</a>
<a href="subject.html#1571">[ subject ]</a>
<a href="author.html#1571">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:43 MDT</em>
</em>
</small>
</body>
</html>
