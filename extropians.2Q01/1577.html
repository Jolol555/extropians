<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Emulation vs. Simulation</title>
<meta name="Author" content="Lee Corbin (lcorbin@ricochet.net)">
<meta name="Subject" content="Re: Emulation vs. Simulation">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Emulation vs. Simulation</h1>
<!-- received="Tue Mar 27 01:26:02 2001" -->
<!-- isoreceived="20010327082602" -->
<!-- sent="Mon, 26 Mar 2001 19:47:13 -0800" -->
<!-- isosent="20010327034713" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@ricochet.net" -->
<!-- subject="Re: Emulation vs. Simulation" -->
<!-- id="200103270337.VAA13636@dal-mail2.ricochet.net" -->
<!-- inreplyto="Emulation vs. Simulation" -->
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@ricochet.net?Subject=Re:%20Emulation%20vs.%20Simulation&In-Reply-To=&lt;200103270337.VAA13636@dal-mail2.ricochet.net&gt;"><em>lcorbin@ricochet.net</em></a>)<br>
<strong>Date:</strong> Mon Mar 26 2001 - 20:47:13 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1578.html">Jim Fehlinger: "BOOK: _Going Inside: A Tour Round a Single Moment of Consciousness_,  John McCrone"</a>
<li><strong>Previous message:</strong> <a href="1576.html">Lee Corbin: "Re: Emulation vs. Simulation"</a>
<li><strong>Maybe in reply to:</strong> <a href="1120.html">Lee Corbin: "Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1571.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<li><strong>Reply:</strong> <a href="1571.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1577">[ date ]</a>
<a href="index.html#1577">[ thread ]</a>
<a href="subject.html#1577">[ subject ]</a>
<a href="author.html#1577">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Robert J. Bradbury Sun, 25 Mar 2001 14:05:49, wrote
<br>
<p><em>&gt; Lee Corbin wrote
</em><br>
<em>&gt;&gt; Yes, but surviving cursory examination by AOL members, 
</em><br>
<em>&gt;&gt; which is only on-line and not real-world anyway, is 
</em><br>
<em>&gt;&gt; hardly much of a challenge. I agree, instead, with 
</em><br>
<em>&gt;&gt; what you wrote earlier: &quot;if a... creature does not 
</em><br>
<em>&gt;&gt; have 'feelings' that promote its survival, then it's 
</em><br>
<em>&gt;&gt; very rapidly a dead [creature]&quot;. Same goes for 
</em><br>
<em>&gt;&gt; consciousness, I think. 
</em><br>
<p><em>&gt; I would maintain that I can construct a zombie that
</em><br>
<em>&gt; had no 'feelings' regarding a fear of being hit by
</em><br>
<em>&gt; a car while crossing the street but still *behaved*
</em><br>
<em>&gt; as if it had a fear of hitting a car while crossing
</em><br>
<em>&gt; the street.
</em><br>
<p>Quite right.  Robots today are capable of such behavior,
<br>
and even little mechanical rats years ago at MIT, I think,
<br>
seemed to act as though they were hungry. I don't want to
<br>
call these &quot;zombies&quot; because they don't even begin to
<br>
imitate full human behavior, and also because they
<br>
wouldn't survive very long (except on roadways,
<br>
perhaps, for which they were partly designed).
<br>
<p>It may sound both unfair and nebulous to demand that a
<br>
zombie display a &quot;full range of human behavior&quot;.  But
<br>
this takes us back to how the very first, and to this
<br>
day extremely important, arguments broke out among 
<br>
philosophers about what life and consciousness are.
<br>
<p>The opponents of scientific materialism have been waging
<br>
(and losing) a war against mechanism for centuries, or at
<br>
least since in 1828 when they lost the battle over whether
<br>
bodily fluids (such as uric acid) could be synthesized.
<br>
One recent claim of theirs is that it is impossible for
<br>
an artificial intelligence to actually be conscious, or
<br>
have feelings.  They maintained that even if you succeeded
<br>
programming a robot to behave completely indistinguishably
<br>
from a human, it still wouldn't have consciousness or even
<br>
be alive.  These creatures, which could imitate a human
<br>
being in every conceivable behavior aspect, were dubbed
<br>
&quot;zombies&quot;, because although identical in behavior, they
<br>
have no feelings or consciousness, and have no &quot;inner life&quot;.
<br>
<p>Of course, extropians have left such beliefs far, far
<br>
behind.  As have some philosophers ever since Turing, we
<br>
realize that there is nothing magical about the biological
<br>
machines that we are.  We, too, are just piles of atoms
<br>
obeying physical law.  But unless you were there, you
<br>
just cannot believe how reluctant almost everyone was
<br>
to accept this thirty or forty years ago.
<br>
<p>&quot;Functionalism&quot; is the name usually associated with the
<br>
doctrine that if it quacks like a duck, walks like a 
<br>
duck, and acts like a duck in every way, then it's a
<br>
duck.  Functionalists believe that anything that acts
<br>
like a human, etc., really does have human awareness,
<br>
intelligence, and feelings.
<br>
<p>Except for the tiny detail of lookup tables, I am also a
<br>
functionalist, and it seems that practically all extropians
<br>
are too.  But of course, all the possibilities surrounding
<br>
the use of computronium, vast processing spaces and speeds,
<br>
virtual reality, remote telepresence, and other recent
<br>
conceptual breakthroughs, make it non-trivial to sort through
<br>
all the issues.  Still, it seems best to say that according
<br>
to the original meaning of &quot;zombie&quot;---not conscious, but in
<br>
every other way completely indistinguishable from human---
<br>
well, zombies are just impossible.
<br>
<p>Were we to admit that they were possible, by the way, then
<br>
a lot of people like Dreyfus would immediately say, &quot;See?
<br>
Even if you do ever succeed with AI, it won't be a REAL
<br>
conscious entity that you have, merely a machine.  And no
<br>
amount of suffering that you inflict on an AI means
<br>
anything, because they cannot have any feelings.&quot;
<br>
<p>And I would just croak if some of these old opponents of
<br>
even soft-AI published an article saying, &quot;many forward
<br>
thinking people, including extropians, also now concur
<br>
today that AIs would only be zombies.&quot;
<br>
<p>Lee Corbin
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1578.html">Jim Fehlinger: "BOOK: _Going Inside: A Tour Round a Single Moment of Consciousness_,  John McCrone"</a>
<li><strong>Previous message:</strong> <a href="1576.html">Lee Corbin: "Re: Emulation vs. Simulation"</a>
<li><strong>Maybe in reply to:</strong> <a href="1120.html">Lee Corbin: "Emulation vs. Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1571.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<li><strong>Reply:</strong> <a href="1571.html">Jim Fehlinger: "Re: Emulation vs. Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1577">[ date ]</a>
<a href="index.html#1577">[ thread ]</a>
<a href="subject.html#1577">[ subject ]</a>
<a href="author.html#1577">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:43 MDT</em>
</em>
</small>
</body>
</html>
