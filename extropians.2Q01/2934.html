<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: SOC/SCIENCE: Something Rotten at the Core of Scienc</title>
<meta name="Author" content="Chris Rasch (crasch@openknowledge.org)">
<meta name="Subject" content="SOC/SCIENCE: Something Rotten at the Core of Science?">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>SOC/SCIENCE: Something Rotten at the Core of Science?</h1>
<!-- received="Mon Apr 23 12:20:27 2001" -->
<!-- isoreceived="20010423182027" -->
<!-- sent="Mon, 23 Apr 2001 12:24:47 -0600" -->
<!-- isosent="20010423182447" -->
<!-- name="Chris Rasch" -->
<!-- email="crasch@openknowledge.org" -->
<!-- subject="SOC/SCIENCE: Something Rotten at the Core of Science?" -->
<!-- id="3AE4736F.7971D6B7@openknowledge.org" -->
<strong>From:</strong> Chris Rasch (<a href="mailto:crasch@openknowledge.org?Subject=Re:%20SOC/SCIENCE:%20Something%20Rotten%20at%20the%20Core%20of%20Science?&In-Reply-To=&lt;3AE4736F.7971D6B7@openknowledge.org&gt;"><em>crasch@openknowledge.org</em></a>)<br>
<strong>Date:</strong> Mon Apr 23 2001 - 12:24:47 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2935.html">Anders Sandberg: "Re: Anti-Capitalism"</a>
<li><strong>Previous message:</strong> <a href="2933.html">Charlie Stross: "Re: Vogel says brain too complex to upload"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2962.html">CurtAdams@aol.com: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="2962.html">CurtAdams@aol.com: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Reply:</strong> <a href="2992.html">Anders Sandberg: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3115.html">Amara Graps: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3152.html">Amara Graps: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3226.html">KPJ: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2934">[ date ]</a>
<a href="index.html#2934">[ thread ]</a>
<a href="subject.html#2934">[ subject ]</a>
<a href="author.html#2934">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Best if read from this URL:
<br>
<p><a href="http://news.bmn.com/hmsbeagle/95/viewpts/op_ed">http://news.bmn.com/hmsbeagle/95/viewpts/op_ed</a>
<br>
<p><p>HMS Beagle Posted February 2, 2001 · Issue 95
<br>
<p>OPINION
<br>
<p>Something Rotten at the Core of Science?
<br>
<p>by David F. Horrobin
<br>
<p>Reprinted with permission from Trends in Pharmacological Sciences,
<br>
Vol. 22, No. 2, February 2001
<br>
<p>--------------------------------------------------------------------------
<br>
<p>Abstract
<br>
<p>A recent U.S. Supreme Court decision and an analysis of the peer
<br>
review system substantiate complaints about this fundamental aspect of
<br>
scientific research. Far from filtering out junk science, peer review
<br>
may be blocking the flow of innovation and corrupting public support
<br>
of science.
<br>
--------------------------------------------------------------------------
<br>
<p>The U.S. Supreme Court has recently been wrestling with the issues of
<br>
the acceptability and reliability of scientific evidence. In its
<br>
judgement in the case of Daubert v. Merrell Dow
<br>
(<a href="http://caselaw.lp.findlaw.com/scripts/getcase.pl?navby=search&court=US&case=/us/509/579.html">http://caselaw.lp.findlaw.com/scripts/getcase.pl?navby=search&court=US&case=/us/509/579.html</a>),
<br>
<p>the court attempted to set guidelines for U.S. judges to follow when
<br>
listening to scientific experts. Whether or not findings had been
<br>
published in a peer-reviewed journal provided one important
<br>
criterion. But in a key caveat, the court emphasized that peer review
<br>
might sometimes be flawed, and that therefore this criterion was not
<br>
unequivocal evidence of validity or otherwise. A recent analysis of
<br>
peer review adds to this controversy by identifying an alarming lack
<br>
of correlation between reviewers' recommendations.
<br>
<p>--------------------------------------------------------------------------
<br>
<p>The Supreme Court questioned the authority of peer review.
<br>
--------------------------------------------------------------------------
<br>
<p>Many scientists and lawyers are unhappy about the admission by the top
<br>
legal authority in the United States that peer review might in some
<br>
circumstances be flawed [1].  David Goodstein
<br>
(<a href="http://broccoli.caltech.edu/~goodstein/">http://broccoli.caltech.edu/~goodstein/</a>), writing in the Guide to the
<br>
Federal Rules of Evidence - one of whose functions is to interpret the
<br>
judgement in the case of Daubert - states that &quot;Peer review is one of
<br>
the sacred pillars of the scientific edifice&quot; [2]. In public, at
<br>
least, almost all scientists would agree. Those who disagree are
<br>
almost always dismissed in pejorative terms such as &quot;maverick,&quot;
<br>
&quot;failure,&quot; and &quot;driven by bitterness.&quot;
<br>
<p>Peer review is central to the organization of modern science. The
<br>
peer-review process for submitted manuscripts is a crucial determinant
<br>
of what sees the light of day in a particular journal. Fortunately, it
<br>
is less effective in blocking publication completely; there are so
<br>
many journals that most even modestly competent studies will be
<br>
published provided that the authors are determined enough. The
<br>
publication might not be in a prestigious journal, but at least it
<br>
will get into print. However, peer review is also the process that
<br>
controls access to funding, and here the situation becomes much more
<br>
serious. There might often be only two or three realistic sources of
<br>
funding for a project, and the networks of reviewers for these sources
<br>
are often interacting and interlocking.  Failure to pass the
<br>
peer-review process might well mean that a project is never
<br>
funded. Science bases its presumed authority in the world on the
<br>
reliability and objectivity of the evidence that is produced. If the
<br>
pronouncements of science are to be greeted with public confidence -
<br>
and there is plenty of evidence to suggest that such confidence is low
<br>
and eroding - it should be able to demonstrate that peer review, &quot;one
<br>
of the sacred pillars of the scientific edifice,&quot; is a process that
<br>
has been validated objectively as a reliable process for putting a
<br>
stamp of approval on work that has been done. Peer review should also
<br>
have been validated as a reliable method for making appropriate
<br>
choices as to what work should be done. Yet when one looks for that
<br>
evidence it is simply not there.
<br>
<p>--------------------------------------------------------------------------
<br>
<p>Why not apply scientific methods to the peer review process?
<br>
--------------------------------------------------------------------------
<br>
<p>For 30 years or so, I and others have been pointing out the
<br>
fallibility of peer review and have been calling for much more
<br>
openness and objective evaluation of its procedures [3-5]. For the
<br>
most part, the scientific establishment, its journals, and its
<br>
grant-giving bodies have resisted such open evaluation. They fail to
<br>
understand that if a process that is as central to the scientific
<br>
endeavor as peer review has no validated experimental base, and if it
<br>
consistently refuses open scrutiny, it is not surprising that the
<br>
public is increasingly skeptical about the agenda and the conclusions
<br>
of science.
<br>
<p>Largely because of this antagonism to openness and evaluation, there
<br>
is a great lack of good evidence either way concerning the objectivity
<br>
and validity of peer review. What evidence there is does not give
<br>
confidence but is open to many criticisms. Now, Peter Rothwell and
<br>
Christopher Martyn have thrown a bombshell [6]. Their conclusions are
<br>
measured and cautious, but there is little doubt that they have
<br>
provided solid evidence of something truly rotten at the core of
<br>
science.
<br>
<p>--------------------------------------------------------------------------
<br>
<p>Forget the reviewers. Just flip a coin.
<br>
--------------------------------------------------------------------------
<br>
<p>Rothwell and Martyn performed a detailed evaluation
<br>
(<a href="http://research.bmn.com/medline/search/record?uid=MDLN.20416120">http://research.bmn.com/medline/search/record?uid=MDLN.20416120</a>) of
<br>
the reviews of papers submitted to two neuroscience journals. Each
<br>
journal normally sent papers out to two reviewers. Reviews of
<br>
abstracts and oral presentations sent to two neuroscience meetings
<br>
were also evaluated. One meeting sent its abstracts to 16 reviewers
<br>
and the other to 14 reviewers, which provides a good opportunity for
<br>
statistical evaluation. Rothwell and Martyn analyzed the correlations
<br>
among reviewers' recommendations by analysis of variance. Their report
<br>
should be read in full; however, the conclusions are alarmingly
<br>
clear. For one journal, the relationships among the reviewers'
<br>
opinions were no better than that obtained by chance. For the other
<br>
journal, the relationship was only fractionally better. For the
<br>
meeting abstracts, the content of the abstract accounted for only
<br>
about 10 to 20 percent of the variance in opinion of referees, and
<br>
other factors accounted for 80 to 90 percent of the variance.
<br>
<p>These appalling figures will not be surprising to critics of peer
<br>
review, but they give solid substance to what these critics have been
<br>
saying. The core system by which the scientific community allots
<br>
prestige (in terms of oral presentations at major meetings and
<br>
publication in major journals) and funding is a non-validated charade
<br>
whose processes generate results little better than does chance. Given
<br>
the fact that most reviewers are likely to be mainstream and broadly
<br>
supportive of the existing organization of the scientific enterprise,
<br>
it would not be surprising if the likelihood of support for truly
<br>
innovative research was considerably less than that provided by
<br>
chance.
<br>
<p>--------------------------------------------------------------------------
<br>
<p>Objective evaluation of grant proposals is a high priority.
<br>
--------------------------------------------------------------------------
<br>
<p>Scientists frequently become very angry about the public's rejection
<br>
of the conclusions of the scientific process. However, the Rothwell
<br>
and Martyn findings, coming on top of so much other evidence, suggest
<br>
that the public might be right in groping its way to a conclusion that
<br>
there is something rotten in the state of science. Public support can
<br>
only erode further if science does not put its house in order and
<br>
begin a real attempt to develop validated processes for the
<br>
distribution of publication rights, credit for completed work, and
<br>
funds for new work. Funding is the most important issue that most
<br>
urgently requires opening up to rigorous research and objective
<br>
evaluation.
<br>
<p>What relevance does this have for pharmacology and pharmaceuticals?
<br>
Despite enormous amounts of hype and optimistic puffery,
<br>
pharmaceutical research is actually failing [[50]7]. The annual number
<br>
of new chemical entities submitted for approval is steadily falling in
<br>
spite of the enthusiasm for techniques such as combinatorial
<br>
chemistry, high-throughput screening, and pharmacogenomics. The drive
<br>
to merge pharmaceutical companies is driven by failure, and not by
<br>
success.
<br>
<p>--------------------------------------------------------------------------
<br>
<p>The peer review process may be stifling innovation.
<br>
--------------------------------------------------------------------------
<br>
<p>Could the peer-review processes in both academia and industry have
<br>
destroyed rather than promoted innovation? In my own field of
<br>
psychopharmacology, could it be that peer review has ensured that in
<br>
depression and schizophrenia, we are still largely pursuing themes
<br>
that were initiated in the 1950s? Could peer review explain the fact
<br>
that in both diseases the efficacy of modern drugs is no better than
<br>
those compounds developed in 1950? Even in terms of side-effects,
<br>
where the differences between old and new drugs are much hyped, modern
<br>
research has failed substantially. Is it really a success that 27 of
<br>
every 100 patients taking the selective 5-HT reuptake inhibitors stop
<br>
treatment within six weeks compared with the 30 of every 100 who take
<br>
a 1950s tricyclic antidepressant compound? The Rothwell-Martyn
<br>
bombshell is a wake-up call to the cozy establishments who run
<br>
science. If science is to have any credibility - and also if it is to
<br>
be successful - the peer-review process must be put on a much sounder
<br>
and properly validated basis or scrapped altogether.
<br>
<p>David F. Horrobin
<br>
(<a href="http://news.bmn.com/hmsbeagle/current/about/contrib#horrobin">http://news.bmn.com/hmsbeagle/current/about/contrib#horrobin</a>), a
<br>
longtime critic of anonymous peer review. heads Laxdale Ltd., which
<br>
develops novel treatments for psychiatric disorders. In 1972 he
<br>
founded Medical Hypotheses
<br>
(<a href="http://www.harcourt-international.com/journals/mehy/default.cfm">http://www.harcourt-international.com/journals/mehy/default.cfm</a>), the
<br>
only journal fully devoted to discussion of ideas in medicine.
<br>
<p><p>Endlinks
<br>
<p><a href="http://www.ama-assn.org/public/peer/7_15_98/toc.htm">http://www.ama-assn.org/public/peer/7_15_98/toc.htm</a> International
<br>
Congress on Biomedical Peer Review and Scientific Publication -
<br>
articles and abstracts from the third congress, held in 1997. The
<br>
fourth congress (<a href="http://www.ama-assn.org/public/peer/peerhome.htm">http://www.ama-assn.org/public/peer/peerhome.htm</a>)
<br>
will be held in September 2001.
<br>
<p><a href="http://www.nap.edu/books/0309071275/html/99.html">http://www.nap.edu/books/0309071275/html/99.html</a> Peer-Review Practices
<br>
at EPA - a section of the 2000 NAS report Strengthening Science at the
<br>
U.S. Environmental Protection Agency: Research-Management and
<br>
Peer-Review Practices, which discusses the strengths and limitations
<br>
of the process.
<br>
<p><a href="http://www.nap.edu/issues/16.3/p_brosnan.htm">http://www.nap.edu/issues/16.3/p_brosnan.htm</a> Can Peer Review Help
<br>
Resolve Natural Resource Conflicts? - suggests that a modified form of
<br>
peer review could be useful in policy-related decisions.
<br>
<p><a href="http://www.willyancey.com/evidence.htm">http://www.willyancey.com/evidence.htm</a> Evidence and Expert Testimony -
<br>
includes many online references for scientific evidence.
<br>
<p><a href="http://www.law.depaul.edu/criminalscience/peerreview/peerreview.html">http://www.law.depaul.edu/criminalscience/peerreview/peerreview.html</a>
<br>
Peer Review Articles - an annotated bibliography covering scientific
<br>
peer review and its relevance to judicial proceedings.
<br>
<p><p>Related HMS Beagle Articles:
<br>
<p>* Top Ten Reasons Against Peer Review
<br>
* (<a href="http://news.bmn.com/hmsbeagle/86/xcursion/topten">http://news.bmn.com/hmsbeagle/86/xcursion/topten</a>) and Top Ten
<br>
* Reasons For Peer Review
<br>
* (<a href="http://news.bmn.com/hmsbeagle/84/xcursion/topten">http://news.bmn.com/hmsbeagle/84/xcursion/topten</a>) - arguments both
<br>
* humorous and serious.
<br>
<p>* Anatomy of a Rejection
<br>
* (<a href="http://news.bmn.com/hmsbeagle/48/labres/adapt.htm">http://news.bmn.com/hmsbeagle/48/labres/adapt.htm</a>) - strategies for
<br>
* improving the outcome of the peer review process.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2935.html">Anders Sandberg: "Re: Anti-Capitalism"</a>
<li><strong>Previous message:</strong> <a href="2933.html">Charlie Stross: "Re: Vogel says brain too complex to upload"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2962.html">CurtAdams@aol.com: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="2962.html">CurtAdams@aol.com: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Reply:</strong> <a href="2992.html">Anders Sandberg: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3115.html">Amara Graps: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3152.html">Amara Graps: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<li><strong>Maybe reply:</strong> <a href="3226.html">KPJ: "Re: SOC/SCIENCE: Something Rotten at the Core of Science?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2934">[ date ]</a>
<a href="index.html#2934">[ thread ]</a>
<a href="subject.html#2934">[ subject ]</a>
<a href="author.html#2934">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:55 MDT</em>
</em>
</small>
</body>
</html>
