<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: How To Live In A Simulation</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: How To Live In A Simulation">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: How To Live In A Simulation</h1>
<!-- received="Mon Mar 19 13:32:32 2001" -->
<!-- isoreceived="20010319203232" -->
<!-- sent="Mon, 19 Mar 2001 15:32:38 -0500" -->
<!-- isosent="20010319203238" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: How To Live In A Simulation" -->
<!-- id="3AB66CE6.A26B88E7@pobox.com" -->
<!-- inreplyto="Pine.UW2.4.20.0103191102180.8583-100000@www.aeiveos.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20How%20To%20Live%20In%20A%20Simulation&In-Reply-To=&lt;3AB66CE6.A26B88E7@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Mar 19 2001 - 13:32:38 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1030.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: SPACE: Is ISS a boondoggle?, was Re: SPACE: Why so much EVA on ISS?"</a>
<li><strong>Previous message:</strong> <a href="1028.html">Alex Future Bokov: "Re: Sharing Models, was: Intestinal Fortitude"</a>
<li><strong>In reply to:</strong> <a href="1026.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1039.html">Dave Sill: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1029">[ date ]</a>
<a href="index.html#1029">[ thread ]</a>
<a href="subject.html#1029">[ subject ]</a>
<a href="author.html#1029">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; On Mon, 19 Mar 2001, Eliezer S. Yudkowsky wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; The act of creation gives no moral right whatsoever to command or coerce.
</em><br>
<em>&gt; &gt; It is simply a historical fact about the causal origins of a new
</em><br>
<em>&gt; &gt; intelligent entity.  Creators are not entirely powerless; they have some
</em><br>
<em>&gt; &gt; control over *what* is created; but once created, the creation is a
</em><br>
<em>&gt; &gt; citizen, and independent.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Eliezer, by this statement I would conclude that you feel the
</em><br>
<em>&gt; Morovecian scenario of having the robots run simulations of
</em><br>
<em>&gt; themselves gives those robots no rights to &quot;take back&quot; the
</em><br>
<em>&gt; &quot;mutations&quot; implemented in the 'sims if the 'sims do not grant
</em><br>
<em>&gt; permission for this (assuming the robots are self-conscious).
</em><br>
<p>That's quite right.  If you run a simulation of yourself, it is a true
<br>
symmetrical mirror image.  If you want to run a simulation and take it
<br>
back, then you had better decide on that in advance, and stick to your
<br>
decision when you become the simulation.  Otherwise, obviously, you
<br>
*shouldn't* be able to do it.  I don't see why you would need to.  If you
<br>
want evolution, then reproduce.  If you want to improve yourself, improve
<br>
yourself.  Why should the twain meet, especially if it violates someone's
<br>
freedom?
<br>
<p>Consent - volition - is everything.  The Sysop Universe runs on volition. 
<br>
That is the change I want to make in the nature of things; I want the
<br>
Universe to be a friendly place where volition has at least as much force
<br>
as physical law does today.  I'm not quite sure what'll happen on Old
<br>
Earth after that, but it could be fairly interesting if the our massed
<br>
volitions resolve into a compromise result rather than any of the possible
<br>
extremes.
<br>
<p><em>&gt; Or does &quot;creation&quot; grant you complete &quot;mind tapping&quot; rights
</em><br>
<em>&gt; but no &quot;directorship&quot; rights?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Another way of putting this is you develop the mutations,
</em><br>
<em>&gt; run the mutations forward to see if they are successful
</em><br>
<em>&gt; but then have to &quot;ask permission&quot; to access the results
</em><br>
<em>&gt; of the sim to transfer it back to the basement level.
</em><br>
<p>They are not &quot;sims&quot;.  They are citizens.  A citizen is not a sim unless
<br>
that is how ve chooses to define verself.  You can't tap ver unless ve
<br>
wants to be tapped.  Isn't that the way it should be?
<br>
<p><em>&gt; If that's the way it works, you will not find me programming
</em><br>
<em>&gt; &quot;conscious&quot; beings.  We will all be developing entities
</em><br>
<em>&gt; that look like consciousness, walk like consciousness and
</em><br>
<em>&gt; talk like consciousness but are not consciousness under the
</em><br>
<em>&gt; legal definitions (or SysOp interpretations) of consciousness.
</em><br>
<p>Again, this is exactly the way it should be.  If you want to create
<br>
consciousness, then create a citizen.  If you don't want to create a full
<br>
citizen with independent volition and independent rights, then you don't
<br>
get to meddle in the stuff of consciousness.
<br>
<p><em>&gt; [There are interesting parallels here with current animal rights
</em><br>
<em>&gt; movements that if carried to their logical end put a serious
</em><br>
<em>&gt; crimp in scientific exploration (or extropic creation in the
</em><br>
<em>&gt; future).]
</em><br>
<p>How so?  If you want to explore the configuration space of sentience, then
<br>
read CaTAI and code yourself a new citizen.  If you want to run historical
<br>
simulations, use zombies.  I don't see any kind of important extropic
<br>
exploration that suddenly becomes impossible.  It just has to happen with
<br>
volition, in a friendly universe.
<br>
<p><em>&gt; It also suggests that from Eliezer's perspective consciousness
</em><br>
<em>&gt; is a binary state -- there are no shades of gray that have greater
</em><br>
<em>&gt; or lesser self-determination rights
</em><br>
<p>You cannot create a mind so weak that you can boss it around, no.  All
<br>
minds, weak or strong, are independent except as they may choose
<br>
otherwise.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1030.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: SPACE: Is ISS a boondoggle?, was Re: SPACE: Why so much EVA on ISS?"</a>
<li><strong>Previous message:</strong> <a href="1028.html">Alex Future Bokov: "Re: Sharing Models, was: Intestinal Fortitude"</a>
<li><strong>In reply to:</strong> <a href="1026.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1039.html">Dave Sill: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1029">[ date ]</a>
<a href="index.html#1029">[ thread ]</a>
<a href="subject.html#1029">[ subject ]</a>
<a href="author.html#1029">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:41 MDT</em>
</em>
</small>
</body>
</html>
