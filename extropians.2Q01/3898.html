<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Keeping AI at bay (was: How to help create a si</title>
<meta name="Author" content="Jim Fehlinger (fehlinger@home.com)">
<meta name="Subject" content="Re: Keeping AI at bay (was: How to help create a singularity)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Keeping AI at bay (was: How to help create a singularity)</h1>
<!-- received="Sun May  6 10:01:45 2001" -->
<!-- isoreceived="20010506160145" -->
<!-- sent="Sun, 06 May 2001 11:34:55 -0400" -->
<!-- isosent="20010506153455" -->
<!-- name="Jim Fehlinger" -->
<!-- email="fehlinger@home.com" -->
<!-- subject="Re: Keeping AI at bay (was: How to help create a singularity)" -->
<!-- id="3AF56F1F.EC0B365A@home.com" -->
<!-- inreplyto="3AEEE118.4898B352@lrz.uni-muenchen.de" -->
<strong>From:</strong> Jim Fehlinger (<a href="mailto:fehlinger@home.com?Subject=Re:%20Keeping%20AI%20at%20bay%20(was:%20How%20to%20help%20create%20a%20singularity)&In-Reply-To=&lt;3AF56F1F.EC0B365A@home.com&gt;"><em>fehlinger@home.com</em></a>)<br>
<strong>Date:</strong> Sun May 06 2001 - 09:34:55 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3899.html">Jim Fehlinger: "One for the ages"</a>
<li><strong>Previous message:</strong> <a href="3897.html">J. R. Molloy: "Re: How You Do Not Tell the Truth"</a>
<li><strong>In reply to:</strong> <a href="3589.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3902.html">James Rogers: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<li><strong>Reply:</strong> <a href="3902.html">James Rogers: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<li><strong>Reply:</strong> <a href="3903.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3898">[ date ]</a>
<a href="index.html#3898">[ thread ]</a>
<a href="subject.html#3898">[ subject ]</a>
<a href="author.html#3898">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="mailto:Eugene.Leitl@lrz.uni-muenchen.de?Subject=Re:%20Keeping%20AI%20at%20bay%20(was:%20How%20to%20help%20create%20a%20singularity)&In-Reply-To=&lt;3AF56F1F.EC0B365A@home.com&gt;">Eugene.Leitl@lrz.uni-muenchen.de</a> wrote:
<br>
<p><em>&gt; [C]urrent early precursors of reconfigurable hardware (FPGAs)
</em><br>
<em>&gt; seem to generate extremely compact, nonobvious solutions even
</em><br>
<em>&gt; using current primitive evolutionary algorithms. The result is
</em><br>
<em>&gt; a curiously stable negative and positive autofeedback coupled
</em><br>
<em>&gt; oscillators. The whole is rather opaque to analytical scrutiny
</em><br>
<em>&gt; and sterile to human attempts of constructive modifications by
</em><br>
<em>&gt; manual means. We can only use the results as building blocks for
</em><br>
<em>&gt; hybrid architectures (which also require man-made glue that is
</em><br>
<em>&gt; immune to noise and nondeterminism -- we haven't even managed
</em><br>
<em>&gt; to do that much yet), and for ingredients for other evolutionary
</em><br>
<em>&gt; recipes.
</em><br>
<p>It crosses my mind that Edelman (and others) would probably snort at drawing
<br>
parallels between &quot;evolved&quot; FPGAs and human brains for much the same reason
<br>
he snorts at comparing artificial neural networks to human brains:  namely,
<br>
that the result has a static physical structure and function.
<br>
<p>In the &quot;selectionist&quot; theories of human intelligence espoused by Edelman,
<br>
Changeux, Plotkin, et al., &quot;evolution&quot;, in some sense, is a never-ending
<br>
process.  Of course, there are nested hierarchies of it -- a person is
<br>
born with a fixed genome.  But these folks believe there are somatic
<br>
processes, analogous to Darwinian evolution, that continue throughout
<br>
an organism's lifetime.  In contrast, with an evolved FPGA as developed
<br>
by Adrian Thompson, there's a prespecified problem, just as there would
<br>
be in a conventional software-design or electrical engineering application
<br>
domain, which is solved without explicit analysis by cranking the handle
<br>
of the magic evolution machine.  But at some point the evolution stops
<br>
(when the FPGA is deemed to have solved the problem), the chip is plugged
<br>
into the system and switched on, and becomes just another piece of
<br>
static hardware.  Same with neural networks -- there's a training set
<br>
corresponding to the problem domain, the network is trained on it,
<br>
and then it's plugged into the OCR program (or whatever), shrink-wrapped,
<br>
and sold.
<br>
<p>Still too static, folks, to be a basis for AI.  When are we going to have
<br>
hardware with the sort of continual plasticity and dynamism that nerve tissue has?
<br>
(I know it's going to be hard.  And, in the meantime, evolved FPGAs
<br>
might have their uses, if people can trust them to be reliable).
<br>
<p>Damien Sullivan wrote:
<br>
<p><em>&gt; So, we know about the 'magical' evolved FPGA with an apparently disconnected
</em><br>
<em>&gt; part which seems to use weird induction effects to function really tightly.
</em><br>
<em>&gt; Within a small temperature range.  Has anyone performed the next step, of
</em><br>
<em>&gt; repeating the experiment while varying the physical environment?  If you make
</em><br>
<em>&gt; the FPGA suffer normal working conditions, does the result look more normal?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I also can't help thinking at if I was an evolved AI I might not thank my
</em><br>
<em>&gt; creators.  &quot;Geez, guys, I was supposed to be an improvement on the human
</em><br>
<em>&gt; condition.  You know, highly modular, easily understadable mechanisms, the
</em><br>
<em>&gt; ability to plug in new senses, and merge memories from my forked copies.
</em><br>
<em>&gt; Instead I'm as fucked up as you, only in silicon, and can't even make backups
</em><br>
<em>&gt; because I'm tied to dumb quantum induction effects.  Bite my shiny metal ass!&quot;
</em><br>
<p>Yes, when I forwarded the news story that Eugene Leitl posted about
<br>
Adrian Thompson's (Center for Computational Neuroscience and Robotics,
<br>
University of Sussex, England) work on evolvable FPGAs
<br>
( <a href="http://www.lucifer.com/exi-lists/extropians/0390.html">http://www.lucifer.com/exi-lists/extropians/0390.html</a> ,
<br>
<a href="http://www.nanotechnews.com/nanotechnews/nanotechnews/nano/986936562">http://www.nanotechnews.com/nanotechnews/nanotechnews/nano/986936562</a> )
<br>
to my friend F, he replied:
<br>
<p><em>&gt; Already!  A machine that we understand as badly as we understand
</em><br>
<em>&gt; ourselves.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ---  Joe Fineman    <a href="mailto:jcf@world.std.com?Subject=Re:%20Keeping%20AI%20at%20bay%20(was:%20How%20to%20help%20create%20a%20singularity)&In-Reply-To=&lt;3AF56F1F.EC0B365A@home.com&gt;">jcf@world.std.com</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ||:  By _disillusionment_ we mean _transillusionment_.  :||
</em><br>
<p>Jim F.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3899.html">Jim Fehlinger: "One for the ages"</a>
<li><strong>Previous message:</strong> <a href="3897.html">J. R. Molloy: "Re: How You Do Not Tell the Truth"</a>
<li><strong>In reply to:</strong> <a href="3589.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3902.html">James Rogers: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<li><strong>Reply:</strong> <a href="3902.html">James Rogers: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<li><strong>Reply:</strong> <a href="3903.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3898">[ date ]</a>
<a href="index.html#3898">[ thread ]</a>
<a href="subject.html#3898">[ subject ]</a>
<a href="author.html#3898">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:03 MDT</em>
</em>
</small>
</body>
</html>
