<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: AI over the Internet (was Re: making microsingu</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: AI over the Internet (was Re: making microsingularities)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: AI over the Internet (was Re: making microsingularities)</h1>
<!-- received="Sun May 27 20:13:21 2001" -->
<!-- isoreceived="20010528021321" -->
<!-- sent="Sun, 27 May 2001 22:10:56 -0400" -->
<!-- isosent="20010528021056" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: AI over the Internet (was Re: making microsingularities)" -->
<!-- id="3B11B3B0.9F44C716@pobox.com" -->
<!-- inreplyto="200105280047.RAA13957@finney.org" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20AI%20over%20the%20Internet%20(was%20Re:%20making%20microsingularities)&In-Reply-To=&lt;3B11B3B0.9F44C716@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sun May 27 2001 - 20:10:56 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4778.html">Eliezer S. Yudkowsky: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<li><strong>Previous message:</strong> <a href="4776.html">hal@finney.org: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<li><strong>In reply to:</strong> <a href="4776.html">hal@finney.org: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4781.html">Ben Goertzel: "RE: AI over the Internet (was Re: making microsingularities)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4777">[ date ]</a>
<a href="index.html#4777">[ thread ]</a>
<a href="subject.html#4777">[ subject ]</a>
<a href="author.html#4777">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="mailto:hal@finney.org?Subject=Re:%20AI%20over%20the%20Internet%20(was%20Re:%20making%20microsingularities)&In-Reply-To=&lt;3B11B3B0.9F44C716@pobox.com&gt;">hal@finney.org</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; There does seem to be a stumbling block if the AI needs the net's
</em><br>
<em>&gt; resources to become superhuman, but it can't exploit them until it
</em><br>
<em>&gt; achieves superhuman competence sufficient to redesign itself to run on
</em><br>
<em>&gt; such a constrained system as the net.  But Eliezer points out that it
</em><br>
<em>&gt; does not need superhuman competence in every arena, only in software
</em><br>
<em>&gt; architecture design, and perhaps an idiot savant super-coder AI can make
</em><br>
<em>&gt; the leap.
</em><br>
<p>Um, like I keep saying, my original statement was made in the context of
<br>
&quot;Will there be a Slow Singularity?&quot;  And I said, &quot;If it works for a Slow
<br>
Singularity, it works for superintelligence.&quot;  I.e., threshold for a Slow
<br>
Singularity is over-and-above the threshold for a hard takeoff.
<br>
<p>If the current AI needs the net's resources to become superhuman, but
<br>
Vastmind isn't a household name, latency is too high, and the AI is too
<br>
dumb to use the 'Net much less eat it... then you don't get a Singularity
<br>
until you can buy a sufficiently large supercomputer, and that's that.
<br>
<p>I deem this scenario to be unlikely because I think that the major
<br>
constraint is likely to be software, not hardware.  I.e., given a smooth
<br>
rate of progress, your AI is &quot;good enough to do a takeoff given the
<br>
Internet&quot; a month or two before the AI is &quot;good enough to do a takeoff on
<br>
the fastest supercomputer around&quot;, and then it's just another month or two
<br>
before the AI can do a takeoff with whatever hardware you developed it
<br>
on.  A few months could easily be ten million lives at the current death
<br>
rate, so yes, Vastmind is worth it, but it probably won't be the
<br>
Singularity itself that's at stake.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4778.html">Eliezer S. Yudkowsky: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<li><strong>Previous message:</strong> <a href="4776.html">hal@finney.org: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<li><strong>In reply to:</strong> <a href="4776.html">hal@finney.org: "Re: AI over the Internet (was Re: making microsingularities)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4781.html">Ben Goertzel: "RE: AI over the Internet (was Re: making microsingularities)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4777">[ date ]</a>
<a href="index.html#4777">[ thread ]</a>
<a href="subject.html#4777">[ subject ]</a>
<a href="author.html#4777">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:08 MDT</em>
</em>
</small>
</body>
</html>
