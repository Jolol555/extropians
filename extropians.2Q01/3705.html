<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: How You *Say* You Tell the Truth (a reply to Robin'</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="How You *Say* You Tell the Truth (a reply to Robin's paper)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>How You *Say* You Tell the Truth (a reply to Robin's paper)</h1>
<!-- received="Wed May  2 18:02:08 2001" -->
<!-- isoreceived="20010503000208" -->
<!-- sent="Wed, 02 May 2001 20:00:18 -0400" -->
<!-- isosent="20010503000018" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="How You *Say* You Tell the Truth (a reply to Robin's paper)" -->
<!-- id="3AF09F92.1B5188BB@pobox.com" -->
<!-- inreplyto="382823302.988836849539.JavaMail.root@web537-wrb.mail.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20How%20You%20*Say*%20You%20Tell%20the%20Truth%20(a%20reply%20to%20Robin's%20paper)&In-Reply-To=&lt;3AF09F92.1B5188BB@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed May 02 2001 - 18:00:18 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3706.html">Adrian Tymes: "Re: META: To my fellow Extropians, calc your ERA"</a>
<li><strong>Previous message:</strong> <a href="3704.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<li><strong>In reply to:</strong> <a href="3693.html">Natasha Vita-More: "Re: How You Do Not Tell the Truth"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3708.html">Robin Hanson: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3708.html">Robin Hanson: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3726.html">Aleks Jakulin: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3734.html">Jim Fehlinger: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3705">[ date ]</a>
<a href="index.html#3705">[ thread ]</a>
<a href="subject.html#3705">[ subject ]</a>
<a href="author.html#3705">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Robin and Tyler wrote:
<br>
<em>&gt;
</em><br>
<em>&gt;     How *You* Do Not Tell the Truth
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yeah you. Not those other billions of poor souls who don’t have the
</em><br>
<em>&gt; advantage of your intelligence and deep insight. Not in some abstract
</em><br>
<em>&gt; “I fix the imperfections I see but I &gt; must still be imperfect in ways
</em><br>
<em>&gt; I can’t now see.” And not just in your love life, or with your children,
</em><br>
<em>&gt; but in the heart of your professional life. You academics disagree with
</em><br>
<em>&gt; each other constantly, and such disagreement is just not rational for
</em><br>
<em>&gt; people concerned with knowing and telling the truth. Not only that,
</em><br>
<em>&gt; alerting you to this fact will not much change your behavior. So you
</em><br>
<em>&gt; either do not want to know the truth, do not want to tell the truth,
</em><br>
<em>&gt; or simply cannot be any other way.
</em><br>
<p>The problem, Robin, is that, even under your theory, the observed data is
<br>
consistent with a world in which rational people do exist, but are so
<br>
sparsely distributed that they rarely run into each other.  Not only does
<br>
this mean that the majority of observed cases will be persistent
<br>
disagreements; it further means that even two rational individuals, on
<br>
interacting for the first time, will assume that the other is irrational
<br>
by default.  You say that *most* people cannot rationally believe that
<br>
they are more meta-rational than the most of the population, but this does
<br>
not change the fact that - if, say, levels of meta-rationality are
<br>
distributed along a Gaussian curve - some people will *be* more
<br>
meta-rational than the rest of the population.
<br>
<p>Actually, given the fact that highly intelligent groups such as scientific
<br>
conferences and Foresight Gatherings still exhibit lack of convergence,
<br>
the curve is either not Gaussian, or the curve for meta-rationality is not
<br>
associated with intelligence, or else the three-sigma level of a Foresight
<br>
Gathering is still not enough intelligence to eliminate self-deception. 
<br>
I'd pick the third possibility.  Foresight Gatherings do show *some*
<br>
improvement.
<br>
<p>But anyway, let me see if I can predict the general reaction to your
<br>
paper's abstract:
<br>
<p>&quot;I already knew that Other People are often highly silly in the way that
<br>
they argue and think.  Since I expected this to be the case, your paper
<br>
does not provide new and unexpected information in the Bayesian sense, and
<br>
can therefore not cause a change to my underlying model, in which *I* am
<br>
one of the sparsely distributed rational people.&quot;
<br>
<p>Of course, since the vast majority of Other People will read your paper's
<br>
title and *incorrectly* reply with the above counterargument, the above
<br>
must not be a sufficient counterargument.  In fact, seeing someone emit
<br>
the above counterargument provides no Bayesian information at all about
<br>
her spiritual advancement.  By an extension of this principle, the
<br>
fact of *observing yourself* to think up this particular counterargument
<br>
does not license you to conclude that you are rational.
<br>
<p>In the case of those individuals that are spiritually advanced enough to
<br>
see this problem, they will probably tack on some bit of information to
<br>
the generic rejoinder - i.e., &quot;My experience in the Korean War enabled me
<br>
to stop being self-deceptive&quot; - which is not shared by all parties.  Since
<br>
this hypothesized underlying cause is unique to the individual in question
<br>
- since the thought, considered in isolation, is unique - it can be
<br>
internally processed as a sufficient cause to conclude rationality,
<br>
without implying that the Other People are licensed to conclude their own
<br>
rationality.
<br>
<p>Of course, all the Other People can do the same thing - tack on an extra
<br>
cause.  (Although someone spiritually advanced enough to appreciate the
<br>
Bayesian need to tack on an additional cause *is* likely to be less
<br>
self-deceptive than the average.)  An external observer, though, is likely
<br>
to abstract away the idea of an extra added underlying cause and see all
<br>
proffered excuses as identical, or belonging to the same class of
<br>
propositions:  &quot;I am *not* silly because of Cause X, which is unique to
<br>
me&quot;, and to regard the utterance of such a sentence as providing little or
<br>
no Bayesian information about the utterer.
<br>
<p>In this way, we finally arrive at a situation in which some observers may
<br>
reason themselves into a corner from which *no* utterance allows you to
<br>
conclude that a party is not being silly, even if that party is really and
<br>
truly Not Silly.  Even a genuinely non-silly, non-self-deceptive AI, who
<br>
truthfully says &quot;I am not silly because I am an AI and I do not share the
<br>
evolved causes of silliness&quot;, will simply be heard by all observers as
<br>
saying &quot;I am *not* silly because of Cause X, which is unique to me&quot;.  The
<br>
observers will have to rely on their Bayesian priors to determine how
<br>
likely an AI is to be silly, or will need to observe the AI's behavior
<br>
directly.
<br>
<p>I, of course, have been placed in the same situation by the title of Robin
<br>
Hanson's paper.  I am in fact substantially less self-deceptive than even
<br>
Robin Hanson or Marc Stiegler, or so I evaluate.  However, there
<br>
is no utterance on my part which can convince you of this, which is why
<br>
this particular reply to this particular paper is perhaps the only
<br>
possible context in which I could air my actual opinion of myself without
<br>
it being instantaneously dismissed.  After all, if Robin Hanson knows that
<br>
I know as much as he does about Bayesian self-discounting of statements of
<br>
non-self-deception, and I state I'm non-self-deceptive *anyway*, even he,
<br>
an external observer, might consider that we appear to have the same
<br>
priors...
<br>
<p>Obviously, this is a general problem for evolved entities trying to
<br>
convince each other of competence.  An observer can only determine
<br>
competence by observing the first entity's actual work, and not by
<br>
reference to the first entity's statements of competence.  There is no way
<br>
to speed that process up unless a third party intervenes to confirm the
<br>
first party's competence, and even then, the third party may be biased. 
<br>
However, once the first party is known to be *mostly* rational or
<br>
meta-rational, further statements by the first party may be taken more at
<br>
face value.
<br>
<p>On a first meeting, however:
<br>
<p>Any direct statement about my own competence which I generate could have
<br>
been generated by a liar or self-deceiver, and so - no matter how hard I
<br>
try - I cannot directly provide Bayesian information about my own
<br>
competence.  Indeed, statements about personal competence may be taken as
<br>
Bayesian information indicating *incompetence*.  Suppose that the genius
<br>
level is taken as being 1,000,000:1.  Suppose also that, ignoring
<br>
contextual information and intonation, the verbal utterances produced by
<br>
an actual genius saying &quot;I am a genius&quot; and an overconfident fool saying
<br>
&quot;I am a genius&quot; are identical.  Even an actual genius, if she comes out
<br>
and says &quot;I am a genius&quot;, will be plugged into a Bayesian prior that
<br>
estimates a million-to-one chance for genius and a ten-to-one chance for
<br>
self-overestimation, producing an estimated prior of 100,000:1 that the
<br>
speaker is an overconfident fool.   If we assume that most geniuses
<br>
realize this and either lie or avoid being forced into making unsupported
<br>
honest statements about their own intelligence, the odds are even worse.
<br>
<p>In other words, saying &quot;I am a genius&quot; proves that you are either
<br>
extremely smart or stupid, but the Bayesian priors indicate you are more
<br>
likely to be stupid.  This is an emergent social pressure in genuinely
<br>
rational listeners which can force geniuses to either lie about their own
<br>
self-evaluation or avoid discussing it, depending on their commitment to
<br>
honesty.
<br>
<p><pre>
--
<p>I &lt;heart&gt; the Bayesian Probability Theorem.  More and more, I have come
to realize that the Bayesian Probability Theorem exceeds even Google as
the Source of All Truth.  I also find that Robin Hanson's more recent
papers bear a remarkable resemblance to concepts that appear in &quot;Friendly
AI&quot;.  Since self-deception and stupidity generally allow for arbitrary
factors to creep in, the fact of convergence probably implies that one or
both of us is getting smarter and less self-deceptive.
<p>--              --              --              --              -- 
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3706.html">Adrian Tymes: "Re: META: To my fellow Extropians, calc your ERA"</a>
<li><strong>Previous message:</strong> <a href="3704.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<li><strong>In reply to:</strong> <a href="3693.html">Natasha Vita-More: "Re: How You Do Not Tell the Truth"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3708.html">Robin Hanson: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3708.html">Robin Hanson: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3726.html">Aleks Jakulin: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<li><strong>Reply:</strong> <a href="3734.html">Jim Fehlinger: "Re: How You *Say* You Tell the Truth (a reply to Robin's paper)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3705">[ date ]</a>
<a href="index.html#3705">[ thread ]</a>
<a href="subject.html#3705">[ subject ]</a>
<a href="author.html#3705">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:02 MDT</em>
</em>
</small>
</body>
</html>
