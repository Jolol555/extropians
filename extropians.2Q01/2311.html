<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Contextualizing seed-AI proposals</title>
<meta name="Author" content="Jim Fehlinger (fehlinger@home.com)">
<meta name="Subject" content="Re: Contextualizing seed-AI proposals">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Contextualizing seed-AI proposals</h1>
<!-- received="Sat Apr 14 09:52:41 2001" -->
<!-- isoreceived="20010414155241" -->
<!-- sent="Sat, 14 Apr 2001 11:25:11 -0400" -->
<!-- isosent="20010414152511" -->
<!-- name="Jim Fehlinger" -->
<!-- email="fehlinger@home.com" -->
<!-- subject="Re: Contextualizing seed-AI proposals" -->
<!-- id="3AD86BD7.24B9DDB6@home.com" -->
<!-- inreplyto="3AD6617C.502F4C74@pobox.com" -->
<strong>From:</strong> Jim Fehlinger (<a href="mailto:fehlinger@home.com?Subject=Re:%20Contextualizing%20seed-AI%20proposals&In-Reply-To=&lt;3AD86BD7.24B9DDB6@home.com&gt;"><em>fehlinger@home.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 14 2001 - 09:25:11 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2312.html">Michael Wiik: "Re: The future of product labeling"</a>
<li><strong>Previous message:</strong> <a href="2310.html">scerir: "E.T."</a>
<li><strong>In reply to:</strong> <a href="2265.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2321.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<li><strong>Reply:</strong> <a href="2321.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2311">[ date ]</a>
<a href="index.html#2311">[ thread ]</a>
<a href="subject.html#2311">[ subject ]</a>
<a href="author.html#2311">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<p><em>&gt; I wrote:
</em><br>
<p><em>&gt; &gt; I've never quite been able to figure out which side of the
</em><br>
<em>&gt; &gt; cognitive vs. post-cognitive or language-as-stuff-of-intelligence
</em><br>
<em>&gt; &gt; vs. language-as-epiphenomenon-of-intelligence fence this document
</em><br>
<em>&gt; &gt; [CaTAI 2.2, <a href="http://www.singinst.org/CaTAI.html">http://www.singinst.org/CaTAI.html</a> ] comes down on...
</em><br>
<p><em>&gt; &quot;Hm, the old debate about symbols, representational power,
</em><br>
<em>&gt; and so on.  I'm well out of it.&quot;
</em><br>
<p>Sigh.  I freely admit to being an amateur (and worse than that --
<br>
a dilettante) in this field, as in all others, but my impression
<br>
is that this &quot;old debate&quot; is far from settled, and that you can't
<br>
afford to be &quot;well out of it&quot; if you want to make a serious
<br>
contribution to AI.
<br>
<p>The precise role of &quot;symbols&quot; in the functional hierarchy of an
<br>
intelligent organism is a wickedly-beckoning trap for human
<br>
philosophers, mathematicians, and AI researchers **precisely** because
<br>
they're so impressed by, and enamored of, human language.  They
<br>
have, historically, succumbed to the temptation to stick it in
<br>
where it doesn't belong.  That tendency is now being successfully
<br>
combatted, I gather.  You, as an AI researcher, need to know
<br>
all about that, and to take it very seriously indeed (though certainly
<br>
not **just** because **I** say so, for God [or Ifni] 's sake! ;-&gt;).
<br>
<p>In particular, you need to armor yourself, in your pursuit
<br>
of the truth of these matters, against what I perceive is
<br>
your own particular weakness -- your burning desire to find
<br>
a rocket fuel to power the runaway Singularity you do desperately
<br>
long for.  Your motives for that may be laudable -- saving the
<br>
human race, and all that -- but the truth needs to come
<br>
first.
<br>
<p>Pay attention to the business at hand, Eliezer.  Even an Algernon
<br>
can do no better than that.  The Singularity will take care of
<br>
itself.  Or not.  Whatever.  Don't try to push the river, as the
<br>
Taoists would say.
<br>
<p><em>&gt; So if you want to know whether CaTAI is symbolic or connectionist AI, the
</em><br>
<em>&gt; answer is a resounding &quot;No&quot;.  This is one of the old, false dichotomies
</em><br>
<em>&gt; that helped to cripple the field of AI.
</em><br>
<p>No, no, a thousand times no!!!  Symbolic vs. &quot;connectionist&quot; isn't
<br>
the point (or at least it's far from being the whole story).
<br>
Which gives me hope, because it means the attractors inside **your**
<br>
head may yet spontaneously undergo a phase transition or two (you're
<br>
liable to pop through the roof when they do, yelling Eurisko, Eureka,
<br>
or something unprintable ;-&gt;  ;-&gt; ).
<br>
<p><em>&gt; Thoughts are built from structures of concepts (&quot;categories&quot;,
</em><br>
<em>&gt; &quot;symbols&quot;).  Concepts are built from sensory modalities.  Sensory
</em><br>
<em>&gt; modalities are built from the actual code.
</em><br>
<p>This is my excuse for another excerpt from _Going Inside_.
<br>
Yes, this is about biological brains, and not the design of
<br>
any hypothetical synthetic intelligence, but as the only
<br>
known example of the sort of thing the AI community has been
<br>
looking to build, the **human** brain needs to be examined
<br>
seriously, and not just dismissed as an inconveniently
<br>
squishy instantiation of some hypothetical (and perhaps
<br>
nonexistent) Turing machine, as Edelman has pointed out.
<br>
<p>&nbsp;From Chapter Five, &quot;A Dynamical Computation&quot; (pp. 106-110):
<br>
<p>&quot;[T]he brain [is] a lot like a computer in having a highly
<br>
structured way of dealing with information; on the other
<br>
[hand], its circuitry [is] basically fluid...  These two ways
<br>
of looking at the brain, the computational and dynamic, seemed
<br>
[irreconcilable].  However, in the 1990s this started to
<br>
change rapidly as people began to understand the idea of
<br>
complexity and saw how it could embrace exactly such a
<br>
hybrid system.
<br>
<p>[C]omplexity is not so much a new concept as a realization
<br>
that the principles behind Darwinian evolution could be
<br>
expanded to form an intellectual framework for tackling a
<br>
great many of the things...  that fit so poorly into the
<br>
traditional reductionist mould of scientific thought.  A
<br>
complex system is one that is fundamentally dynamic,
<br>
even chaotic, but which has found ways of harnessing this
<br>
dynamism.  It has developed machinery that channels
<br>
activity down certain predictable and constructive paths
<br>
to inflate a state of organisation...
<br>
<p>A well-adapted system becomes meta-stable. It is built of
<br>
dynamic material, yet a network of internal checks and
<br>
balances holds its structure firm, or at least firm-ish.
<br>
Like the brain, it looks solid enough -- it hangs together
<br>
for sufficient time to do the job for which it is
<br>
designed -- but it is not solid really...  [A] complex
<br>
system can begin to evolve hierarchies of structure.
<br>
Having evolved a first level of organization...  it can
<br>
go on to add layer upon layer of fresh structure to 
<br>
develop into something that is super-complex.
<br>
<p>Life is the most familiar example of this.  The DNA
<br>
molecule is a device for milking structure from the
<br>
randomness of organic chemistry...  A strand of DNA
<br>
is no more than a recipe for churning out a particular
<br>
brew of proteins at a given time.  But this list has
<br>
been so carefully tuned over millennia of evolution
<br>
that when it is transcribed, the resulting mix cannot
<br>
help but self-assemble to form a cell.  The proteins
<br>
coming off the DNA manufacturing line will jostle about
<br>
on individually chaotic trajectories, their fate
<br>
apparently ruled by chance, yet the blend is so precisely
<br>
specified that the proteins will find themselves falling
<br>
into the same old conjunctions, time and time again...
<br>
<p>DNA acts as a kind of digital bottleneck.  It does
<br>
information processing on a generational timescale,
<br>
trapping knowledge about what protein mixtures work and
<br>
applying that to each new cycle of birth and growth.
<br>
DNA is computer-like in that it has the necessary
<br>
rigidity to make particular kinds of structure as soon
<br>
as the winds of chemical chance begin to blow through
<br>
it.  But it also has just enough plasticity to act
<br>
as a memory, to be changed by events...
<br>
<p>The brain is similar in that it has a machinery... which
<br>
can milk organization from the disorder of the moment...
<br>
[T]he brain appears to have hierarchies of digital-like
<br>
bottlenecks for distilling order from a flow of events.
<br>
The channelling starts right down at the synapse level,
<br>
perhaps even at the membrane pore level.  A synaptic
<br>
junction has the right mix of rigidity and plasticity
<br>
to turn a soupy mix of electro-chemistry into the
<br>
transmission of a signal...  [S]omething reasonably
<br>
definite happens...  The synapse also learns in some
<br>
way... becoming either fatigued or sensitised and, over
<br>
a longer timescale, generally strengthened or weakened.
<br>
<p>Stacked up above the synapse are layer upon layer of
<br>
further bottlenecks.  Neurons turn a complex mix of
<br>
synaptic activity into a crisp output decision...
<br>
After neurons come topographical mappings and
<br>
hierarchies of such mappings...  Synapses, neurons,
<br>
and cortex mappings are sufficient to raise the level
<br>
of activity from raw electro-chemistry to orderly
<br>
neural representations...  [F]or these maps to
<br>
be woven into a graded field of consciousness -- an
<br>
awareness with a bright, focused foreground and a
<br>
dimly-perceived yet still organized periphery -- they
<br>
must feed through some form of system-wide, whole-brain
<br>
transition... probably achieved by the cortex sheet...
<br>
using a clutter of sub-cortical organs as a bottleneck
<br>
to connect back to itself and so focus aspects of
<br>
its own activity...
<br>
<p>[T]he brain... has many levels at which it wrings
<br>
information from basically dynamic processes...
<br>
Computation is about stability; dynamism is about
<br>
instability; but complexity is about getting just the
<br>
right pitch of meta-stability out of a basically
<br>
dynamic system so that it keeps moving forward, never
<br>
falling back...  The brain... evolves its way to
<br>
a state of output.  Everything has to happen in concert.
<br>
An individual synapse, neuron, or mapping area can only
<br>
arrive at a meaningful level of activity after the
<br>
entire stack of representation across the brain has
<br>
had time to settle down.  All the eddies of competition
<br>
and feedback have to have the chance to play themselves
<br>
out and reach some kind of fleeting balance...
<br>
<p>[I]n a computer, information is something compartmentalised
<br>
and stable.  But in the brain, information had a trajectory --
<br>
it had to develop.  And by the time a neuron or map had
<br>
settled into some kind of output state -- although by now,
<br>
even the word 'output' had dubious connotations --
<br>
this activity would as much represent what the rest of
<br>
the brain thought about the response as what the cell or
<br>
mapping area felt about the stimulus that provoked the
<br>
firing in the first place.  Information only became
<br>
information when each fragment of brain activation came
<br>
also to reflect something about the whole.&quot;
<br>
<p><em>&gt; Intelligence (&quot;problem-solving&quot;, &quot;stream of consciousness&quot;)
</em><br>
<em>&gt; is built from thoughts.  Thoughts are built from structures
</em><br>
<em>&gt; of concepts (&quot;categories&quot;, &quot;symbols&quot;).  Concepts are built from
</em><br>
<em>&gt; sensory modalities.  Sensory modalities are built from the
</em><br>
<em>&gt; actual code.
</em><br>
<p>Too static, I fear.  Also, too dangerously perched on
<br>
the edge of what you have already dismissed as the &quot;suggestively-
<br>
named Lisp token&quot; fallacy.
<br>
<p>Fee, fie, foe, fum.
<br>
Cogito, ergo sum.
<br>
<p>Please understand that I'm **not** succumbing to mysticism
<br>
or oceanic holism here (or at least, I hope I'm not!).  I'm
<br>
not even saying that the panorama of alternating soupy
<br>
and sticky, complexity-generated levels of hierarchy that
<br>
McCrone describes above couldn't one day be simulated on
<br>
some &quot;honkin' big&quot; computer (it won't have the &quot;Intel inside&quot;
<br>
sticker on it, though! ;-&gt;).
<br>
<p>Don't give up, Eliezer!  You may have to pay more attention
<br>
to the near end, rather than the far end of the tunnel, though.
<br>
The light there remains, whether or not any of us will get to
<br>
step into it.  Remember, vegetable before dessert ;-&gt;  ;-&gt; .
<br>
<p>Jim F.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2312.html">Michael Wiik: "Re: The future of product labeling"</a>
<li><strong>Previous message:</strong> <a href="2310.html">scerir: "E.T."</a>
<li><strong>In reply to:</strong> <a href="2265.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2321.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<li><strong>Reply:</strong> <a href="2321.html">Eliezer S. Yudkowsky: "Re: Contextualizing seed-AI proposals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2311">[ date ]</a>
<a href="index.html#2311">[ thread ]</a>
<a href="subject.html#2311">[ subject ]</a>
<a href="author.html#2311">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:46 MDT</em>
</em>
</small>
</body>
</html>
