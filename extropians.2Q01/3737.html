<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Keeping AI at bay (was: How to help create a si</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Keeping AI at bay (was: How to help create a singularity)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Keeping AI at bay (was: How to help create a singularity)</h1>
<!-- received="Thu May  3 10:56:08 2001" -->
<!-- isoreceived="20010503165608" -->
<!-- sent="Thu, 03 May 2001 12:57:02 -0400" -->
<!-- isosent="20010503165702" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Keeping AI at bay (was: How to help create a singularity)" -->
<!-- id="3AF18DDE.65D402F4@posthuman.com" -->
<!-- inreplyto="200105031341.IAA24794@dal-mail2.ricochet.net" -->
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Keeping%20AI%20at%20bay%20(was:%20How%20to%20help%20create%20a%20singularity)&In-Reply-To=&lt;3AF18DDE.65D402F4@posthuman.com&gt;"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Thu May 03 2001 - 10:57:02 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3738.html">Adrian Tymes: "Re: META: To my fellow Extropians, calc your ERA"</a>
<li><strong>Previous message:</strong> <a href="3736.html">Anders Sandberg: "Re: NEWS: Microsoft Is Set to Be Top Foe of Free Code"</a>
<li><strong>In reply to:</strong> <a href="3733.html">Lee Corbin: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3941.html">Robert Wasley: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3737">[ date ]</a>
<a href="index.html#3737">[ thread ]</a>
<a href="subject.html#3737">[ subject ]</a>
<a href="author.html#3737">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Nevertheless, he has a point: it'd be a real shame to spend 5 years and
<br>
big wads of cash to evolve some kind of real intelligence, and then find
<br>
out that it crashes when you bring a magnet too close to it because it
<br>
relies on some effect that you didn't worry about (or know about). Evolution
<br>
can suffer its own forms of brittleness, moreso in too simplistic
<br>
environments.
<br>
<p>Lee Corbin wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Damien Sullivan appears to commit a very common error concerning AI:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;I also can't help thinking at if I was an evolved AI I might not thank my
</em><br>
<em>&gt; &gt;creators.  &quot;Geez, guys, I was supposed to be an improvement on the human
</em><br>
<em>&gt; &gt;condition.  You know, highly modular, easily understadable mechanisms, the
</em><br>
<em>&gt; &gt;ability to plug in new senses, and merge memories from my forked copies.
</em><br>
<em>&gt; &gt;Instead I'm as fucked up as you, only in silicon, and can't even make backups
</em><br>
<em>&gt; &gt;because I'm tied to dumb quantum induction effects.  Bite my shiny metal
</em><br>
<em>&gt; ass!&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It's as Eliezer (usually) never tires of stating:  explicit emotions
</em><br>
<em>&gt; such as these simply do not happen unless they're designed or evolved
</em><br>
<em>&gt; somehow.  Probably the toughest part is leaving behind our intuition that
</em><br>
<em>&gt; where goes intelligence must go certain kinds of survival attitudes.  Now
</em><br>
<em>&gt; of course, the very moment that you step forth on a new planet, and begin
</em><br>
<em>&gt; to suspect that there is intelligent life, you should also being to
</em><br>
<em>&gt; suspect that it will have some kinds of emotions; e.g., you might cause
</em><br>
<em>&gt; it to become angry or to experience suffering.  But artificial intelligence
</em><br>
<em>&gt; isn't necessarily evolved in the way that natural intelligence is, and so
</em><br>
<em>&gt; need not have such capabilities.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Lee Corbin
</em><br>
<p><pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.singinst.org/">http://www.singinst.org/</a>
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3738.html">Adrian Tymes: "Re: META: To my fellow Extropians, calc your ERA"</a>
<li><strong>Previous message:</strong> <a href="3736.html">Anders Sandberg: "Re: NEWS: Microsoft Is Set to Be Top Foe of Free Code"</a>
<li><strong>In reply to:</strong> <a href="3733.html">Lee Corbin: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3941.html">Robert Wasley: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3737">[ date ]</a>
<a href="index.html#3737">[ thread ]</a>
<a href="subject.html#3737">[ subject ]</a>
<a href="author.html#3737">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:02 MDT</em>
</em>
</small>
</body>
</html>
