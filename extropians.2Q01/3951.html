<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Keeping AI at bay (was: How to help create a si</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Keeping AI at bay (was: How to help create a singularity)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Keeping AI at bay (was: How to help create a singularity)</h1>
<!-- received="Mon May  7 10:58:36 2001" -->
<!-- isoreceived="20010507165836" -->
<!-- sent="Mon, 07 May 2001 12:56:26 -0400" -->
<!-- isosent="20010507165626" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Keeping AI at bay (was: How to help create a singularity)" -->
<!-- id="3AF6D3BA.504209CA@pobox.com" -->
<!-- inreplyto="001301c0d42b$6da22900$783afea9@desktop" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Keeping%20AI%20at%20bay%20(was:%20How%20to%20help%20create%20a%20singularity)&In-Reply-To=&lt;3AF6D3BA.504209CA@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon May 07 2001 - 10:56:26 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3952.html">Robin Hanson: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Previous message:</strong> <a href="3950.html">John Clark: "God Diagnosed With Bipolar Disorder"</a>
<li><strong>In reply to:</strong> <a href="3941.html">Robert Wasley: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3898.html">Jim Fehlinger: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3951">[ date ]</a>
<a href="index.html#3951">[ thread ]</a>
<a href="subject.html#3951">[ subject ]</a>
<a href="author.html#3951">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Robert Wasley wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Lee Corbin wrote
</em><br>
<em>&gt; &gt; It's as Eliezer (usually) never tires of stating:  explicit emotions
</em><br>
<em>&gt; &gt; such as these simply do not happen unless they're designed or evolved
</em><br>
<em>&gt; &gt; somehow.  Probably the toughest part is leaving behind our intuition that
</em><br>
<em>&gt; &gt; where goes intelligence must go certain kinds of survival attitudes......
</em><br>
<em>&gt; &gt; But artificial intelligence
</em><br>
<em>&gt; &gt; isn't necessarily evolved in the way that natural intelligence is, and so
</em><br>
<em>&gt; &gt; need not have such capabilities.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is a very good point and possibly event true. Nevertheless interacting
</em><br>
<em>&gt; with such
</em><br>
<em>&gt; an intelligence will truely be a very alien experience and as such the value
</em><br>
<em>&gt; of such intercourse
</em><br>
<em>&gt; would be very limited indeed. This is the reason designers around the world
</em><br>
<em>&gt; from basic
</em><br>
<em>&gt; consumer software to robots are trying to make them &quot;human&quot; so that we feel
</em><br>
<em>&gt; more comfortable
</em><br>
<em>&gt; interacting with them, thus deriving more value from the experience.
</em><br>
<p>Even a Friendly AI might need to maintain a personality overlay that could
<br>
appear to take offense at insults and so on - a possibility I conceded
<br>
after watching episode 3 of &quot;Bubblegum Crisis Tokyo 2040&quot;.  I adjusted
<br>
pretty quickly by reminding myself of the AI's internal perspective - that
<br>
it was just requested behaviors being carried out, with no particular
<br>
meaning to the AI - after which I lost the impulse to flee screaming into
<br>
the night.  I'm just not sure that the rest of humanity would adjust
<br>
equally quickly to an android waitress that sees nothing particularly
<br>
wrong or offensive or abnormal about, for example, being asked to lick
<br>
spilled coffee off of someone's boots, or an android secretary being asked
<br>
to laugh for two minutes.  The point is that a personality overlay would
<br>
be maintained as a subgoal of Friendliness - of not sending people
<br>
screaming into the night - and wouldn't affect the underlying goal system.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3952.html">Robin Hanson: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Previous message:</strong> <a href="3950.html">John Clark: "God Diagnosed With Bipolar Disorder"</a>
<li><strong>In reply to:</strong> <a href="3941.html">Robert Wasley: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3898.html">Jim Fehlinger: "Re: Keeping AI at bay (was: How to help create a singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3951">[ date ]</a>
<a href="index.html#3951">[ thread ]</a>
<a href="subject.html#3951">[ subject ]</a>
<a href="author.html#3951">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:03 MDT</em>
</em>
</small>
</body>
</html>
