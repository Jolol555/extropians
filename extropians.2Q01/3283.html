<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Genetic transition to posthumanism</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Genetic transition to posthumanism">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Genetic transition to posthumanism</h1>
<!-- received="Fri Apr 27 21:03:17 2001" -->
<!-- isoreceived="20010428030317" -->
<!-- sent="Fri, 27 Apr 2001 23:04:08 -0400" -->
<!-- isosent="20010428030408" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Genetic transition to posthumanism" -->
<!-- id="3AEA3328.4F052500@posthuman.com" -->
<!-- inreplyto="a0.139045be.281b20f8@aol.com" -->
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Genetic%20transition%20to%20posthumanism&In-Reply-To=&lt;3AEA3328.4F052500@posthuman.com&gt;"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Fri Apr 27 2001 - 21:04:08 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3284.html">Eliezer S. Yudkowsky: "Re: How to help create a singularity."</a>
<li><strong>Previous message:</strong> <a href="3282.html">Lee Corbin: "Unprovabililty and the Goldbach Conjecture"</a>
<li><strong>In reply to:</strong> <a href="3251.html">JacqMath@aol.com: "Re: Genetic transition to posthumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3389.html">J. R. Molloy: "Re: Genetic transition to posthumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3283">[ date ]</a>
<a href="index.html#3283">[ thread ]</a>
<a href="subject.html#3283">[ subject ]</a>
<a href="author.html#3283">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="mailto:JacqMath@aol.com?Subject=Re:%20Genetic%20transition%20to%20posthumanism&In-Reply-To=&lt;3AEA3328.4F052500@posthuman.com&gt;">JacqMath@aol.com</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; On April 27, 2001 Eliezer S. Yudkowsky wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;Genetics is too slow to have any impact, and receives little or no mention
</em><br>
<em>&gt; &gt;among knowledgeable transhumanists.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I would say that it is a little naive to claim that genetics will not have an
</em><br>
<em>&gt; impact on the future evolutionary path of humanity.  Maybe it is due to a
</em><br>
<em>&gt; limited education that some people would claim this.  I fully believe in the
</em><br>
<em>&gt; potential of science, including nanotechnology and AI, but it seems like some
</em><br>
<em>&gt; people on this list live in a fantasy land.
</em><br>
<em>&gt; 
</em><br>
<p>Have you done the math? Let's say amazingly enough that by 2015 they
<br>
have figured out enough about intelligence genes to be able to engineer
<br>
a significantly smarter-than-human human (not just gimmicks). And let's
<br>
assume that magically the government has deigned to allow such an abomination
<br>
to be born. So by 2040! you might have a few scattered people on the planet
<br>
contributing to tech that are somewhat smarter than Einstein or whoever.
<br>
<p>Do you think AI and/or nanotech will not have already been developed by
<br>
then? If not, why not, and if yes then how do you expect these kiddies to
<br>
have any effect since the Singularity will likely have already occurred
<br>
long before 2040?
<br>
<p>I just don't see a scenario where slow-moving genetic technology has any
<br>
significant effect on the timing of the Singularity, unless AI/nano just
<br>
turns out to incredibly more difficult than we currently think it will.
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.singinst.org/">http://www.singinst.org/</a>
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3284.html">Eliezer S. Yudkowsky: "Re: How to help create a singularity."</a>
<li><strong>Previous message:</strong> <a href="3282.html">Lee Corbin: "Unprovabililty and the Goldbach Conjecture"</a>
<li><strong>In reply to:</strong> <a href="3251.html">JacqMath@aol.com: "Re: Genetic transition to posthumanism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3389.html">J. R. Molloy: "Re: Genetic transition to posthumanism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3283">[ date ]</a>
<a href="index.html#3283">[ thread ]</a>
<a href="subject.html#3283">[ subject ]</a>
<a href="author.html#3283">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:00 MDT</em>
</em>
</small>
</body>
</html>
