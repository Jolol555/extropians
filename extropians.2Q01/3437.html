<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: RE: Maximizing results of efforts Re: Mainstreaming</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Maximizing results of efforts Re: Mainstreaming">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>RE: Maximizing results of efforts Re: Mainstreaming</h1>
<!-- received="Sun Apr 29 22:01:29 2001" -->
<!-- isoreceived="20010430040129" -->
<!-- sent="Mon, 30 Apr 2001 00:01:27 -0400" -->
<!-- isosent="20010430040127" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Maximizing results of efforts Re: Mainstreaming" -->
<!-- id="NDBBIBGFAPPPBODIPJMMIEMCFHAA.ben@goertzel.org" -->
<!-- inreplyto="3AEC612E.7CBF3062@pobox.com" -->
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Maximizing%20results%20of%20efforts%20Re:%20Mainstreaming&In-Reply-To=&lt;NDBBIBGFAPPPBODIPJMMIEMCFHAA.ben@goertzel.org&gt;"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Apr 29 2001 - 22:01:27 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3438.html">John Marlow: "Re: META: blanks"</a>
<li><strong>Previous message:</strong> <a href="3436.html">James Rogers: "Re: How to help create a singularity."</a>
<li><strong>In reply to:</strong> <a href="3413.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3454.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<li><strong>Reply:</strong> <a href="3454.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3437">[ date ]</a>
<a href="index.html#3437">[ thread ]</a>
<a href="subject.html#3437">[ subject ]</a>
<a href="author.html#3437">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eli, this was a very interesting and well-thought-out reply.
<br>
<p>I like your categorization of plans:
<br>
<p><em>&gt; Plans can be divided into three types.  There are plans like Bill Joy's,
</em><br>
<em>&gt; that work only if everyone on the planet signs on, and which get hosed if
</em><br>
<em>&gt; even 1% disagree.  Such plans are unworkable.  There are plans like the
</em><br>
<em>&gt; thirteen colonies' War for Independence, which work only if a *lot* of
</em><br>
<em>&gt; people - i.e., 30% or 70% or whatever - sign on.  Such plans require
</em><br>
<em>&gt; tremendous effort, and pre-existing momentum, to build up to the requisite
</em><br>
<em>&gt; number of people.
</em><br>
<em>&gt;
</em><br>
<em>&gt; And there are plans like building a seed AI, which require only a finite
</em><br>
<em>&gt; number of people to sign on, but which benefit the whole world.  The third
</em><br>
<em>&gt; class of plan requires only that a majority *not* get ticked off enough to
</em><br>
<em>&gt; shut you down, which is a more achievable goal than proselytizing a
</em><br>
<em>&gt; majority of the entire planet.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Plans of the third type are far less tenuous than plans of the second
</em><br>
<em>&gt; type.
</em><br>
<p>Here is my sense of things, which I know is different than yours.
<br>
<p>There's the seed AI, and then there's the &quot;global brain&quot; -- the network of
<br>
computing and communication systems and humans that increasingly acts as a
<br>
whole system.
<br>
<p>For the seed AI to be useful to humans rather than indifferent or hostile to
<br>
them, what we need in my view is NOT an artificially-rigged Friendliness
<br>
goal system, but rather, an organic integration of the seed AI with the
<br>
global brain.
<br>
<p>And this, I suspect, is a plan of the second type, according to your
<br>
categorization....
<br>
<p><em>&gt; And the fact is that a majority of the world isn't about to knock on my
</em><br>
<em>&gt; door and complain that I'm doing all this useless paddling instead of
</em><br>
<em>&gt; fishing.  The fall-off-the-edge-of-the-world types might knock and
</em><br>
<em>&gt; complain about my *evil* paddling, but *no way* is a *majority* going to
</em><br>
<em>&gt; complain about my paddling instead of fishing.  Certainly not here in the
</em><br>
<em>&gt; US, where going your own way is a well-established tradition, and most
</em><br>
<em>&gt; people are justifiably impressed if you spend a majority of your time
</em><br>
<em>&gt; doing *anything* for the public benefit.
</em><br>
<p>My belief is that one will work toward Friendly AI better if one spends a
<br>
bit of one's time actually engaged in directly Friendly (compassionate,
<br>
helpful) activities toward humans in real-time.  This is because such
<br>
activities help give one a much richer intuition for the nuances of what
<br>
helping people really means.
<br>
<p>This is an age-old philosophical dispute, of course.  Your lifestyle and
<br>
approach to work are what Nietzsche called &quot;ascetic&quot;, and he railed against
<br>
ascetisicm mercilessly while practicing it himself.  I'm fairly close to an
<br>
ascetic by most standards -- I spend most of my time working on abstract
<br>
stuff, and otherwise I don't do all that much else aside from play with my
<br>
kids -- but, yes, I admit it, I spend some of my time indulging myself in
<br>
the various pleasures of the real world ;p ... and some of my time doing
<br>
stuff like teaching in my kids' schools, which is fun and useful to the
<br>
kids, but doesn't use my unique talents as fully as working on AI.   I think
<br>
my work is the better, not the worse, for these &quot;diversions&quot;....  But
<br>
perhaps it wouldn't be so for you....  Perhaps the philosophical dispute
<br>
over the merits of asceticism just comes down to individual differences in
<br>
personality ;p
<br>
<p><p>ben
<br>
<p><p><p><em>&gt;
</em><br>
<em>&gt; As Brian Atkins said:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;The moral of the story, when it comes to actually having a large effect
</em><br>
<em>&gt; on
</em><br>
<em>&gt; the world: the more advanced technology you have access to, the more
</em><br>
<em>&gt; likely
</em><br>
<em>&gt; that the &quot;lone crusader&quot; approach makes more sense to take compared to the
</em><br>
<em>&gt; traditional &quot;start a whole movement&quot; path. Advanced technologies like AI
</em><br>
<em>&gt; give huge power to the individual/small org, and it is an utter waste of
</em><br>
<em>&gt; time (and lives per day) to miss this fact.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt;
</em><br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3438.html">John Marlow: "Re: META: blanks"</a>
<li><strong>Previous message:</strong> <a href="3436.html">James Rogers: "Re: How to help create a singularity."</a>
<li><strong>In reply to:</strong> <a href="3413.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3454.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<li><strong>Reply:</strong> <a href="3454.html">Eliezer S. Yudkowsky: "Re: Maximizing results of efforts Re: Mainstreaming"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3437">[ date ]</a>
<a href="index.html#3437">[ thread ]</a>
<a href="subject.html#3437">[ subject ]</a>
<a href="author.html#3437">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:00 MDT</em>
</em>
</small>
</body>
</html>
