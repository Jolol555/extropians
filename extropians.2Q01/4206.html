<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Existential Risks: Analyzing Human Extinction Scena</title>
<meta name="Author" content="Nick Bostrom (nick@nickbostrom.com)">
<meta name="Subject" content="Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards</h1>
<!-- received="Sat May 12 01:50:16 2001" -->
<!-- isoreceived="20010512075016" -->
<!-- sent="Sat, 12 May 2001 03:50:18 -0400" -->
<!-- isosent="20010512075018" -->
<!-- name="Nick Bostrom" -->
<!-- email="nick@nickbostrom.com" -->
<!-- subject="Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards" -->
<!-- id="5.0.2.1.2.20010512033852.04901748@nlb28.mail.yale.edu" -->
<!-- inreplyto="20010429134822.A28433@akira.nada.kth.se" -->
<strong>From:</strong> Nick Bostrom (<a href="mailto:nick@nickbostrom.com?Subject=Re:%20Existential%20Risks:%20Analyzing%20Human%20Extinction%20Scenarios%20and%20Related%20Hazards&In-Reply-To=&lt;5.0.2.1.2.20010512033852.04901748@nlb28.mail.yale.edu&gt;"><em>nick@nickbostrom.com</em></a>)<br>
<strong>Date:</strong> Sat May 12 2001 - 01:50:18 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4207.html">Spudboy100@aol.com: "Douglas Adams Dies"</a>
<li><strong>Previous message:</strong> <a href="4205.html">Emlyn \(onetel\): "Re: I strongly disagree with Lee's answer"</a>
<li><strong>In reply to:</strong> <a href="3381.html">Anders Sandberg: "Re: Origins of Political Beliefs"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4213.html">Eliezer S. Yudkowsky: "Re: Existential Risks: Analyzing Human Extinction Scenarios andRelated  Hazards"</a>
<li><strong>Reply:</strong> <a href="4213.html">Eliezer S. Yudkowsky: "Re: Existential Risks: Analyzing Human Extinction Scenarios andRelated  Hazards"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4206">[ date ]</a>
<a href="index.html#4206">[ thread ]</a>
<a href="subject.html#4206">[ subject ]</a>
<a href="author.html#4206">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->

I now have a presentable version of the paper I presented at the most
recent Foresight gathering. It's available in two formats:<br>
<br>
<a href="http://www.nickbostrom.com/existential/risks.html" eudora="autourl">http://www.nickbostrom.com/existential/risks.</a><a href="http://www.nickbostrom.com/existential/risks.html" eudora="autourl">html<br>
</a><a href="http://www.nickbostrom.com/existential/risks.doc" eudora="autourl">http://www.nickbostrom.com/existential/risks.doc</a><br>
<br>
Footnotes and formatting are nicer in the M$-version.<br>
<br>
(Spoiler-warning to those planning to attend the Transvision conference
in Berlin, where I'll give this paper again.)<br>
<br>
<br>
<b>ABSTRACT<br>
</b>Because of accelerating technological progress, humankind may be
rapidly approaching a critical phase in its career. The prospects of
nanotech systems and machine intelligence present us with unprecedented
opportunities and risks. Our future, and whether we will have a future at
all, may well be determined by how these radically transforming
technologies are managed. A better understanding of the transition
dynamics from a human to a “posthuman” society is needed in order to plot
approaches that maximize the probability of a favorable outcome. Of
particular importance is to know where the pitfalls are: the ways in
which things could go disastrously wrong. While we have had long exposure
to various personal, local, or endurable global hazards, this paper
analyzes a rather recently emerging category: that of <i>existential
risks</i>. These are threats that endanger the survival of intelligent
life or that could ruin the potential of human civilization for all time
to come. Some of these threats are relatively well known while others
(including some of the gravest) have gone almost unrecognized.
Existential risks have a cluster of features that make ordinary risk
management ineffective. A clearer understanding of the threat picture
will enable us to formulate better strategies, and several implications
for policy and ethics are discussed.<br>
<br>
<br>
<div>Nick Bostrom</div>
<div>Department of Philosophy</div>
<div>Yale University</div>
Homepage:
<a href="http://www.nickbostrom.com/" EUDORA=AUTOURL>http://www.nickbostrom.com</a>

<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4207.html">Spudboy100@aol.com: "Douglas Adams Dies"</a>
<li><strong>Previous message:</strong> <a href="4205.html">Emlyn \(onetel\): "Re: I strongly disagree with Lee's answer"</a>
<li><strong>In reply to:</strong> <a href="3381.html">Anders Sandberg: "Re: Origins of Political Beliefs"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4213.html">Eliezer S. Yudkowsky: "Re: Existential Risks: Analyzing Human Extinction Scenarios andRelated  Hazards"</a>
<li><strong>Reply:</strong> <a href="4213.html">Eliezer S. Yudkowsky: "Re: Existential Risks: Analyzing Human Extinction Scenarios andRelated  Hazards"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4206">[ date ]</a>
<a href="index.html#4206">[ thread ]</a>
<a href="subject.html#4206">[ subject ]</a>
<a href="author.html#4206">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:04 MDT</em>
</em>
</small>
</body>
</html>
