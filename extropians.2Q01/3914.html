<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: How You Do Not Tell the Truth</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: How You Do Not Tell the Truth">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: How You Do Not Tell the Truth</h1>
<!-- received="Sun May  6 14:23:50 2001" -->
<!-- isoreceived="20010506202350" -->
<!-- sent="Sun, 06 May 2001 13:21:52 -0700" -->
<!-- isosent="20010506202152" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: How You Do Not Tell the Truth" -->
<!-- id="3AF5B260.E1DB04F@objectent.com" -->
<!-- inreplyto="3AF1ECD7.CC7A918C@pobox.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20How%20You%20Do%20Not%20Tell%20the%20Truth&In-Reply-To=&lt;3AF5B260.E1DB04F@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun May 06 2001 - 14:21:52 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3915.html">Franklin Wayne Poley: "Re: Fuel Cell House, was Re: TECH: fuel cell car"</a>
<li><strong>Previous message:</strong> <a href="3913.html">Samantha Atkins: "Re: NEWS: Microsoft Is Set to Be Top Foe of Free Code"</a>
<li><strong>In reply to:</strong> <a href="3750.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3923.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Reply:</strong> <a href="3923.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Reply:</strong> <a href="3952.html">Robin Hanson: "Re: How You Do Not Tell the Truth"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3914">[ date ]</a>
<a href="index.html#3914">[ thread ]</a>
<a href="subject.html#3914">[ subject ]</a>
<a href="author.html#3914">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; <a href="mailto:hal@finney.org?Subject=Re:%20How%20You%20Do%20Not%20Tell%20the%20Truth&In-Reply-To=&lt;3AF5B260.E1DB04F@objectent.com&gt;">hal@finney.org</a> wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The part about Robin's paper (<a href="http://hanson.gmu.edu/deceive.pdf">http://hanson.gmu.edu/deceive.pdf</a>) that
</em><br>
<em>&gt; &gt; I have a hardest time understanding is the discussion of common priors.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Hm.  Well, I understood it perfectly.  Therefore, you should take this
</em><br>
<em>&gt; into account in deciding whether or not the paper makes sense, unless you
</em><br>
<em>&gt; don't think we have common priors.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Essentially, Robin's paper gives a rigorous mathematical proof that for
</em><br>
<em>&gt; two people to (a) disagree and (b) maintain their disagreement after
</em><br>
<em>&gt; interaction, one or both of the parties must believe that they are more
</em><br>
<em>&gt; likely to be rational than the other person.  This does not necessarily
</em><br>
<em>&gt; prove irrationality in *all* cases but it proves irrationality for *most*
</em><br>
<em>&gt; cases.  If we take into account the evolutionary-psychology arguments,
</em><br>
<em>&gt; Robin's paper makes a strong case for a built-in irrationality factor
</em><br>
<em>&gt; common to all humans.
</em><br>
<em>&gt; 
</em><br>
<p>This seems a bit strained to me.  That A has a strong argument for X
<br>
that I cannot defeat logically does not compell me to accept X at that
<br>
time.  I may believe the argument leaves out something crucial than I
<br>
have as yet been unable to identify.  I may be correct or incorrect in
<br>
that evaluation and able or unable to express solid reasons for the
<br>
evaluation that others will be swayed by.  But to conclude I am simply
<br>
irrational or do not care about truth because I did not agree with A
<br>
about X in such circumstances does not follow.  
<br>
<p>Humans are not pure reasoning machines and certainly not effective
<br>
Bayseian processors.  Much of our &quot;reasoning&quot;, our processing of data,
<br>
concepts and so on is not even in the conscious realm.  It is quite
<br>
unlikely that only our conscious evaluations and adhering only to them
<br>
at all points will generally bring us closer to truth in all
<br>
circumstances.  The argument applies much better to a SI than to a
<br>
creature organized as we are.
<br>
<p><p><em>&gt; If a 100,000:1 genius is interacting with a 10,000,000:1 genius, but
</em><br>
<em>&gt; neither of them knows the other's percentile, both will rationally assume
</em><br>
<em>&gt; that they are more likely to be rational than the other person.  However,
</em><br>
<em>&gt; Robin's paper does prove that in *most* cases, rather than in the rarer
</em><br>
<em>&gt; instances where two geniuses unknowingly interact, people must be
</em><br>
<em>&gt; overestimating their own rationality relative to others, or else must not
</em><br>
<em>&gt; be using rigorous Bayesian reasoning with respect to what they are
</em><br>
<em>&gt; licensed to conclude from their own thoughts.
</em><br>
<em>&gt;
</em><br>
<p>Rationality is not only a matter of how much general intelligence you
<br>
have.  
<br>
<p>&nbsp;
<br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3915.html">Franklin Wayne Poley: "Re: Fuel Cell House, was Re: TECH: fuel cell car"</a>
<li><strong>Previous message:</strong> <a href="3913.html">Samantha Atkins: "Re: NEWS: Microsoft Is Set to Be Top Foe of Free Code"</a>
<li><strong>In reply to:</strong> <a href="3750.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3923.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Reply:</strong> <a href="3923.html">Eliezer S. Yudkowsky: "Re: How You Do Not Tell the Truth"</a>
<li><strong>Reply:</strong> <a href="3952.html">Robin Hanson: "Re: How You Do Not Tell the Truth"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3914">[ date ]</a>
<a href="index.html#3914">[ thread ]</a>
<a href="subject.html#3914">[ subject ]</a>
<a href="author.html#3914">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 10:00:03 MDT</em>
</em>
</small>
</body>
</html>
