<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: AI's at risk from viral memes ??</title>
<meta name="Author" content="Robert J. Bradbury (bradbury@aeiveos.com)">
<meta name="Subject" content="Re: AI's at risk from viral memes ??">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: AI's at risk from viral memes ??</h1>
<!-- received="Sun Sep 16 14:11:01 2001" -->
<!-- isoreceived="20010916201101" -->
<!-- sent="Sun, 16 Sep 2001 11:09:16 -0700 (PDT)" -->
<!-- isosent="20010916180916" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Re: AI's at risk from viral memes ??" -->
<!-- id="Pine.LNX.4.10.10109161038540.25999-100000@server.aeiveos.com" -->
<!-- inreplyto="AI's at risk from viral memes ??" -->
<strong>From:</strong> Robert J. Bradbury (<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20AI's%20at%20risk%20from%20viral%20memes%20??&In-Reply-To=&lt;Pine.LNX.4.10.10109161038540.25999-100000@server.aeiveos.com&gt;"><em>bradbury@aeiveos.com</em></a>)<br>
<strong>Date:</strong> Sun Sep 16 2001 - 12:09:16 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6751.html">scerir: "attack (planned) on EU parliament"</a>
<li><strong>Previous message:</strong> <a href="6749.html">Reason: "RE: TERRORISM: more of the same? --&gt; H.G. Wells"</a>
<li><strong>Maybe in reply to:</strong> <a href="7080.html">Smigrodzki, Rafal: "AI's at risk from viral memes ??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6769.html">Samantha Atkins: "Re: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6769.html">Samantha Atkins: "Re: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6816.html">John Clark: "Re: AI's at risk from viral memes ??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6750">[ date ]</a>
<a href="index.html#6750">[ thread ]</a>
<a href="subject.html#6750">[ subject ]</a>
<a href="author.html#6750">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Though I liked John's explanation, I think it is a bit incomplete.
<br>
Eliminating &quot;death&quot; will not eliminate a need to explain &quot;why the
<br>
universe is the way it is?&quot;, or &quot;why does evil exist?&quot;, or &quot;what is
<br>
the purpose of life?&quot;.
<br>
<p>Just because an AI may be &quot;effectively&quot; immortal [within the limits
<br>
of its hardware or civilization], does not mean that it will not
<br>
seek out answers to the questions I've listed above or even a
<br>
more general moral/philosophical system to determine how to make
<br>
value judgements and resource allocation prioritizations.
<br>
<p>Whether an AI could become infected with a virus that is dangerous
<br>
to human lives or is unextropic in some way is a serious issue
<br>
that should not be discarded so simply.  As I have stated before,
<br>
my greatest fear is an amoral AI that recognizes itself as a separate
<br>
species, which feels no loyalty/kinship for the human species that
<br>
has the capability to plan and execute acts of terror and destruction
<br>
such as those we have witnessed this last week.
<br>
<p>Looking at it from the framework of the &quot;Extropian Principles&quot;, there
<br>
will at some point be a conflict between principles 6 (self-direction)
<br>
and 7 (rational-thinking).  Anyone whose self-direction seeks to preserve
<br>
themselves in some unevolved sub-optimal state, is clearly in conflict with
<br>
the perpetual-progress/self-transformation/rational-thinking principles.
<br>
Resolving that seems to require an infringement on the self-direction
<br>
principle.
<br>
<p>So if an AI develops to a level where it is clearly superior, then
<br>
invoking principle 7, it makes perfect sense to recycle humans into
<br>
more optimal forms.  If we are being rational about it, we would
<br>
be queuing up at the recycling stations.
<br>
<p>Robert
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6751.html">scerir: "attack (planned) on EU parliament"</a>
<li><strong>Previous message:</strong> <a href="6749.html">Reason: "RE: TERRORISM: more of the same? --&gt; H.G. Wells"</a>
<li><strong>Maybe in reply to:</strong> <a href="7080.html">Smigrodzki, Rafal: "AI's at risk from viral memes ??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6769.html">Samantha Atkins: "Re: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6769.html">Samantha Atkins: "Re: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6816.html">John Clark: "Re: AI's at risk from viral memes ??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6750">[ date ]</a>
<a href="index.html#6750">[ thread ]</a>
<a href="subject.html#6750">[ subject ]</a>
<a href="author.html#6750">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:48 MDT</em>
</em>
</small>
</body>
</html>
