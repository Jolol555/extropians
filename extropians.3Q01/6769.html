<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: AI's at risk from viral memes ??</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: AI's at risk from viral memes ??">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: AI's at risk from viral memes ??</h1>
<!-- received="Sun Sep 16 16:47:55 2001" -->
<!-- isoreceived="20010916224755" -->
<!-- sent="Sun, 16 Sep 2001 15:48:29 -0700" -->
<!-- isosent="20010916224829" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: AI's at risk from viral memes ??" -->
<!-- id="3BA52C3D.7F17AC2C@objectent.com" -->
<!-- inreplyto="Pine.LNX.4.10.10109161038540.25999-100000@server.aeiveos.com" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20AI's%20at%20risk%20from%20viral%20memes%20??&In-Reply-To=&lt;3BA52C3D.7F17AC2C@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Sep 16 2001 - 16:48:29 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6770.html">Samantha Atkins: "Re: Impact on History"</a>
<li><strong>Previous message:</strong> <a href="6768.html">Bill Douglass: "The Counterterrorist Myth"</a>
<li><strong>In reply to:</strong> <a href="6750.html">Robert J. Bradbury: "Re: AI's at risk from viral memes ??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6776.html">Harvey Newstrom: "RE: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6776.html">Harvey Newstrom: "RE: AI's at risk from viral memes ??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6769">[ date ]</a>
<a href="index.html#6769">[ thread ]</a>
<a href="subject.html#6769">[ subject ]</a>
<a href="author.html#6769">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Though I liked John's explanation, I think it is a bit incomplete.
</em><br>
<em>&gt; Eliminating &quot;death&quot; will not eliminate a need to explain &quot;why the
</em><br>
<em>&gt; universe is the way it is?&quot;, or &quot;why does evil exist?&quot;, or &quot;what is
</em><br>
<em>&gt; the purpose of life?&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Just because an AI may be &quot;effectively&quot; immortal [within the limits
</em><br>
<em>&gt; of its hardware or civilization], does not mean that it will not
</em><br>
<em>&gt; seek out answers to the questions I've listed above or even a
</em><br>
<em>&gt; more general moral/philosophical system to determine how to make
</em><br>
<em>&gt; value judgements and resource allocation prioritizations.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Whether an AI could become infected with a virus that is dangerous
</em><br>
<em>&gt; to human lives or is unextropic in some way is a serious issue
</em><br>
<em>&gt; that should not be discarded so simply.  As I have stated before,
</em><br>
<em>&gt; my greatest fear is an amoral AI that recognizes itself as a separate
</em><br>
<em>&gt; species, which feels no loyalty/kinship for the human species that
</em><br>
<em>&gt; has the capability to plan and execute acts of terror and destruction
</em><br>
<em>&gt; such as those we have witnessed this last week.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Looking at it from the framework of the &quot;Extropian Principles&quot;, there
</em><br>
<em>&gt; will at some point be a conflict between principles 6 (self-direction)
</em><br>
<em>&gt; and 7 (rational-thinking).  Anyone whose self-direction seeks to preserve
</em><br>
<em>&gt; themselves in some unevolved sub-optimal state, is clearly in conflict with
</em><br>
<em>&gt; the perpetual-progress/self-transformation/rational-thinking principles.
</em><br>
<em>&gt; Resolving that seems to require an infringement on the self-direction
</em><br>
<em>&gt; principle.
</em><br>
<em>&gt; 
</em><br>
<p>It sounds to me like we may need to extend the Principles to
<br>
have a clearer right to self-determination and non-interference
<br>
for all sentients.  
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6770.html">Samantha Atkins: "Re: Impact on History"</a>
<li><strong>Previous message:</strong> <a href="6768.html">Bill Douglass: "The Counterterrorist Myth"</a>
<li><strong>In reply to:</strong> <a href="6750.html">Robert J. Bradbury: "Re: AI's at risk from viral memes ??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6776.html">Harvey Newstrom: "RE: AI's at risk from viral memes ??"</a>
<li><strong>Reply:</strong> <a href="6776.html">Harvey Newstrom: "RE: AI's at risk from viral memes ??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6769">[ date ]</a>
<a href="index.html#6769">[ thread ]</a>
<a href="subject.html#6769">[ subject ]</a>
<a href="author.html#6769">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:49 MDT</em>
</em>
</small>
</body>
</html>
