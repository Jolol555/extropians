<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: RE: Hawking on AI dominance</title>
<meta name="Author" content="Amara D. Angelica (amara@kurzweilai.net)">
<meta name="Subject" content="RE: Hawking on AI dominance">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>RE: Hawking on AI dominance</h1>
<!-- received="Tue Sep  4 16:24:55 2001" -->
<!-- isoreceived="20010904222455" -->
<!-- sent="Tue, 4 Sep 2001 15:26:03 -0700" -->
<!-- isosent="20010904222603" -->
<!-- name="Amara D. Angelica" -->
<!-- email="amara@kurzweilai.net" -->
<!-- subject="RE: Hawking on AI dominance" -->
<!-- id="NFBBLBPNELPPDGOGAIEBCEMADPAA.amara@kurzweilai.net" -->
<!-- inreplyto="03ae01c133ff$1d1866a0$f35c2a42@jrmolloy" -->
<strong>From:</strong> Amara D. Angelica (<a href="mailto:amara@kurzweilai.net?Subject=RE:%20Hawking%20on%20AI%20dominance&In-Reply-To=&lt;NFBBLBPNELPPDGOGAIEBCEMADPAA.amara@kurzweilai.net&gt;"><em>amara@kurzweilai.net</em></a>)<br>
<strong>Date:</strong> Tue Sep 04 2001 - 16:26:03 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Previous message:</strong> <a href="5764.html">Charlie Stross: "Re: technological accleration?"</a>
<li><strong>In reply to:</strong> <a href="5639.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Reply:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Reply:</strong> <a href="5776.html">Spike Jones: "sphexish behavior in ants"</a>
<li><strong>Reply:</strong> <a href="5825.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5765">[ date ]</a>
<a href="index.html#5765">[ thread ]</a>
<a href="subject.html#5765">[ subject ]</a>
<a href="author.html#5765">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Ray Kurzweil responds to Stephen Hawking on CNN at 7:30 PM ET, Sept. 4.
<br>
<p>Ray’s response, posted to to KurzweilAI.net’s MindX forum:
<br>
<a href="http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D238">http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D238</a>
<br>
6%23id2402
<br>
<p>Stephen Hawking recently told the German magazine Focus that computers were
<br>
evolving so rapidly that they would eventually outstrip the intelligence of
<br>
humans. Professor Hawking went on to express the concern that eventually,
<br>
computers with artificial intelligence could come to dominate the world.
<br>
<p>Hawking’s recommendation is to (i) improve human intelligence with genetic
<br>
engineering to &quot;raise the complexity of ... the DNA&quot; and (ii) develop
<br>
technologies that make possible &quot;a direct connection between brain and
<br>
computer, so that artificial brains contribute to human intelligence rather
<br>
than opposing it.&quot;
<br>
<p>Hawking’s perception of the acceleration of nonbiological intelligence is
<br>
essentially on target. It is not simply the exponential growth of
<br>
computation and communication that is behind it, but also our mastery of
<br>
human intelligence itself through the exponential advancement of brain
<br>
reverse engineering.
<br>
<p>Once our machines can master human powers of pattern recognition and
<br>
cognition, they will be in a position to combine these human talents with
<br>
inherent advantages that machines already possess: speed (contemporary
<br>
electronic circuits are already 100 million times faster than the
<br>
electrochemical circuits in our interneuronal connections), accuracy (a
<br>
computer can remember billions of facts accurately, whereas we’re hard
<br>
pressed to remember a handful of phone numbers), and, most importantly, the
<br>
ability to instantly share knowledge.
<br>
<p>However, Hawking’s recommendation to do genetic engineering on humans in
<br>
order to keep pace with AI is unrealistic. He appears to be talking about
<br>
genetic engineering through the birth cycle, which would be absurdly slow.
<br>
By the time the first genetically engineered generation grows up, the era of
<br>
beyond-human-level machines will be upon us.
<br>
<p>Even if we were to apply genetic alterations to adult humans by introducing
<br>
new genetic information via gene therapy techniques (not something we’ve yet
<br>
mastered), it still won’t have a chance to keep biological intelligence in
<br>
the lead. Genetic engineering (through either birth or adult gene therapy)
<br>
is inherently DNA-based and a DNA-based brain is always going to be
<br>
extremely slow and limited in capacity compared to the potential of an AI.
<br>
<p>As I mentioned, electronics is already 100 million times faster than our
<br>
electrochemical circuits; we have no quick downloading ports on our
<br>
biological neurotransmitter levels, and so on. We could bioengineer smarter
<br>
humans, but this approach will not begin to keep pace with the exponential
<br>
pace of computers, particularly when brain reverse engineering is complete
<br>
(within thirty years from now).
<br>
<p>The human genome is 800 million bytes, but if we eliminate the redundancies
<br>
(e.g., the sequence called “ALU” is repeated hundreds of thousands of
<br>
times), we are left with only about 23 million bytes, less than Microsoft
<br>
Word. The limited amount of information in the genome specifies stochastic
<br>
wiring processes that enable the brain to be millions of times more complex
<br>
than the genome which specifies it. The brain then uses self-organizing
<br>
paradigms so that the greater complexity represented by the brain ends up
<br>
representing meaningful information. However, the architecture of a
<br>
DNA-specified brain is relatively fixed and involves cumbersome
<br>
electrochemical processes. Although there are design improvements that could
<br>
be made, there are profound limitations to the basic architecture that no
<br>
amount of tinkering will address.
<br>
<p>As far as Hawking’s second recommendation is concerned, namely direct
<br>
connection between the brain and computers, I agree that this is both
<br>
reasonable, desirable and inevitable. It’s been my recommendation for years.
<br>
I describe a number of scenarios to accomplish this in my most recent book,
<br>
The Age of Spiritual Machines, and in the book précis “The Singularity is
<br>
Near”
<br>
(<a href="http://www.kurzweilai.net/meme/frame.html?main=/articles/art0134.html">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0134.html</a>).
<br>
<p>I recommend establishing the connection with noninvasive nanobots that
<br>
communicate wirelessly with our neurons. As I discuss in the précis, the
<br>
feasibility of communication between the electronic world and that of
<br>
biological neurons has already been demonstrated. There are a number of
<br>
advantages to extending human intelligence through the nanobot approach.
<br>
They can be introduced noninvasively (i.e., without surgery). The
<br>
connections will not be limited to one or a small number of positions in the
<br>
brain. Rather, the nanobots can communicate with neurons (and with each
<br>
other) in a highly distributed manner. They would be programmable, would all
<br>
be on a wireless local area network, and would be on the web.
<br>
<p>They would provide many new capabilities, such as full-immersion virtual
<br>
reality involving all the senses. Most importantly, they will provide many
<br>
trillions of new interneuronal connections as well as intimate links to
<br>
nonbiological forms of cognition. Ultimately, our minds won’t need to stay
<br>
so small, limited as they are today to a mere hundred trillion connections
<br>
(extremely slow ones at that).
<br>
<p>However, even this will only keep pace with the ongoing exponential growth
<br>
of AI for a couple of additional decades (to around mid-twenty-first
<br>
century). As Hans Moravec has pointed out, ultimately a hybrid
<br>
biological-nonbiological brain will ultimately be 99.999...% nonbiological,
<br>
so the biological portion becomes pretty trivial.
<br>
<p>We should keep in mind, though, that all of this exponentially advancing
<br>
intelligence is derivative of biological human intelligence, derived
<br>
ultimately from the thinking reflected in our technology designs, as well as
<br>
the design of our own thinking. So it's the human-technology civilization
<br>
taking the next step in evolution. I don’t agree with Hawking that &quot;strong
<br>
AI&quot; is a fate to be avoided. I do believe that we have the ability to shape
<br>
this destiny to reflect our human values, if only we could achieve a
<br>
consensus on what those are.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Previous message:</strong> <a href="5764.html">Charlie Stross: "Re: technological accleration?"</a>
<li><strong>In reply to:</strong> <a href="5639.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Reply:</strong> <a href="5766.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<li><strong>Reply:</strong> <a href="5776.html">Spike Jones: "sphexish behavior in ants"</a>
<li><strong>Reply:</strong> <a href="5825.html">J. R. Molloy: "Re: Hawking on AI dominance"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5765">[ date ]</a>
<a href="index.html#5765">[ thread ]</a>
<a href="subject.html#5765">[ subject ]</a>
<a href="author.html#5765">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:25 MDT</em>
</em>
</small>
</body>
</html>
