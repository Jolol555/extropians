<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Artificial Reality</title>
<meta name="Author" content="Christopher McKinstry (cmckinst@eso.org)">
<meta name="Subject" content="Artificial Reality">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Artificial Reality</h1>
<!-- received="Sat Jul  7 01:29:36 2001" -->
<!-- isoreceived="20010707072936" -->
<!-- sent="Sat, 07 Jul 2001 03:28:41 -0400" -->
<!-- isosent="20010707072841" -->
<!-- name="Christopher McKinstry" -->
<!-- email="cmckinst@eso.org" -->
<!-- subject="Artificial Reality" -->
<!-- id="3B46BA29.BE0E6AAB@eso.org" -->
<strong>From:</strong> Christopher McKinstry (<a href="mailto:cmckinst@eso.org?Subject=Re:%20Artificial%20Reality&In-Reply-To=&lt;3B46BA29.BE0E6AAB@eso.org&gt;"><em>cmckinst@eso.org</em></a>)<br>
<strong>Date:</strong> Sat Jul 07 2001 - 01:28:41 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0435.html">Damien Sullivan: "Re: SEMI SPOILER - Re: AI - My Favorite Moments"</a>
<li><strong>Previous message:</strong> <a href="0433.html">Eliezer S. Yudkowsky: "Re: Debunk All Religiosity Equally (D.A.R.E.) ---&gt; inloading"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0450.html">Eliezer S. Yudkowsky: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0450.html">Eliezer S. Yudkowsky: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0472.html">hal@finney.org: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0642.html">Miriam English: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0657.html">Zero Powers: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#434">[ date ]</a>
<a href="index.html#434">[ thread ]</a>
<a href="subject.html#434">[ subject ]</a>
<a href="author.html#434">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Here's some questions and answers from an interview I gave at
<br>
<a href="http://www.missingmatter.net">http://www.missingmatter.net</a> in April. The full interview is here:
<br>
<a href="http://missingmatter.net/article.pl?sid=01/04/28/0334205">http://missingmatter.net/article.pl?sid=01/04/28/0334205</a>
<br>
<p>It explains that GAC is essentially an artificial reality.
<br>
=========================================================
<br>
<p>2. lopati: also, in response to queries everything2 provides multiple
<br>
'nodes' because the database doesn't know anything about you or the
<br>
context really in which you asked the question or what kind of heuristic
<br>
you're applying when searching for your own answer. or like google will
<br>
rank its responses but it is up to you to interpret its oracular
<br>
pronouncement to your own ends. in a way these databases are senseless,
<br>
without proper stimulation or input they cannot 'know' what exactly it
<br>
is you're asking of it. without 'being in the world' how can
<br>
consciousness arise out of just language queries, i.e. is (abstract)
<br>
language enough to communicate the territory to the map or do you need
<br>
direct sensory receptors (sight, sound..)? 
<br>
<p>2. Chris: My assertion is that the Mindpixel corpus IS the world in
<br>
textual format. It's a digital model of everything that a person can
<br>
experience and communicate unambiguously. The point of the corpus is
<br>
that it can be used as the ultimate fitness test to evolve artificial
<br>
entities that perform like humans for the same reasons. GAC is just a
<br>
database. It is the things that we use GAC to automatically create that
<br>
are interesting, not GAC itself.
<br>
<p>5. jmatthews: While Mindpixel is no doubt an excellent project that will
<br>
help developers create smarter programs, how useful is Mindpixel in the
<br>
long run? Our commonsense isn't something that is immediately and/or
<br>
explicity built into us, we learn through experience - and we probably
<br>
benefit from this fact. A lot of the common sense is relatively
<br>
subjective to the circumstances and the environment. AI will culminate
<br>
(imo) in a smart, cognitive android that will exhibit all the behaviours
<br>
of it's human counterparts. Will something like MindPixel be behind the
<br>
common-sensical part of such a machine? 
<br>
<p>5. Chris: Like I said before, the primary purpose of the Mindpixel
<br>
corpus is to simply be a high resolution model of reality for evolving
<br>
real intelligence in. Anything that artificially evolves to handle the
<br>
Mindpixel corpus will have to have much in common with humans. Think of
<br>
Mindpixel as a playroom for emerging AI's and not as AI itself. When the
<br>
emerging system is good enough to handle everything in the corpus, then
<br>
it is good enough to come outside and play with us. 
<br>
<p>6. jmatthews: Following on from the previous question, what do you think
<br>
will prevail: top-down approaches such as Cyc and Mindpixel or bottom-up
<br>
approaches such as Cog and other &quot;learning&quot; projects.
<br>
<p>6. Chris: Though GAC could be considered a top-down AI, the Mindpixel
<br>
project itself isn't top-down. It is bottom-up! Remember the Mindpixel
<br>
Corpus is a training set for evolving artificial intelligences, it is
<br>
not in itself artificially intelligent. 
<br>
<p>I don't believe that top-down approaches can succeed until we've had
<br>
sucess from the bottom up simply because we don't know what we're doing.
<br>
We really need a bottom-up example that we can take apart and look at in
<br>
detail before we have any hope of top-down understanding. Another point
<br>
is that top-down understanding of human cognition may be beyond us. I
<br>
recall Danny Hillis talking about evolving simple sorting algorithms
<br>
that worked very well, but when he looked at the evolved code, he could
<br>
not understand it. Evolved solutions can be so complex that there are no
<br>
top top-down simplifications of them; the evolved code itself is it's
<br>
own simplest description. 
<br>
<p>7. missingmatterboy: You've often compared GAC to HAL. But HAL's story
<br>
is one of an AI gone awry, who killed  humans because he was given
<br>
conflicting orders and couldn't handle it. Do you think a truly
<br>
conscious computer could be dangerous? If GAC becomes conscious, would
<br>
you place safeguards on it? 
<br>
<p>7. Chris: Can a person be dangerous? Sure. So can a machine. The
<br>
difference between man and machine is that we can (for now) control all
<br>
the inputs into a machine. We can control reality for them and test them
<br>
and certify their behavior in given situations. We can say much more
<br>
about the potential behavior of a machine because we can test it. And
<br>
I'm quite sure that we will do a lot of behavioral certification before
<br>
we let any artificially conscious entity loose. 
<br>
<p>Deeper in the future, things start to get funny when you factor out the
<br>
basic biological limitations of people, such as life span and memory
<br>
capacity that are not limitations for machines. Eventually we will enter
<br>
into resource conflicts with immortal machines. We will lose and
<br>
rightfully so. Evolution will say &quot;Next&quot; and that will be that.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0435.html">Damien Sullivan: "Re: SEMI SPOILER - Re: AI - My Favorite Moments"</a>
<li><strong>Previous message:</strong> <a href="0433.html">Eliezer S. Yudkowsky: "Re: Debunk All Religiosity Equally (D.A.R.E.) ---&gt; inloading"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0450.html">Eliezer S. Yudkowsky: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0450.html">Eliezer S. Yudkowsky: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0472.html">hal@finney.org: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0642.html">Miriam English: "Re: Artificial Reality"</a>
<li><strong>Maybe reply:</strong> <a href="0657.html">Zero Powers: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#434">[ date ]</a>
<a href="index.html#434">[ thread ]</a>
<a href="subject.html#434">[ subject ]</a>
<a href="author.html#434">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:42 MDT</em>
</em>
</small>
</body>
</html>
