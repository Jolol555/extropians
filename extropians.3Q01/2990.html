<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Stem Cell Debate --Banned in the USA ---&gt; li</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Stem Cell Debate --Banned in the USA ---&gt; libertarian societiesas  unicorn (">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Stem Cell Debate --Banned in the USA ---&gt; libertarian societiesas  unicorn (</h1>
<!-- received="Fri Aug  3 16:08:43 2001" -->
<!-- isoreceived="20010803220843" -->
<!-- sent="Fri, 03 Aug 2001 18:10:36 -0400" -->
<!-- isosent="20010803221036" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Stem Cell Debate --Banned in the USA ---&gt; libertarian societiesas  unicorn (" -->
<!-- id="3B6B215C.5FEC09F0@posthuman.com" -->
<!-- inreplyto="Pine.LNX.4.10.10108022238180.3992-100000@server.aeiveos.com" -->
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Stem%20Cell%20Debate%20--Banned%20in%20the%20USA%20---&gt;%20libertarian%20societiesas%20%20unicorn%20(&In-Reply-To=&lt;3B6B215C.5FEC09F0@posthuman.com&gt;"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 03 2001 - 16:10:36 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2991.html">Al Villalobos: "RE: Fred Reed - The Dave Barry of Racists"</a>
<li><strong>Previous message:</strong> <a href="2989.html">Michael M. Butler: "Re: Chem: Silicon Explosives now"</a>
<li><strong>In reply to:</strong> <a href="2952.html">Robert J. Bradbury: "RE: Stem Cell Debate --Banned in the USA ---&gt; libertarian societies as unicorn ("</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3339.html">Samantha Atkins: "Re: Stem Cell Debate --Banned in the USA ---&gt; libertarian societiesas  unicorn ("</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2990">[ date ]</a>
<a href="index.html#2990">[ thread ]</a>
<a href="subject.html#2990">[ subject ]</a>
<a href="author.html#2990">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Brian wrote:
</em><br>
<em>&gt; &gt; At some point the matter (as in atoms) must fall under someone's
</em><br>
<em>&gt; &gt; control, and personally I don't relish the idea of having to
</em><br>
<em>&gt; &gt; constantly protect myself from everyone else who can't be trusted
</em><br>
<em>&gt; &gt; with nanotech and AI.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This statement contains some assumptions that mis-represent
</em><br>
<em>&gt; the problem.  You *are* already at war with bio-nanotech
</em><br>
<em>&gt; entities who have no interest in your personal survival.
</em><br>
<em>&gt; Your immune system is generally effective in defending
</em><br>
<em>&gt; against such entities without the requirement for constant
</em><br>
<p>And how praytell will I come up with an effective immune system
<br>
against hostile nanotech and/or SIs? I'm sorry Robert, but you
<br>
are the one misrepresenting the problem here :-)
<br>
<p><em>&gt; intervention.  Further, you link nanotech and AI in a way
</em><br>
<em>&gt; that suggests a threat that may be invalid.  You can have
</em><br>
<em>&gt; nanotech and you can have AI but for either of them to be
</em><br>
<em>&gt; overwhelmingly threatening their heat/surface area dissipation
</em><br>
<em>&gt; has to have a very recognizable signature.  You have to make
</em><br>
<em>&gt; a strong assertion that such organizations of matter can
</em><br>
<em>&gt; hide themselves from detection or elimination.  If you cannot
</em><br>
<em>&gt; make that case then it does not matter whether or not such
</em><br>
<em>&gt; organizations of matter can be &quot;trusted&quot;.
</em><br>
<p>This doesn't make much sense to me either, but perhaps you can
<br>
explain how I am going to have some nanotech to defend against
<br>
the (most likely) superior nanotech of a SI. Am I forced to
<br>
engage in an intelligence war with it, trying to stay as smart
<br>
just so I can keep my defenses worthy? And what about the other
<br>
people whose defenses fail?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; All it takes is one Blight to wipe us out. That kind of threat
</em><br>
<em>&gt; &gt; does not go away as humans progress to transhumanity, rather it
</em><br>
<em>&gt; &gt; increases in likelihood. What is the stable state if not Sysop
</em><br>
<em>&gt; &gt; or total death? There may be some other possibilities, can
</em><br>
<em>&gt; &gt; you name some?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Well, evolution in an upward spiral committed to extropian
</em><br>
<em>&gt; principles seems like a stable state.   Note that this is
</em><br>
<p>Sure if every single person in the solar system agrees with you, that
<br>
might work. Personally I am not happy to be forced (coerced) by the
<br>
kind of environment you are describing into constantly evolving my
<br>
intelligence and defenses just to keep from being killed.
<br>
<p><em>&gt; an unstable state for humanity as it likely concludes that
</em><br>
<em>&gt; the instantiation of organized matter as &quot;humans&quot; is an
</em><br>
<em>&gt; inefficient use of the locally available resources and must
</em><br>
<em>&gt; be concluded.
</em><br>
<p>And your answer for the Amish is? They get eaten by whoever lacks your
<br>
ethical standards?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; So, the question would be, can one (as an extropian)
</em><br>
<em>&gt; provide a coherent defense of the use of the material
</em><br>
<em>&gt; and energy required for you to remain &quot;intact&quot; in the
</em><br>
<em>&gt; light of more efficient reallocation of the resources
</em><br>
<em>&gt; you are consuming?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is the moral problem -- Are you committed to the evolution
</em><br>
<em>&gt; of matter to its highest extropic state or are you committed
</em><br>
<em>&gt; to the preservation of oneself in a form that seems comfortable
</em><br>
<em>&gt; to you?
</em><br>
<p>My personal committments do not matter to another person, nor should
<br>
they. I will not be a willing party to a future where everyone is
<br>
coerced into upgrading. It should ideally be left to each person's
<br>
own choice.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Do the needs of the many (the potential application of the atoms
</em><br>
<em>&gt; at our disposal) outweigh the needs of the one (your personal survival)?
</em><br>
<em>&gt; 
</em><br>
<p>In the Universe I want to live in, the needs of each individual will
<br>
be protected. If this makes it impossible for you to use the Earth's
<br>
atoms for your pet science project, too bad.
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.singinst.org/">http://www.singinst.org/</a>
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2991.html">Al Villalobos: "RE: Fred Reed - The Dave Barry of Racists"</a>
<li><strong>Previous message:</strong> <a href="2989.html">Michael M. Butler: "Re: Chem: Silicon Explosives now"</a>
<li><strong>In reply to:</strong> <a href="2952.html">Robert J. Bradbury: "RE: Stem Cell Debate --Banned in the USA ---&gt; libertarian societies as unicorn ("</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3339.html">Samantha Atkins: "Re: Stem Cell Debate --Banned in the USA ---&gt; libertarian societiesas  unicorn ("</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2990">[ date ]</a>
<a href="index.html#2990">[ thread ]</a>
<a href="subject.html#2990">[ subject ]</a>
<a href="author.html#2990">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:01 MDT</em>
</em>
</small>
</body>
</html>
