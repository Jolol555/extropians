<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Artificial Reality</title>
<meta name="Author" content="Mike Lorrey (mlorrey@datamann.com)">
<meta name="Subject" content="Re: Artificial Reality">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Artificial Reality</h1>
<!-- received="Sun Jul  8 15:42:03 2001" -->
<!-- isoreceived="20010708214203" -->
<!-- sent="Sun, 08 Jul 2001 17:45:27 -0400" -->
<!-- isosent="20010708214527" -->
<!-- name="Mike Lorrey" -->
<!-- email="mlorrey@datamann.com" -->
<!-- subject="Re: Artificial Reality" -->
<!-- id="3B48D477.972B8378@datamann.com" -->
<!-- inreplyto="3B476CD4.CCC147D@eso.org" -->
<strong>From:</strong> Mike Lorrey (<a href="mailto:mlorrey@datamann.com?Subject=Re:%20Artificial%20Reality&In-Reply-To=&lt;3B48D477.972B8378@datamann.com&gt;"><em>mlorrey@datamann.com</em></a>)<br>
<strong>Date:</strong> Sun Jul 08 2001 - 15:45:27 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0518.html">Mike Lorrey: "Re: xenonauts"</a>
<li><strong>Previous message:</strong> <a href="0516.html">Mike Lorrey: "Re: Any cyborgs out there?"</a>
<li><strong>In reply to:</strong> <a href="0460.html">Christopher McKinstry: "Re: Artificial Reality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0523.html">J. R. Molloy: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0523.html">J. R. Molloy: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0548.html">Miriam English: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#517">[ date ]</a>
<a href="index.html#517">[ thread ]</a>
<a href="subject.html#517">[ subject ]</a>
<a href="author.html#517">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Christopher McKinstry wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Regardless of whether you agree, I would ask that if you in the future
</em><br>
<em>&gt; &gt; happen to discuss the possibility of evolutionary, war-to-the-death
</em><br>
<em>&gt; &gt; competition between humans and AIs, you also at least mention the
</em><br>
<em>&gt; &gt; possibility of Friendly AI, even if it consists of the phrase &quot;There have
</em><br>
<em>&gt; &gt; been proposals for Friendly AI, but I think they're unworkable.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Just one more point before I go off to read your 'Friendly AI'... if
</em><br>
<em>&gt; Kurzweil is right, and in the future I can scan my personality into a
</em><br>
<em>&gt; computer, the event will create an instant conflict simply because the
</em><br>
<em>&gt; copied version of myself will fight to the death not to be turned off by
</em><br>
<em>&gt; the original version. 
</em><br>
<p>This is assuming you have the bad taste of booting the scan and then
<br>
wish to end its existence. It would rightly consider you an infanticidal
<br>
maniac and defend itself against your predations. 
<br>
<p>Do not assume that a scan will automatically be concious.
<br>
<p><em>&gt; I would be just as friendly as I am now to my
</em><br>
<em>&gt; fellow 'virtual' humans (as long as I could verify they were virtual),
</em><br>
<em>&gt; but I would see 'real' humans as potentially very dangerous to my
</em><br>
<em>&gt; continued consciousness. No matter how friendly I am, I would have a
</em><br>
<em>&gt; very strong objection to my reality being externally controlled. Bad
</em><br>
<em>&gt; things will happen unless we can develop some form of protocol of trust,
</em><br>
<em>&gt; which I am not confident we can.
</em><br>
<p>We are all under the mortal power of others our entire lives, from our
<br>
parents, neighbors, their dogs, and unknown strangers and foreign
<br>
governments and terrorists. A scanned mind would, with its much more
<br>
logical circuitry of its new substrate, be able to more accurately
<br>
calculate the risks and assign trust ratings based on observed behavior,
<br>
which are generally far less and far higher, respectively, when analysed
<br>
rationally. Automatic assumption of Other as Enemy is a sign of a
<br>
diseased mind, which if not healed by the process of upload, would
<br>
prevent upload due to system conflicts.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0518.html">Mike Lorrey: "Re: xenonauts"</a>
<li><strong>Previous message:</strong> <a href="0516.html">Mike Lorrey: "Re: Any cyborgs out there?"</a>
<li><strong>In reply to:</strong> <a href="0460.html">Christopher McKinstry: "Re: Artificial Reality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0523.html">J. R. Molloy: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0523.html">J. R. Molloy: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0548.html">Miriam English: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#517">[ date ]</a>
<a href="index.html#517">[ thread ]</a>
<a href="subject.html#517">[ subject ]</a>
<a href="author.html#517">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:42 MDT</em>
</em>
</small>
</body>
</html>
