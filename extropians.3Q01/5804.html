<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<title>extropians: Re: Hawking on AI dominance</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Hawking on AI dominance">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Hawking on AI dominance</h1>
<!-- received="Wed Sep  5 10:39:22 2001" -->
<!-- isoreceived="20010905163922" -->
<!-- sent="Wed, 5 Sep 2001 09:39:12 -0700" -->
<!-- isosent="20010905163912" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Hawking on AI dominance" -->
<!-- id="044901c13629$4d27d660$6c5d2a42@jrmolloy" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="F201G6onZJ1X6ewxqea000074a9@hotmail.com" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Hawking%20on%20AI%20dominance&In-Reply-To=&lt;044901c13629$4d27d660$6c5d2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Sep 05 2001 - 10:39:12 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5805.html">Charles Hixson: "Re: Questions about the Singularity"</a>
<li><strong>Previous message:</strong> <a href="5803.html">J. R. Molloy: "Re: sphexish behavior in ants"</a>
<li><strong>In reply to:</strong> <a href="5783.html">Zero Powers: "Re: Hawking on AI dominance"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5806.html">J. R. Molloy: "ECON: What Complexity Theory Can Teach Business"</a>
<li><strong>Reply:</strong> <a href="5806.html">J. R. Molloy: "ECON: What Complexity Theory Can Teach Business"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5804">[ date ]</a>
<a href="index.html#5804">[ thread ]</a>
<a href="subject.html#5804">[ subject ]</a>
<a href="author.html#5804">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
From: &quot;Zero Powers&quot; &lt;<a href="mailto:zero_powers@hotmail.com?Subject=Re:%20Hawking%20on%20AI%20dominance&In-Reply-To=&lt;044901c13629$4d27d660$6c5d2a42@jrmolloy&gt;">zero_powers@hotmail.com</a>&gt;
<br>
<em>&gt; it seems to me, that what he is proposing is some sort of symbiosis
</em><br>
<em>&gt; between the biological and artificial intelligences.
</em><br>
<p>&lt;&lt;As far as Hawking's second recommendation is concerned, namely direct
<br>
connection between the brain and computers, I agree that this is both
<br>
reasonable, desirable and inevitable. It's been my recommendation for years.
<br>
I describe a number of scenarios to accomplish this in my most recent book,
<br>
The Age of Spiritual Machines, and in the book précis &quot;The Singularity is
<br>
Near&quot;&gt;&gt;
<br>
--Raymond Kurzweil
<br>
[Refer to message Sent: Tuesday, September 04, 2001 3:26 PM
<br>
Subject: RE: Hawking on AI dominance]
<br>
<p><em>&gt; At that point we pathetic meat-puppets had
</em><br>
<em>&gt; better cross over and abandon the bio-brain, or get seriously left behind.
</em><br>
<p>&lt;&lt;I recommend establishing the connection with noninvasive nanobots that
<br>
communicate wirelessly with our neurons. As I discuss in the précis, the
<br>
feasibility of communication between the electronic world and that of
<br>
biological neurons has already been demonstrated. There are a number of
<br>
advantages to extending human intelligence through the nanobot approach.
<br>
They can be introduced noninvasively (i.e., without surgery). The
<br>
connections will not be limited to one or a small number of positions in the
<br>
brain. Rather, the nanobots can communicate with neurons (and with each
<br>
other) in a highly distributed manner. They would be programmable, would all
<br>
be on a wireless local area network, and would be on the web.
<br>
<p>&lt;&lt;They would provide many new capabilities, such as full-immersion virtual
<br>
reality involving all the senses. Most importantly, they will provide many
<br>
trillions of new interneuronal connections as well as intimate links to
<br>
nonbiological forms of cognition. Ultimately, our minds won't need to stay
<br>
so small, limited as they are today to a mere hundred trillion connections
<br>
(extremely slow ones at that).
<br>
<p>&lt;&lt;However, even this will only keep pace with the ongoing exponential growth
<br>
of AI for a couple of additional decades (to around mid-twenty-first
<br>
century). As Hans Moravec has pointed out, ultimately a hybrid
<br>
biological-nonbiological brain will ultimately be 99.999...% nonbiological,
<br>
so the biological portion becomes pretty trivial.
<br>
<p>&lt;&lt;We should keep in mind, though, that all of this exponentially advancing
<br>
intelligence is derivative of biological human intelligence, derived
<br>
ultimately from the thinking reflected in our technology designs, as well as
<br>
the design of our own thinking. So it's the human-technology civilization
<br>
taking the next step in evolution. I don't agree with Hawking that &quot;strong
<br>
AI&quot; is a fate to be avoided. I do believe that we have the ability to shape
<br>
this destiny to reflect our human values, if only we could achieve a
<br>
consensus on what those are.&gt;&gt;
<br>
--Raymond Kurzweil
<br>
[Refer to message Sent: Tuesday, September 04, 2001 3:26 PM
<br>
Subject: RE: Hawking on AI dominance]
<br>
<p>----------------------------------
<br>
<p>From: &quot;James Rogers&quot; &lt;<a href="mailto:jamesr@best.com?Subject=Re:%20Hawking%20on%20AI%20dominance&In-Reply-To=&lt;044901c13629$4d27d660$6c5d2a42@jrmolloy&gt;">jamesr@best.com</a>&gt;
<br>
<em>&gt; I don't suppose you remember the Tandem Non-Stop systems and similar devices
</em><br>
<em>&gt; from well over a decade ago.  Extreme fault tolerance.  On some of those
</em><br>
<em>&gt; systems, essentially every transient action was in persistent memory.  Of
</em><br>
<em>&gt; course, the occasional crash is usually much, much cheaper than buying an
</em><br>
<em>&gt; unstoppable computer for most businesses/people.
</em><br>
<p>Fault tolerance may be an important component of &quot;strong AI.&quot; In addition,
<br>
fault tolerant systems make it possible for AI to supercede the pitfalls
<br>
associated with the problem of confabulation which plagues human cognition
<br>
(too often resulting in cockamamie stories about UFO abductions,
<br>
synchronicity, spiritualism, etc.). Unfortunately, fault tolerance cannot
<br>
restore previous clarity to machines infected with software viruses. The human
<br>
correlate to such viruses is &quot;values&quot; which are infectious memes with no known
<br>
cure.
<br>
<p>--J. R.
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5805.html">Charles Hixson: "Re: Questions about the Singularity"</a>
<li><strong>Previous message:</strong> <a href="5803.html">J. R. Molloy: "Re: sphexish behavior in ants"</a>
<li><strong>In reply to:</strong> <a href="5783.html">Zero Powers: "Re: Hawking on AI dominance"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5806.html">J. R. Molloy: "ECON: What Complexity Theory Can Teach Business"</a>
<li><strong>Reply:</strong> <a href="5806.html">J. R. Molloy: "ECON: What Complexity Theory Can Teach Business"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5804">[ date ]</a>
<a href="index.html#5804">[ thread ]</a>
<a href="subject.html#5804">[ subject ]</a>
<a href="author.html#5804">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:25 MDT</em>
</em>
</small>
</body>
</html>
