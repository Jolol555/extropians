<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Big Bang is Bunk</title>
<meta name="Author" content="Stirling Westrup (sti@cam.org)">
<meta name="Subject" content="Re: Big Bang is Bunk">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Big Bang is Bunk</h1>
<!-- received="Sun Jul 29 09:23:54 2001" -->
<!-- isoreceived="20010729152354" -->
<!-- sent="Sun, 29 Jul 2001 11:27:57 EST" -->
<!-- isosent="20010729162757" -->
<!-- name="Stirling Westrup" -->
<!-- email="sti@cam.org" -->
<!-- subject="Re: Big Bang is Bunk" -->
<!-- id="3B63F33D.17959.3B662F7@localhost" -->
<!-- inreplyto="3B63887F.64FAE53E@pobox.com" -->
<strong>From:</strong> Stirling Westrup (<a href="mailto:sti@cam.org?Subject=Re:%20Big%20Bang%20is%20Bunk&In-Reply-To=&lt;3B63F33D.17959.3B662F7@localhost&gt;"><em>sti@cam.org</em></a>)<br>
<strong>Date:</strong> Sun Jul 29 2001 - 10:27:57 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2519.html">Mike Lorrey: "Re: regarding the YINYANG post on extropians"</a>
<li><strong>Previous message:</strong> <a href="2517.html">Russell Blackford: "Re: Olga Lee and the Lurkers"</a>
<li><strong>In reply to:</strong> <a href="2496.html">Eliezer S. Yudkowsky: "Re: Big Bang is Bunk"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2528.html">Tiberius Gracchus: "CryoProtect: surveillance and alert system for cryonics"</a>
<li><strong>Reply:</strong> <a href="2528.html">Tiberius Gracchus: "CryoProtect: surveillance and alert system for cryonics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2518">[ date ]</a>
<a href="index.html#2518">[ thread ]</a>
<a href="subject.html#2518">[ subject ]</a>
<a href="author.html#2518">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eliezer S. Yudkowsky wrote:
<br>
<p><em>&gt; The Singularity is defined to occur as soon as any greater-than-human
</em><br>
<em>&gt; intelligence comes into existence - big or small.  It has to be genuine,
</em><br>
<em>&gt; hardware transhumanity, not just humans put together in interesting shapes,
</em><br>
<em>&gt; but that's it.
</em><br>
<p>By who's definition?  I can agree that the singularity will have occurred 
<br>
when a sentience is formed that is capable of making substantial 
<br>
improvements to its own intelligence in such a way as to bootstrap itself 
<br>
into a Power (and I may be willing to accept even broader definitions). 
<br>
That definition does not preclude any particular cycle time, nor does it 
<br>
rule out 'humans put together in interesting shapes'.  An off-the-top-of-
<br>
the-head list of apparent routes to the singularity are:
<br>
<p>1) produce a self-improving seed-ai with sufficient hardware resources, or 
<br>
the ability to design and fabricate further resources.
<br>
<p>2) Join some critical number of humans together into a super-intelligent 
<br>
hive mind that can redesign humanity via direct genetic modification 
<br>
(possibly via powerful retrovirii so as to reduce cycle times.)
<br>
<p>3) Create a superintelligent cyborgs by melding computers and neural 
<br>
tissue, and allowing them to design new parts and surgical techniques for 
<br>
themselves.
<br>
<p>4) Understand human intelligence enough so as to either upload or simulate 
<br>
large numbers of brains working together on the problem of improving 
<br>
humanity.
<br>
<p>5) A breakthrough in the understanding of human intelligence such that we 
<br>
can program nanobots to re-wire brains into more intelligent versions of 
<br>
themselves, and allow further changes to be dictated by the rewired brains 
<br>
themselves...
<br>
<p>And of course there are any number of hybrid variations.  Frankly, as far 
<br>
as I can see, any truely self-sustaining positive-feedback loop that acts 
<br>
upon the knowledge or intelligence of humans is going to lead to a 
<br>
singularity.
<br>
<p>Of course, some routes may be more preferable that others...
<br>
<p><p><pre>
-- 
 Stirling Westrup  |  Use of the Internet by this poster
 <a href="mailto:sti@cam.org?Subject=Re:%20Big%20Bang%20is%20Bunk&In-Reply-To=&lt;3B63F33D.17959.3B662F7@localhost&gt;">sti@cam.org</a>       |  is not to be construed as a tacit
                   |  endorsement of Western Technological
                   |  Civilization or its appurtenances.
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2519.html">Mike Lorrey: "Re: regarding the YINYANG post on extropians"</a>
<li><strong>Previous message:</strong> <a href="2517.html">Russell Blackford: "Re: Olga Lee and the Lurkers"</a>
<li><strong>In reply to:</strong> <a href="2496.html">Eliezer S. Yudkowsky: "Re: Big Bang is Bunk"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2528.html">Tiberius Gracchus: "CryoProtect: surveillance and alert system for cryonics"</a>
<li><strong>Reply:</strong> <a href="2528.html">Tiberius Gracchus: "CryoProtect: surveillance and alert system for cryonics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2518">[ date ]</a>
<a href="index.html#2518">[ thread ]</a>
<a href="subject.html#2518">[ subject ]</a>
<a href="author.html#2518">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:58 MDT</em>
</em>
</small>
</body>
</html>
