<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: ROBOT: Swiss Hysteria</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="ROBOT: Swiss Hysteria">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>ROBOT: Swiss Hysteria</h1>
<!-- received="Wed Aug 29 00:18:34 2001" -->
<!-- isoreceived="20010829061834" -->
<!-- sent="Tue, 28 Aug 2001 23:18:18 -0700" -->
<!-- isosent="20010829061818" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="ROBOT: Swiss Hysteria" -->
<!-- id="00a701c13052$69302920$255c2a42@jrmolloy" -->
<!-- inreplyto="3.0.6.32.20010829154256.007eb380@ariel.its.unimelb.edu.au" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20ROBOT:%20Swiss%20Hysteria&In-Reply-To=&lt;00a701c13052$69302920$255c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 29 2001 - 00:18:18 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5265.html">Lee Corbin: "RE: Mexican Immigration"</a>
<li><strong>Previous message:</strong> <a href="5263.html">Lee Corbin: "RE: Diversity (was:  Morality is Relative)"</a>
<li><strong>In reply to:</strong> <a href="5261.html">Damien Broderick: "Re: Media ignores Ballistic [Missile] Defense."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5284.html">Eugene Leitl: "Re: Media ignores Ballistic [Missile] Defense."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5264">[ date ]</a>
<a href="index.html#5264">[ thread ]</a>
<a href="subject.html#5264">[ subject ]</a>
<a href="author.html#5264">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Six more years to go, folks. Then robots are going to kill us all.
<br>
Oh, well.
<br>
--J. R.
<br>
<p>Swiss scientists warn of robot Armageddon
<br>
&nbsp;&nbsp;<a href="http://www.cnn.com/TECH/science/9802/18/swiss.robot/">http://www.cnn.com/TECH/science/9802/18/swiss.robot/</a>
<br>
The robot that learns by itself
<br>
<em>&gt;From Correspondent Patricia Kelly
</em><br>
<p>DAVOS, Switzerland (CNN) -- Could artificially intelligent robots signal the
<br>
end of the human race? Some Swiss scientists say such a threat may be closer
<br>
than we think.
<br>
<p>Their doom and gloom talk was prompted by one of their own creations: an
<br>
autonomous robot that learns from its environment.
<br>
<p>Within a few minutes, the microprocessor based robot can learn not to bump
<br>
into a barrier. No one programs the robot's actions, and its creator isn't
<br>
exactly sure how it will behave in any given situation.
<br>
<p>Within 10 years, they predict that similar but more advanced machines,
<br>
equipped with artificial intelligence, will be as clever as humans. Soon
<br>
after, they say, the man-made objects could become more intelligent than their
<br>
creators -- and capable of taking over.
<br>
<p>&quot;Next century's global politics will be dominated by the question of should
<br>
humanity build ultra-intelligent machines or not,&quot; said Hugo de Garis, who's
<br>
already created an artificially intelligent machine.
<br>
<p><p>&quot;In fact, I'm going so far as saying there will be major warfare between these
<br>
two major groups, one saying building machines is the destiny of the human
<br>
species, something people should do and the other group saying it's too
<br>
dangerous,&quot; de Garis said.
<br>
<p>Kevin Warwick, a professor of cybernetics -- the science of comparing
<br>
biological and computerized brains -- agrees that thinking robots could be
<br>
dangerous.
<br>
<p>&quot;I can't see any reason why machines will not be more intelligent than humans
<br>
in the next 20 to 30 years and that is an enormous threat,&quot; Warwick said.
<br>
<p>De Garis speculates that the robots might soon tire of their human creators.
<br>
<p>&quot;We could never be sure these artellects, as we call them -- artificial
<br>
intellects -- wouldn't decide that humanity is a pest and try to exterminate
<br>
us, and they'd be so intelligent they could do it easily,&quot; de Garis said.
<br>
<p>Warwick has even gloomier premonitions.
<br>
<p>&quot;We're talking in the future the end of the human race as we know it,&quot; Warwick
<br>
said.
<br>
<p>The day when robots no longer do what we want them to may already be here.
<br>
<p>De Garis' machine quickly decided it was camera shy and refused to be filmed
<br>
by a CNN crew.
<br>
<p>Shy or not, only time will tell if these artificially intelligent machines
<br>
will evolve enough to bring about our demise.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5265.html">Lee Corbin: "RE: Mexican Immigration"</a>
<li><strong>Previous message:</strong> <a href="5263.html">Lee Corbin: "RE: Diversity (was:  Morality is Relative)"</a>
<li><strong>In reply to:</strong> <a href="5261.html">Damien Broderick: "Re: Media ignores Ballistic [Missile] Defense."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5284.html">Eugene Leitl: "Re: Media ignores Ballistic [Missile] Defense."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5264">[ date ]</a>
<a href="index.html#5264">[ thread ]</a>
<a href="subject.html#5264">[ subject ]</a>
<a href="author.html#5264">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:21 MDT</em>
</em>
</small>
</body>
</html>
