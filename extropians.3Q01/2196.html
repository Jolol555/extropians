<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Many Worlds</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Many Worlds">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Many Worlds</h1>
<!-- received="Wed Jul 25 17:21:57 2001" -->
<!-- isoreceived="20010725232157" -->
<!-- sent="Wed, 25 Jul 2001 16:21:44 -0700" -->
<!-- isosent="20010725232144" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Many Worlds" -->
<!-- id="05c301c11560$93b8f3a0$ad5c2a42@jrmolloy" -->
<!-- inreplyto="CPEJKGJHDIBPPGBDFCEBAEMMCAAA.seankenny@blueyonder.co.uk" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Many%20Worlds&In-Reply-To=&lt;05c301c11560$93b8f3a0$ad5c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Jul 25 2001 - 17:21:44 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2197.html">J. R. Molloy: "Re: META: Attachments"</a>
<li><strong>Previous message:</strong> <a href="2195.html">CurtAdams@aol.com: "Re: Engineering Yog-Sothoth for Fun and Profit"</a>
<li><strong>In reply to:</strong> <a href="2189.html">Sean Kenny: "RE: Many Worlds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2207.html">Lee Corbin: "RE: Many Worlds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2196">[ date ]</a>
<a href="index.html#2196">[ thread ]</a>
<a href="subject.html#2196">[ subject ]</a>
<a href="author.html#2196">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
From: &quot;Sean Kenny&quot; &lt;<a href="mailto:seankenny@blueyonder.co.uk?Subject=Re:%20Many%20Worlds&In-Reply-To=&lt;05c301c11560$93b8f3a0$ad5c2a42@jrmolloy&gt;">seankenny@blueyonder.co.uk</a>&gt;
<br>
<em>&gt; I'm struggling through Deutsch's book &quot;The Fabric of reality&quot; at the moment,
</em><br>
<em>&gt; about half way through after several months (and it's only a short book!),
</em><br>
<em>&gt; but I was talking to a friend the other day about some of the ideas and it,
</em><br>
<em>&gt; and he said he struggled with being able to accept that consciousness would
</em><br>
<em>&gt; be able to survive millions of different versions of itself being peeled off
</em><br>
<em>&gt; in different directions every second. I can't say I'd thought of it before
</em><br>
<em>&gt; but I expect some version of myself had a decent answer for him.
</em><br>
<p>Yes, let's consider that you've made the right decision in struggling through
<br>
Deutsch's book, or at least the version of the book that found it's way into
<br>
the version of your hands at the time of that version of you. The version of
<br>
your friend with whom you talked on the version of that day (in the version of
<br>
your memory that you recall) may have progressed to more accurate versions of
<br>
modeled reality if the version of you and he had thought in other categories
<br>
than &quot;consciousness,&quot; which, like phlogiston, has been debunked in this
<br>
consensus version of existence. ©¿©¬
<br>
<p>Please excuse that version of inquiry, but Many Worlds do seem to invite it,
<br>
don't they?
<br>
<p>Does Deutsch mention &quot;consciousness&quot; in &quot;The Fabric of reality&quot;?
<br>
<p>Here's an article which may help to explain why I don't believe in
<br>
&quot;consciousness.&quot;
<br>
(This was posted to the list by Max More several months ago.)
<br>
<p>Note this quotation in particular:
<br>
&lt;&lt;Dr. Terrence Sejnowski, director of the Computational Neurobiology
<br>
Laboratory at the Salk Institute, agrees that the properties of the brain
<br>
can likely be duplicated in artificial devices, although he regards
<br>
questions of consciousness with a decidedly unphilosophical bent of mind.
<br>
[Something else I don't believe in. --J. R. ]
<br>
&quot;My own suspicion is that words like 'consciousness' and 'qualia' will go
<br>
the way of words like 'phlogistem' and 'vitalism.'&quot;&gt;&gt;
<br>
<p>What Neuroscientists and Computer Scientists Can Learn from Each Other
<br>
By Karl A. Thiel
<br>
<a href="http://www.doubletwist.com/news/columns/article.jhtml?section=weekly01&nam">http://www.doubletwist.com/news/columns/article.jhtml?section=weekly01&nam</a>
<br>
e=weekly0130
<br>
<p>Metaphors are powerful things. Ever since the first digital computers were
<br>
created in the 1950s, we have had a seemingly irresistible urge to
<br>
anthropomorphize them, likening computers to artificial brains,
<br>
anticipating and sometimes even fearing the powers of intention and
<br>
cognition they might someday embody.
<br>
<p>And why not? Computers, like us, seem to understand language of a sort.
<br>
They take input from various sources, process it and offer
<br>
conclusions--much like we seem to do. With the right instruction, they can
<br>
be trained to do new things, just as we can. They can do all these things
<br>
and more, and do it much more quickly and powerfully than we can, making
<br>
computer intelligence a humbling prospect. As computer pioneer Marvin
<br>
Minsky once quipped, we will &quot;be lucky if they are willing to keep us
<br>
around as household pets.&quot;
<br>
<p>Parallels between computers and brains have not simply been offered up as
<br>
a piece of poetic comparison. It is meant is some quarters quite
<br>
literally: The brain is a computer, and the mind is its program. Many
<br>
efforts to create artificial intelligence have focused on determining how
<br>
to replicate in computers what some believe happens in our brains: We
<br>
receive discrete bits of information about the world from our senses,
<br>
decode them in our brain, and assemble them into coherent pictures of
<br>
reality. By apprehending the world and applying an inherent sense of
<br>
logic, reasoning ensues, and with it an ability to solve problems--even
<br>
unfamiliar ones in novel contexts.
<br>
<p>It's a terrible metaphor, says Dr. Gerald Edelman, and a damaging one.
<br>
Edelman, who won the 1972 Nobel Prize in medicine for his discoveries
<br>
about the structure of antibodies, has spent the last two decades studying
<br>
the brain. He says the notion that the brain is a kind of supercomputer
<br>
hasn't just misled computer scientists pursuing artificial intelligence;
<br>
it has distracted us from a better understanding of how the brain really
<br>
works.
<br>
<p>And yet, computers really do seem to be getting smarter. Even as advances
<br>
in neuroscience shed light on the &quot;black box&quot; of the brain, new approaches
<br>
to computer programming are achieving results that seem more and more like
<br>
intelligence. In fact, the two disciplines have a great deal to teach each
<br>
other. Some of the most fascinating parallels may be found right at the
<br>
Neuroscience Institute in La Jolla, CA, which Edelman founded and directs.
<br>
<p>The Theory of Neuronal Group Selection
<br>
<p>Edelman has set out to &quot;complete the project of Darwin&quot;--that is, to show
<br>
how natural selection could lead to the emergence of consciousness and the
<br>
mind of humankind. It was a notion Darwin struggled with in his later
<br>
years, believing his theory could explain all aspects of the origin of
<br>
species, even though his colleague Alfred Russel Wallace rejected the
<br>
notion.
<br>
<p>&quot;You just can't get around Darwin,&quot; says Edelman. &quot;Darwin's theory is the
<br>
central theory of biology. Anything that says it's going to emulate
<br>
biology by ignoring that and doing it instructively instead of
<br>
selectionally is barking up the wrong tree.&quot;
<br>
<p>Most of us are used to thinking of natural selection as a slow process
<br>
that occurs over generations. But Edelman's own Nobel Prize-winning work
<br>
on the human immune system proves that the creation of diversity and the
<br>
process of natural selection can lead to powerful change on a scale of
<br>
seconds rather than decades. So why not the brain?
<br>
<p>Computer scientists daunted by the idea of the brain as a &quot;Darwin machine&quot;
<br>
will be relieved to learn that the tenets of Edelmans &quot;Theory of Neuronal
<br>
Group Selection&quot; (TNGS) are few in number. In fact, he says, the theater
<br>
in our mind is a result of just three essential processes: Developmental
<br>
selection, experiential selection, and reentry.
<br>
<p>The broad principles may be few but there's a lot of wiring required.
<br>
There are only two major cell types in the brain--neurons and glial cells,
<br>
with the signaling activity coming from neurons, of which there are over
<br>
200 subtypes. In the course of development, the brain forms an absolutely
<br>
astounding number of neurons--over 100 billion; about 10 billion in the
<br>
cerebral cortex alone, which reach out to form over a million billion
<br>
connections with each other. This circuitry represents an absolutely
<br>
unfathomable number of potential circuits.a number with millions of zeroes
<br>
after it.
<br>
<p>While the development of the gross morphology of the brain is dictated by
<br>
gene expression, the complexity of interconnections among neurons goes
<br>
beyond the genetic code. A dense web of neural connections is formed
<br>
stochastically--not at random, perhaps, but certainly unpredictably. No
<br>
two people--not even identical twins--have identical brain circuitry.
<br>
<p>For natural selection to take place, it must occur in an environment of
<br>
sufficient variety that alternatives can be chosen--which the complexity
<br>
of our brains certainly provides. The formation of myriad connections
<br>
during development is important in this regard, because during the course
<br>
of your lifetime, you will define new neural pathways, using experience to
<br>
strengthen some routes and weaken others--even as neurons die and others
<br>
are formed.
<br>
<p>Edleman first laid out his TNGS in the 1987 book Neural Darwinism--at a
<br>
time when some of the scientific support for the ideas within was
<br>
equivocal. Until relatively recently, for example, it was believed that no
<br>
new neurons could form during ones lifetime, but neurogenesis in the adult
<br>
human brain was proven by a team of researchers in a 1998 study published
<br>
in Nature Medicine. The notion that existing pathways can be strengthened
<br>
and weakened as a result of experience, and that this is related to
<br>
learning, was a subject of the 2000 Nobel Prize in medicine, awarded to
<br>
Dr. Eric Kandel of Columbia University (New York, NY).
<br>
<p>Do You, Uh, Google?
<br>
<p>To understand how this process of experiential selection works, consider
<br>
the search engine Google.com. Before Google, Internet search engines
<br>
generally worked under one of two methods. The first involved &quot;crawler&quot;
<br>
programs that search out keywords across the worldwide web, ranking
<br>
pages--any pages--in order of the best keyword match. The results are
<br>
familiar to many of us: enter a query about &quot;sexual reproduction,&quot; and
<br>
you'll likely get a pornography site. Enter a query about &quot;recombinant
<br>
DNA,&quot; and you still might get a pornography site.
<br>
<p>With the Tower of Babel that the Internet has become, others thought a
<br>
little human oversight was necessary, leading to the second type of search
<br>
engine. Yahoo is perhaps the most prominent example of this &quot;index&quot;-based
<br>
approach, in which teams of real people categorize web pages--meaning that
<br>
categories tend to truly contain what you'd expect. The downside is that
<br>
the web grows far faster than any team of people can index pages, and such
<br>
a system is necessarily incomplete. But the founders of Google looked at
<br>
the Internet a little differently. Individual web pages abound, connected
<br>
to their respective servers but also to each other by hyperlinks. It is
<br>
indeed tempting to view them as neurons, linked in some broadly
<br>
characterizable ways but interconnected in a fashion so numerous and
<br>
complex (and changing so rapidly) that it defies any comprehensive human
<br>
attempt at mapping.
<br>
<p>But all pathways are not equal. The Internet, in a more-than-metaphorical
<br>
sense, evolves over time. A new page appears and, if it is authoritative
<br>
and useful, gets visited by people. Other pages link to it. And each link
<br>
is a sort of vote in favor of that page, an endorsement of its relevance
<br>
and utility. But this is no democracy, and all votes are not equal. Votes
<br>
from pages that are themselves ranked high in importance are given more
<br>
weight than others. In a very real sense, some pathways through the
<br>
Internet are more heavily traveled than others, and Google looks for
<br>
these. It doesn't define the pathways, but it uses them in ranking pages.
<br>
<p>In the brain, pathways are constantly changing, and it is these changes in
<br>
part that allow us to learn and adapt and have conscious experience,
<br>
Edelman says. Observations of infants have led to some remarkable theories
<br>
about brain development in this regard. Infants almost always try to grasp
<br>
at an object held near them, but newborns are seldom successful at first.
<br>
In fact, they flail more or less at random, not having inherited a
<br>
&quot;program&quot; that tells them how to coordinate the information coming in
<br>
their eyes with the movements of their hands. Not until they achieve
<br>
success--at first, essentially by luck--do they learn to distinguish
<br>
successful behaviors from ineffective strategies. This example and a
<br>
million others that occur throughout our lifetime are how experiential
<br>
selection takes place--some neural pathways strengthened while others are
<br>
weakened, or pathways created while others are destroyed.
<br>
<p>The final wiring requirement for consciousness is reentry. To understand
<br>
reentry, Edelman and his Neuroscience Institute colleague Giulio Tononi
<br>
suggest you imagine a string quartet beginning to play without sheet
<br>
music. The players begin improvising their own tunes, oblivious of what
<br>
the others are playing. But quickly their awareness of what the others
<br>
players are doing cause them to act in concert, so to speak. This metaphor
<br>
doesn't indicate anything of the complexity of reentrant connections in
<br>
the brain, however, and Edelman and Tononi go on to suggestion that you
<br>
imagine thousands of strings connecting the arms of each player to each of
<br>
the others. This way, other players are immediately aware of their
<br>
fellows' movements, drawing independent action almost instantly into
<br>
concert. This is reentry, on a tiny scale.
<br>
<p>Don't confuse this with feedback, which various computer systems could be
<br>
said to demonstrate. Feedback happens in two directions. Reentry happens
<br>
on a massive scale, with neuronal groups connected tightly to neighboring
<br>
neuronal groups, slight less tightly to more distant regions of the brain,
<br>
but essentially meaning that when one part of the brain is active, the
<br>
rest is aware. &quot;Reentry is the binding principal of the brain--it's the
<br>
way in which dynamically you have higher order selection that correlates
<br>
map to map,&quot; says Edelman.
<br>
<p>How Does the Light Go On?
<br>
<p>But no matter how complex and adaptive our brain's wiring is, how does it
<br>
result in the subjective experience of consciousness? Here at the troubled
<br>
crossroads of science and philosophy lies the nut of the problem.
<br>
Consciousness, as any good solipsist understands, is something you know
<br>
only about yourself. You cannot prove that you are not alone in a world of
<br>
zombies that behave the same way you do, but without the flavor of
<br>
consciousness--able to identify react to stimuli with accurate perception
<br>
but not knowing what it feels like the way you do.
<br>
<p>Edelman doesn't deny the problem; but he does believe that we can study
<br>
consciousness nonetheless. And one way to do it is by simulating
<br>
it--perhaps one day even creating it--in machines.
<br>
<p>&quot;[T]he only way we may be able to integrate our knowledge of the brain
<br>
effectively, given all its levels, is by synthesizing artifacts,&quot; Edelman
<br>
wrote in his 1992 book Bright Air, Brilliant Fire. The ultimate version of
<br>
such an artifact would be a conscious machine, or what some might call
<br>
true artificial intelligence. Eight years later, he still believes that it
<br>
may eventually be possible to build such an artifact. &quot;As we go along, I
<br>
have no doubt we'll be able to simulate more and more complex dynamics of
<br>
the brain.and we will get to that point where we've struck something that
<br>
will integrate into primary consciousness,&quot; says Edelman. &quot;But the
<br>
language part--oh, boy. That's going to be hard.&quot;
<br>
<p>Even if such a feat were achieved, however, it would still be hard to
<br>
silence critics. &quot;If you asked me whether I think dogs are conscious, I'd
<br>
say yes, but I can't prove it,&quot; says Edelman. &quot;All I can tell you is that
<br>
[dogs have] all of the structures that we know are essential for
<br>
consciousness. They have a behavioral repertoire that is suggestive of tha
<br>
t fact.&quot; The same will go for a machine with primary consciousness, and
<br>
even a machine with a higher-order consciousness and an advanced
<br>
linguistic ability will be unable to prove its consciousness. Instead,
<br>
we'll likely be reduced to comparing the electrical activity of its
<br>
artificial brain to a human brain and administering some sort of Turing
<br>
test--basically seeing if we can distinguish it from a human by
<br>
questioning it. &quot;The philosophical problem is not going to go away, but I
<br>
wouldn't elevate it to the highest metaphysical proportions,&quot; says
<br>
Edelman.
<br>
<p>Dr. Terrence Sejnowski, director of the Computational Neurobiology
<br>
Laboratory at the Salk Institute, agrees that the properties of the brain
<br>
can likely be duplicated in artificial devices, although he regards
<br>
questions of consciousness with a decidedly unphilosophical bent of mind.
<br>
&quot;My own suspicion is that words like 'consciousness' and 'qualia' will go
<br>
the way of words like 'phlogistem' and 'vitalism.'&quot;
<br>
<p>&quot;If you go back a hundred years,&quot; he explains, &quot;one of the biggest
<br>
scientific questions was 'what is life?' And one of the most prominent
<br>
theories had to do with vitalism--some substance, some thing that is
<br>
transmitted from cell to cell, animal to animal, that is the essence of
<br>
life. Well, you don't hear anybody talking about vitalism anymore. We've
<br>
come far enough to see all the mechanics--we've seen how DNA works, we've
<br>
seen all the pieces of the cell, and we don't have need for a hypothesis
<br>
like vitalism.&quot; So it will go, Sejnowski suspects, with consciousness.
<br>
(Phlogistem, incidentally, refers to a theoretical substance that people
<br>
once sought in combustible material, thinking it made up the &quot;substance&quot;
<br>
of fire.)
<br>
<p>Not Proof, But.
<br>
<p>A less decisive proof may come from a future version of a robot, or
<br>
&quot;brain-based device&quot; called NOMAD (for Neurally Organized Mobile Adaptive
<br>
Device) at the Neurosciences Institute. NOMAD looks a little like the
<br>
computer-controlled robots used in artificial intelligence experiments of
<br>
years past--a device on wheels, rolling around in a world of simple
<br>
shapes, looking out through a small camera. There's a big difference,
<br>
however.
<br>
<p>&quot;When you look at it, it's pretty stupid,&quot; acknowledges Edelman. &quot;All it's
<br>
doing is going around a room picking up blocks. But when you understand
<br>
what it's really doing, it's a real show-stopper. If you brought a
<br>
hardcore AI programmer, he'd say 'I could write a program in 500 lines
<br>
that would do better than that.' The answer is yes--you're doing it. This
<br>
thing does it by itself.&quot;
<br>
<p>Take a small detour here to consider one of Edelman's theories of
<br>
consciousness. How does our memory work? It's tempting to fall back on the
<br>
computer metaphor--computers use a certain part of their brain to record
<br>
bits of their experience, and so do we.right? Not so. It's an odd concept,
<br>
but Edelman says we don't really record memory at all. Memory is a system
<br>
property.
<br>
<p>This is where the intersection of theory and experiment becomes a bit
<br>
hairy. After all, the brain is still mysterious in many ways. While
<br>
Sejnowski notes that we have fairly detailed knowledge of the individual
<br>
components of the brain, &quot;we're still at the very beginning stage of
<br>
putting them back together.&quot; Part of Sejnowski's own work involves what he
<br>
jokingly refers to as the &quot;Humpty Dumpty Project&quot;--building complex
<br>
computer models of individual neural cell types and linking them together
<br>
into detailed computer simulations. His team has found that simulations
<br>
accurately model the overall electrical patterns seen in the brain; the
<br>
ultimate goal will be to have a detailed enough simulation to work in
<br>
reverse--to model an overall brain pattern associated with some experience
<br>
and trace it back to its individual neural origins.
<br>
<p>We know which &quot;part&quot; of the brain controls various aspects of
<br>
consciousness or function by using imaging devices that show electrical
<br>
activity over time or by analyzing in detail the activity of a small
<br>
number of neurons. That a particular part of the brain is active during a
<br>
certain function, however--or that the loss of that area knocks out a
<br>
certain function--doesn't mean you've located the function. You can't find
<br>
the brain's &quot;memory chip&quot; that way. Although certain parts of the brain
<br>
are heavily associated with memory, they may be hubs of activity that
<br>
nonetheless rely on other parts--and that, Edelman says, is indeed the
<br>
case. When it comes to consciousness, asking a question like &quot;where does
<br>
memory reside?&quot; is kind of like asking &quot;where is the Internet?&quot; You could
<br>
pinpoint some hubs that are more important than others, but it would be a
<br>
mistake to address these as &quot;the Internet.&quot; Likewise for memory, vision,
<br>
proprioception, and just about any other aspect of consciousness. It's
<br>
difficult to grasp--how could Marcel Proust nibble a petite madeleine cake
<br>
and have 10 volumes of Remembrance of Things Past come flooding in,
<br>
without some sort of neural recording device?
<br>
<p>Memory, in Edelman's view, occurs when, by will or new experience, through
<br>
interaction with the environment or within your brain or both, you explore
<br>
previous defined neural pathways. Because an experience was frightening,
<br>
or pleasant, or odd, or moving, your brain's circuitry adapted to it and,
<br>
across reentrant pathways, linked it to other aspects of your
<br>
consciousness, some of which may have seemed unimportant at the time--a
<br>
smell, perhaps, or the taste of a petite madeleine. (Note that, almost by
<br>
definition, it is difficult to remember something boring without a
<br>
conscious effort. Boringness does not trigger a lot of Darwinistic
<br>
response--you're more likely to remember the experience of being bored,
<br>
which is unpleasant, rather than boring content, which is just plain
<br>
boring.)
<br>
<p>NOMAD may not offer proof of this notion, but it offers an amazing piece
<br>
of support. The device has no memory, not in the computer sense at
<br>
least.but it remembers. It does not record its memories in a computer chip
<br>
or in any other fashion; it simply undergoes a reshaping of its simulated
<br>
neural pathways in response to the world it encounters--and memory
<br>
results. &quot;NOMAD has a memory,&quot; says Edelman. &quot;If you watch NOMAD before
<br>
and after it has learned something, you yourself can see in its behavior a
<br>
reflection of memory.&quot;
<br>
<p>Meanwhile, in the Computer World
<br>
<p>The application of Darwinistic forces to abstract problem-solving has also
<br>
found a foothold among computer scientists. At Natural Selection in La
<br>
Jolla, programmers have used &quot;evolutionary computation&quot; as a schema for
<br>
letting computers approach unique problems in unique contexts. In broad
<br>
terms, says president Dr. Lawrence Fogel, this means computers are left to
<br>
approach problems in a combinatorial fashion, making a &quot;population&quot; of
<br>
strategies and culling out those that are unfit, duplicating and then
<br>
&quot;mutating&quot; successful strategies as a means of refinement. The programs
<br>
can either start out with no information beyond the overall constraints of
<br>
the problem, or be given a starting population representing the
<br>
programmer's acquired wisdom.
<br>
<p>To Fogel, this is artificial intelligence--&quot;that is, simply, the ability
<br>
to solve new problems in new ways. In fact, I would go further--I don't
<br>
call it artificial if a computer can do it; I call it intelligence. The
<br>
machine may not be aware of it, it may not be conscious, but it's
<br>
intelligence.&quot;
<br>
<p>Fogel's interest lies in problem solving, not creating consciousness. And
<br>
whether or not intelligence requires consciousness, of course, is a
<br>
semantic argument. (John McCarthy, who coined the term &quot;artificial
<br>
intelligence,&quot; is said to have claimed that even a machine as simple as a
<br>
thermostat has beliefs. A thermostat believes three things: 'it's too hot
<br>
in here,' 'it's too cold in here,' and 'it's just right in here.' Hmmmm.
<br>
Most of us, however, agree that 'belief' requires consciousness and take
<br>
it as a matter of common sense that things like thermostats don't have
<br>
it.)
<br>
<p>Fogel, who has met with Edelman and admires his theories, has used
<br>
evolutionary computing to tackle some interesting problems. For Agouron
<br>
Pharmaceuticals (La Jolla, CA, now part of Pfizer), his company used a
<br>
natural selection scheme to find drug candidates to fit the HIV protease.
<br>
The result, ultimately, was the successful protease inhibitor Viracept.
<br>
(Fogel hastens to add, however, that it wasn't Natural Selection's program
<br>
that led directly to the compound. &quot;In linear programming, you get one
<br>
answer,&quot; he notes. &quot;In evolutionary computation, you don't get one answer;
<br>
you get a population of answers.&quot;)
<br>
<p>His son, chief scientist Dr. David Fogel, gained considerable attention
<br>
for the company when he wrote a program the taught itself how to play
<br>
checkers. The computer was given only the rules--no strategy or
<br>
instruction. A population of players was created and the successful
<br>
survived while the weak were winnowed out. The result was that sloppy,
<br>
random play became good enough to beat amateur and even some advanced
<br>
players.
<br>
<p>Sejnowski agrees that biological theories have informed computer
<br>
scientists, pointing to the &quot;genetic algorithms&quot; created by John Holland,
<br>
now professor at the University of Michigan. Holland (who got the world's
<br>
first Ph.D. in computer science) pioneered the idea of programs as &quot;genes&quot;
<br>
which have to survive in a competitive environment, the fittest surviving
<br>
and mutating into better approaches. These were the precursors of the
<br>
evolutionary computation of today.
<br>
<p>But the Darwin metaphor for the brain is limited, he adds. While Sejnowski
<br>
doesn't deny the scientific support for synaptic plasticity and
<br>
neurogenesis, he thinks the parallel to Darwinism is inexact. &quot;If you want
<br>
to be strict--if you don't just want it to be a literary metaphor--there
<br>
needs to be a process of duplication. You need to take something that is
<br>
successful, make many copies, and mutate it. There's nothing that
<br>
corresponds to that in the brain.&quot;
<br>
<p>Indeed, Edelman's theory makes no mention of the brain reproducing
<br>
identical pathways that have met with success; rather, there is enough
<br>
diversity developed during development and added by the growth of new
<br>
neurons and synapses, that the process of natural selection can proceed
<br>
without literal duplication.
<br>
<p>Brave New Machines?
<br>
<p>What is clear is that neuroscientists and computer scientists have greatly
<br>
benefited from one another. &quot;Neuroscience has already had a big impact on
<br>
computer science,&quot; says Sejnowksi. Not least of all is the fact that the
<br>
brain is the original model for a &quot;thinking machine,&quot; however imperfectly
<br>
digital computers represent it. But it goes beyond that. &quot;I think it's
<br>
pretty clear that massive parallelism has won in the supercomputer
<br>
business, he says. &quot;The general principle you take away looking at the
<br>
brain is that lots of small processors--even if they're individually not
<br>
very powerful-- can solve enormously complex problems very efficiently.&quot;
<br>
<p>Another example might be found in Hewlett-Packard's Teramac, a computer
<br>
that operates despite having over 220,000 flaws in its CPU. Dr. Phil
<br>
Kuekes, who led the team that designed the Teramac, explains that the goal
<br>
was to prepare for molecular scale computers that must tolerate a
<br>
considerable number of manufacturing errors--something standard
<br>
microprocessors cannot do.
<br>
<p>&quot;There are good biological analogs,&quot; Kuekes says. His team &quot;invested a lot
<br>
in hardware,&quot; putting in switches at every transistor that can reroute
<br>
current in case of a flaw. &quot;If you put glasses on a kitten that turns
<br>
everything upside, the brain wires appropriately,&quot; he observes. &quot;Based on
<br>
external circumstances, some wiring gets done later on. That's what we
<br>
did--based on external circumstances, we may find defects. Then some
<br>
wiring gets done later on.&quot; This is analogous to what Edelman calls
<br>
&quot;degeneracy&quot;--the ability of the brain to do the same thing in more than
<br>
one way.
<br>
<p>If Edelman is correct in his broad theory of neural Darwinism, neuronal
<br>
group selection, and the origin of consciousness, it will likely be many
<br>
years before skeptics are convinced--if they ever are. Perhaps it will
<br>
require a conscious machine. But in the meantime, many isolated aspects of
<br>
modern neuroscience are finding their way into computer science. From the
<br>
pathway selection of Google to the redundant structure of HP's Teramac,
<br>
from the &quot;evolutionary compuation&quot; of Natural Selection to emerging
<br>
&quot;neural networks,&quot; from the massive parallelism powering cutting edge
<br>
supercomputers to the distributed computing making networks better and
<br>
more reliable, computer systems are looking a lot more like the brain
<br>
these days. And of course, it works the other way: Some of these hardware
<br>
and software advances may well find their way back to a future version of
<br>
NOMAD or some similar brain-based device.
<br>
<p>But in the end, is artificial intelligence--the kind that involves
<br>
consciousness--really what we want? Edelman believes brain-based devices
<br>
like NOMAD will not just teach us about they brain, they will prove
<br>
incredibly valuable in their own right. &quot;We don't want to be too snobbish,
<br>
he says. &quot; I personally think someone is going to make billions of dollars
<br>
when we have brain-based devices that can go beyond what we're now doing.
<br>
Because the brain preceded logic--after all, Aristotle came later in human
<br>
history. The brain gave rise to culture and culture gave rise to
<br>
Aristotle. Prior to that, selectionism is what counted. If that's the
<br>
case, then it's perfectly obvious that brain-based devices are going to
<br>
supplement the computer in remarkable ways.&quot;
<br>
<p>Edelman adds that the Neurosciences Institute was recently visited by a
<br>
researcher from IBM. &quot;He's trying very hard to persuade his colleagues
<br>
that they need to wake up to this approach.&quot;
<br>
<p>©¿©¬
<br>
<p>Stay hungry,
<br>
<p>--J. R.
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, and ego.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Everything that can happen has already happened, not just once,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but an infinite number of times, and will continue to do so forever.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Everything that can happen = more than anyone can imagine.)
<br>
<p>We won't move into a better future until we debunk religiosity, the most
<br>
regressive force now operating in society.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2197.html">J. R. Molloy: "Re: META: Attachments"</a>
<li><strong>Previous message:</strong> <a href="2195.html">CurtAdams@aol.com: "Re: Engineering Yog-Sothoth for Fun and Profit"</a>
<li><strong>In reply to:</strong> <a href="2189.html">Sean Kenny: "RE: Many Worlds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2207.html">Lee Corbin: "RE: Many Worlds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2196">[ date ]</a>
<a href="index.html#2196">[ thread ]</a>
<a href="subject.html#2196">[ subject ]</a>
<a href="author.html#2196">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:56 MDT</em>
</em>
</small>
</body>
</html>
