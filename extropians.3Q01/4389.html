<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<title>extropians: ROBOT: Self-organizing Autonomous Incremental Learn</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="ROBOT: Self-organizing Autonomous Incremental Learner">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>ROBOT: Self-organizing Autonomous Incremental Learner</h1>
<!-- received="Fri Aug 17 12:02:23 2001" -->
<!-- isoreceived="20010817180223" -->
<!-- sent="Fri, 17 Aug 2001 11:02:14 -0700" -->
<!-- isosent="20010817180214" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="ROBOT: Self-organizing Autonomous Incremental Learner" -->
<!-- id="049b01c12746$c13ed900$9b5c2a42@jrmolloy" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="200108171741.KAA16271@well.com" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20ROBOT:%20Self-organizing%20Autonomous%20Incremental%20Learner&In-Reply-To=&lt;049b01c12746$c13ed900$9b5c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 17 2001 - 12:02:14 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4390.html">Eugene Leitl: "IP: MUST READ -- Censorship in action why I don't publish my HDCPresults by Niels Ferguson (fwd)"</a>
<li><strong>Previous message:</strong> <a href="4388.html">Reason: "RE: META:  How to respond to Crank Science?"</a>
<li><strong>In reply to:</strong> <a href="4384.html">Brian D Williams: "SOCIETY: The privatization of public security in South America?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4449.html">Dehede011@aol.com: "Re: SOCIETY: The privatization of public security in South America?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4389">[ date ]</a>
<a href="index.html#4389">[ thread ]</a>
<a href="subject.html#4389">[ subject ]</a>
<a href="author.html#4389">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="http://www.siliconvalley.com/docs/news/svfeatures/084346.htm">http://www.siliconvalley.com/docs/news/svfeatures/084346.htm</a>
<br>
BY ROBERT S. BOYD
<br>
Knight Ridder Newspapers
<br>
<p>EAST LANSING, Mich. -- Would you like it if your kids came equipped with
<br>
``good'' and ``bad'' buttons you could push to make them behave?
<br>
<p>Of course not. Nobody wants to raise a child to be a robot. Yet that's the way
<br>
John Weng, a robotics expert at Michigan State University here, is teaching a
<br>
robot to learn like a child -- to obey spoken commands, trundle down a hall,
<br>
find and pick up toys with its mechanical hand.
<br>
<p>Weng is breeding a new kind of ``intelligent'' robot that learns in a novel
<br>
way: by experience, the way animals and people do. He said this approach to
<br>
learning will be cheaper, faster and more flexible than traditional robot
<br>
training methods, which mostly are limited to what a human programmer tells
<br>
the machine to do.
<br>
<p>Instead of stuffing its computer brain with elaborate instructions, like Big
<br>
Blue, the IBM chess champion, Weng teaches his robot a few basic skills and
<br>
then lets it learn on its own by interacting with its environment.
<br>
<p>He compares the process to teaching a baby to walk by holding its hands and
<br>
then letting go. In his lab, a human trainer first controls the robot's
<br>
actions manually, then sets it free to perform its new tricks on its own.
<br>
<p>Weng calls his machine a developmental robot, because -- unlike most
<br>
traditional robots -- it ``develops'' its new abilities through practice,
<br>
gaining skill with each training session.
<br>
<p>``Humans mentally raise the developmental robot by interacting with it,'' he
<br>
said. ``Human trainers teach robots through verbal, gestural or written
<br>
commands in much the same way as parents teach their children.''
<br>
<p>Named SAIL (for Self-organizing Autonomous Incremental Learner), Weng's
<br>
robot-in-training wanders the halls of Michigan State's Engineering Building,
<br>
responding to touch, voices and what it ``sees'' with its stereoscopic vision
<br>
system.
<br>
<p>It works something like AIBO, the robotic toy dog from Sony Corp. that
<br>
responds to pats on the head, but on a vastly more sophisticated level.
<br>
<p>Five feet tall and black-skinned, SAIL has a boxy torso, a round head, two
<br>
eyes, one arm and hand, and a wheelchair base to roll around on. A more
<br>
human-looking successor, nicknamed Dave, is on the drawing boards for next
<br>
summer.
<br>
<p>According to Weng, a developmental robot acquires its smarts in two ways: The
<br>
first is ``supervised learning'' under the direct control of a human teacher.
<br>
Then comes ``reinforcement learning,'' in which the trainer lets the robot
<br>
operate on its own but rewards it for successful action and penalizes it for
<br>
failure.
<br>
<p>In supervised learning, for example, Becky Smith, one of Weng's students,
<br>
steers SAIL down a corridor by pushing touch sensors on its shoulders. ``To
<br>
train the baby robot to get around, we take it for a walk,'' she said.
<br>
<p>After a few practice sessions, Smith lets the machine go free. She said SAIL
<br>
needs only one lesson to learn to move in a straight line, but 10 sessions to
<br>
get the hang of going around corners on its own.
<br>
<p>In another type of lesson, the human trainer speaks an order -- such as ``go
<br>
left,'' ``arm up'' or ``open hand'' -- then makes the robot perform the action
<br>
by pushing one of the 32 control sensors on its body.
<br>
<p>``The robot associates what it hears with the correct action,'' Weng said.
<br>
After 15 minutes' training, SAIL could follow such commands correctly 90
<br>
percent of the time, he said.
<br>
<p>To strengthen the robot's newfound skills, it next attends an advanced class
<br>
of reinforcement learning. The trainer lets the robot ``explore the world on
<br>
its own, but encourages and discourages its actions by pressing its `good'
<br>
button or `bad' button,'' Weng explained.
<br>
<p>Alternatively, instead of pressing the buttons, a trainer says ``Good'' when
<br>
SAIL does what it's supposed to do, and barks ``Bad'' when it makes a mistake.
<br>
<p>Numbers in SAIL's computer brain are adjusted to reflect these experiences.
<br>
The next time, presumably, it will do better.
<br>
<p>``The `good' and `bad' commands speed up the learning process,'' said Weng.
<br>
``Mind and intelligence emerge gradually from such interactions.''
<br>
<p>Weng's research on developmental robots is supported by the Defense
<br>
Department's Advanced Research Project Agency and by the National Science
<br>
Foundation. Microsoft and Siemens AG, the German electronics giant, also have
<br>
contributed money. So far, about $1 million has been spent, he said.
<br>
<p>Eventually, Weng hopes ordinary people will be able to buy and train their own
<br>
robots to do household chores, take Grandpa for a walk and simply to
<br>
entertain.
<br>
<p>``Anyone can train a highly improved developmental robot of the future -- a
<br>
child, an elderly person, a teacher, a worker,'' Weng predicts. ``You could
<br>
personalize it and teach it tricks. You could have a competition -- say, my
<br>
robot can dance better than your robot.''
<br>
<p>Weng is by no means the only researcher who is struggling to make robots that
<br>
can learn on their own. Many others are developing machines that learn to
<br>
maneuver in their surroundings with minimum human control.
<br>
<p>For example, Ron Arkin, an expert on robot behavior at the Georgia Institute
<br>
of Technology in Atlanta, is developing robots that can explore previously
<br>
unknown environments. The Defense Department is financing his work on teams of
<br>
mobile robots that can scout out hostile territory and report what they find.
<br>
<p>``We cannot foresee all the events that may occur to a robot,'' Arkin said.
<br>
<p>At Carnegie Mellon University in Pittsburgh, Christopher Atkeson uses a
<br>
version of reinforcement learning to train robots. ``The goal is to reduce the
<br>
amount of expensive expert human input into robot programming,'' he said.
<br>
<p>Even AIBO, the toy robot dog, ``learns'' from experience. If you pat its head
<br>
when it puts out its paw to you, that increases the probability that it will
<br>
put out its paw again.
<br>
<p>But Weng insists that SAIL comes closest to mimicking a real child's learning
<br>
process. ``It's like teaching a kid to ride a bicycle -- you push him first
<br>
and then let go,'' he said. ``Nobody else does it this way.''
<br>
***************************
<br>
<p>--J. R.
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, and ego.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Everything that can happen has already happened, not just once,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but an infinite number of times, and will continue to do so forever.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Everything that can happen = more than anyone can imagine.)
<br>
<p>We won't move into a better future until we debunk religiosity, the most
<br>
regressive force now operating in society.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4390.html">Eugene Leitl: "IP: MUST READ -- Censorship in action why I don't publish my HDCPresults by Niels Ferguson (fwd)"</a>
<li><strong>Previous message:</strong> <a href="4388.html">Reason: "RE: META:  How to respond to Crank Science?"</a>
<li><strong>In reply to:</strong> <a href="4384.html">Brian D Williams: "SOCIETY: The privatization of public security in South America?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4449.html">Dehede011@aol.com: "Re: SOCIETY: The privatization of public security in South America?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4389">[ date ]</a>
<a href="index.html#4389">[ thread ]</a>
<a href="subject.html#4389">[ subject ]</a>
<a href="author.html#4389">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:10 MDT</em>
</em>
</small>
</body>
</html>
