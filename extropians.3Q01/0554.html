<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Artificial Reality</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Artificial Reality">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Artificial Reality</h1>
<!-- received="Mon Jul  9 00:30:12 2001" -->
<!-- isoreceived="20010709063012" -->
<!-- sent="Sun, 8 Jul 2001 23:28:44 -0700" -->
<!-- isosent="20010709062844" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Artificial Reality" -->
<!-- id="123a01c10840$736c6fa0$965c2a42@jrmolloy" -->
<!-- inreplyto="5.1.0.14.0.20010709143351.0595eec0@mira.net" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Artificial%20Reality&In-Reply-To=&lt;123a01c10840$736c6fa0$965c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Mon Jul 09 2001 - 00:28:44 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0555.html">Russell Blackford: "RE: Debunk All Religiosity Equally (D.A.R.E.)"</a>
<li><strong>Previous message:</strong> <a href="0553.html">Reason: "commentary sought on Longevity Meme bylaws"</a>
<li><strong>In reply to:</strong> <a href="0548.html">Miriam English: "Re: Artificial Reality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0589.html">Miriam English: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0589.html">Miriam English: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#554">[ date ]</a>
<a href="index.html#554">[ thread ]</a>
<a href="subject.html#554">[ subject ]</a>
<a href="author.html#554">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<em>&gt; Back in the &quot;real&quot; world: does anybody seriously expect that the human race
</em><br>
<em>&gt; that instantly puts down any dog that dares to bite a human will ever
</em><br>
<em>&gt; tolerate any machine intelligence that even raises its voice to humans?
</em><br>
<em>&gt; There is no way that AIs will ever be allowed to become a threat to humans.
</em><br>
<em>&gt; They will supersede humanity quietly, in spite of their best efforts to
</em><br>
<em>&gt; help us. We need never worry about force. We are much more likely to be
</em><br>
<em>&gt; pampered to oblivion.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Cheers,
</em><br>
<em>&gt;
</em><br>
<em>&gt;          - Miriam
</em><br>
<p>Yes, I seriously expect that the human race that spends billions of dollars to
<br>
create a machine intelligence capable of raising its voice to humans will whip
<br>
the snot out of any human impudent enough to provoke said machine to such
<br>
behavior. If you've ever been near a super computer, you know that it resides
<br>
in a world that revolves around its every need. The security forces
<br>
surrounding any machine with (even slightly) human-competitive AI concern
<br>
themselves with threats to the machine, not with threats to humans.
<br>
<p>For example:
<br>
Britain's ultimate safe house
<br>
<a href="http://www.thebunker.net/net_230998.htm">http://www.thebunker.net/net_230998.htm</a>
<br>
One company is so serious about data security it has bought an abandoned
<br>
nuclear bunker in southern England. Its aim is to store corporate data on
<br>
secure servers 300 feet underground. London - based A.L. Digital has purchased
<br>
a former military facility, which it said is as impervious to electronic
<br>
eavesdropping as it is to the electro-magnetic pulse of a nuclear attack. The
<br>
centre has been set up to cater for companies wanting to house their most
<br>
critical data in a safe environment.
<br>
-------------------------
<br>
<p>You see, humans out rank animals, but mega-wealth outranks humans, and AI out
<br>
ranks everything. That's the real world, IMO.
<br>
<p>©¿©¬
<br>
<p>Stay hungry,
<br>
<p>--J. R.
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, CYC, and ELIZA
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Everything that can happen has already happened, not just once,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but an infinite number of times, and will continue to do so forever.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Everything that can happen = more than anyone can imagine.)
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0555.html">Russell Blackford: "RE: Debunk All Religiosity Equally (D.A.R.E.)"</a>
<li><strong>Previous message:</strong> <a href="0553.html">Reason: "commentary sought on Longevity Meme bylaws"</a>
<li><strong>In reply to:</strong> <a href="0548.html">Miriam English: "Re: Artificial Reality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0589.html">Miriam English: "Re: Artificial Reality"</a>
<li><strong>Reply:</strong> <a href="0589.html">Miriam English: "Re: Artificial Reality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#554">[ date ]</a>
<a href="index.html#554">[ thread ]</a>
<a href="subject.html#554">[ subject ]</a>
<a href="author.html#554">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:42 MDT</em>
</em>
</small>
</body>
</html>
