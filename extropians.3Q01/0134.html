<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: GAC</title>
<meta name="Author" content="Chris & Jessie McKinstry (mckinst@vtr.net)">
<meta name="Subject" content="Re: GAC">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: GAC</h1>
<!-- received="Mon Jul  2 20:53:03 2001" -->
<!-- isoreceived="20010703025303" -->
<!-- sent="Mon, 2 Jul 2001 22:34:10 -0400" -->
<!-- isosent="20010703023410" -->
<!-- name="Chris & Jessie McKinstry" -->
<!-- email="mckinst@vtr.net" -->
<!-- subject="Re: GAC" -->
<!-- id="010301c10368$a499a7a0$94159818@jessicap.vtr.net" -->
<!-- inreplyto="GAC" -->
<strong>From:</strong> Chris & Jessie McKinstry (<a href="mailto:mckinst@vtr.net?Subject=Re:%20GAC&In-Reply-To=&lt;010301c10368$a499a7a0$94159818@jessicap.vtr.net&gt;"><em>mckinst@vtr.net</em></a>)<br>
<strong>Date:</strong> Mon Jul 02 2001 - 20:34:10 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0135.html">Sabine Atkins: "SciFi.com: CYC yourself up for AI, Lab notes"</a>
<li><strong>Previous message:</strong> <a href="0133.html">Damien Broderick: "Re: Movie Review - AI Artificial Intelligence"</a>
<li><strong>Maybe in reply to:</strong> <a href="0175.html">Chris & Jessie McKinstry: "GAC"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0177.html">J. R. Molloy: "Re: GAC"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#134">[ date ]</a>
<a href="index.html#134">[ thread ]</a>
<a href="subject.html#134">[ subject ]</a>
<a href="author.html#134">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<em>&gt;Chris, since you have probably already read Eliezer's comments
</em><br>
<em>&gt;(if you haven't you should follow the links from extropy.org
</em><br>
<em>&gt;to the archives of the last week or so), I'll simply comment
</em><br>
<em>&gt;that some of us are fairly neutral regarding approaches to
</em><br>
<em>&gt;different aspects of AI (and will freely admit our lack of
</em><br>
<em>&gt;knowledge with regard to much of it).
</em><br>
<em>&gt;
</em><br>
<em>&gt;So, stating my ignorance in advance, I'll simply make a few comments
</em><br>
<em>&gt;on your comments:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; 1 - GAC is a black box. I have made no disclosures on what it uses for
</em><br>
<em>&gt;&gt; pattern matching [snip]
</em><br>
<em>&gt;
</em><br>
<em>&gt;While I can understand reasons for doing this, it will leave a bad
</em><br>
<em>&gt;taste in the mouths of many with an academic or open source perspectives.
</em><br>
<p>GAC won't stay a black box forever. I'm doing some work now that I hope to
<br>
have in peer review soon that involves processing the Mindpixel Corpus using
<br>
a string based SOM.
<br>
<p><p><em>&gt;&gt; 2 - The primary purpose of GAC is to build a fitness test for humanness
</em><br>
in a
<br>
<em>&gt;&gt; binary response domain. This will in the future allow GAC to babysit a
</em><br>
truly
<br>
<em>&gt;&gt; evolving artificial consciousness, rewarding and punishing it as needed
</em><br>
at
<br>
<em>&gt;&gt; machine speeds.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I'd say this statement is flawed from two perspectives.  First, if you
</em><br>
<em>&gt;have no verifiction of the &quot;reputation&quot; of your &quot;humanness&quot; sources you
</em><br>
<em>&gt;have no controls on the results.  You are going to get much different
</em><br>
<em>&gt;results if your humans are Jesuit priests vs. modern-day neo-nazis.
</em><br>
<em>&gt;Presumably you get a slightly more intelligent and affluent cross
</em><br>
<em>&gt;section of humanity (i.e. the people net-connected and producing
</em><br>
<em>&gt;the inputs to your system).  That would seem to imply you are going
</em><br>
<em>&gt;to get a pretty &quot;average&quot; human perspective out of the whole effort.
</em><br>
<em>&gt;Producing more &quot;average&quot; humans isn't of much use from an extropian
</em><br>
<em>&gt;perspective.  We have more than enough problems figuring out how to
</em><br>
<em>&gt;feed the ones produced using the regular old-fashioned manufacturing
</em><br>
<em>&gt;methods.
</em><br>
<p><p>For now, I'm only really concerned with the items which there is fairly
<br>
uniform consensus. The things that vary from Jesuit to neo-nazi don't really
<br>
concern me. It's what they share in common that interests me.
<br>
<p><p><em>&gt; Second, there seems to be an implicit assumption that using
</em><br>
<em>&gt;current &quot;humaneness&quot; can evolve an artificial consciousness.  Leaving
</em><br>
<em>&gt;aside the meaning of the suitcase term &quot;consciousness&quot;, the
</em><br>
<em>&gt;problem may be that for humans to have reached that state they
</em><br>
<em>&gt;had to go through their entire evolutionary history.  Modern humans,
</em><br>
<em>&gt;not knowing how to chip flint or stalk a mammoth, may not be able
</em><br>
<em>&gt;to regenerate &quot;consciousness&quot;.  All you may end up with is a machine
</em><br>
<em>&gt;able to pass the Turing test, but still not be &quot;conscious&quot;.
</em><br>
<p>I disagree. I consider consciousness a communication issue and a subset of
<br>
the humaness problem. I firmly believe that once you have a machine that
<br>
really passes the Turing Test, you must consider it conscious, or create a
<br>
double standard.
<br>
<p><em>&gt;&gt; Right now, GAC is a 50,000+ term fitness test for humanness. At each
</em><br>
<em>&gt;&gt; one of those points GAC knows what it should expect it were testing an
</em><br>
<em>&gt;&gt; average human, because for each one of those points GAC has made at least
</em><br>
20
<br>
<em>&gt;&gt; measurements of real people.
</em><br>
<em>&gt;
</em><br>
<em>&gt;That's 20 real &quot;average&quot; people.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; 3 - Any contradictions in GAC are real contradictions in us. It can't
</em><br>
<em>&gt;&gt; believe anything that hasn't been confirmed by at least 20 people.
</em><br>
<em>&gt;
</em><br>
<em>&gt;You can get 20 real average people to confirm a belief in God --
</em><br>
<em>&gt;getting a combination of a database and some statistical analysis
</em><br>
<em>&gt;software to do the same doesn't make God any more &quot;real&quot;.
</em><br>
<p>But, the human concept of God is very real.  I'm not measuring reality. I'm
<br>
measuring our shared conception of reality.
<br>
<p><p><em>&gt;&gt; 4 - GAC is science. Over 8 million actual measurements of human consensus
</em><br>
<em>&gt;&gt; have been made.  There are at least two other projects that claim to be
</em><br>
<em>&gt;&gt; collecting human consensus information - CYC and Open Mind [snip]
</em><br>
<em>&gt;
</em><br>
<em>&gt;I don't know much about Open Mind, and only know a little more about Cyc.
</em><br>
<em>&gt;I would not classify Cyc as trying to collect human &quot;consensus&quot;
</em><br>
information.
<br>
<p>Maybe you don't, but Doug Lenat does. Just go to google and search on 'CYC
<br>
Lenat consensus' - and see for yourself.
<br>
<p><em>&gt;Human &quot;consensus&quot; information is often wrong and I doubt Doug would be
</em><br>
<em>&gt;building wrong concepts into a common sense database.  I'd classify Cyc
</em><br>
<em>&gt;more of an attempt to get the commonly agreed upon as scientifically
</em><br>
correct
<br>
<em>&gt;information into a database with an attached reasoning and inference
</em><br>
engine.
<br>
<em>&gt;I would agree that GAC may be interesting social science, but I
</em><br>
<em>&gt;deeply doubt it will produce a useful path to an advanced
</em><br>
<em>&gt;artificial intelligence.  Since an advanced artificial intelligence
</em><br>
<em>&gt;is what most extropians would find of interest, the approach
</em><br>
<em>&gt;isn't likely to find a warm reception here.
</em><br>
<p>You have to start somewhere. I don't have 40,000 PhD's entering data. I have
<br>
40,000 normal people. Now of course it's a simple matter for me to give my
<br>
users some objective test and have GAC pay more attention to those that
<br>
score well... but that's in the future.
<br>
<p>&nbsp;(But you probably
<br>
<em>&gt;have already figured that out...).  What might be interesting
</em><br>
<em>&gt;at some future point in time is to watch a Turing test between
</em><br>
<em>&gt;Cyc and GAC.  It could reveal some very interesting insights
</em><br>
<em>&gt;into the many false beliefs that most people hold.
</em><br>
<p><em>&gt;I'd suggest you consider the problem of how one would build into
</em><br>
<em>&gt;GAC the concepts of &quot;trust&quot; and &quot;reputations&quot;.  A quick search
</em><br>
<em>&gt;turns up:
</em><br>
<em>&gt;  &quot;The Production of Trust in Online Markets&quot; by Peter Kollock
</em><br>
<em>&gt;  <a href="http://www.sscnet.ucla.edu/soc/faculty/kollock/papers/online_trust.htm">http://www.sscnet.ucla.edu/soc/faculty/kollock/papers/online_trust.htm</a>
</em><br>
<em>&gt;which references some of the early work by Miller &amp; Drexler.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I've got little interest in knowing what the average human knows.
</em><br>
<em>&gt;I've got a great interest in knowing what &quot;high&quot; reputation
</em><br>
<em>&gt;humans know.
</em><br>
<p>Me too. There are just far too few of them to be useful at the moment. Don't
<br>
worry though. GAC will be around forever. I'm setting it up with its own
<br>
income stream and the ability for consensus to decide what happens to it in
<br>
the future.
<br>
<p>Chris.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0135.html">Sabine Atkins: "SciFi.com: CYC yourself up for AI, Lab notes"</a>
<li><strong>Previous message:</strong> <a href="0133.html">Damien Broderick: "Re: Movie Review - AI Artificial Intelligence"</a>
<li><strong>Maybe in reply to:</strong> <a href="0175.html">Chris & Jessie McKinstry: "GAC"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0177.html">J. R. Molloy: "Re: GAC"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#134">[ date ]</a>
<a href="index.html#134">[ thread ]</a>
<a href="subject.html#134">[ subject ]</a>
<a href="author.html#134">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:41 MDT</em>
</em>
</small>
</body>
</html>
