<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re GAC</title>
<meta name="Author" content="Christopher McKinstry (cmckinst@eso.org)">
<meta name="Subject" content="Re GAC">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re GAC</h1>
<!-- received="Wed Jul  4 03:06:21 2001" -->
<!-- isoreceived="20010704090621" -->
<!-- sent="Wed, 04 Jul 2001 05:05:21 -0400" -->
<!-- isosent="20010704090521" -->
<!-- name="Christopher McKinstry" -->
<!-- email="cmckinst@eso.org" -->
<!-- subject="Re GAC" -->
<!-- id="3B42DC51.43A6DC0B@eso.org" -->
<strong>From:</strong> Christopher McKinstry (<a href="mailto:cmckinst@eso.org?Subject=Re:%20Re%20GAC&In-Reply-To=&lt;3B42DC51.43A6DC0B@eso.org&gt;"><em>cmckinst@eso.org</em></a>)<br>
<strong>Date:</strong> Wed Jul 04 2001 - 03:05:21 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0230.html">Michael M. Butler: "Re: TECH: wireless gets real"</a>
<li><strong>Previous message:</strong> <a href="0228.html">J. R. Molloy: "ROBOT: Transcending Borders"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#229">[ date ]</a>
<a href="index.html#229">[ thread ]</a>
<a href="subject.html#229">[ subject ]</a>
<a href="author.html#229">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<em>&gt;Eliezer S. Yudkowsky wote:
</em><br>
<p><em>&gt; Anyway, if GAC is a black box, it says to me that you think a simple 
</em><br>
<em>&gt; algorithm lies at the core; if you're playing with SOMs and SRNs, it says 
</em><br>
<em>&gt; to me that the internal functionality complexity of GAC is almost nil. 
</em><br>
<p>It says nothing of the sort. What I intended to communicate is that you
<br>
could not possibly know how GAC works because I haven't disclosed it.
<br>
You were speaking as if you knew absolutely what was going on with my
<br>
system, which is of course absolutely impossible. You don't have access
<br>
to the information to make the statements you made.
<br>
<p>And what on earth does the fact that I'm using SOMs and SRNs got to do
<br>
with 'internal functionality complexity' or any type of complexity for
<br>
that matter? One has nothing to do with the other. I can use a SOM or  a
<br>
SRN on data of ANY complexity.
<br>
<p>&nbsp;
<br>
<em>&gt; &gt; 2 - The primary purpose of GAC is to build a fitness test for humanness in a 
</em><br>
<em>&gt; &gt; binary response domain. This will in the future allow GAC to babysit a truly 
</em><br>
<em>&gt; &gt; evolving artificial consciousness, rewarding and punishing it as needed at 
</em><br>
<em>&gt; &gt; machine speeds. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That certainly isn't what it says on your Website. On your Website, it 
</em><br>
<em>&gt; says things along the lines of: GAC! The new revolution in AI! The 
</em><br>
<em>&gt; first step towards true artificial consciousness! We're teaching it what 
</em><br>
<em>&gt; it means to be human! 
</em><br>
<p>Which is true. But read it again and see what you missed! Additionally
<br>
read any public
<br>
interview I've given (this one for example:
<br>
<a href="http://slashdot.org/articles/00/07/04/2114223.shtml">http://slashdot.org/articles/00/07/04/2114223.shtml</a>) It's always been
<br>
about building a fitness test. I hate to quote myself, but it looks like
<br>
I have to. From <a href="http://www.mindpixel.com/About/about.php3">http://www.mindpixel.com/About/about.php3</a>:
<br>
<p>&quot;Eventually, it is hoped a GAC trained neural  network will become
<br>
indistinguishable from any human being when presented with any yes/no
<br>
question/statement independent of whether or  not GAC has seen that
<br>
particular question/statement before. GAC's database will also be used
<br>
to develop the first true images of the entire human conceptual network;
<br>
the first true images of the human mind...&quot;
<br>
<p>Or more clearly from <a href="http://www.mindpixel.com/Cyc_vs_GAC/cyc_vs_gac.php3">http://www.mindpixel.com/Cyc_vs_GAC/cyc_vs_gac.php3</a>
<br>
<p>&quot;Remember, GAC is just a database; just a high-res copy of our reality. 
<br>
But with enough mindpixels, we can make all the connections the Cyc team
<br>
is trying to make manually, automatically.&quot;
<br>
<p><p><p><p><em>&gt; &gt; 4 - GAC is science. Over 8 million actual measurements of human consensus 
</em><br>
<em>&gt; &gt; have been made. There are at least two other projects that claim to be 
</em><br>
<em>&gt; &gt; collecting human consensus information - CYC and Open Mind - neither has 
</em><br>
<em>&gt; &gt; actually done the science to verify that what is in their databases is 
</em><br>
<em>&gt; &gt; actually consensus human fact. It's all hearsay until the each item is 
</em><br>
<em>&gt; &gt; presented to at least 20 people (central limit theorem.) 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 4.1: I'm not fond of Cyc either. But Cyc isn't claiming to collect human 
</em><br>
<em>&gt; consensus information; rather, they are claiming to collect the 
</em><br>
<em>&gt; commonsense knowledge that one human might be expected to have. I think 
</em><br>
<em>&gt; Cyc has nothing but a bunch of suggestively named LISP predicates. If 
</em><br>
<em>&gt; they *were* collecting knowledge, however, what would be relevant would 
</em><br>
<em>&gt; not be whether the knowledge was true, or whether it was consensual, but 
</em><br>
<em>&gt; whether it duplicated the relevant functional complexity of the 
</em><br>
<em>&gt; commonsense knowledge possessed by a single human mind. 
</em><br>
<p>You seem to be slipping on your basic reading again. From
<br>
<a href="http://www.cyc.com/overview.html">http://www.cyc.com/overview.html</a>
<br>
<p>&quot;The knowledge base is built upon a core of over 1,000,000 hand-entered
<br>
assertions (or &quot;rules&quot;) designed to capture a large portion of what we
<br>
normally consider consensus knowledge about the world. For example, Cyc
<br>
knows that trees are usually outdoors, that once people die they stop
<br>
buying things, and that glasses of liquid should be carried
<br>
rightside-up.&quot;
<br>
<p>As well, note that the core rules are binary. Each one cost about $50.00
<br>
to make!
<br>
<p>&nbsp;
<br>
<em>&gt; 4.2: Performing lots and lots of actual measurements does not make it 
</em><br>
<em>&gt; science. To make it science, you need to come up with a central 
</em><br>
<em>&gt; hypothesis about AI or human cognition, use the hypothesis to make a 
</em><br>
<em>&gt; prediction, and use those lots and lots of measurements to test that 
</em><br>
<em>&gt; prediction. Analogously, I would also note that until GAC can use its 
</em><br>
<em>&gt; pixels to predict new pixels, it is not &quot;AI&quot; in even the smallest sense; 
</em><br>
<em>&gt; it remains a frozen picture, possibly useful as a fitness test for some 
</em><br>
<em>&gt; other AI (I disagree), but not intelligent in itself; as unthinking as the 
</em><br>
<em>&gt; binay JPEG data of the Mona Lisa. 
</em><br>
<p>Not quite. I assume you've heard of observational science? Like the kind
<br>
the astronomer over my right should is doing right now?
<br>
<p>And a JPEG of the Mona Lisa is not quite as unthinking as you suppose.
<br>
If you build a model of the her from random samples, those samples
<br>
contain within them information about samples not sampled. After all
<br>
it's a holigraphic universe.
<br>
<p>As for theory... it's hypertomography. What GAC is is a very large
<br>
database of high dimensional prototype vectors. The same math that can
<br>
give you 2-d reconstructions of the brain with MRI scanner data can give
<br>
you low dimensional projections of the very high dimensional human
<br>
conceptual network.
<br>
<p>Comparing an unknown vector to all of these vectors allows for a
<br>
statistical prediction of the truth value of the vector. The more
<br>
prototype vectors, the better the prediction. The catch is, for the math
<br>
to work you need millions of prototypes (which is why tomographic
<br>
scanners need to make so many samples.)
<br>
<p>Read Elman's SRN paper 'Finding Structure in Time' to see just how well
<br>
SRNs extract grammatical structure from prototype vectors. It's rather
<br>
shocking - and more than a decade old.
<br>
<p>Now, once you have a system that can classify true and false vectors, so
<br>
what? Well, then it's just like Big Blue - all it really does is
<br>
classify chess moves - millions and millions per second until it finds
<br>
the best in a given time. You can do the same thing with a system that
<br>
can classify vectors true and false. Feed it millions and millions of
<br>
random vectors with just the statistics of English - most of the time it
<br>
won't be able to classify the vectors as strongly true or strongly
<br>
false, because well, they're random garbage. But every once in a while
<br>
it will find a vector it can classify and that it can prove it has never
<br>
seen before - that vector is an artificial thought.
<br>
<p>Chris.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0230.html">Michael M. Butler: "Re: TECH: wireless gets real"</a>
<li><strong>Previous message:</strong> <a href="0228.html">J. R. Molloy: "ROBOT: Transcending Borders"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#229">[ date ]</a>
<a href="index.html#229">[ thread ]</a>
<a href="subject.html#229">[ subject ]</a>
<a href="author.html#229">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:39:41 MDT</em>
</em>
</small>
</body>
</html>
