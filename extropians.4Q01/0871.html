<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: The Path (was: This War Is Not About Terror...)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The Path (was: This War Is Not About Terror...)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: The Path (was: This War Is Not About Terror...)</h1>
<!-- received="Sun Oct 14 18:34:57 2001" -->
<!-- isoreceived="20011015003457" -->
<!-- sent="Sun, 14 Oct 2001 20:34:52 -0400" -->
<!-- isosent="20011015003452" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The Path (was: This War Is Not About Terror...)" -->
<!-- id="3BCA2F2C.F6201045@pobox.com" -->
<!-- inreplyto="3BCA1FAD.1010701@pacbell.net" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20Path%20(was:%20This%20War%20Is%20Not%20About%20Terror...)&In-Reply-To=&lt;3BCA2F2C.F6201045@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sun Oct 14 2001 - 18:34:52 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0872.html">Spike Jones: "Re: Monitoring people (was Re: Meritocracies and freedom of information)"</a>
<li><strong>Previous message:</strong> <a href="0870.html">Colin Hales: "RE: GRRR Vent Vent."</a>
<li><strong>In reply to:</strong> <a href="0868.html">Edwin Evans: "The Path (was: This War Is Not About Terror...)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#871">[ date ]</a>
<a href="index.html#871">[ thread ]</a>
<a href="subject.html#871">[ subject ]</a>
<a href="author.html#871">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Edwin Evans wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Eliezer Yudkowsky wrote:
</em><br>
<em>&gt;  &gt;Due to some of the other modifications by the Eliezer Yudkowsky path, the
</em><br>
<em>&gt;  &gt;'Eliezer Yudkowsky path' has gone from (a) asserting that THE PATH is
</em><br>
<em>&gt;  &gt;completely observer-independent to (b) admitting of the possibility, and
</em><br>
<em>&gt;  &gt;even considering as the null hypothesis, that THE PATH is inherent to the
</em><br>
<em>&gt;  &gt;human frame of reference, or rather to the frame of reference of a large
</em><br>
<em>&gt;  &gt;cluster of evolved social species.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why?
</em><br>
<p>Basically from the original EY path pondering two questions:
<br>
<p>1)  What if there's some kind of initial complexity, over and above raw
<br>
problem-solving ability, needed to understand and seek out objective
<br>
morality?
<br>
<p>2)  What if objective morality is something that needs to be built, or
<br>
synthesized, rather than being a pre-existing feature of reality?  Would
<br>
the human preferences need to be included as a suggestion?
<br>
<p>The combination of these two questions led me to start thinking of the
<br>
human goal system as containing a *drive toward* objectivity, such that an
<br>
assertion of this goal system was that, if morality were objective, or to
<br>
the degree that morality turned out to be objective, the goal system
<br>
should be regarded as a successive approximation to that objective
<br>
morality.  This reasoning can be validated *either* because it's part of
<br>
the human baseline, *or* because it leads to an actual objective morality
<br>
under which the use of such reasoning is desirable.  If an objective
<br>
morality is found, then of course whether or not something is part of the
<br>
human baseline becomes irrelevant.  But it doesn't become irrelevant until
<br>
then.
<br>
<p>The Friendly AI semantics are actually a superset of the objective
<br>
morality semantics whose purpose is to describe - or rather target for
<br>
acquisition - all the complexity that a human being uses to reason about
<br>
morality, including objective morality.  If an objective morality is
<br>
found, then the FAI semantics collapse into a reference to objective
<br>
morality, just like your or my philosophy would.  But Friendly AI works
<br>
even if the philosophical reasoning about objective morality contains an
<br>
error.  It should be able to enfold any philosophical reasoning a human
<br>
can execute; that's the purpose of Friendly AI.
<br>
<p>Sigh... this isn't really much of a description.  Ifni knows it probably
<br>
won't make any sense at all to those list members who haven't already been
<br>
following the objective morality debate for a while.  I probably need to
<br>
write this up in more detail one of these days.
<br>
<p>But Friendly AI is supposed to work no matter what philosophical position
<br>
you take.  Any argument you can use on a human philosopher can be used on
<br>
a Friendly AI.  That's what it's there for.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0872.html">Spike Jones: "Re: Monitoring people (was Re: Meritocracies and freedom of information)"</a>
<li><strong>Previous message:</strong> <a href="0870.html">Colin Hales: "RE: GRRR Vent Vent."</a>
<li><strong>In reply to:</strong> <a href="0868.html">Edwin Evans: "The Path (was: This War Is Not About Terror...)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#871">[ date ]</a>
<a href="index.html#871">[ thread ]</a>
<a href="subject.html#871">[ subject ]</a>
<a href="author.html#871">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:13 MDT</em>
</em>
</small>
</body>
</html>
