<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<title>extropians: ROBOT: Speech Recognition &amp; Relationship Issues</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="ROBOT: Speech Recognition &amp; Relationship Issues">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>ROBOT: Speech Recognition &amp; Relationship Issues</h1>
<!-- received="Tue Oct 23 10:41:40 2001" -->
<!-- isoreceived="20011023164140" -->
<!-- sent="Tue, 23 Oct 2001 09:41:45 -0700" -->
<!-- isosent="20011023164145" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="ROBOT: Speech Recognition &amp; Relationship Issues" -->
<!-- id="07a801c15be1$9e06cea0$6f5c2a42@jrmolloy" -->
<!-- charset="Windows-1252" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20ROBOT:%20Speech%20Recognition%20&amp;%20Relationship%20Issues&In-Reply-To=&lt;07a801c15be1$9e06cea0$6f5c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 23 2001 - 10:41:45 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1509.html">John Clark: "Re: Two essays on the violence seemingly inherent in Islam"</a>
<li><strong>Previous message:</strong> <a href="1507.html">Alex F. Bokov: "Re: &quot;A Call to the Muslims of the World&quot;"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1508">[ date ]</a>
<a href="index.html#1508">[ thread ]</a>
<a href="subject.html#1508">[ subject ]</a>
<a href="author.html#1508">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Speech interfaces are ready to listen
<br>
<a href="http://www.cnn.com/2001/TECH/industry/10/22/speech.interfaces.idg/index.html">http://www.cnn.com/2001/TECH/industry/10/22/speech.interfaces.idg/index.html</a>
<br>
By Fred Hapgood
<br>
<p>(IDG) -- In the early '90s CIO Magazine stuck a fork, editorially speaking,
<br>
into speech recognition and declared it done.
<br>
<p>The reason for such excitement was that the technical problems that had
<br>
bottled up the technology in labs for decades were finally being addressed.
<br>
The most basic issue had been associating specific vocalizations with specific
<br>
phonemes. (Phonemes are the basic units of speech. For example, the &quot;wuh&quot;
<br>
sound in &quot;one.&quot;)
<br>
<p>Making the associations required compiling huge databases of how the more than
<br>
40 English-language phonemes are spoken by those of different ages, genders,
<br>
linguistic cultures and under different phone-line conditions. Developers then
<br>
had to write programs that could find the degree of fit between a given user's
<br>
vocalization and one of those samples.
<br>
<p>Once software recognizes a phoneme, the sound has to be assigned to a meaning
<br>
(unless the product in question is a simple dictation engine for directly
<br>
recording and transcribing speech). That meant building more databases, and
<br>
this time of all the ways humans might express meanings of interest, such as
<br>
&quot;yes,&quot; &quot;sure,&quot; &quot;right,&quot; &quot;correct,&quot; &quot;yep,&quot; &quot;yup,&quot; &quot;yeah,&quot; &quot;uh-huh,&quot; &quot;fine,&quot;
<br>
&quot;OK,&quot; &quot;affirmative,&quot; &quot;good&quot; and so on. Since the culture was throwing off new
<br>
expressions constantly -- &quot;whatever,&quot; &quot;no doubt,&quot; &quot;word&quot; -- the programs also
<br>
needed to be easy to update in the field. Then grammar algorithms needed to be
<br>
written and hardware developed that was fast enough to do all that computation
<br>
in real-time, yet cheap enough for ordinary businesses to buy.
<br>
<p>By the early '90s all those pieces were falling into place or were close to
<br>
doing so, and we felt the implications were significant. A wide range of
<br>
enterprise functions, from order-entry to customer support to incident and
<br>
inspection reporting, were about to get cheaper and easier to perform.
<br>
Computation and telephony were going to merge. We were all going to get out of
<br>
voice-mail jail. &quot;A decade from now perhaps speech recognition will be as
<br>
ubiquitous as voice-messaging is today,&quot; we concluded.
<br>
<p>While considerable progress has been made since then, we're not there yet.
<br>
Were we wrong in our judgment of what had been achieved technically? Probably
<br>
not.
<br>
<p>It turned out, however, that speech recognition is only partly a technical
<br>
problem. Recognition implies a conversation, and conversations make sense only
<br>
in the context of relationships. When humans enter relationships they
<br>
immediately impose a structure of assumptions and expectations. Is the person
<br>
smart? Knowledgeable? Nice? Lazy? Snobbish? That structure controls the
<br>
interaction. If a comprehension problem comes up during a conversation with a
<br>
smart person we assume we are at fault and take on the responsibility of
<br>
working it out. We do the same if we think our respondent is not too bright
<br>
but basically nice. On the other hand, if we think the other party is lazy,
<br>
doesn't care or worse, is trying to manipulate us, we behave very differently.
<br>
<p>Those relationship issues are just as important when talking with machines as
<br>
with people; even more so, since most users were and are uncertain about how
<br>
to talk to software. &quot;Suppose you said you wanted to go to Boston and you
<br>
heard the reply, 'I don't understand,'&quot; says William Meisel, president of TMA
<br>
Associates, a speech recognition consultancy in Tarzana, California. &quot;This was
<br>
a common response at the time. But what didn't (the computer) understand? Was
<br>
it your pronunciation? Usage? The logical thread? You didn't know.&quot;
<br>
<p>What you did know was that the program refused to give help when you needed
<br>
it. This refusal became a cue in and of itself -- a sign that the machine
<br>
planned to shift all the work of the conversation onto the user. Humans
<br>
reacted to that the same way they would have in a conversation, with
<br>
resentment and irritation. They raised their voices and sounded out words as
<br>
if they were speaking to a child. Their voice became stressed. They changed
<br>
their pitch. They started to swear. This would confuse the program even more,
<br>
until eventually users hung up with a bang.
<br>
<p>Today the industry understands the importance of giving the user as much help
<br>
as possible, Meisel concludes, which might mean building another database --
<br>
this time of the most common errors -- and writing prompts that suggest
<br>
specific solutions to problems. For example, the computer could ask, &quot;Do you
<br>
want Austin or Boston?&quot; This does more than locate the problem as a
<br>
pronunciation issue; it reassures the user that the program has the smarts to
<br>
understand the situation and is willing to help the speaker solve it, which in
<br>
turn makes users more disposed to working with the program.
<br>
<p>Mike Phillips, CTO of SpeechWorks International, a speech recognition product
<br>
and services vendor in Boston, offers many other examples. Answering a
<br>
question with &quot;unauthorized request&quot; might work on a Web page, for instance,
<br>
but in the context of speech it communicates a haughty indifference. A better
<br>
answer would be, &quot;I'm sorry, my supervisor doesn't allow me to make that
<br>
transaction&quot; in a sympathetic, you-and-me-against-the-world tone of voice. The
<br>
old way of saying that a database is down was simply, &quot;That database is down.&quot;
<br>
That might work as an error message onscreen, but in the context of speech a
<br>
better way might be to sigh and say, &quot;I'm sorry, the system is giving me a lot
<br>
of trouble right now.&quot;
<br>
<p>Speech recognition systems used to ask people to &quot;Wait for the prompt to
<br>
finish before speaking.&quot; That made the technology easier to implement, but it
<br>
communicated a snippy insistence on privilege and hierarchy that annoyed
<br>
users. Today most speech recognition software is &quot;barge-in enabled,&quot; which
<br>
means that speech recognition programs defer to users whenever they interrupt.
<br>
&quot;The point is to keep assuring the user that the system is on her side,&quot;
<br>
Meisel says.
<br>
<p>During the past few years, the underlying technology has continued to improve.
<br>
(Meisel estimates that the error rate in phoneme recognition accuracy falls by
<br>
about 30 percent per year.) The technology is now in the peculiar position of
<br>
outrunning expectations, says Phillips. Good speech recognition is perfectly
<br>
capable of handling a complete sentence, such as &quot;I want to take the redeye
<br>
from Boston to Austin a week from Wednesday,&quot; but most users still want a
<br>
highly structured interaction that prompts for each element of the
<br>
transaction. Phillips' hope is that as their experience with speech
<br>
recognition applications grows, users will relax and conversations will get
<br>
more ambitious and wide-ranging. But whatever happens, the programs will
<br>
always be very, very nice.
<br>
<p>---   ---   ---   ---   ---
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego, human values, scientific relinquishment
<br>
<p>We  move into a better future in proportion as science displaces superstition.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1509.html">John Clark: "Re: Two essays on the violence seemingly inherent in Islam"</a>
<li><strong>Previous message:</strong> <a href="1507.html">Alex F. Bokov: "Re: &quot;A Call to the Muslims of the World&quot;"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1508">[ date ]</a>
<a href="index.html#1508">[ thread ]</a>
<a href="subject.html#1508">[ subject ]</a>
<a href="author.html#1508">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:15 MDT</em>
</em>
</small>
</body>
</html>
