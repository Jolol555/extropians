<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Lanier essay of 2001.12.04</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Lanier essay of 2001.12.04">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Lanier essay of 2001.12.04</h1>
<!-- received="Thu Dec 13 13:20:21 2001" -->
<!-- isoreceived="20011213202021" -->
<!-- sent="Thu, 13 Dec 2001 12:21:42 -0800" -->
<!-- isosent="20011213202142" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Lanier essay of 2001.12.04" -->
<!-- id="3C190DD6.8B2F31B3@objectent.com" -->
<!-- inreplyto="20011213163029.A24816@akira.nada.kth.se" -->
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Lanier%20essay%20of%202001.12.04&In-Reply-To=&lt;3C190DD6.8B2F31B3@objectent.com&gt;"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 13 2001 - 13:21:42 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4251.html">Samantha Atkins: "Re: META: what is verbal abuse, anyway?  (Caution: foul   languageahead/not wo..."</a>
<li><strong>Previous message:</strong> <a href="4249.html">Samantha Atkins: "Re: Sincere Questions on Identity"</a>
<li><strong>In reply to:</strong> <a href="4228.html">Anders Sandberg: "Re: Lanier essay of 2001.12.04"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4250">[ date ]</a>
<a href="index.html#4250">[ thread ]</a>
<a href="subject.html#4250">[ subject ]</a>
<a href="author.html#4250">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Anders Sandberg wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; On Wed, Dec 12, 2001 at 11:20:05PM -0800, Samantha Atkins wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I share that fear considering what will happen if the current
</em><br>
<em>&gt; &gt; general society determines in detail what kind of human beings
</em><br>
<em>&gt; &gt; it wants for the next generation.  Overall, given reasonably
</em><br>
<em>&gt; &gt; democratic free-choice this will result in the proliferation of
</em><br>
<em>&gt; &gt; a number of traits many today would consider desirable and the
</em><br>
<em>&gt; &gt; suppression of a number of others, including some arguably part
</em><br>
<em>&gt; &gt; of high intelligence and creativity.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What meaning do you put in the word 'society'? Do you mean it like many
</em><br>
<em>&gt; swedes would use it, as 'the government', or in the wider sense of 'our
</em><br>
<em>&gt; social environment'? In the first case, the solution is fairly clear:
</em><br>
<em>&gt; make sure the government is not allowed to interfere with our
</em><br>
<em>&gt; reproductive choices in any way.
</em><br>
<p>Insufficient if the vast majority of free agents make choices
<br>
that
<br>
are destructive enough of what we value and is needed to
<br>
advance.
<br>
<p><p><em>&gt; In the second case (which seems more
</em><br>
<em>&gt; likely) you have the problem of claiming it determines what humans are
</em><br>
<em>&gt; born *in detail*. Sure, there are prevalent ideals and values that
</em><br>
<em>&gt; affect the decisions of parents, but they do not control them 100% -
</em><br>
<em>&gt; given the diversity of modern societies we instead see that while most
</em><br>
<em>&gt; people do like most others do, there are a sizeable fraction that behave
</em><br>
<em>&gt; in other ways. While there are many pressures to conform, there are also
</em><br>
<em>&gt; counterpressures for individuality and rebellion.
</em><br>
<p>Sure.  But I still have some bit of worry that I believe is
<br>
valid given
<br>
general individual and group lack of foresight and wisdom.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; &gt; In short, we are in a sort of Catch-22.  We can't seem to get
</em><br>
<em>&gt; &gt; too much better without getting smarter and more capable and we
</em><br>
<em>&gt; &gt; can't get smarter and more capable without using certain
</em><br>
<em>&gt; &gt; technologies with more wisdom than we generally possess.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think you are seeing things as a vicious circle, while I think it is a
</em><br>
<em>&gt; positive feedback loop: if people can help themselves a bit with
</em><br>
<em>&gt; technology, that will affect society in positive ways that will in turn
</em><br>
<em>&gt; help develop better technology, and so on. There may still be unwanted
</em><br>
<em>&gt; side effects, but in general society seems to be made up of a
</em><br>
<em>&gt; sufficiently complex mixture of people and views not to get trapped in
</em><br>
<em>&gt; dead ends very easily.
</em><br>
<em>&gt;
</em><br>
<p>Except that if we make sufficient mistakes of a serious enough
<br>
kind
<br>
then of course the &quot;game&quot; is simply over.  I have less faith in
<br>
current
<br>
humans being both capable and balanced enough to use technology
<br>
wisely
<br>
enough to avoid catastrophe.  Given that, we have no choice but
<br>
to 
<br>
go on and attempt to balance the boat and provide a bit of
<br>
steering where
<br>
we can.
<br>
&nbsp;
<br>
<em>&gt; &gt; I don't assume things would get worse.  I simply assume, based
</em><br>
<em>&gt; &gt; on a lot of observation, that some pretty screw things will be
</em><br>
<em>&gt; &gt; done with any powerful new technology, not just or even
</em><br>
<em>&gt; &gt; necessarily predominantly good things.  There is reason for some
</em><br>
<em>&gt; &gt; caution and safeguards.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure. Note that my criticisms of the idea that we are socially better
</em><br>
<em>&gt; off unable to change ourselves are not directed at you or anybody else,
</em><br>
<em>&gt; but the idea itself.
</em><br>
<em>&gt;
</em><br>
<p>I didn't take it personally.   Nor is my remark meant as just my
<br>
personal view.
<br>
I believe there are legitimate reasons for concern that weren't
<br>
so clearly
<br>
acknowledged in the former post.
<br>
<p><em>&gt; &gt; I am not so much worried about a repressive society as about not
</em><br>
<em>&gt; &gt; especially wise or more or less rational or ethical human beings
</em><br>
<em>&gt; &gt; and human organizations wielding powers increasingly able to
</em><br>
<em>&gt; &gt; really screw us up in perhaps a terminal degree.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Then the question is: who can we allow to wield these technologies?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The relinquishment argument answers 'nobody', but that clearly fails
</em><br>
<em>&gt; since it is enough for somebody to develop a technology and the genie is
</em><br>
<em>&gt; out of the bottle.
</em><br>
<em>&gt;
</em><br>
<p>It also fails as some of these technologies are essential to
<br>
allow us to
<br>
solve problems perhaps insoluble without them that are crucial
<br>
to our
<br>
(all humans) well-being.
<br>
<p>&nbsp;
<br>
<em>&gt; The answer 'the government, since they are elected by the people' is
</em><br>
<em>&gt; popular, but has the problem that even a democratic government may
</em><br>
<em>&gt; misbehave due to public choice effects, lack of accountability and
</em><br>
<em>&gt; especially its top-down, one-size fits all approach. The real danger in
</em><br>
<em>&gt; centralized schemes is that there is a single point of failure
</em><br>
<em>&gt; (accountability and power division lessens this problem a bit, but does
</em><br>
<em>&gt; not wholly remove it), and a bad decision made will affect all.
</em><br>
<em>&gt;
</em><br>
<p>It is certainly true that governments are not more trustworthy
<br>
than individuals.
<br>
&nbsp;
<br>
<em>&gt; Another answer to the question is 'the people themselves'. This has the
</em><br>
<em>&gt; advantage of being a bottom-up, self-organizing approach, where local
</em><br>
<em>&gt; information and individual values can be used by people. It also implies
</em><br>
<em>&gt; that bad values or stupid people will affect technology use; whether
</em><br>
<em>&gt; this is disastrous or not depends very much on the technology: if
</em><br>
<em>&gt; individual people make bad reproductory choices it will affect them and
</em><br>
<em>&gt; their families, while dangerous experiments with black holes in the
</em><br>
<em>&gt; kitchen may threaten everybody. In situations where the effects of
</em><br>
<em>&gt; misuse are limited and can be curbed by holding users accountable, this
</em><br>
<em>&gt; approach seems preferrable to the government approach, and I think this
</em><br>
<em>&gt; holds true for many reproductive technologies. It is less clear how well
</em><br>
<em>&gt; it works for black holes.
</em><br>
<em>&gt;
</em><br>
<p>Self-organization works whether there is sufficient leeway for
<br>
an organic
<br>
balance to evolve.  I am not always so sure there is that much
<br>
leeway.  If
<br>
enough people make bad choices about say, designing the next
<br>
generation, then
<br>
the next generation is more deeply screwed up than this one. 
<br>
The effect does
<br>
not end at the supposed border of the family.  
<br>
&nbsp;
<br>
<em>&gt; There are general ways of making people behave more rationally and
</em><br>
<em>&gt; ethically, such as accountability, transparency and setting up
</em><br>
<em>&gt; institutions which, while fallible, help bias behavior in beneficial
</em><br>
<em>&gt; ways and protect from the effects of mistakes (insurance companies, for
</em><br>
<em>&gt; example). I think more thought on how such means can be applied in
</em><br>
<em>&gt; reproduction would be helpful.
</em><br>
<em>&gt;
</em><br>
<p>How exactly will you make people accountable for unintended and
<br>
unpredictable
<br>
consequences?  How do you make insurance rational rather than a
<br>
statistical
<br>
greed machine as it often (and unfortunately) becomes today?  
<br>
&nbsp;
<br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I do not worry about super-soldiers.  I do worry about people
</em><br>
<em>&gt; &gt; become obsolete and no consideration given to their well-being.
</em><br>
<em>&gt; &gt; Whether they are made obsolete by genetic design of superior new
</em><br>
<em>&gt; &gt; humans or by AI or robotics or something else is immaterial to
</em><br>
<em>&gt; &gt; the basic concern.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Isn't the issue really lack of concern for their well-being, rather than
</em><br>
<em>&gt; being made obsolete? If I become obsolete in some sense, it might be a
</em><br>
<em>&gt; blow to my self-esteem, but if I can still grow and flourish as a human
</em><br>
<em>&gt; being I am still well off.
</em><br>
<em>&gt; 
</em><br>
<p>Yes.  That is my concern.  The old &quot;nature red of tooth and
<br>
claw&quot; memes would
<br>
lead to those who are less efficient in the new landscape not
<br>
being of 
<br>
concern at all.  In my opinion we can do a lot better than that
<br>
and have
<br>
the opportunity to.
<br>
<p>- samantha
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4251.html">Samantha Atkins: "Re: META: what is verbal abuse, anyway?  (Caution: foul   languageahead/not wo..."</a>
<li><strong>Previous message:</strong> <a href="4249.html">Samantha Atkins: "Re: Sincere Questions on Identity"</a>
<li><strong>In reply to:</strong> <a href="4228.html">Anders Sandberg: "Re: Lanier essay of 2001.12.04"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4250">[ date ]</a>
<a href="index.html#4250">[ thread ]</a>
<a href="subject.html#4250">[ subject ]</a>
<a href="author.html#4250">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:26 MDT</em>
</em>
</small>
</body>
</html>
