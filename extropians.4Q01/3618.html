<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Intelligence enhancement (was: Selfish Reason T</title>
<meta name="Author" content="Mark Walker (mdwalker@quickclic.net)">
<meta name="Subject" content="Re: Intelligence enhancement (was: Selfish Reason To Preserve Chimps)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Intelligence enhancement (was: Selfish Reason To Preserve Chimps)</h1>
<!-- received="Fri Nov 30 16:20:11 2001" -->
<!-- isoreceived="20011130232011" -->
<!-- sent="Fri, 30 Nov 2001 18:22:18 -0800" -->
<!-- isosent="20011201022218" -->
<!-- name="Mark Walker" -->
<!-- email="mdwalker@quickclic.net" -->
<!-- subject="Re: Intelligence enhancement (was: Selfish Reason To Preserve Chimps)" -->
<!-- id="013201c17a0f$006fa760$c8c8f418@southmount.com" -->
<!-- inreplyto="Intelligence enhancement (was: Selfish Reason To Preserve Chimps)" -->
<strong>From:</strong> Mark Walker (<a href="mailto:mdwalker@quickclic.net?Subject=Re:%20Intelligence%20enhancement%20(was:%20Selfish%20Reason%20To%20Preserve%20Chimps)&In-Reply-To=&lt;013201c17a0f$006fa760$c8c8f418@southmount.com&gt;"><em>mdwalker@quickclic.net</em></a>)<br>
<strong>Date:</strong> Fri Nov 30 2001 - 19:22:18 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3619.html">Anders Sandberg: "Re: How do we rise to the challenge of statism?"</a>
<li><strong>Previous message:</strong> <a href="3617.html">Mark Walker: "Re: Selfish Reason to Preserve Chimps"</a>
<li><strong>Maybe in reply to:</strong> <a href="3575.html">Eliezer S. Yudkowsky: "Intelligence enhancement (was: Selfish Reason To Preserve Chimps)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3588.html">J. R. Molloy: "Re: Selfish Reason To Preserve Chimps"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3618">[ date ]</a>
<a href="index.html#3618">[ thread ]</a>
<a href="subject.html#3618">[ subject ]</a>
<a href="author.html#3618">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Eliezer S. Yudkowsky wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; We do not have the technology.  We have the technology to make arbitrary
</em><br>
<em>&gt; alterations to DNA, in the same sense that we have the technology to make
</em><br>
<em>&gt; arbitrary alterations from ones and zeroes.
</em><br>
I am not sure in what sense the changes I described are arbitrary. We have
<br>
the technology to make specific changes to different homeobox genes which
<br>
control the relative size of different parts of the brain. So the changes
<br>
are not arbitrary in this sense. It is true that we do not know what the
<br>
changes will do for the organism but this would be the point of
<br>
experimenting.
<br>
<em>  &gt;Going from DNA to
</em><br>
<em>&gt; intelligence enhancement is not necessarily easier than going from ones
</em><br>
<em>&gt; and zeroes to Artificial Intelligence.  And your compile-build-debug cycle
</em><br>
<em>&gt; is 14 years long, and illegal.
</em><br>
<em>&gt;
</em><br>
I said that this was a back-up plan, so it is consistent with this that it
<br>
is not necessarily easier. Damien pointed out as well that it would take
<br>
time for the experiments to mature. I didn't think to mention this but I
<br>
suppose I should have: I have some expertise in the subject of a maturation
<br>
period as a former child myself.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;G.E is a good BACK-UP plan because: (1)  we have the technology
<br>
presently to make non-arbitrary alterations, and (2) manipulating the
<br>
homeobox genes in question might prove to be a sufficient condition for
<br>
creating a greater than human intelligence. Given the plasticity of the
<br>
neocortex during ontogenesis, and its role in so-called higher cognitive
<br>
functions, I think this would be a good area to experiment with. There are a
<br>
number of hypotheses one could try here right now (at least on animals),
<br>
e.g., one null hypothesis is that a 50% increase in the neocortex in a pygmy
<br>
chimp will not lead to an increase in intelligence. Barring financial,
<br>
ethical and legal worries, this is the sort of thing would could attempt
<br>
after lunch. If memory serves I think the cycle time on the pygmy chimp is
<br>
about 3-5 years.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;I am not proposing G.E. as a competitor to AI. We may agree that the
<br>
biggest worry is suffering at the hands of our own stupidity. I hope SIAI
<br>
works, but I would feel a little better with a back-up plan.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3619.html">Anders Sandberg: "Re: How do we rise to the challenge of statism?"</a>
<li><strong>Previous message:</strong> <a href="3617.html">Mark Walker: "Re: Selfish Reason to Preserve Chimps"</a>
<li><strong>Maybe in reply to:</strong> <a href="3575.html">Eliezer S. Yudkowsky: "Intelligence enhancement (was: Selfish Reason To Preserve Chimps)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3588.html">J. R. Molloy: "Re: Selfish Reason To Preserve Chimps"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3618">[ date ]</a>
<a href="index.html#3618">[ thread ]</a>
<a href="subject.html#3618">[ subject ]</a>
<a href="author.html#3618">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:23 MDT</em>
</em>
</small>
</body>
</html>
