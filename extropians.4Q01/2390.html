<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Economics, posthumanity, and self-replication (</title>
<meta name="Author" content="Anders Sandberg (asa@nada.kth.se)">
<meta name="Subject" content="Re: Economics, posthumanity, and self-replication (was: MORALITY)">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Economics, posthumanity, and self-replication (was: MORALITY)</h1>
<!-- received="Fri Nov  9 10:04:38 2001" -->
<!-- isoreceived="20011109170438" -->
<!-- sent="Fri, 9 Nov 2001 18:04:33 +0100" -->
<!-- isosent="20011109170433" -->
<!-- name="Anders Sandberg" -->
<!-- email="asa@nada.kth.se" -->
<!-- subject="Re: Economics, posthumanity, and self-replication (was: MORALITY)" -->
<!-- id="20011109180433.B17088@akira.nada.kth.se" -->
<!-- inreplyto="3BEBD524.BCAAD52D@pobox.com" -->
<strong>From:</strong> Anders Sandberg (<a href="mailto:asa@nada.kth.se?Subject=Re:%20Economics,%20posthumanity,%20and%20self-replication%20(was:%20MORALITY)&In-Reply-To=&lt;20011109180433.B17088@akira.nada.kth.se&gt;"><em>asa@nada.kth.se</em></a>)<br>
<strong>Date:</strong> Fri Nov 09 2001 - 10:04:33 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2391.html">Dehede011@aol.com: "Re: War Support Ebbs"</a>
<li><strong>Previous message:</strong> <a href="2389.html">Eliezer S. Yudkowsky: "Re: War Support Ebbs"</a>
<li><strong>In reply to:</strong> <a href="2369.html">Eliezer S. Yudkowsky: "Economics, posthumanity, and self-replication (was: MORALITY)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2410.html">natashavita@earthlink.net: "Re: Economics, posthumanity, and self-replication (was: MORALITY)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2390">[ date ]</a>
<a href="index.html#2390">[ thread ]</a>
<a href="subject.html#2390">[ subject ]</a>
<a href="author.html#2390">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
On Fri, Nov 09, 2001 at 08:07:48AM -0500, Eliezer S. Yudkowsky wrote:
<br>
<em>&gt; Anders Sandberg wrote:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I'm not discussing the posthuman world here, but the world of tomorrow.
</em><br>
<em>&gt; &gt; While people do worry about scenarios where superintelligent grey goo
</em><br>
<em>&gt; &gt; from the stars eats humanity, the most powerful impact is with the idea
</em><br>
<em>&gt; &gt; that within a few years you *must* get yourself a better brain in order
</em><br>
<em>&gt; &gt; to avoid becoming poor and powerless. That slots neatly into a lot of
</em><br>
<em>&gt; &gt; political pre-programming and gives us a ready-made organized political
</em><br>
<em>&gt; &gt; resistance to our projects. To worsen things, most people are used to
</em><br>
<em>&gt; &gt; ideologies that prescribe the same behavior for all humans, and do not
</em><br>
<em>&gt; &gt; accept the idea that other humans may have other goals.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The real answer here is simply &quot;Are these technologies self-replicating?&quot; 
</em><br>
<em>&gt; Non-self-replicating technologies will likely be expensive and limited to
</em><br>
<em>&gt; the First World, at least at first. 
</em><br>
<p>You mean like the cellular phones, which are spreading across Somalia
<br>
and Bangladesh?
<br>
<p><em>&gt; Self-replicating technologies are not
</em><br>
<em>&gt; expensive unless an enforceable patent exists.  Genetic engineering is
</em><br>
<em>&gt; self-replicating but patented.  Software is self-replicating but
</em><br>
<em>&gt; unenforceably copyrighted.  Nanotechnology is self-replicating at
</em><br>
<em>&gt; sufficiently advanced levels.  Intelligence enhancement technology is
</em><br>
<em>&gt; &quot;self-replicating&quot; if there's even one philanthropist among the enhanced,
</em><br>
<em>&gt; although it may take a while for that process to complete.  And the
</em><br>
<em>&gt; nanotech-plus-Friendly-SI scenario is not only self-replicating, it
</em><br>
<em>&gt; bypasses the existing economic system completely.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think that's the counterslogan:  &quot;Posthumanity will bypass the existing
</em><br>
<em>&gt; economic system and offer everyone the same opportunities.&quot;  Then you have
</em><br>
<em>&gt; to argue it.  But it makes a good opening line.
</em><br>
<p>What about &quot;God will bypass the existing economic system and make you
<br>
all rich and equal&quot; ? It is the same argument, and will get roughly the
<br>
same reception (perhaps even a bit more favorable than the posthuman
<br>
one). While there might be a good way of arguing it without having to
<br>
rely on too much handwaving and faith, it is still an extreme uphill
<br>
battle. Meanwhile those who think that genetic engineering, AI, nanotech
<br>
and all other new tech will make the current inequalities *worse* sit on
<br>
the top of the memetic hill, with a ready made paradigm that many people
<br>
buy into - consciously or not - and can easily throw down stones. Take a
<br>
look at _The ETC CENTURY: Erosion, Technological Transformation and
<br>
Corporate Concentration in the 21st Century_
<br>
(<a href="http://www.rafi.org/web/docus/pdfs/DD99_1-2.pdf">http://www.rafi.org/web/docus/pdfs/DD99_1-2.pdf</a>) for an example - this
<br>
is the kind of views that is getting more and more respected in many
<br>
international organisations close to the UN and major environmental
<br>
conferences. The trend we observed when writing our book on the
<br>
genetics debate was that views that once belonged to the nutty red-green
<br>
fringe has become not just acceptable but accepted by many politicians -
<br>
thanks to a long and consistent campaign of connecting these views with
<br>
current issues but with the long term-goal of influencing the
<br>
ideological climate of the future. 
<br>
<p>Honestly, I think your argument shows a serious error many
<br>
transhumanists do. We assume that since various future technologies may
<br>
fix our current problems (although what happens if self replicating
<br>
systems end up patented and under the control of some groups?) the
<br>
current concerns are not that important. Which is terribly, sadly wrong.
<br>
The current situation will *shape* what technologies become developed
<br>
and for what uses they will be developed. If we just ignore current
<br>
concerns with &quot;in nanotopia sexism/racism/poverty/death/whatever will no
<br>
longer be a problem&quot; we will 1) make people think we are total airheads
<br>
with no connection to reality, 2) decrease our ability to influence the
<br>
important decisions about the future since we marginalise ourselves and
<br>
3) leave the field open to those who have opposing long-range views but
<br>
tie them to the current situation. 
<br>
<p>RAFI wants centralized international control over nanotech (and they are
<br>
moving towards putting it on the 2002 environmental agenda!) in order to
<br>
prevent a corporate dystopia - if they start to think AI can get
<br>
somewhere they will start to work on the same thing, and likely get a
<br>
lot of support from other groups who for their own reasons think that AI
<br>
would be a bad thing. Even unenforceable laws have dangerous effects,
<br>
especially when combined with ideas that certain things must be
<br>
prevented at any cost. 
<br>
<p>I think far too many transhumanists are ignoring the interface between
<br>
transhumanism and the real world, and this weakens transhumanism
<br>
tremendously. We need qualified analysis of where we are, where we want
<br>
to go and how to go about it if we want to convince anybody else - as
<br>
well as get our own thinking into shape. 
<br>
<p><p><pre>
-- 
-----------------------------------------------------------------------
Anders Sandberg                                      Towards Ascension!
<a href="mailto:asa@nada.kth.se?Subject=Re:%20Economics,%20posthumanity,%20and%20self-replication%20(was:%20MORALITY)&In-Reply-To=&lt;20011109180433.B17088@akira.nada.kth.se&gt;">asa@nada.kth.se</a>                            <a href="http://www.nada.kth.se/~asa/">http://www.nada.kth.se/~asa/</a>
GCS/M/S/O d++ -p+ c++++ !l u+ e++ m++ s+/+ n--- h+/* f+ g+ w++ t+ r+ !y
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2391.html">Dehede011@aol.com: "Re: War Support Ebbs"</a>
<li><strong>Previous message:</strong> <a href="2389.html">Eliezer S. Yudkowsky: "Re: War Support Ebbs"</a>
<li><strong>In reply to:</strong> <a href="2369.html">Eliezer S. Yudkowsky: "Economics, posthumanity, and self-replication (was: MORALITY)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2410.html">natashavita@earthlink.net: "Re: Economics, posthumanity, and self-replication (was: MORALITY)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2390">[ date ]</a>
<a href="index.html#2390">[ thread ]</a>
<a href="subject.html#2390">[ subject ]</a>
<a href="author.html#2390">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:18 MDT</em>
</em>
</small>
</body>
</html>
