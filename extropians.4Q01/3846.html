<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: The Politics of Dancing [was: SPACE/IDEA FUTURE</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The Politics of Dancing [was: SPACE/IDEA FUTURES...]">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: The Politics of Dancing [was: SPACE/IDEA FUTURES...]</h1>
<!-- received="Thu Dec  6 06:55:37 2001" -->
<!-- isoreceived="20011206135537" -->
<!-- sent="Thu, 06 Dec 2001 08:56:51 -0500" -->
<!-- isosent="20011206135651" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The Politics of Dancing [was: SPACE/IDEA FUTURES...]" -->
<!-- id="3C0F7923.C5A3E722@pobox.com" -->
<!-- inreplyto="Pine.LNX.4.10.10112051835270.28641-100000@server.aeiveos.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20Politics%20of%20Dancing%20[was:%20SPACE/IDEA%20FUTURES...]&In-Reply-To=&lt;3C0F7923.C5A3E722@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 06 2001 - 06:56:51 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3847.html">Eliezer S. Yudkowsky: "Re: The Politics of Dancing"</a>
<li><strong>Previous message:</strong> <a href="3845.html">G.P.: "Re: what I envision"</a>
<li><strong>In reply to:</strong> <a href="3836.html">Robert J. Bradbury: "The Politics of Dancing [was: SPACE/IDEA FUTURES...]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3832.html">Robert J. Bradbury: "Re: SPACE/IDEA FUTURES: Is the Pluto Mission a silly idea?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3846">[ date ]</a>
<a href="index.html#3846">[ thread ]</a>
<a href="subject.html#3846">[ subject ]</a>
<a href="author.html#3846">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; There is a post in the queue that I believe addresses some of this.
</em><br>
<em>&gt; But I have to protest the characterization of being a &quot;singularitarian&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I am an extropian.  I would probably classify myself as a &quot;romantic&quot;
</em><br>
<em>&gt; extropian.  So I'm all for the creation of new information but *not* at
</em><br>
<em>&gt; the expense of &quot;old&quot; information.  *I* consider the label &quot;singularitarian&quot;
</em><br>
<em>&gt; to be individuals who value the acceleration of change without considering
</em><br>
<em>&gt; the value of &quot;old&quot; information.  (I'm sure others may differ with definitions
</em><br>
<em>&gt; but we aren't exactly dealing with dictionary term here.)
</em><br>
<p>Yes, but I've never heard that definition before (and here I thought I'd
<br>
heard them all).  Furthermore, it should be obvious that this does not
<br>
reflect the held philosophy of a great many actual Singularitarians, or at
<br>
least, they would not report it so - where Singularitarian is defined
<br>
under either of the two more common definitions, as one who predicts or
<br>
expects a Singularity, or as one who acts so as to bring about a
<br>
Singularity.
<br>
<p>Whether old information is valued is, strictly speaking, quite
<br>
orthogonal.  Although in fact I know of no Singularitarian who assigns
<br>
this a definite value of zero.
<br>
<p><em>&gt; I often reflect upon the quote:
</em><br>
<em>&gt;   &quot;You must give up everything you are for who you might become&quot;.
</em><br>
<em>&gt;    (Sources of this are unclear to me at this time.)
</em><br>
<p>So why attribute it to the entire Singularitarian community?  Especially
<br>
when what binds us together is our common belief that we ought to be doing
<br>
something about the Singularity, rather than our belief about what we plan
<br>
to do afterward?  I may think that someone who plans to spend the next
<br>
million years waterskiing is being silly and has completely failed to get
<br>
the whole point of intelligence enhancement and will almost certainly give
<br>
up this plan once the alternatives become clearer; it doesn't mean that,
<br>
here-and-now, the person can't contribute to the Singularity.
<br>
<p><em>&gt; Instead, I consider:
</em><br>
<em>&gt;   &quot;You should become whatever you can be remembering who you once were.&quot;
</em><br>
<p>Is memory enough?  Never mind, orthogonal issue.
<br>
<p><em>&gt; I'll simply note the lack of a Sysop AI in either of these scenarios.
</em><br>
<em>&gt; (Something I'm sure will draw flak).
</em><br>
<p>Good call.  Why?  Because:
<br>
<p>THE SYSOP SCENARIO HAS NOTHING TO DO WITH THE SINGULARITY.
<br>
THE SYSOP SCENARIO HAS NOTHING TO DO WITH SINGULARITARIANISM.
<br>
THE SYSOP SCENARIO HAS NOTHING TO DO WITH THE SINGULARITY INSTITUTE.
<br>
THE SYSOP SCENARIO HAS NOTHING TO DO WITH FRIENDLY AI.
<br>
<p>Everyone repeat this to themselves until such time as it reverses whatever
<br>
damage I inadvertantly did by blurting out such an unfortunately monikered
<br>
description of A SINGLE POSSIBLE OUTCOME of the Singularity GIVEN A
<br>
CERTAIN SET OF STARTING ASSUMPTIONS.
<br>
<p><em>&gt; In a singularitarian scenario
</em><br>
<em>&gt; there is fundamental question of a democracy of power or a delegation
</em><br>
<em>&gt; of power.  In the former situation everyone gets to evolve as fast as they
</em><br>
<em>&gt; choose to do so, in the later it is a function of the 'overlord(s)' being
</em><br>
<em>&gt; willing to grant favors.
</em><br>
<p>As some of you may have noticed, by this point I've simply given up on the
<br>
Sysop Scenario, the reason being that it apparently cannot be explained to
<br>
a substantial minority of human beings, including Extropian Elders.  Just
<br>
as our visual cortex can be made to interpret nonexistent shapes by
<br>
optical illusions that incorporate a few simple visual cues, there is
<br>
apparently some chunk of brainware somewhere that insists on interpreting
<br>
the Sysop as an extrema of the tribal-chief archetype, regardless of all
<br>
lectures on anthropomorphism.  I am not willing to fight it any more; I
<br>
give up.  It was never necessary to Singularity description in the first
<br>
place and it is not necessary now.
<br>
<p>I will simply confine myself to noting that &quot;in the latter, it is a
<br>
function of the overlord being willing to grant favors&quot; implicitly assumes
<br>
that the probability of the favor being granted is something less than
<br>
100%.  It assumes, in short, that the Sysop behaves like a tribal chief;
<br>
selectively granting favors, either to enforce the return of reciprocal
<br>
favors, or simply for the joy of meddling.  It assumes that the presence
<br>
of an intelligent substrate for reality retards changes because that
<br>
substrate interferes with changes, rather than improving changes because
<br>
that substrate assists with changes.  Above all, it involves the inherent
<br>
human distrust of any mind involved in a transaction, based on our always
<br>
assigning a significant probability of that mind interfering with the
<br>
transaction, which in turn is an evolved instinct resulting from the fact
<br>
that our sole experience of minds is with humans who *do* tend to
<br>
interfere.  When was the last time a law of physics decided to interfere
<br>
with a falling rock?  In time humanity will learn that not all
<br>
minds-in-general are as meddlesome as we, but until then I've given up on
<br>
fighting instinct.
<br>
<p>Otherwise the distinction is simply that between needing to evolve oneself
<br>
using nonsentient technology, and being able to make a much wider range of
<br>
choices about the type and speed of evolution using assistance from a
<br>
sympathetic superintelligence.  Do you really want to try rewiring your
<br>
own neurons?  Well, apparently you do.  But if you do try to go it alone -
<br>
which is, of course, possible under a Sysop Scenario; simply not
<br>
recommended - it is going to impose certain constraints on the directions
<br>
in which you can evolve, just as genuine evolution imposes other
<br>
constraints on the design of the organism.  You would probably get to the
<br>
same place eventually, but your choice of intermediate path - that is, the
<br>
kind and number of steps between humanity and superintelligence - would be
<br>
much more constrained.  
<br>
<p><em>&gt; I'm not an individual who strongly favors &quot;court politics&quot;, so I do
</em><br>
<em>&gt; not consider myself to be a &quot;singularitarian&quot;.
</em><br>
<p>I'm not an individual who strongly favors anthropomorphic descriptions of
<br>
superintelligence, so I'm against the use of the term &quot;court politics&quot;.
<br>
<p><em>&gt; It would be nice if this &quot;realm&quot; of perspectives had a positional
</em><br>
<em>&gt; scale similar to that which Max recently provided regarding &quot;IDENTITY&quot;.
</em><br>
<em>&gt; That would serve to foster productive discussion instead of unproductive
</em><br>
<em>&gt; sniping.
</em><br>
<p>And on it, beliefs about the Sysop Scenario would be totally orthogonal to
<br>
beliefs about the Singularity.  Pardon me; beliefs about the Sysop
<br>
Scenario would be dependent on beliefs about the Singularity, but not vice
<br>
versa.
<br>
<p>But you know what?  Screw it.  It doesn't matter.  Consider the Sysop
<br>
Scenario junked.  Leave the Singularity blank.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3847.html">Eliezer S. Yudkowsky: "Re: The Politics of Dancing"</a>
<li><strong>Previous message:</strong> <a href="3845.html">G.P.: "Re: what I envision"</a>
<li><strong>In reply to:</strong> <a href="3836.html">Robert J. Bradbury: "The Politics of Dancing [was: SPACE/IDEA FUTURES...]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3832.html">Robert J. Bradbury: "Re: SPACE/IDEA FUTURES: Is the Pluto Mission a silly idea?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3846">[ date ]</a>
<a href="index.html#3846">[ thread ]</a>
<a href="subject.html#3846">[ subject ]</a>
<a href="author.html#3846">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:24 MDT</em>
</em>
</small>
</body>
</html>
