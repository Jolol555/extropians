<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Posthuman Politics</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="Re: Posthuman Politics">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Posthuman Politics</h1>
<!-- received="Wed Oct 17 21:35:54 2001" -->
<!-- isoreceived="20011018033554" -->
<!-- sent="Wed, 17 Oct 2001 20:32:30 -0700" -->
<!-- isosent="20011018033230" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="Re: Posthuman Politics" -->
<!-- id="012701c15785$87b90100$0c5c2a42@jrmolloy" -->
<!-- inreplyto="Pine.GSO.4.32.0110162203130.2925-100000@jane.itd.umich.edu" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20Posthuman%20Politics&In-Reply-To=&lt;012701c15785$87b90100$0c5c2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Wed Oct 17 2001 - 21:32:30 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1155.html">Ralph Lewis: "Re: Mass Media target of Anthrax-terrorism!"</a>
<li><strong>Previous message:</strong> <a href="1153.html">Adrian Tymes: "Re: Humans doomed without space colonies, says Hawking"</a>
<li><strong>In reply to:</strong> <a href="1042.html">Alex F. Bokov: "Re: Posthuman Politics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0862.html">Steve Nichols: "Re: Posthuman Politics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1154">[ date ]</a>
<a href="index.html#1154">[ thread ]</a>
<a href="subject.html#1154">[ subject ]</a>
<a href="author.html#1154">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
From: &quot;Alex F. Bokov&quot; &lt;<a href="mailto:alexboko@umich.edu?Subject=Re:%20Posthuman%20Politics&In-Reply-To=&lt;012701c15785$87b90100$0c5c2a42@jrmolloy&gt;">alexboko@umich.edu</a>&gt;
<br>
<em>&gt; Executive summary: corporations and governments (I'll charitably call
</em><br>
<em>&gt; them collective intelligences, or CIs) are a model system for how
</em><br>
<em>&gt; humans can coexist with AI. Want to make AI friendly? Come up with
</em><br>
<em>&gt; a way to make CIs friendly, and you'll have something resembling a
</em><br>
<em>&gt; game plan.
</em><br>
<p>Friendly? Perhaps...
<br>
but I'd settle for sane AI.
<br>
<p>Speaking of collective intelligence, here's some background:
<br>
<p>Collective Intelligence
<br>
<a href="http://ic.arc.nasa.gov/projects/COIN">http://ic.arc.nasa.gov/projects/COIN</a>
<br>
There are many information-processing problems that can only be solved by the
<br>
joint action of large communities of computers each running a sophisticated
<br>
machine learning algorithm, where those algorithms are not subject to
<br>
centralized, global control. Examples are routing of air traffic, control of
<br>
swarms of spacecraft, routing of packets across the internet, and
<br>
communication between the multiple processors in a modern computer. There are
<br>
also many instances of natural systems that address such problems. Examples
<br>
here are ecosystems, economies, the organelles within a living cell.
<br>
<p>Such problems can be addressed with the emerging science of ``COllective
<br>
INtelligence'' (COIN), which is concerned with the design of a multi-agent
<br>
system where:
<br>
<p>Agents are ``selfish'' in that they act to try to optimize their own
<br>
utilities, without explicit regard to cooperation with other agents.
<br>
There is a well-specified global objective, and we are confronted with the
<br>
inverse problem of how to configure the system to achieve that objective.
<br>
In particular, we are interested in such collectives in which each agent runs
<br>
a reinforcement learning (RL) algorithm. Rather than use a conventional
<br>
modeling approach (e.g., model the system dynamics, and hand-tune agents to
<br>
cooperate), we aim to solve the problem of collective design problem
<br>
implicitly, via the ``adaptive'' character of the RL algorithms of each of the
<br>
agents. This approach introduces an entirely new, profound design problem:
<br>
Assuming the RL algorithms are able to achieve high rewards, what reward
<br>
functions for the individual agents will, when pursued by those agents, result
<br>
in high world utility? In other words, what reward functions will best ensure
<br>
that we do not have phenomena like the tragedy of the commons, Braess's
<br>
paradox, or the liquidity trap?
<br>
<p>Although still very young, research specifically concentrating on this design
<br>
problem has already resulted in successes in artificial domains, in particular
<br>
in packet-routing, the leader-follower problem, and in variants of Arthur's El
<br>
Farol bar problem. It is expected that as it matures and draws upon other
<br>
disciplines related to collective design, this research will greatly expand
<br>
the range of tasks addressable by human engineers. Moreover, in addition to
<br>
drawing on them, such a fully developed field of collective intelligence may
<br>
provide insight into other already established scientific fields, such as
<br>
mechanism design, economics, game theory, and population biology.
<br>
<p><pre>
---
<p>See also:
Adaptive Intelligent Systems
<a href="http://www.ksl.stanford.edu/projects/AIS/">http://www.ksl.stanford.edu/projects/AIS/</a>
<p>David Wolpert and Kagan Tumer
&quot;Avoiding Braess' Paradox through Collective Intelligence,&quot; (in review). Tech
Report NASA-ARC-IC-99-124. Abstract . postscript (640 Kb), pdf (300 Kb).
<p><p>David Wolpert, Sergey Kirshner, Chris Merz and Kagan Tumer
&quot;Adaptivity in Agent-Based Routing for Data Networks,&quot; Fourth International
Conference on Automomous Agents , Barcelona, Spain, June 2000 (to appear). pdf
(170 Kb).
<p><p>David Wolpert and Kagan Tumer,
&quot;An Introduction to Collective Intelligence,&quot; Tech Report NASA-ARC-IC-99-63.(A
shorter version of this paper is to appear in: Jeffrey M. Bradshaw, editor,
Handbook of Agent Technology, AAAI Press/MIT Press, 1999). Abstract,
postscript (1.4 MB), pdf (715 Kb).
<p><p>David Wolpert, Kevin Wheeler and Kagan Tumer,
&quot;Collective Intelligence for Control of Distributed Dynamical Systems,&quot;
Europhysics Letters , Vol. 49, No. 6, March 2000. pdf (190 Kb).
<p><p>David H. Wolpert, Mike H. New, and Ann M. Bell,
``Distorting Reward Functions to Improve Reinforcement Learning,'' (in
review). Tech Report NASA-ARC-IC-99-71. Abstract, postscript (570 Kb), pdf
(120 Kb).
<p><p>David Wolpert, Kevin Wheeler and Kagan Tumer,
``General Principles of Learning-Based Multi-Agent Systems,'' Third
International Conference on Automomous Agents , pp. 77-83, Seattle, WA, May
1999. Abstract, postscript (520 Kb), pdf (230 Kb).
<p><p>David H. Wolpert, Kagan Tumer, and Jeremy Frank,
``Using Collective Intelligence to Route Internet Traffic,'' Advances in
Neural Information Processing Systems-11, pp. 952-958, Denver, CO, December
1998. Abstract, postscript (300 Kb), pdf (125 Kb).
<p><p>C. Ronald Kube and Hong Zhang
&quot;Collective Robotic Intelligence &quot; Abstract, postscript, pdf.
<p>---   ---   ---   ---   ---
<p>Useless hypotheses, etc.:
 consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
uniqueness, ego, human values, scientific relinquishment
<p>We  move into a better future in proportion as science displaces superstition.
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1155.html">Ralph Lewis: "Re: Mass Media target of Anthrax-terrorism!"</a>
<li><strong>Previous message:</strong> <a href="1153.html">Adrian Tymes: "Re: Humans doomed without space colonies, says Hawking"</a>
<li><strong>In reply to:</strong> <a href="1042.html">Alex F. Bokov: "Re: Posthuman Politics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0862.html">Steve Nichols: "Re: Posthuman Politics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1154">[ date ]</a>
<a href="index.html#1154">[ thread ]</a>
<a href="subject.html#1154">[ subject ]</a>
<a href="author.html#1154">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:14 MDT</em>
</em>
</small>
</body>
</html>
