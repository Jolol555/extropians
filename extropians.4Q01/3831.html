<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: stats folding@home team #346</title>
<meta name="Author" content="Robert J. Bradbury (bradbury@aeiveos.com)">
<meta name="Subject" content="Re: stats folding@home team #346">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: stats folding@home team #346</h1>
<!-- received="Wed Dec  5 18:59:22 2001" -->
<!-- isoreceived="20011206015922" -->
<!-- sent="Wed, 5 Dec 2001 17:59:20 -0800 (PST)" -->
<!-- isosent="20011206015920" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@aeiveos.com" -->
<!-- subject="Re: stats folding@home team #346" -->
<!-- id="Pine.LNX.4.10.10112051758360.28641-100000@server.aeiveos.com" -->
<!-- inreplyto="stats folding@home team #346" -->
<strong>From:</strong> Robert J. Bradbury (<a href="mailto:bradbury@aeiveos.com?Subject=Re:%20stats%20folding@home%20team%20#346&In-Reply-To=&lt;Pine.LNX.4.10.10112051758360.28641-100000@server.aeiveos.com&gt;"><em>bradbury@aeiveos.com</em></a>)<br>
<strong>Date:</strong> Wed Dec 05 2001 - 18:59:20 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3832.html">Robert J. Bradbury: "Re: SPACE/IDEA FUTURES: Is the Pluto Mission a silly idea?"</a>
<li><strong>Previous message:</strong> <a href="3830.html">E. Shaun Russell: "List Problems"</a>
<li><strong>Maybe in reply to:</strong> <a href="3804.html">Smigrodzki, Rafal: "stats folding@home team #346"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3831">[ date ]</a>
<a href="index.html#3831">[ thread ]</a>
<a href="subject.html#3831">[ subject ]</a>
<a href="author.html#3831">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
On Tue, 4 Dec 2001, Smigrodzki, Rafal wrote:
<br>
<p><em>&gt; ### I had some problems with Folding@home - the machine started warning
</em><br>
<em>&gt; about low virtual memory and crashed. I am not authorized to increase the
</em><br>
<em>&gt; paging file (now it's at 70MB), so I had to uninstall it. I still have it
</em><br>
<em>&gt; running on a couple of other computers (it's the kaufneuro7 team member) but
</em><br>
<em>&gt; I wonder if the program could put too much of a load on the LAN. Any advice?
</em><br>
<p>Rafal -- you should seriously talk to whomever the system managers are
<br>
about increasing the paging file size.  I assume you are running NT.
<br>
If so, that is way too small a size for any real work.  Its probably
<br>
too small for even '95 or '98.
<br>
<p>I can get my Netscape process size under NT up to 50-60 MB on the
<br>
task manager (if I run it for a week or so and work with 40-60
<br>
windows).  IE will push up into the 10-30 MB range, Acrobat can
<br>
be a pig at times as well.  Add in all the other processes and
<br>
shared libraries and you need to be up around 128-256 MB of paging
<br>
space for &quot;real work&quot; (yea, I remember dose days when weal men
<br>
could do weal work in 64KB but da people writing code now-a-days
<br>
are *soooo* slappy).  I bumped my machines to 256MB of main memory
<br>
and 512MB of paging space long ago when I kept hitting a limit
<br>
that prevented new windows from being opened.  Turned out its
<br>
a stupid hardwired limit in NT that Microsoft probably won't
<br>
fix for a year or two -- but I digress.
<br>
<p>It looks to me like under NT, its taking 4-5 MB of memory while
<br>
on Linux its more like 6-8 MB, perhaps due to a lack of accounting
<br>
for dynamically loaded libraries under NT (I've been told the NT
<br>
task manager sizes do not accurately reflect the real process size).
<br>
<p>I can watch my LAN activity and it looks like that isn't an issue.
<br>
I had assumed that doing this would require a lot of net traffic
<br>
but apparently that isn't the way it works.  They seem to
<br>
download a work unit (perhaps its a small fragment of the protein)
<br>
do a lot of computing on it, checkpointing as they go.  Perhaps
<br>
this is just modeling the folding of that fragment.  Then when
<br>
the unit is done (after 1-6 days), they load the results back up
<br>
to Stanford and fetch the next Work Unit.  Very little net overhead
<br>
at all.  I think they periodically retry net access to download or
<br>
upload Work Units so it actually works with the machines offline
<br>
from the net.  It may be they have a larger &quot;overlord&quot; program
<br>
at Stanford that stiches individual Work Units back together to
<br>
get a complete picture.
<br>
<p>[At least that is my impression so far.]
<br>
<p>Robert
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3832.html">Robert J. Bradbury: "Re: SPACE/IDEA FUTURES: Is the Pluto Mission a silly idea?"</a>
<li><strong>Previous message:</strong> <a href="3830.html">E. Shaun Russell: "List Problems"</a>
<li><strong>Maybe in reply to:</strong> <a href="3804.html">Smigrodzki, Rafal: "stats folding@home team #346"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3831">[ date ]</a>
<a href="index.html#3831">[ thread ]</a>
<a href="subject.html#3831">[ subject ]</a>
<a href="author.html#3831">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:24 MDT</em>
</em>
</small>
</body>
</html>
