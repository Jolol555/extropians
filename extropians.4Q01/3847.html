<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: The Politics of Dancing</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The Politics of Dancing">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: The Politics of Dancing</h1>
<!-- received="Thu Dec  6 07:01:49 2001" -->
<!-- isoreceived="20011206140149" -->
<!-- sent="Thu, 06 Dec 2001 09:03:13 -0500" -->
<!-- isosent="20011206140313" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The Politics of Dancing" -->
<!-- id="3C0F7AA1.52209CA8@pobox.com" -->
<!-- inreplyto="The Politics of Dancing" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20Politics%20of%20Dancing&In-Reply-To=&lt;3C0F7AA1.52209CA8@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 06 2001 - 07:03:13 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3848.html">Curious: "Re: Fwd: Lanier essay of 2001.12.04"</a>
<li><strong>Previous message:</strong> <a href="3846.html">Eliezer S. Yudkowsky: "Re: The Politics of Dancing [was: SPACE/IDEA FUTURES...]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3850.html">Robert J. Bradbury: "Re: The Politics of Dancing"</a>
<li><strong>Reply:</strong> <a href="3850.html">Robert J. Bradbury: "Re: The Politics of Dancing"</a>
<li><strong>Maybe reply:</strong> <a href="3853.html">Brian D Williams: "Re: The Politics of Dancing"</a>
<li><strong>Maybe reply:</strong> <a href="3859.html">hal@finney.org: "Re: The Politics of Dancing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3847">[ date ]</a>
<a href="index.html#3847">[ thread ]</a>
<a href="subject.html#3847">[ subject ]</a>
<a href="author.html#3847">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Damien Broderick wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; At 07:03 PM 12/5/01 -0800, Robert wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;I'm not an individual who strongly favors &quot;court politics&quot;, so I do
</em><br>
<em>&gt; &gt;not consider myself to be a &quot;singularitarian&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Apologies for using the wrong word there: I know that Eliezer and his
</em><br>
<em>&gt; colleagues have appropriated this term.
</em><br>
<p>For the record, it was appropriated with the permission of Mark Plus, the
<br>
original inventor.  And it was redefined simply to mean &quot;Singularity
<br>
activist&quot; rather than &quot;Singularity expecter&quot;.
<br>
&nbsp;
<br>
<em>&gt; On the matter of whether Sysops and other less congenial forms of what I've
</em><br>
<em>&gt; lately suggested calling Custodians or Stewards would have the odious
</em><br>
<em>&gt; characteristics you ascribe to them, Eliezer repudiated this suggestion on
</em><br>
<em>&gt; SL4. I hope he might cc. that post to the extropian list so all may munch
</em><br>
<em>&gt; on its nutrients.
</em><br>
<p>Okey dokey.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>

<br><p><strong>attached mail follows:</strong><hr noshade>
<p>
Damien Broderick wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I wasn't *really* suggesting `Prefect', you understand (although it amuses
</em><br>
<em>&gt; me that it's an anagram of `Perfect'); I was gesturing toward the nature of
</em><br>
<em>&gt; the beast under discussion. `Monitor' is another possibility; as are
</em><br>
<em>&gt; `Custodian', `Protector' and `Steward'. The last of these is perhaps the
</em><br>
<em>&gt; most general and least offensive... although the idea itself remains rather
</em><br>
<em>&gt; offensive however it's parsed.
</em><br>
<p>Doesn't that last remark say it all...
<br>
<p>If you think the idea has offensive consequences, you're going to pick a
<br>
term that has connotations that remind you of those offensive
<br>
consequences.  Thus, from our perspective, short-circuiting the process of
<br>
rational argument, which should start with a morally neutral term
<br>
describing what the hypothesis *is*.
<br>
<p>A Sysop is not a Prefect, Monitor, Custodian, Protector, or Steward.  At
<br>
most it might be a Protector, and the reason this term is salvageable is
<br>
that a &quot;protector&quot; does not specify how something is being protected, or
<br>
for what motive; the other terms all have specific connotations of
<br>
political and moral authority in a human social context.
<br>
<p>The Sysop is not a human mind.  If it were, most of this would be nonsense
<br>
and the rest would be actively dangerous.  This is something that becomes
<br>
possible only when you step outside the realm of evolved minds and start
<br>
considering what a mind-in-general can be asked to do.  If you import
<br>
terms that have specific connotations and meanings in the context of human
<br>
society, you are anthropomorphizing the whole situation; you have sucked
<br>
all the interestingly alien aspects out of it.
<br>
<p>In this sense, Gordon Worley's Unix Scenario, in which &quot;root&quot; is not a
<br>
*conscious* process, is psychologically superior to the Sysop Scenario; it
<br>
is less likely to be confused with human ideas of gods, fathers, and other
<br>
extrema of the &quot;tribal chief&quot; concept.  Unfortunately I also think the
<br>
Unix Scenario version is less plausible, but that's a separate issue.
<br>
<p>Humans have a phobia of minds, which unfortunately extends from human
<br>
minds (where it is justified) to minds in general (since no other mind
<br>
types were encountered in the ancestral environment).  Someone looking
<br>
over Gordon Worley's Unix Scenario says &quot;Hm, underlying reality works
<br>
according to certain definite physical rules; there are no minds here; I'm
<br>
probably safe.&quot;  Someone in a Sysop Scenario is just as likely to be safe,
<br>
but the human instincts look over the Sysop Scenario and say:  &quot;There is a
<br>
mind here; that mind is likely to act against me,&quot; or even worse, &quot;There
<br>
is a mind here; this mind is an extrema of concept tribal-chief;
<br>
therefore, this mind will boss me around.&quot;  The motivations of a nonhuman
<br>
superintelligence that does not *want* to boss you around can be just as
<br>
solid a safeguard as an absolute physical impossibility of interference. 
<br>
The fact that your sexual habits are of absolutely no concern to the
<br>
singleton substrate mean that your midnight assignations might as well be
<br>
outside the light cone of the solar system; the only difference is that
<br>
nobody else can interfere with you either.
<br>
<p>Outside the human realm, dealing with real extremes of cognition instead
<br>
of imagined extremes of social categories, superintelligent motivations
<br>
can be just as solid and impartial as physical law.  Maybe, to reflect
<br>
this, we should skip both Sysop Scenario and Unix Reality and go straight
<br>
to discussing Michael Anissimov's ontotechnology scenarios.  For some
<br>
reason there's a rule that says you can't hurt someone without their
<br>
consent.  Is it because the Sysop predicts a violation of volition? 
<br>
Because the low-level rules of Unix Reality don't permit the physical
<br>
interaction?  Because, back in the dawn of the Singularity, the first
<br>
Friendly SI made some quiet adjustments to the laws of physics?  Because
<br>
of something entirely unimaginable?  What difference does it really make,
<br>
except to human psychology?
<br>
<p>If it's theoretically possible for transhumans to retain motivations that
<br>
would make them hostile toward other transhumans, then a possible problem
<br>
exists of transhuman war or even transhuman existential catastrophe; but,
<br>
there exists at least one comprehensible proposed solution to this
<br>
problem, and it is therefore disingenuous to present it as unsolvable. 
<br>
Maybe totally unrestricted technology for everyone in the universe,
<br>
including humans who've refused intelligence enhancement and still have
<br>
their original emotional architectures, won't threaten the welfare of one
<br>
single sentient being, for reasons we can't now understand.  But if not,
<br>
we know what to do about it.  That's all.
<br>
<p>The utility of discussing the Sysop Scenario is this: that we retain the
<br>
ability to say &quot;There are no known unsolvable problems between us and the
<br>
Singularity&quot;.  Nothing more.  It's a *prediction*, not a *decision*;
<br>
whether Unix/Sysop/whatever is actually needed would be up to the first
<br>
Friendly SI.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3848.html">Curious: "Re: Fwd: Lanier essay of 2001.12.04"</a>
<li><strong>Previous message:</strong> <a href="3846.html">Eliezer S. Yudkowsky: "Re: The Politics of Dancing [was: SPACE/IDEA FUTURES...]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3850.html">Robert J. Bradbury: "Re: The Politics of Dancing"</a>
<li><strong>Reply:</strong> <a href="3850.html">Robert J. Bradbury: "Re: The Politics of Dancing"</a>
<li><strong>Maybe reply:</strong> <a href="3853.html">Brian D Williams: "Re: The Politics of Dancing"</a>
<li><strong>Maybe reply:</strong> <a href="3859.html">hal@finney.org: "Re: The Politics of Dancing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3847">[ date ]</a>
<a href="index.html#3847">[ thread ]</a>
<a href="subject.html#3847">[ subject ]</a>
<a href="author.html#3847">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Sat May 11 2002 - 17:44:24 MDT</em>
</em>
</small>
</body>
</html>
