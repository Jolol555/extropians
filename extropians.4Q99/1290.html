<!-- received="Sun Oct 24 22:06:16 1999 MST" -->
<!-- sent="Sun, 24 Oct 1999 23:09:31 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Preventing AI Breakout [was Genetics, nannotechnology, and" -->
<!-- id="3813D7F9.E038DEF@pobox.com" -->
<!-- inreplyto="Preventing AI Breakout [was Genetics, nannotechnology, and" -->
<!-- version=1.10, linesinbody=19 -->
<html><head><title>extropians: Re: Preventing AI Breakout [was Genetics, nannotechnology, and</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Preventing AI Breakout [was Genetics, nannotechnology, and</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 24 Oct 1999 23:09:31 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1290">[ date ]</a><a href="index.html#1290">[ thread ]</a><a href="subject.html#1290">[ subject ]</a><a href="author.html#1290">[ author ]</a>
<!-- next="start" -->
<li><a href="1291.html">[ Next ]</a><a href="1289.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1285.html">Joseph Sterlynne</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1304.html">Robert J. Bradbury</a>
</ul>
<!-- body="start" -->

<p>
<a name="1304qlink1">Joseph Sterlynne wrote:
<br>
<i>&gt; </i><br>
<a href="1285.html#1290qlink1">&gt; It seems that everyone is confident that an AI of sufficient intelligence</a><br>
<i>&gt; will be able to discover that it exists within a simulation.</a>  This is a</i><br>
<i>&gt; little surprising.  I won't say that we could absolutely guarantee its</i><br>
<i>&gt; eternal ignorance but I don't see why an AI would not simply accept the</i><br>
<i>&gt; laws of its environment as the laws of a nonconstructed universe.</i><br>

<p>
<a name="1304qlink2"><a name="1292qlink1">Maybe it'd accept the laws of physics, if it wasn't smart enough to
engage in a-priori ontological reasoning.  But how is the AI supposed to
accept itself?  We all know that the human body and human mind are the
result of evolution, right?  Conscious design would be just as obvious
to the AI.</a></a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1291.html">[ Next ]</a><a href="1289.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1285.html">Joseph Sterlynne</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="1304.html">Robert J. Bradbury</a>
</ul>
</body></html>
