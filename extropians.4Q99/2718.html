<!-- received="Sun Nov 28 12:37:36 1999 MST" -->
<!-- sent="28 Nov 99 19:38:54 GMT" -->
<!-- name="bbrown@transcient.com" -->
<!-- email="bbrown@transcient.com" -->
<!-- subject="Re: [Re: NANO: Custom molecules (gulp!)]" -->
<!-- id="19991128193854.17026.qmail@pb151.postoffice.net" -->
<!-- inreplyto="[Re: NANO: Custom molecules (gulp!)]" -->
<!-- version=1.10, linesinbody=25 -->
<html><head><title>extropians: Re: [Re: NANO: Custom molecules (gulp!)]</title>
<meta name=author content="bbrown@transcient.com">
<link rel=author rev=made href="mailto:bbrown@transcient.com" title ="bbrown@transcient.com">
</head><body>
<h1>Re: [Re: NANO: Custom molecules (gulp!)]</h1>
<i>bbrown@transcient.com</i><br>
<i>28 Nov 99 19:38:54 GMT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2718">[ date ]</a><a href="index.html#2718">[ thread ]</a><a href="subject.html#2718">[ subject ]</a><a href="author.html#2718">[ author ]</a>
<!-- next="start" -->
<li><a href="2719.html">[ Next ]</a><a href="2717.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2701.html">D.den Otter</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
"D.den Otter" &lt;neosapient@geocities.com&gt; wrote:
<br>
<a href="2701.html#2718qlink1">&gt; Better ask some "neutral" third party (he's rather biased, you</a><br>
<i>&gt; know, and of course so am I).</i><br>

<p>
As a relatively neutral (if somewhat opinionated) third party, I'd have to say
that this debate misses the point.

<p>
If Eli's seed AI scenario is possible at all, no choice we make can possibly
prevent it from happening.  The first SI will emerge decades before human
uploading is possible, and the only real question is what it will evolve from.
 You only need around a TeraFLOPS for human-equivalent hardware, and we've
built that already (the first PeraFLOPS machine is expected to be operational
around 2006-2008).

<p>
If, OTOH, exponential self-improvement is not possible unless you are already
well beyond human intelligence levels, neither the seed AI nor an upload is
going to be an instant demigod.  Instead we'll be stuck with several decades
of gradual, society-wide augmentation and (probably) the eventual ascention of
a significant fraction of the population.  The major risk here is the
instability of a society with immature nanotech, and the best insurance policy
is to look for ways to reduce the risk of genocidal nanowars.

<p>
Billy Brown, MCSE+I
<br>
bbrown@transcient.com
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2719.html">[ Next ]</a><a href="2717.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2701.html">D.den Otter</a>
<!-- nextthread="start" -->
</ul>
</body></html>
