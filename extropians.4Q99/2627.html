<!-- received="Fri Nov 26 08:16:20 1999 MST" -->
<!-- sent="Fri, 26 Nov 1999 07:16:27" -->
<!-- name="E. Shaun Russell" -->
<!-- email="e_shaun@uniserve.com" -->
<!-- subject="Re: Objective morality" -->
<!-- id="3.0.6.16.19991126071627.3f4f3466@pop.uniserve.com" -->
<!-- inreplyto="002801bf37d8$3d9fa700$18b84d0c@flrjs" -->
<!-- version=1.10, linesinbody=32 -->
<html><head><title>extropians: Re: Objective morality</title>
<meta name=author content="E. Shaun Russell">
<link rel=author rev=made href="mailto:e_shaun@uniserve.com" title ="E. Shaun Russell">
</head><body>
<h1>Re: Objective morality</h1>
E. Shaun Russell (<i>e_shaun@uniserve.com</i>)<br>
<i>Fri, 26 Nov 1999 07:16:27</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2627">[ date ]</a><a href="index.html#2627">[ thread ]</a><a href="subject.html#2627">[ subject ]</a><a href="author.html#2627">[ author ]</a>
<!-- next="start" -->
<li><a href="2628.html">[ Next ]</a><a href="2626.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2619.html">John Clark</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
John Clark wrote:

<p>
<a href="2619.html#2627qlink1">&gt;Suppose the existence of objective morality is Turing unprovable, that means</a><br>
<i>&gt;it exists so you'll never find a counterexample to show it doesn't but it</i><br>
<i>&gt;also means you'll never find a proof (a demonstration in a finite number</i><br>
of &gt;steps) to show that it does. A moralist who designs a AI and gives the
<br>
<a href="2619.html#2627qlink2">&gt;investigation of this problem priority over everything else will send the</a><br>
<i>&gt;machine into a infinite loop.  To make maters worse, you may not even be</i><br>
able &gt;to prove it's futile, that the issue is either false or true but
unprovable, &gt;so I don't think it would be wise to hardwire a AI to keep
working on any &gt;problem until an answer is found.

<p>
	An alternate way of looking at it is how people try to instill objective
morality into their progeny, essentially programming them.  It is easy for
a parent to say that "killing people is bad, helping people is good,"
though circumstances dictate that there are occasions when people need to
be killed (in self defense etc.) and when others shouldn't be helped.  No
matter how complex the morality appears to be, there seem to be exceptions
to the alleged "objectivity."<a name="2631qlink1">  The same, of course, is true of AI; if
someone tried to program objective morality into an AI, the lack of
flexibile rationality and reasoning based on situations would likely still
resemble "just a computer" whether Turing proven or otherwise.</a>


<hr>
<pre>
E. Shaun Russell	Extropian, Musician, ExI Member
e_shaun@uniserve.com	 &lt;KINETICIZE *YOUR* POTENTIAL&gt;
-------------------------------------------------------

"The reason I'm involved with Extropy...is to end the carnage."
				      -Robert Bradbury, Extro-4
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2628.html">[ Next ]</a><a href="2626.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2619.html">John Clark</a>
<!-- nextthread="start" -->
</ul>
</body></html>
