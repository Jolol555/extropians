<!-- received="Sun Dec 12 17:29:32 1999 MST" -->
<!-- sent="Sun, 12 Dec 1999 19:28:54 EST" -->
<!-- name="Kate Riley" -->
<!-- email="kate_riley7@hotmail.com" -->
<!-- subject="Re: purpose of AIs" -->
<!-- id="19991213002854.99474.qmail@hotmail.com" -->
<!-- inreplyto="purpose of AIs" -->
<!-- version=1.10, linesinbody=27 -->
<html><head><title>extropians: Re: purpose of AIs</title>
<meta name=author content="Kate Riley">
<link rel=author rev=made href="mailto:kate_riley7@hotmail.com" title ="Kate Riley">
</head><body>
<h1>Re: purpose of AIs</h1>
Kate Riley (<i>kate_riley7@hotmail.com</i>)<br>
<i>Sun, 12 Dec 1999 19:28:54 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3719">[ date ]</a><a href="index.html#3719">[ thread ]</a><a href="subject.html#3719">[ subject ]</a><a href="author.html#3719">[ author ]</a>
<!-- next="start" -->
<li><a href="3720.html">[ Next ]</a><a href="3718.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3716.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a href="3716.html#3719qlink1">&gt;The goal of AIs is to create something substantially smarter than a</a><br>
<i>&gt;human in all domains, from science to philosophy, so that there's no</i><br>
<i>&gt;question of who judges the AI to be intelligent; the AI is a better</i><br>
<i>&gt;judge than we are.</i><br>
<i>&gt;</i><br>
<i>&gt;The purpose of AI is to create something substantially smarter than</i><br>
<i>&gt;human, bringing about the next step into the future - the first truly</i><br>
<i>&gt;substantial step since the rise of the Cro-Magnons - and ending human</i><br>
<i>&gt;history before it gets ugly (nanotechnological warfare, et cetera).  We</i><br>
<i>&gt;don't really know what comes after that, because the AIs are smarter</i><br>
<i>&gt;than we are; if we knew what they'd do, we'd be that smart ourselves.</i><br>
<i>&gt;But it's probably better than sticking with human minds until we manage</i><br>
<i>&gt;to blow ourselves up.</i><br>

<p>
<a name="3722qlink1">I must admit that this puzzles me.<a name="3723qlink1">  If we create such a thing and always 
assume that it is the best judge in all situations, how do we know when it 
</a>is mistaken?<a name="3723qlink2">  What happens if the AI decides, in its expanisve wisdom (or 
perhaps in one of its inevitable flaws), that the human race should not 
exist, and decides to pull the plug?</a>  Would you fight it?  Or decide that 
<a name="3723qlink3">since the AI is smarter than you, it must be right, and willingly lay down 
your life for the "greatest good"?</a></a>

<p>
Kathryn Riley

<hr>
<br>
Get Your Private, Free Email at <a href="http://www.hotmail.com">http://www.hotmail.com</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3720.html">[ Next ]</a><a href="3718.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3716.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
