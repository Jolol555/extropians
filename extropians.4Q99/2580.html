<!-- received="Wed Nov 24 18:46:20 1999 MST" -->
<!-- sent="Wed, 24 Nov 1999 20:45:36 EST" -->
<!-- name="Delvieron@aol.com" -->
<!-- email="Delvieron@aol.com" -->
<!-- subject="Re: AI and Asimov's Laws" -->
<!-- id="0.eedcc063.256deec0@aol.com" -->
<!-- inreplyto="AI and Asimov's Laws" -->
<!-- version=1.10, linesinbody=89 -->
<html><head><title>extropians: Re: AI and Asimov's Laws</title>
<meta name=author content="Delvieron@aol.com">
<link rel=author rev=made href="mailto:Delvieron@aol.com" title ="Delvieron@aol.com">
</head><body>
<h1>Re: AI and Asimov's Laws</h1>
<i>Delvieron@aol.com</i><br>
<i>Wed, 24 Nov 1999 20:45:36 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2580">[ date ]</a><a href="index.html#2580">[ thread ]</a><a href="subject.html#2580">[ subject ]</a><a href="author.html#2580">[ author ]</a>
<!-- next="start" -->
<li><a href="2581.html">[ Next ]</a><a href="2579.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2577.html">Dan Fabulich</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2586.html">Dan Fabulich</a>
</ul>
<!-- body="start" -->

<p>
In a message dated 99-11-24 18:55:51 EST, you write:

<p>
<a href="2577.html#2580qlink1">&lt;&lt; 'What is your name?'  'Delvieron@aol.com.'  'IT DOESN'T MATTER WHAT YOUR</a><br>
 NAME IS!!!':&gt;&gt;

<p>
<a name="2586qlink1">No, my name is Glen Raymond Finney.  And it does matter to me&lt;g&gt;.  I've never 
been able to figure out exactly what this intro of yours means.  One thing 
</a>
that I do know is, it is a little bothersome to be addressed by a yell.  Now 
on to what really matters.
 
<p>
 &lt;&lt;I strongly doubt that anything we'd call "intelligent" could be built in a
 non-upgrading manner.&gt;&gt;

<p>
<a name="2586qlink2">I believe we may be thinking of different things when we use the term 
upgrading.  I am talking about being able to change the physical parameters 
of how the "brain" works in order to improve function, as opposed to being 
able to add information and remember optimal strategies that are within the 
current parameters.  Even humans are not yet able to really upgrade our 
intelligence....optimize it, yes, but nothing that would increase it 
substantially.  If we did, then we would have less concern about bootstrap 
AIs, because we would be bootstrapping humans.  Think about it.  Has there 
been any improvement between humans today and, say, humans in Hellenic Greece?</a>

<p>
<a href="2577.html#2580qlink2">&lt;&lt;Would you call a thing intelligent if it could not</a><br>
 change its own behavior in response to stimuli?&gt;&gt;

<p>
Nope.  But I'm not saying that it couldn't change its behavior in response to 
stimuli, only that the range of behaviors could be constrained to a preset 
range.  Heck, most humans are constrained in the kinds of behaviors they will 
generate based on personality traits.  And it is very hard to modify 
personality in humans (not imposible, though, in that way we would have more 
flexibility than constrained AIs).
  
<p>
<a href="2577.html#2580qlink3">&lt;&lt;If it could not (at least apparently) revise its own beliefs in response to </a><br>
what it observes?&gt;&gt;

<p>
I've unfortunately met some reasonably intelligent, closed-minded people in 
my life.  It does tend to limit the full potential of their intellect, but 
does not change the fact that they are intelligent.
 
<p>
 &lt;&lt;Imagine something like this trying to pass the Turing Test:
 
<p>
 You:  My favorite color is red.  What's your favorite color?
 AI:  My favorite color is green.
<br>
 You:  What's my favorite color?
<br>
 AI:  I don't know.&gt;&gt;

<p>
<a name="2583qlink1">This is not what I envision as a non-upgrading AI.  First, a non-upgrading AI 
would have little or no conscious control over its own programming.  It could 
respond to environmental stimuli, formulate behaviors based on its 
motivational parameters, and implement those behaviors.  This is basically 
what humans do.  Technically, such an AI could possibly learn about itself, 
if creative enough figure out a way to improve itself, then find some tools 
and do it (if it could remain active while making modifications).  This would 
be no different than you or me.  However, it might never do so if we program 
it to have an aversion to consciously tinkering with its internal functions 
except for repairs.  This would be in my estimation a non-upgrading AI.</a>
 
<p>
Now then, an upgrading AI would likely start out with an intrinsic knowledge 
of its internal structure, maybe even be able to be conscious of how it 
processes information and be able to change internal architecture simply by 
willing it.  This would be different from the way humans operate.  And more 
importantly, the upgrading AI would have a motivational drive to improve its 
capabilities, at least in the seed AI (for, of course, the upgrading AI can 
and would consider altering all its functions even the drive to improve 
function).
 
<p>
<a href="2577.html#2580qlink4">&lt;&lt;Analogies to Alzheimer's patents aside, we can quickly see what sort of</a><br>
 limitations "non-upgrading" AIs would be under.  We might, at best, hope
 to build some kind of non-upgrading idiot savant, but not an A*I*.
 
<p>
 The I is important.  ;)&gt;&gt;

<p>
Intelligence is important, but so is inclination and ability.
 
<p>
 &lt;&lt;-Dan&gt;&gt;

<p>
'What is your name?'  'Dan'  'It doesn't matter what your name is...or does 
it?'
 
<pre>
  &lt;&lt;     -unless you love someone-
     -nothing else makes any sense-
            e.e. cumming.  &gt;&gt;


</pre>
<p>
<a name="2586qlink3">BTW, great ee cumming quote.</a>

<p>
Glen Raymond Finney
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2581.html">[ Next ]</a><a href="2579.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2577.html">Dan Fabulich</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2586.html">Dan Fabulich</a>
</ul>
</body></html>
