<!-- received="Sun Nov 21 10:03:42 1999 MST" -->
<!-- sent="Sun, 21 Nov 1999 11:07:28 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Is vs. Ought (was: A Physicist Experiments With CulturalStudies)" -->
<!-- id="383826CE.5E1F94AA@pobox.com" -->
<!-- inreplyto="Is vs. Ought (was: A Physicist Experiments With CulturalStudies)" -->
<!-- version=1.10, linesinbody=55 -->
<html><head><title>extropians: Re: Is vs. Ought (was: A Physicist Experiments With CulturalStudies)</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Is vs. Ought (was: A Physicist Experiments With CulturalStudies)</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Sun, 21 Nov 1999 11:07:28 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2456">[ date ]</a><a href="index.html#2456">[ thread ]</a><a href="subject.html#2456">[ subject ]</a><a href="author.html#2456">[ author ]</a>
<!-- next="start" -->
<li><a href="2457.html">[ Next ]</a><b>In reply to:</b> <a href="2455.html">GBurch1@aol.com</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="2597qlink1">Greg Burch said:
<pre>
&gt;
</pre>
<br>
<a href="2455.html#2456qlink1">&gt; This smacks of the kind of naive "scientific" approach to society</a> that one </a><br>
<a name="2597qlink2"><i>&gt; finds in Marx and his followers.  Substitute "the vanguard party"</a> for "SI", </i><br>
<a name="2597qlink3"><i>&gt; and you have the kind of elitist, "we know what's best for society" mentality </i><br>
<i>&gt; that lead inevitably to Bolshevism.</i><br>

<p>
As a meme, maybe.  As a reality, never.  &lt;Let the SIs decide&gt; may bear a
</a>memetic resemblance to &lt;let Marx decide&gt;, when implemented on naive
hardware, but in reality, the Bolsheviks are human and the SI is not. 
The reality of a state run by Bolsheviks and the reality of a world
<a name="2597qlink4">rewritten by an SI would be utterly, unimaginably different.</a>  Humans
<a name="2597qlink5">have always been arguing that their political parties know best.  It's
human nature.  The whole point of building an SI is to get out of the
trap by transcending human nature.</a>

<p>
<a name="2597qlink6">We don't trust humans who claim to know best, because we know that
humans have evolved to believe they know what's best and then abuse that
power for their own benefit.  But to extend this heuristic to SIs
borders on the absurd.  And that makes &lt;turn power over to SIs&gt;
different from &lt;turn power over to me&gt; in practice as well.  The latter
says "Keep playing the game, but give me more points"; the former says
"Smash the damn game to pieces."
</a>

<p>
<a name="2597qlink7">&gt; I honestly can't imagine what process <br>
<a href="2455.html#2456qlink2">&gt; you're picturing this SI would engage in to make a "scientific" decision.</a><br>

<p>
But that doesn't preclude the SI doing so!  The whole foundation of
"letting SIs decide" is the belief that somewhere out there is some
completely obvious answer to all of the philosophical questions that
<a name="2597qlink8">perplex us.</a>  The very fact that we, the high-IQ Extropians, are
discussing this question in the late twentieth century, and making more
sense than eleventh-century philosophers or twentieth-century
postmodernists, should lead us to conclude that intelligence does play a
part in moral decisions - not just with respect to internal consistency
and game-theoretical stability, but with respect to the basic
foundations of morality.  The very fact that we are making more sense
than Neanderthals (or frogs) should lead us to conclude that
intelligence plays a part.  What lies beyond the human debate?  I don't
know, but I think it's reasonable to hope that beyond humanity lies the
truth.  And if I'm wrong, well, this course of action is as good as any.
</a>

<p>
<a href="2455.html#2456qlink3">&gt; Some kind of balancing of everyone's utility functions based on perfect </a><br>
<i>&gt; knowledge of their internal brain states?  This sounds like one is merely </i><br>
<i>&gt; substituting "SI" for "god" and "scientific decision making" for "paradise".</i><br>

<p>
Hey, if it works, why argue?  Personally I'd hope for something a little
more exciting, like some kind of provably moral grand adventure, but
your scenario also sounds like fun.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2457.html">[ Next ]</a>
<b>In reply to:</b> <a href="2455.html">GBurch1@aol.com</a>
<!-- nextthread="start" -->
</ul>
</body></html>
