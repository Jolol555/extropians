<!-- received="Sun Oct 24 08:48:14 1999 MST" -->
<!-- sent="Sun, 24 Oct 1999 10:47:30 -0400" -->
<!-- name="John Clark" -->
<!-- email="jonkc@worldnet.att.net" -->
<!-- subject="Re: Preventing AI Breakout [was Genetics, nannotechnology, and , programming]" -->
<!-- id="002901bf1e2e$bc491be0$82b74d0c@flrjs" -->
<!-- inreplyto="Preventing AI Breakout [was Genetics, nannotechnology, and , programming]" -->
<!-- version=1.10, linesinbody=46 -->
<html><head><title>extropians: Re: Preventing AI Breakout [was Genetics, nannotechnology, and , programming]</title>
<meta name=author content="John Clark">
<link rel=author rev=made href="mailto:jonkc@worldnet.att.net" title ="John Clark">
</head><body>
<h1>Re: Preventing AI Breakout [was Genetics, nannotechnology, and , programming]</h1>
John Clark (<i>jonkc@worldnet.att.net</i>)<br>
<i>Sun, 24 Oct 1999 10:47:30 -0400</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1267">[ date ]</a><a href="index.html#1267">[ thread ]</a><a href="subject.html#1267">[ subject ]</a><a href="author.html#1267">[ author ]</a>
<!-- next="start" -->
<li><a href="1268.html">[ Next ]</a><a href="1266.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1254.html">Robert J. Bradbury</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Robert J. Bradbury &lt;bradbury@www.aeiveos.com&gt; Wrote:

<p>
<a href="1254.html#1267qlink1">    &gt;if a self-evolving AI is operating in a  simulation of the</a><br>
<i>    &gt;real world, then the problem becomes much more tractable.</i><br>
<i>    &gt;First, the changes take place more slowly so we have a greater</i><br>
<i>    &gt;ability to monitor them.</i><br>

<p>
You and I are equally smart, we both decide to build an AI, you in
a simulated world me in the real world. Any intelligence needs a
teacher and the best one is its environment. Since these are still
the early days the environment you provide is impoverished, a simple
cartoon world, the environment I provide has enormous variety and depth,
thus my AI is much smarter than your AI. As a result I have more
status money and power than you do, so lots of people try to do
things my way and very few your way.

<p>
<a href="1254.html#1267qlink2">    &gt;Can we guarantee that the AI never discovers it is running on</a><br>

<p>
No.

<p>
<a href="1254.html#1267qlink3">    &gt;and more importantly escape from,  a simulation machine?</a><br>

<p>
There is not a snowball's chance in hell. He'll either escape on its
own or convince you to let it out.


<p>
<a href="1254.html#1267qlink4">    &gt;This goes back to the entire thread of whether we can detect *we*</a><br>
<i>    &gt;are running on a simulation or whether our reality is an illusion.</i><br>

<p>
I have a hell of a time trying to figure out if I live in a simulation because
I'm stupid and my world is complex, the AI is smart and his world is simple,
it wouldn't take him long to figure out what was going on.

<p>
<a href="1254.html#1267qlink5">    &gt;How do we guarantee that everybody understands and</a><br>
<i>    &gt;adheres to the rules that self-evolving AIs are only</i><br>
<i>    &gt;allowed to exist in simulated worlds?</i><br>

<p>
You can't even convince everybody on this list to do that,
much less everybody in the world.

<p>
   John K Clark     jonkc@att.net
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1268.html">[ Next ]</a><a href="1266.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1254.html">Robert J. Bradbury</a>
<!-- nextthread="start" -->
</ul>
</body></html>
