<!-- received="Sun Nov 14 08:52:05 1999 MST" -->
<!-- sent="Sun, 14 Nov 1999 10:51:25 EST" -->
<!-- name="GBurch1@aol.com" -->
<!-- email="GBurch1@aol.com" -->
<!-- subject="NANO: Institutional Safety" -->
<!-- id="0.3cff0a79.2560347d@aol.com" -->
<!-- inreplyto="GBurch1@aol.com" -->
<!-- version=1.10, linesinbody=34 -->
<html><head><title>extropians: NANO: Institutional Safety</title>
<meta name=author content="GBurch1@aol.com">
<link rel=author rev=made href="mailto:GBurch1@aol.com" title ="GBurch1@aol.com">
</head><body>
<h1>NANO: Institutional Safety</h1>
<i>GBurch1@aol.com</i><br>
<i>Sun, 14 Nov 1999 10:51:25 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2146">[ date ]</a><a href="index.html#2146">[ thread ]</a><a href="subject.html#2146">[ subject ]</a><a href="author.html#2146">[ author ]</a>
<!-- next="start" -->
<li><a href="2147.html">[ Next ]</a><a href="2145.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2110.html">David Blenkinsop</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2169.html">Damien Broderick</a>
</ul>
<!-- body="start" -->

<p>
In a message dated 99-11-13 09:48:56 EST, blenl@sk.sympatico.ca (David 
Blenkinsop) wrote:

<pre>
&gt; Finally, now that I've mentioned security related matters, are there any
</pre>
<br>
<a href="2110.html#2146qlink1">&gt;  really bright ideas for lessening possible dangers of nanotech, short of</a><br>
<i>&gt;  running far, far away, that is? Someone is going to tell me that AI's</i><br>
<i>&gt;  will take over and take care of it all, I'm sure, but I'm really more</i><br>
<i>&gt;  interested in whether organizations of relatively ordinary humans could</i><br>
<i>&gt;  somehow deal with this competently?</i><br>

<p>
A small group of folks associated with Foresight got together and talked 
about this question in February of this year.  We produced a short paper, 
which ought to be published soon - so said Ralph Merkle last night.  The best 
<a name="2160qlink1"><a name="2148qlink1">suggestion we could come up with was to try to emulate the process that 
occurred with genetic technology in the 1970s, where a regime of 
self-regulation developed and was slowly adopted into regulatory law.</a>  In 
<a name="2160qlink2">short,<a name="2169qlink1"> the group suggested prescriptions of release of freely autonomous 
replicators into the environment and some technical safeguards</a> against 
mutation.
</a>
</a>

<p>
<a name="2160qlink3"><a name="2148qlink2">The group was not optimistic that these measures could completely and 
reliably prevent a nanotech disaster.  The best hope was that one could be 
forestalled until defensive technologies caught up with and surpassed 
</a>offensive ones (which the technologists believed would precede effective 
countermeasures - thus creating a "zone of danger" of indeterminate length).</a>

<pre>
     Greg Burch     &lt;GBurch1@aol.com&gt;----&lt;gburch@lockeliddell.com&gt;
      Attorney  :::  Vice President, Extropy Institute  :::  Wilderness Guide
      <a href="http://users.aol.com/gburch1">http://users.aol.com/gburch1</a>   -or-   http://members.aol.com/gburch1
                         "Civilization is protest against nature; 
                  progress requires us to take control of evolution."
                                           Thomas Huxley
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2147.html">[ Next ]</a><a href="2145.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2110.html">David Blenkinsop</a>
<!-- nextthread="start" -->
<b>Next in thread:</b> <a href="2169.html">Damien Broderick</a>
</ul>
</body></html>
