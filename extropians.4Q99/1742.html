<!-- received="Tue Nov  2 20:28:27 1999 MST" -->
<!-- sent="Tue, 02 Nov 1999 21:31:30 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Preservation, Rationality, and ETI" -->
<!-- id="381FAC89.9941A378@pobox.com" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=38 -->
<html><head><title>extropians: Preservation, Rationality, and ETI</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Preservation, Rationality, and ETI</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Tue, 02 Nov 1999 21:31:30 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1742">[ date ]</a><a href="index.html#1742">[ thread ]</a><a href="subject.html#1742">[ subject ]</a><a href="author.html#1742">[ author ]</a>
<!-- next="start" -->
<li><a href="1743.html">[ Next ]</a><a href="1741.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1721.html">hal@finney.org</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
hal@finney.org wrote:
<br>
<i>&gt; </i><br>
<a href="1721.html#1742qlink1">&gt; The next step in this slippery slope is to say that the aliens are here,</a><br>
<i>&gt; silently monitoring us, but as each person dies they take a snapshot of</i><br>
<i>&gt; his brain state and take him off to live a new life elsewhere, one free</i><br>
<i>&gt; of trouble and pain, until they can be rejoined with their loved ones.</i><br>

<p>
The thought has occurred to me.

<p>
<a href="1721.html#1742qlink2">&gt; This addresses the moral issue in a very familiar manner, one which has</a><br>
<i>&gt; been taught in Sunday schools for centuries.</i><br>

<p>
And that's exactly why this *is* a significant probability, albeit not
one that much affects the choices I make.  If the Prime Directive is
psychologically plausible, so is mind-state preservation.  In fact, I
would argue that they're more plausible together than they are apart. 
Given the number of people on this list who insist that Powers (AI,
upload, whatever... Powers are Powers) can be preprogrammed, or retain
their human motives, don't you think that the tremendous mortal-level
emotional attractiveness of mind-state preservation makes it one of the
most likely motives for a persistent-motive Power to have?

<p>
Of course, I personally don't care much about such things; in fact, I
think I may actively dislike the whole concept, since what I *do* care
about is a no-holds-barred Singularity, while *this* scenario implies
that the first race to get there imposed limits on everyone else.  I
know that if my desires were given free reign, there wouldn't be any
damn Prime Directive anywhere that people were suffering.

<p>
And before you ask:  No, I don't care how the concept has been abused in
the past.  I do my own navigation, and what other people think doesn't
enter into it, either way.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1743.html">[ Next ]</a><a href="1741.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1721.html">hal@finney.org</a>
<!-- nextthread="start" -->
</ul>
</body></html>
