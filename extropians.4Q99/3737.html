<!-- received="Sun Dec 12 22:52:25 1999 MST" -->
<!-- sent="Sun, 12 Dec 1999 21:43:35 -0800" -->
<!-- name="Carol Tilley" -->
<!-- email="tilley@worldnet.att.net" -->
<!-- subject="Re: purpose of AIs" -->
<!-- id="004401bf452d$e5170840$08e2fea9@xps120" -->
<!-- inreplyto="purpose of AIs" -->
<!-- version=1.10, linesinbody=44 -->
<html><head><title>extropians: Re: purpose of AIs</title>
<meta name=author content="Carol Tilley">
<link rel=author rev=made href="mailto:tilley@worldnet.att.net" title ="Carol Tilley">
</head><body>
<h1>Re: purpose of AIs</h1>
Carol Tilley (<i>tilley@worldnet.att.net</i>)<br>
<i>Sun, 12 Dec 1999 21:43:35 -0800</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3737">[ date ]</a><a href="index.html#3737">[ thread ]</a><a href="subject.html#3737">[ subject ]</a><a href="author.html#3737">[ author ]</a>
<!-- next="start" -->
<li><a href="3738.html">[ Next ]</a><a href="3736.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3730.html">Kate Riley</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->


<p>
From: Kate Riley
<br>
<a href="3730.html#3737qlink1">&gt; ....My problem with this notion</a><br>
<i>&gt; of AI is that it is inherently circular, in that ultimately, the only way</i><br>
we
<br>
<a href="3730.html#3737qlink2">&gt; could know that the AI is phenominally more intelligent than any of us is</a><br>
<i>&gt; for a being of phenominally high intelligence to tell us so.</i><br>

<p>
Kate, I know that there are many posters to this list that are phenomenally
more intelligent than myself. And there is even a higher tier composed of
phenomenally higher intelligences here that would be happy to tell me that
this is the case. Testing, prediction and retrodiction are a few of the
tools that could confirm this 'suspicion' I have about their superior
intelligence. You view the argument as being circular. I see it as more
'spiral' -like in representation.

<p>
<a href="3730.html#3737qlink3">&gt; ....if the AI agreed with everything the human populace agreed with,</a><br>
<i>&gt; it would be pretty useless to us as a Power.</i><br>

<p>
I do not see AI and Power as equivalent. As Eliezer pointed out, the
Cro-Magnons were the last enormous evolutionary step in the hominid
progression. Achievement of AI is one of the possible approaches that could
culminate in the next step. And from there, exponential/geometric evolution
might progress to this 'Power'....or it might not. Hominid evolution has
been rather boringly flat, as of late, it's time to take that next leap,
dontcha think?

<p>
<a href="3730.html#3737qlink4">&gt; Therefore, if the AI decided that the human species should be obliterated,</a><br>
I
<br>
&gt; would be justified in calling it a bad judgment call and taking arms<br>
&gt; against it.<br>

<p>
"True warfare in which large rival armies fight to the death is known only
in man and in social insects."  Dawkins: The Selfish Gene. One can only hope
that the AI has not 'inherited' this aspect of socialization that we seem
unable to
<br>
overcome.

<p>
Ct
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3738.html">[ Next ]</a><a href="3736.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3730.html">Kate Riley</a>
<!-- nextthread="start" -->
</ul>
</body></html>
