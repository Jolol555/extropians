<!-- received="Sun Nov 14 16:19:05 1999 MST" -->
<!-- sent="Mon, 15 Nov 1999 03:18 EST" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@ilr.genebee.msu.su" -->
<!-- subject="Re: NANO: Institutional Safety" -->
<!-- id="382fc2360.e4d@ilr.genebee.msu.su" -->
<!-- inreplyto="NANO: Institutional Safety" -->
<!-- version=1.10, linesinbody=77 -->
<html><head><title>extropians: Re: NANO: Institutional Safety</title>
<meta name=author content="Robert J. Bradbury">
<link rel=author rev=made href="mailto:bradbury@ilr.genebee.msu.su" title ="Robert J. Bradbury">
</head><body>
<h1>Re: NANO: Institutional Safety</h1>
Robert J. Bradbury (<i>bradbury@ilr.genebee.msu.su</i>)<br>
<i>Mon, 15 Nov 1999 03:18 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2160">[ date ]</a><a href="index.html#2160">[ thread ]</a><a href="subject.html#2160">[ subject ]</a><a href="author.html#2160">[ author ]</a>
<!-- next="start" -->
<li><a href="2161.html">[ Next ]</a><a href="2159.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2146.html">GBurch1@aol.com</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="2172qlink1">Greg wrote:

<p>
<a href="2146.html#2160qlink1">&gt; The best </a><br>
<i>&gt; suggestion we could come up with was to try to emulate the process that </i><br>
<i>&gt; occurred with genetic technology in the 1970s, where a regime of </i><br>
<i>&gt; self-regulation developed and was slowly adopted into regulatory law.</i><br>

<p>
Actually Greg, I'm not sure this is the case.  My recollection of the
mid-late-'70s was there was a lot of debate over whether or not these
things should be regulated and whether or not there were any dangers.
After looking at it for a while the scientists came up with the relative
scale of dangers and implemented with the P1-P4 scaling system that is
in practice today (P1 is relatively non contained, P3 is for bugs
such as HIV and has positive pressure labs and throw away materials
and clothing, while P4 is for Ebola and leans strongly towards
remote-manipulation).  [I've worked in a P3 lab.]

<p>
Now, I suspect the "regulatory" penalties for violating these are
not particularly severe, but common sense and fear</a> of loss of
reputation keep scientists following them.

<p>
I imagine that a clever group could review the biotech containment
levels and adapt them to nanotechnology fairly easily.

<p>
<a name="2172qlink2"><a href="2146.html#2160qlink2">&gt; In short, the group suggested prescriptions of release of freely autonomous </a><br>
<i>&gt; replicators into the environment and some technical safeguards against </i><br>
<i>&gt; mutation.</i><br>

<p>
In my mind, you have to divide the problem into wet biotech &amp; hard nanotech.
<a name="2172qlink3">We do now release into the environment autonomous replicators that we
</a>
have patched in various ways.  The interesting thing is that these
have precious little in the way of ECC or failsafe mechanisms.
What is going to be interesting is that our ability to create highly
complex organisms from the ground up is going to advance by leaps
and bounds in the near future.  It is doubtful whether we can predict
all of the consequences of the release of such organisms and so we
need to be thinking hard about preventing self-replication, adding ECC
and failsafes.  [I've got some ideas about this but I can't discuss
them.]</a>

<p>
Now, with hard nanotech, things are simpler, since there isn't a
"huge" incentive to release *mutating* replicators.  I've got no problem
with releasing self-replicating solar-cell constructors because they
only have a solar cell construction "system" and can reliably copy it.
You design in ECC and failsafes and you can get reliability out to
any desired level.  The only "catch" comes in when the programs are
*so* complex that they have wierd "glitches" as current software
systems do.  If our software engineering abilities and program
prooving abilities continue to advance, I would hope that these
problems can be minimized.

<p>
<a name="2172qlink4"><a href="2146.html#2160qlink3">&gt; The group was not optimistic that these measures could completely and </a><br>
<i>&gt; reliably prevent a nanotech disaster.  The best hope was that one</a> could be </i><br>
<a name="2172qlink5"><i>&gt; forestalled until defensive technologies caught up with and surpassed </i><br>
<i>&gt; offensive ones (which the technologists believed would precede effective </i><br>
<i>&gt; countermeasures - thus creating a "zone of danger"</a> of indeterminate length).</i><br>

<p>
<a name="2172qlink6">Designing self-contained  highly "intelligent", reliable nanotech offensive
weapons that can tolerate macroscale defenses *will NOT* be easy.</a>  First
they are going to be radiation senstive.  A shielded directional radiation
emitter makes a good defensive weapon.  Second, they have limited current
capacities.  You put a nanocockroach between the ends of a 120V 20A
circuit and it better be a good insulator otherwise its "poof".
The same could be said for high intensity micro-torches (exceeds
heat capacity of the nanobots) and/or diamond studded gestapo boots
(exceeds pressure capacity of the nanocockroaches).

<p>
Add this to our ability to starve the nanobots (energy or material-wise)
and I think the picture is not so grim.  To every "defence" against
an "offence" there is a counter-offence, but designing these things
*will* take time.  As I've said before, it all comes down to designs
and unless someone cracks the design problem in a way that is much
further along the exponential curve, I would expect defense to balance
offense (or accidents) fairly well.

<p>
Robert
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2161.html">[ Next ]</a><a href="2159.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2146.html">GBurch1@aol.com</a>
<!-- nextthread="start" -->
</ul>
</body></html>
