<!-- received="Sun Dec 12 20:15:28 1999 MST" -->
<!-- sent="Sun, 12 Dec 1999 22:14:51 EST" -->
<!-- name="Kate Riley" -->
<!-- email="kate_riley7@hotmail.com" -->
<!-- subject="Re: purpose of AIs" -->
<!-- id="19991213031452.52884.qmail@hotmail.com" -->
<!-- inreplyto="purpose of AIs" -->
<!-- version=1.10, linesinbody=38 -->
<html><head><title>extropians: Re: purpose of AIs</title>
<meta name=author content="Kate Riley">
<link rel=author rev=made href="mailto:kate_riley7@hotmail.com" title ="Kate Riley">
</head><body>
<h1>Re: purpose of AIs</h1>
Kate Riley (<i>kate_riley7@hotmail.com</i>)<br>
<i>Sun, 12 Dec 1999 22:14:51 EST</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3730">[ date ]</a><a href="index.html#3730">[ thread ]</a><a href="subject.html#3730">[ subject ]</a><a href="author.html#3730">[ author ]</a>
<!-- next="start" -->
<li><a href="3731.html">[ Next ]</a><a href="3729.html">[ Previous ]</a>
<b>Maybe in reply to:</b> <a href="3712.html">jeff nordahl</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Ah, don't I wish I had a bloody microwave!

<p>
Eliezer, I must admit that I have not yet read your essay on this topic, so 
please forgive me if I am raising points you already raise.

<p>
My apologies, I haven't been completely clear.<a name="3737qlink1">  My problem with this notion 
of AI is that it is inherently circular, in that ultimately, the only</a> way we 
<a name="3737qlink2">could know that the AI is phenominally more intelligent than any of us is 
<a name="3798qlink1">for a being of phenominally high intelligence to tell us so.</a>  Let's say that 
we determine the intelligence of an AI by the number of right "answers" it 
gives us (answers being defined here as correct solutions to problems and/or 
</a>
questions in all fields, science to philosophy - a haphazard definition, so 
feel free to correct me, and I'll reassess).  Somewhere down the line, the 
AI is going to give an answer that does not concur with what is believed by 
the human populace to be the right answer.<a name="3798qlink5">  This is inevitable, since it is 
all but certain that we as a species are wrong in some of our beliefs.</a>  In 
addition,<a name="3737qlink3"> if the AI agreed with everything the human populace agreed with, 
it would be pretty useless to us as a Power.</a>
Now, when the AI hit one of these points, and comes up with an answer 
contrary to what we believe to be true, there is no way of knowing whether 
the AI is right or mistaken, for there is no outside third party (which 
would have to be more intelligent than either the AI or the humans) to 
mediate.<a name="3798qlink8">  Therefore, sure, I'm willing to grant that a Power is possible.  
However, we cannot be certain that an AI /is/ a Power in the sense that we 
cannot be certain that it is sufficiently more intelligent than us.</a>  
<a name="3816qlink1"><a name="3737qlink4"><a name="3736qlink1">Therefore, if the AI decided that the human species should be obliterated,</a> I 
would be justified in calling it a bad judgement call and taking arms 
</a></a>against it.

<p>
I feel as if I'm still not being terribly clear, and once again, I 
apologize.  I would be happy to answer any questions or challenges.

<p>
Best,
<br>
Kathryn Riley

<hr>
<br>
Get Your Private, Free Email at <a href="http://www.hotmail.com">http://www.hotmail.com</a>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3731.html">[ Next ]</a><a href="3729.html">[ Previous ]</a>
<b>Maybe in reply to:</b> <a href="3712.html">jeff nordahl</a>
<!-- nextthread="start" -->
</ul>
</body></html>
