<!-- received="Mon Oct 25 08:22:37 1999 MST" -->
<!-- sent="Mon, 25 Oct 1999 09:25:36 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Preventing AI Breakout [was Genetics, nannotechnology, and ," -->
<!-- id="3814685F.77E0151F@pobox.com" -->
<!-- inreplyto="Preventing AI Breakout [was Genetics, nannotechnology, and ," -->
<!-- version=1.10, linesinbody=40 -->
<html><head><title>extropians: Re: Preventing AI Breakout [was Genetics, nannotechnology, and ,</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Preventing AI Breakout [was Genetics, nannotechnology, and ,</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 25 Oct 1999 09:25:36 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#1315">[ date ]</a><a href="index.html#1315">[ thread ]</a><a href="subject.html#1315">[ subject ]</a><a href="author.html#1315">[ author ]</a>
<!-- next="start" -->
<li><a href="1316.html">[ Next ]</a><a href="1314.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1302.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Anders Sandberg wrote:
<br>
<i>&gt; </i><br>
<a href="1302.html#1315qlink1">&gt; "Eliezer S. Yudkowsky" &lt;sentience@pobox.com&gt; writes:</a><br>
<i>&gt; </i><br>
<i>&gt; &gt; &gt;   (a) whether an AI can discover it is running in a simulation?</i><br>
<i>&gt; &gt;</i><br>
<i>&gt; &gt; Almost certainly.  If it really is smarter-than-human - say, twice as</i><br>
<i>&gt; &gt; smart as I am - then just the fact that it's running in a Turing</i><br>
<i>&gt; &gt; formalism should be enough for it to deduce that it's in a simulation.</i><br>
<i>&gt; </i><br>
<a name="1381qlink1"><i>&gt; So if the Church-Turing thesis holds for the physical world, it is a</i><br>
<i>&gt; simulation?</i><br>

<p>
In one sense, yes.  But (1) if the world I saw was Turing-computable, I
probably wouldn't see anything wrong with it - *I'm* not that smart.  Or
perhaps I underestimate myself... but nonetheless, the only way I
learned how to reason about the subject was trying to explain phenomena
that weren't Turing-computable, i.e. qualia.  And (2) if *this* world is
Turing-computable, then obviously all my reasoning is wrong and I don't
know a damn thing about the subject.</a>

<p>
<a href="1302.html#1315qlink2">&gt; If the AI runs on a Game of Life automaton, why should it believe the</a><br>
<i>&gt; world is embedded in another world? The simplest consistent</i><br>
<i>&gt; explanation involves just the automaton.</i><br>

<p>
But the explanation isn't complete.  Where did the automaton come from?

<p>
<a href="1302.html#1315qlink3">&gt; &gt; You really can't outwit something that's smarter than you are, no matter</a><br>
<i>&gt; &gt; how hard you try.</i><br>
<i>&gt; </i><br>
<a name="1381qlink2"><i>&gt; Ever tried to rear children? Outwitting goes both ways.</i><br>

<p>
Someone tried to rear me.  Perhaps I flatter myself, but my experience
would tend to indicate that it only goes one way.</a>
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="1316.html">[ Next ]</a><a href="1314.html">[ Previous ]</a>
<b>In reply to:</b> <a href="1302.html">Anders Sandberg</a>
<!-- nextthread="start" -->
</ul>
</body></html>
