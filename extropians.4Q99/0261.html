<!-- received="Mon Oct  4 21:27:30 1999 MST" -->
<!-- sent="Mon, 04 Oct 1999 22:30:22 -0500" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Berkeleyans Against "Techno-Eugenics"" -->
<!-- id="37F970AB.EC93C0BD@pobox.com" -->
<!-- inreplyto="Berkeleyans Against "Techno-Eugenics"" -->
<!-- version=1.10, linesinbody=39 -->
<html><head><title>extropians: Re: Berkeleyans Against "Techno-Eugenics"</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: Berkeleyans Against "Techno-Eugenics"</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Mon, 04 Oct 1999 22:30:22 -0500</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#261">[ date ]</a><a href="index.html#261">[ thread ]</a><a href="subject.html#261">[ subject ]</a><a href="author.html#261">[ author ]</a>
<!-- next="start" -->
<li><a href="0262.html">[ Next ]</a><a href="0260.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0254.html">Chris Fedeli</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a name="0270qlink1">Chris Fedeli wrote:
<br>
<i>&gt; </i><br>
<a href="0254.html#0261qlink1">&gt; I want to alert you to a nascent movement originating here in</a><br>
<i>&gt; Berkeley opposed to "Techno-eugenics'" i.e. human germ-line engineering</i><br>
<i>&gt; with the intent of producing super-people, which presents some very</i><br>
<i>&gt; serious threats to the future of humanity, social equality and the</i><br>
<i>&gt; like.. The technology is movign forward quite quiickly, with little</i><br>
<i>&gt; public awareness.</i><br>

<p>
I would also agree that human genetic engineering poses a serious threat
- to public relations; it's too slow to become a serious problem in its
own right.  Eugenics, especially, poses a problem - I don't even
consider it Extropian; it doesn't respect the defining quality of
ultratechnology, which is that ultratechnology requires pushing buttons.
 But it's become something of a curse-word, in this century, and for
good reason - we should oppose an attempt to extend it to transhumanism
in general.</a>

<p>
<a name="0270qlink2">But I would strongly advise that we all watch these people for a while
before attempting to convert them, or even asking them about positions
on, say, neurohacking.  Some of their list charter implies that these
people are technophobes, or at least less sane than the attempted image
of justifiably concerned technophiles would imply.  Of course, there
*is* in fact a small group trying to promote a transhuman, if not
techno-eugenic, future... but just because they're out to get you
doesn't mean you're not paranoid.</a>

<p>
<a href="0254.html#0261qlink2">&gt; I'll be doing some major lurking.  I promise to forward more juicy</a><br>
<i>&gt; tidbits as they arrive.</i><br>
<i>&gt; </i><br>
<i>&gt; Chris</i><br>

<p>
Good work.  I agree, these people will take watching.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0262.html">[ Next ]</a><a href="0260.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0254.html">Chris Fedeli</a>
<!-- nextthread="start" -->
</ul>
</body></html>
