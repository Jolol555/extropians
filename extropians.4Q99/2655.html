<!-- received="Sat Nov 27 06:29:29 1999 MST" -->
<!-- sent="Sat, 27 Nov 1999 05:29:24 -0800 (PST)" -->
<!-- name="Robert J. Bradbury" -->
<!-- email="bradbury@www.aeiveos.com" -->
<!-- subject="Re: absolute morality? ha! free will? pnyah!" -->
<!-- id="Pine.UW2.4.20.9911270506420.870-100000@www.aeiveos.com" -->
<!-- inreplyto="NDBBJEGIMDDABOBCCDCHMEGOCAAA.rob@hbinternet.co.uk" -->
<!-- version=1.10, linesinbody=56 -->
<html><head><title>extropians: Re: absolute morality? ha! free will? pnyah!</title>
<meta name=author content="Robert J. Bradbury">
<link rel=author rev=made href="mailto:bradbury@www.aeiveos.com" title ="Robert J. Bradbury">
</head><body>
<h1>Re: absolute morality? ha! free will? pnyah!</h1>
Robert J. Bradbury (<i>bradbury@www.aeiveos.com</i>)<br>
<i>Sat, 27 Nov 1999 05:29:24 -0800 (PST)</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2655">[ date ]</a><a href="index.html#2655">[ thread ]</a><a href="subject.html#2655">[ subject ]</a><a href="author.html#2655">[ author ]</a>
<!-- next="start" -->
<li><a href="2656.html">[ Next ]</a><a href="2654.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2624.html">Rob Harris</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->


<p>
On Fri, 26 Nov 1999, Rob Harris wrote:

<p>
<a href="2624.html#2655qlink1">&gt; ... It is</a><br>
<i>&gt; following it's program to win the game, this is it's root motivation, and it</i><br>
<i>&gt; is far from free - it was strictly defined by the game creator and is</i><br>
<i>&gt; therefore completely invariable.</i><br>

<p>
<a href="2624.html#2655qlink2">&gt; Our base motivations are also strictly defined and completely invariable.</a><br>
<i>&gt; Any action we devise to fulfil these goals, is just that - an intelligent</i><br>
<i>&gt; system devising a method of achieving the strictly defined goals.</i><br>

<p>
Rob, I feel I'm forced to disagree with you on the simple basis that
a chess program doesn't have access to the "base motivations", while
we perhaps can either access those goals or shift those priorities.
<a name="2739qlink1">I'll use the example of the celibate priest or monk.  Certainly the
"designer", put in the goal to procreate.  However with enough
training or desire, we can usurp that goal and replace it with
another, *perhaps* flying in the face of "rational" behavior
(i.e. substituting the pursuit of a belief system that has no
concrete visible results with one that has concrete visible results).</a>

<p>
Now, the interesting problem, IMO, from the perspective of sending
and AI after an "absolute morality" is the problem that to implement
the acceptance of the "discovered" morality, you have to give the AI
access to the source code (i.e. it (like humans) can shift the weights
or priorities of its belief system).  How do you prevent the AI from
worshiping some false god (as I would argue so many humans do...)?

<p>
Now, with regard to whether an "absolute morality" existing, I'm
inclined to agree that that is doubtful.  My experience says
everything is context specific.  Is is wrong to murder her
children?  Yes.  Is it wrong for a mother to murder a younger
child so that an older child (in which greater investment has
been made) may survive in conditions of food scarcity?  No.
Is it wrong for a mother to murder an older child (with say
a mental handicap) in favor of a younger, but more mentally
promising child, in similar conditions of scarcity?  Probably
again, no.  [For those who don't like the examples, tough,
live with it.]  So in my mind, morality is *highly* context
specific.  I think our morality develops only on the basis
of experience (i.e. we can look back and see decisions that
in retrospect would have been better had alternate solutions
been selected).  To presume that an absolute morality exists
in such an environment seems difficult.

<p>
<a name="2677qlink1">At the end of the lifetime of this universe you may have two
possibilities -- (a) to eventually let everything die; (b) to
prematurely sacrifice virtually everything that is the result of
trillions of years of work to create a seed in a new universe.
Do you want to argue the morality of choosing between those positions?
</a>

<p>
Robert
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2656.html">[ Next ]</a><a href="2654.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2624.html">Rob Harris</a>
<!-- nextthread="start" -->
</ul>
</body></html>
