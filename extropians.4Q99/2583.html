<!-- received="Wed Nov 24 19:46:54 1999 MST" -->
<!-- sent="Wed, 24 Nov 1999 20:51:43 -0600" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: AI and Asimov's Laws" -->
<!-- id="383CA42E.C88D8120@pobox.com" -->
<!-- inreplyto="AI and Asimov's Laws" -->
<!-- version=1.10, linesinbody=26 -->
<html><head><title>extropians: Re: AI and Asimov's Laws</title>
<meta name=author content="Eliezer S. Yudkowsky">
<link rel=author rev=made href="mailto:sentience@pobox.com" title ="Eliezer S. Yudkowsky">
</head><body>
<h1>Re: AI and Asimov's Laws</h1>
Eliezer S. Yudkowsky (<i>sentience@pobox.com</i>)<br>
<i>Wed, 24 Nov 1999 20:51:43 -0600</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#2583">[ date ]</a><a href="index.html#2583">[ thread ]</a><a href="subject.html#2583">[ subject ]</a><a href="author.html#2583">[ author ]</a>
<!-- next="start" -->
<li><a href="2584.html">[ Next ]</a><a href="2582.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2580.html">Delvieron@aol.com</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
Delvieron@aol.com wrote:
<br>
<i>&gt; </i><br>
<a href="2580.html#2583qlink1">&gt; This is not what I envision as a non-upgrading AI.  First, a non-upgrading AI</a><br>
<i>&gt; would have little or no conscious control over its own programming.  It could</i><br>
<i>&gt; respond to environmental stimuli, formulate behaviors based on its</i><br>
<i>&gt; motivational parameters, and implement those behaviors.  This is basically</i><br>
<i>&gt; what humans do.  Technically, such an AI could possibly learn about itself,</i><br>
<i>&gt; if creative enough figure out a way to improve itself, then find some tools</i><br>
<i>&gt; and do it (if it could remain active while making modifications).  This would</i><br>
<i>&gt; be no different than you or me.  However, it might never do so if we program</i><br>
<i>&gt; it to have an aversion to consciously tinkering with its internal functions</i><br>
<i>&gt; except for repairs.  This would be in my estimation a non-upgrading AI.</i><br>

<p>
<a name="2593qlink1">Human brains have millions of years of evolution behind them.</a>  The only
thing that makes it remotely possible to match that immense evolutionary
investment with a few years of programming is the recursive-redesign
capability of seed AI, reinvesting the dividends of intelligence.  I
guarantee you that the first artificial intelligence smart enough to
matter will be a seed AI, because doing it without seed AI will take at
least another twenty years and hundreds or thousands of times as much labor.
<pre>
-- 
           sentience@pobox.com          Eliezer S. Yudkowsky
        <a href="http://pobox.com/~sentience/tmol-faq/meaningoflife.html">http://pobox.com/~sentience/tmol-faq/meaningoflife.html</a>
Running on BeOS           Typing in Dvorak          Programming with Patterns
Voting for Libertarians   Heading for Singularity   There Is A Better Way
</pre>
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="2584.html">[ Next ]</a><a href="2582.html">[ Previous ]</a>
<b>In reply to:</b> <a href="2580.html">Delvieron@aol.com</a>
<!-- nextthread="start" -->
</ul>
</body></html>
