<!-- received="Tue Dec 14 09:20:44 1999 MST" -->
<!-- sent="Tue, 14 Dec 1999 16:21:46 -0000" -->
<!-- name="Rob Harris" -->
<!-- email="rob@hbinternet.co.uk" -->
<!-- subject="AI" -->
<!-- id="00ed01bf464f$52725ad0$1500000a@hbi" -->
<!-- inreplyto="" -->
<!-- version=1.10, linesinbody=81 -->
<html><head><title>extropians: AI</title>
<meta name=author content="Rob Harris">
<link rel=author rev=made href="mailto:rob@hbinternet.co.uk" title ="Rob Harris">
</head><body>
<h1>AI</h1>
Rob Harris (<i>rob@hbinternet.co.uk</i>)<br>
<i>Tue, 14 Dec 1999 16:21:46 -0000</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#3798">[ date ]</a><a href="index.html#3798">[ thread ]</a><a href="subject.html#3798">[ subject ]</a><a href="author.html#3798">[ author ]</a>
<!-- next="start" -->
<li><a href="3799.html">[ Next ]</a><a href="3797.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3755.html">Clinton O'Dell</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
<a href="3730.html#3798qlink1">&gt; Let's say that</a><br>
<i>&gt; we determine the intelligence of an AI by the number of right "answers" it</i><br>
<i>&gt; gives us (answers being defined here as correct solutions to problems</i><br>
and/or
<br>
<a href="3755.html#3798qlink2">&gt; questions in all fields, science to philosophy - a haphazard definition,</a><br>
so
<br>
<a href="3755.html#3798qlink3">&gt; feel free to correct me, and I'll reassess).  Somewhere down the line, the</a><br>
<i>&gt; AI is going to give an answer that does not concur with what is believed</i><br>
by
<br>
<a href="3755.html#3798qlink4">&gt; the human populace to be the right answer.</a><br>

<p>
For this you have to consider the method by which the AI in question
"thinks". Humans are not objective intelligences that will always give the
answer that the evidence points to - I hope I don't have to elaborate here.
You use the word "belief". If the AI was as the layman usually
conceptualises an AI, (an artificial human), then the AI will give you all
the correct answers to mathematical problems and so forth, but any
philosophical output will be tainted with a desire for certain things to be
<a name="3872qlink1">true.<a name="3801qlink1"> If this AI is instead a purely rational master problem solver,</a> then
</a>
humanity will surely disagree with much of its philosophical output too. It
would have no motivation to glorify humanity or itself, and so would keep
giving answers like "insufficient data" or "logical fallacy in input" or
something.

<p>
<a href="3730.html#3798qlink5">&gt;This is inevitable, since it is</a><br>
<i>&gt; all but certain that we as a species are wrong in some of our beliefs.</i><br>

<p>
Yes, here's the old "belief" chestnut again. Unless you explicitly build the
AI to distort its worldview with "beliefs" by any mechanism, then to use it
as an objective problem solver would produce results no better than a human.
The strength of AI would be the ability to scrutinize hypotheses with
impeccable logic.

<p>
<i>&gt; In</i><br>
<a href="3755.html#3798qlink6">&gt; addition, if the AI agreed with everything the human populace agreed with,</a><br>
<i>&gt; it would be pretty useless to us as a Power.</i><br>

<p>
Indeed.

<p>
<a href="3755.html#3798qlink7">&gt; Now, when the AI hit one of these points, and comes up with an answer</a><br>
<i>&gt; contrary to what we believe to be true, there is no way of knowing whether</i><br>
<i>&gt; the AI is right or mistaken, for there is no outside third party (which</i><br>
<i>&gt; would have to be more intelligent than either the AI or the humans) to</i><br>
<i>&gt; mediate.</i><br>

<p>
You don't need a mediator. The AI would certainly have the ability to
provide a full explanation of it's "thought" processes. Otherwise, as you
say, the output is useless.

<p>
<a href="3730.html#3798qlink8">&gt;Therefore, sure, I'm willing to grant that a Power is possible.</a><br>
<i>&gt; However, we cannot be certain that an AI /is/ a Power in the sense that we</i><br>
<i>&gt; cannot be certain that it is sufficiently more intelligent than us.</i><br>

<p>
This depends on how you define intelligence. If you define it as an ability
to perform calculations in time, then any AI would vastly outperform any
human. If you mean it as the human fitness function that it is, then what
use is a swarve, charming and knowledgeable computer anyway? I suppose you
could attach a big plastic knob to it or something......whatever yanks your
chain.

<p>
<a href="3755.html#3798qlink9">&gt; Therefore, if the AI decided that the human species should be obliterated,</a><br>
I
<br>
<a href="3755.html#3798qlink10">&gt; would be justified in calling it a bad judgement call and taking arms</a><br>
<i>&gt; against it.</i><br>

<p>
Anyone that constructed an AI that was capable of considering human
extermination and provided the means to achieve it would have to be a nutter
anyway. There's no need for the AI bit - just program a hacking program to
launch nukes or something......

<p>
All this talk of AI, and it's obvious that most people here have no academic
experience of AI. It's a very different bag o' nuts once you study it, let
me tell you. There's no clear cut "intelligence", nobody has the faintest
idea how to instantiate consciousness, and really there's nothing very
special about an "intelligent" program that makes it conceptually different
from a conventional program. To clear the old mind on such matters, start by
<a name="3872qlink3"><a name="3801qlink2">thinking about constructing a solid definition for "intelligence",</a> then
</a>
think about how you might program a computer to posess this quality, and
what use it would be. You will be disappointed, I'm afraid.
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="3799.html">[ Next ]</a><a href="3797.html">[ Previous ]</a>
<b>In reply to:</b> <a href="3755.html">Clinton O'Dell</a>
<!-- nextthread="start" -->
</ul>
</body></html>
