<!-- received="Mon Oct 18 23:28:26 1999 MST" -->
<!-- sent="Tue, 19 Oct 1999 01:27:40 EDT" -->
<!-- name="Sayke@aol.com" -->
<!-- email="Sayke@aol.com" -->
<!-- subject="Re: &gt;H: The next 100 months" -->
<!-- id="0.afc02d94.253d5b4c@aol.com" -->
<!-- inreplyto="&gt;H: The next 100 months" -->
<!-- version=1.10, linesinbody=181 -->
<html><head><title>extropians: Re: &gt;H: The next 100 months</title>
<meta name=author content="Sayke@aol.com">
<link rel=author rev=made href="mailto:Sayke@aol.com" title ="Sayke@aol.com">
</head><body>
<h1>Re: &gt;H: The next 100 months</h1>
<i>Sayke@aol.com</i><br>
<i>Tue, 19 Oct 1999 01:27:40 EDT</i>
<p>
<ul>
<li> <b>Messages sorted by:</b> <a href="date.html#994">[ date ]</a><a href="index.html#994">[ thread ]</a><a href="subject.html#994">[ subject ]</a><a href="author.html#994">[ author ]</a>
<!-- next="start" -->
<li><a href="0995.html">[ Next ]</a><a href="0993.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0982.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
<!-- body="start" -->

<p>
In a message dated 10/18/99 7:33:30 PM Pacific Daylight Time, 
sentience@pobox.com writes:

<p>
<a href="0982.html#0994qlink1">&gt; Sayke@aol.com wrote:</a><br>
<i>&gt;  &gt; </i><br>
<i>&gt;  &gt; In a message dated 10/18/99 9:22:53 AM Pacific Daylight Time,</i><br>
<i>&gt;  &gt; sentience@pobox.com writes:</i><br>
<i>&gt;  &gt; </i><br>
<i>&gt;  &gt;     1:30 pm est: eliezer climbs up onto the the roof of the singularity</i><br>
<i>&gt;  &gt; institute's main building, pulls a large optic taser out of a suitcase, </i><br>
plugs
<br>
<a href="0982.html#0994qlink2">&gt;  &gt; it into the wall, checks the backup batteries, and sits down on an </a><br>
airvent to
<br>
<a href="0982.html#0994qlink3">&gt;  &gt; await... whatever.</a><br>
<i>&gt;  </i><br>
<i>&gt;  It's entirely irrelevant what I do after this point.  Or at least,</i><br>
<i>&gt;  that's the idea.  I would simply wait, just like everyone else...  And</i><br>
<i>&gt;  will it ever feel good to be able to say that.</i><br>

<p>
    in the first paragraph i write, and so as to get it out in the open, i 
would like to say that i did not intend my neal-stephenson-wannabe rant to be 
taken nearly as seriously as you seem to have taken it. i was not trying to 
"shock" you. my opinion of you is higher then that. and also, i took it as a 
given that, if the singularity somehow appears to 'do nothing', youll try 
something else. and, i dont think i will be in the position to steal a 
russian nuclear sub anytime in the next several years... but ya never know... 
;)

<p>
[snip 'if !singularity();' scenerios]

<p>
<a href="0982.html#0994qlink4">&gt;  &gt;     1:55 pm est: eliezer stands on an air vent casing, looks around, for </a><br>
one
<br>
<a href="0982.html#0994qlink5">&gt;  &gt; last time, at the placid cityscape surrounding him,  and starts busting </a><br>
high
<br>
<a href="0982.html#0994qlink6">&gt;  &gt; voltage caps into the air and shouting "hey, elisson! i wanna know the</a><br>
<i>&gt;  &gt; meaning of life, the universe, and everything!!!"</i><br>
<i>&gt;  </i><br>
<i>&gt;  I think you've managed to misunderstand my motives completely.</i><br>

<p>
    poetic license, dammit! you had to stand on a high place and shout 
something!

<p>
<a href="0982.html#0994qlink7">&gt;  &gt;     1:57 pm est: although elisson notices its surroundings almost</a><br>
<i>&gt;  &gt; immediately, it takes a short time for it to realize that the ant on the </i><br>
roof
<br>
<a href="0982.html#0994qlink8">&gt;  &gt; is its creator. its decision-making process is something vaguely like the</a><br>
<i>&gt;  &gt; following: "a monkey is discharging a monkey weapon on the roof. it </i><br>
might do
<br>
<a href="0982.html#0994qlink9">&gt;  &gt; something bad with that. no, there is no way it can damage me with that. </a><br>
this
<br>
<a href="0982.html#0994qlink10">&gt;  &gt; monkey seems to be one of my primary creators. its asking me questions. </a><br>
it is
<br>
<a href="0982.html#0994qlink11">&gt;  &gt; not necessary to answer its questions. cells 0x9e83fa823 through </a><br>
0x9e83fc907,
<br>
<a href="0982.html#0994qlink12">&gt;  &gt; disassemble the monkey."</a><br>
<i>&gt;  </i><br>
<i>&gt;  Oh, please!  A Power isn't a super-AI any more than it's a super-human.</i><br>

<p>
    hey, ive got an idea, how about we predict the by-definition 
unpredictable? and for the record, i trend towards agreeing with you, but... 
its just that you seem to be trying to exude this aura of knowing what your 
talking about (even when you cant know what your talking about). i dont dig 
those auras. [excuse my wetware; its annoyed.]

<p>
<a href="0982.html#0994qlink13">&gt;  &gt;     1:58 pm est: on the roof, the wind picks up, and eliezer notices the </a><br>
dust
<br>
<a href="0982.html#0994qlink14">&gt;  &gt; rise from the ground like a fractal wave of soot, and opens his arms in</a><br>
<i>&gt;  &gt; welcome. elisson, like a sandblaster, embraces him. eliezer ceases to </i><br>
exist
<br>
<a href="0982.html#0994qlink15">&gt;  &gt; in a sheet of black razorblade snowflakes.</a><br>
<i>&gt;  </i><br>
<i>&gt;  Am I supposed to be shocked by this scenario?  You don't want to know</i><br>
<i>&gt;  what I would consider a bad end.</i><br>

<p>
    naaaaaa, you werent supposed to be shocked. amused, possibly... and i 
really do want to know what you would consider a bad end. do tell.

<p>
<a name="1006qlink1"><a href="0982.html#0994qlink16">&gt;  There are two problems with trying to shock me this way.  First, unlike</a><br>
<i>&gt;  you and den Otter, I suffer from no illusion that the world is fair.</i><br>

<p>
    since when do i think the world is fair? when i put words into your 
mouth, i at least attempt to be ridiculous to the point of amusement. you 
actually sound like you think i think the world is fair. amusing, yes, but 
not quite ridiculous enough for me to infer an attempt at irony and 
thought-provocation. i am left with no choice but to take you seriously.</a>

<p>
<a href="0982.html#0994qlink17">&gt;  You believe, because it is implicit in the human model of the world,</a><br>
<i>&gt;  that every risk can be ameliorated by your actions.</i><br>

<p>
    you believe, because it is implicit in your attempt to rebel against the 
human model of the world, that the human model of the world is wrong, because 
it is the human model of the world.
<p>
    another idea: how about we stop making unsupported assertions about each 
others beliefs and just ask each other what the beliefs in question are?

<p>
<i>&gt;  You'll choose a</i><br>
<a href="0982.html#0994qlink18">&gt;  path that's far more dangerous than mine in absolute terms, simply</a><br>
<i>&gt;  because it allows you to "do something", or believe you're doing</i><br>
<i>&gt;  something, about the risk that you'll be destroyed by AIs.</i><br>

<p>
    ::shrug:: death is probably final. there is no more "absolute term" then 
"im dying". so... resistance is not futile, etc... remember the alamo!

<p>
<a href="0982.html#0994qlink19">&gt;  I choose the</a><br>
<a name="1006qlink2"><i>&gt;  path with the best absolute probability, even if it isn't as emotionally</i><br>
<i>&gt;  satisfying, even if it contains risks I admit to myself that I can't</i><br>
<i>&gt;  affect, because the next best alternative is an order of magnitude less </i><br>
<i>&gt;  attractive.</i><br>

<p>
    best absolute probability of what, exactly? and why is that to be strived 
for? if you dont trust philosophy and you dont trust your wetware, what do 
you trust? ("and who do you serve?" sorry... damn that new babylon 5 
</a>spinoff...)
<p>
    and, please describe exactly how you figure that the next best 
alternative (become a singularity, dammit! and please dont tell me how hard 
it would be. its a lot like cryonics: better then nothing) is an order of 
magnitude less attractive?

<p>
<a href="0982.html#0994qlink20">&gt;  If Powers don't like mortals, then mortal life is doomed and there's</a><br>
<i>&gt;  nothing we can do about it - whether we're humans or AIs or neurohacks</i><br>
<i>&gt;  or augments or telepaths or hybrids or anything else on this side of the</i><br>
<i>&gt;  line - that doesn't involve such enormous risks that we'd have to be</i><br>
<i>&gt;  a-priori certain that the Powers would kill us before it would be</i><br>
<i>&gt;  survival-rational to do anything but steer for a Singularity.</i><br>

<p>
    there is a nonzero chance that there are no powers, and there is a larger 
chance that the powers dont know about us, because they cant see us, and even 
if they did, they wouldnt care, simply because they cant get here in less 
then a Very Long Time. ftl could very well be impossible, and the economics 
of being a deity could be such that leaving the solar system of your 'birth' 
is a waste of time. at least, this is the impression that i get. correct me 
if im wrong.
<p>
<a name="1006qlink3">    and anyway, it seems to me that your basicly saying "the powers will eat 
us if the powers will eat us. their will be done on earth, as it is in 
heaven, forever and ever, amen." damn the man! root for the underdogs! etc... 
(yes, i know my saying that probably has something to do with my tribal-issue 
wetware. so? it makes sense to me. if it shouldnt, point out the whole</a> in my 
premises)

<p>
<a href="0982.html#0994qlink21">&gt;  Second, in a case like this, I would have to evaluate whether I wanted</a><br>
<i>&gt;  my ultimate goal to be survival.</i><br>

<p>
<a name="1006qlink4">    does not 'the state of having goals' depend upon personal survival?</a> if 
<a name="1006qlink5">so, are not all other goals secondary to personal survival?</a>

<p>
<i>&gt;  I don't really have to do that</i><br>
<a href="0982.html#0994qlink22">&gt;  evaluation now, because the Singularity is intuitively obvious as the</a><br>
<i>&gt;  thing to do next.  Which is good, because I don't really trust</i><br>
<i>&gt;  philosophy, even my own; I do, however, trust certain kinds of</i><br>
<i>&gt;  intuitions.  Nonetheless, if my choice of actions became dependent on</i><br>
<i>&gt;  philosophy, personal survival wouldn't be my first pick as priority goal.</i><br>

<p>
<a name="1006qlink6">    the singularity is not, to me, intuitively obvious as "the thing to do 
next." and, i do not trust any kind of intuition, if i can help it. why do 
you? yes, im asking for to justify your reliance on intuition (if thats what 
it is), and thats philosophy. if you will not explain, please explain why you 
will not explain.... heh.</a>

<p>
<a href="0982.html#0994qlink23">&gt;  &gt;     pardon my rehash of what seems obvious, but isnt suicide bad?</a><br>
<i>&gt;  </i><br>
<i>&gt;  Prove it.  I don't trust philosophy, but I trust the limbic system even </i><br>
less.

<p>
    that the limbic system agrees with me is completly beside the point. in 
order to have goals, i must exist. in order for goals to effectively *be*, i 
must exist. i think significance is an observer-dependant property; even a 
me-dependant property. quite literally, nothing matters if im not there to 
say "that matters." goals are a function of the-point-of-view-that-i-am, like 
perceptions. if you disagree, please tell me how and why. as best i can 
figure, you havnt really answered den otter. ive interpeted you as saying, in 
response to his questions, "ive been able to change my goal system to 
something that may seem irrational to you; deal with it." ...?
<p>
<a name="1006qlink7">    and are intuitions not a function of your tribalistic and vestigial 
wetware, as well as my instinct for survival?</a>
<p>
    and why are you not a functional solipsist? (or enlightend 
self-interisted person, if you want to use that term... but thats so clumsy).

<p>
    baaaaaah humbug. may you live in interisting times,

<p>
sayke, v2.3.05
<!-- body="end" -->
<p>
<ul>
<!-- next="start" -->
<li><a href="0995.html">[ Next ]</a><a href="0993.html">[ Previous ]</a>
<b>In reply to:</b> <a href="0982.html">Eliezer S. Yudkowsky</a>
<!-- nextthread="start" -->
</ul>
</body></html>
